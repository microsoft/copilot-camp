{"config":{"lang":["en","ja"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":"<p>Copilot Developer Camp is a self-paced learning resource, designed to help you build agents for Microsoft 365 Copilot. It provides practical guidance and real-world examples to support your development journey.</p>"},{"location":"#building-agents-for-microsoft-365","title":"Building Agents for Microsoft 365","text":"<p>Agents for Microsoft 365 are conversational AI-powered assistants designed to help users automate tasks, answer questions, and streamline workflows across Microsoft 365 apps and services. Agents can be used in various scenarios, such as customer support, IT helpdesk, HR support, and more.</p> <p></p> <p>An agent for Microsoft 365 is typically made up of these components\u2014foundational model,  an orchestrator, which is running that taps into that knowledge, skills, and autonomous processes that it has those capabilities to do, and it may or may not have a user interface. \u200b</p> <p>You can either extend Microsoft 365 Copilot by using the same infrastructure, orchestrator, foundation model, and security controls as Microsoft 365 Copilot, which ensures a consistent and familiar user experience.</p> <p>Or you can pick your own foundation model, orchestrator, and responsible AI controls.</p>"},{"location":"#where-should-i-start-to-build-agents","title":"\ud83e\uddea Where should I start to build agents?","text":"<p>There are three major pathways with several labs. If you want a no-code/low-code approach, choose the Maker path (\"MAB\", \"MSA\", or \"MCS\" lab). If you want to extend Microsoft 365 Copilot, choose the Extend path (\"E\" lab). If you want to build a completely custom agent using Microsoft Foundry or any AI of your choice, choose the Build path (\"BMA\" lab).</p> <p></p>        Make agents      <p>Make your agents with no-code or low-code with Copilot Studio or SharePoint Online. (\"MAB\", \"MSA\", and \"MCS\" lab)</p> Get Started        Extend M365 Copilot      <p>Build a Declarative agent where Microsoft 365 provides the AI model and orchestration. (\"E\" lab)</p> Get Started        Build your own agent      <p>Build a custom engine agent with custom AI model and orchestration using Azure OpenAI. (\"BMA\" lab)</p> Get Started Overview of Copilot Dev Camp"},{"location":"#whats-new","title":"\ud83c\udd95 What's New?","text":"<p>Updated in Jan 2026</p> <p>We\u2019re excited to introduce three new hands-on labs designed to help you build powerful Copilot experiences. </p> <ul> <li> <p>Connect Declarative agent to MCP Server: Run a complete Model Context Protocol (MCP) server for Zava Insurance's claims system and integrate it with Declarative Agent in Microsoft 365 Copilot. \ud83d\udd17 Start this lab</p> </li> <li> <p>Connected Agents using Copilot Studio: Understand how to create agents in Microsoft Copilot Studio that can communicate with other agents. \ud83d\udd17 Start this lab</p> </li> <li> <p>Build with Microsoft 365 Agents SDK: Leverage the full capabilities of the Microsoft 365 Agents SDK to create production-ready Copilot agents that integrate with real business data. \ud83d\udd17 Start this lab</p> </li> </ul>"},{"location":"#more","title":"\ud83e\uddd1\u200d\ud83d\udcbb More","text":"Learn more      <p>Learn more from various resources</p> <ul> <li>Microsoft Learn</li> <li>Video tutorials</li> </ul>        Connect with us      <p>Join the conversation on GitHub Discussion!</p>"},{"location":"#copilot-camp-in-a-box","title":"\ud83c\udf81 Copilot Camp in a Box","text":"<p>Got the labs working? Ready to share your knowledge? Why not run your own Copilot Camp workshop using our\u00a0Copilot Camp in a Box\u00a0resources! We've got you covered with presentation materials that even include embedded demos.</p>"},{"location":"#issues","title":"\ud83d\ude91 Issues","text":"<p>We really appreciate your feedback! Please use the issues list to share your comments and issues, or if you're in Microsoft let us know in the \"Copilot Developer Camp Early Testers\" chat in Microsoft Teams. Thanks!</p>"},{"location":"#code-of-conduct","title":"\ud83d\udcdc Code of Conduct","text":"<p>This project has adopted the Microsoft Open Source Code of Conduct.</p> <p>Resources:</p> <ul> <li>Microsoft Open Source Code of Conduct</li> <li>Microsoft Code of Conduct FAQ</li> <li>Contact opencode@microsoft.com with questions or concerns</li> </ul> <p></p> <p>\u2b50\ufe0f Star our repo</p>"},{"location":"awards/","title":"Awards","text":""},{"location":"awards/#copilot-developer-camp-awards","title":"Copilot Developer Camp Awards","text":"<p>We are excited to announce a thrilling initiative that will challenge you to showcase your knowledge and skills in Microsoft 365 Copilot extensibility. This is your chance to dive deep into the world of Copilot, explore its capabilities, and demonstrate your expertise.</p>"},{"location":"awards/#why-participate","title":"Why participate?","text":"<ul> <li>Learn and Grow: This initiative is a fantastic opportunity to expand your understanding of Microsoft 365 Copilot extensibility.</li> <li>Earn Badges: Show off your achievements with exclusive badges awarded based on your performance.</li> <li>Community Recognition: Stand out in the community and get recognized for your contributions and knowledge.</li> </ul>"},{"location":"awards/#how-to-participate","title":"How to participate?","text":"<ul> <li>Register: Sign up for the Microsoft 365 &amp; Power Platform Community Recognition Program through this form. If you already claimed badges through the Microsoft 365 &amp; Power Platform Community Recognition Program, you don't need to sign up again.</li> <li>Complete a Copilot Developer Camp pathway: Complete all the labs of any of the learning pathways (Maker Path, Extend, and Build) of Copilot Developer Camp to claim a blue-belt badge!</li> </ul> <ul> <li>Complete all the pathways: Complete all the labs of all of the learning pathways of Copilot Developer Camp to get a black-belt badge and to become a Path Master!</li> </ul> <ul> <li>Submit a community sample: Once you have earned the black-belt badge, submit one or more Microsoft 365 Copilot extensibility samples to the Sample Solution Gallery and prove to yourself and to the whole community what you have learned! You will get a red-belt badge and become a Sample Sensei!</li> </ul>"},{"location":"awards/#timeline-and-limits","title":"Timeline and Limits","text":"<ul> <li>Initiative Starts: March 25, 2025</li> <li>Initiative Ends: May 31, 2025</li> <li>Limits: only the first 200 community members will earn badges</li> </ul> <p>Every single week, during Microsoft 365 &amp; Power Platform Community calls, we will announce community members awarded with one or more badges. Challenge yourself and be among the first 200 community members to earn badges and seize this unique opportunity!</p> <p>Don't miss out on this exciting opportunity to earn recognition in the community. Whether you're a seasoned expert or just starting out, this initiative is designed for everyone. So, gear up, get ready, and let's see how much you know about Microsoft 365 Copilot extensibility!</p> <p>Happy learning and good luck!</p> <p></p>"},{"location":"mslearn/","title":"Microsoft Learn \ud83d\udcd6","text":""},{"location":"mslearn/#copilot-extensibility-official-documentation","title":"Copilot Extensibility official documentation","text":"<p>Discover Microsoft Learn content to extend Copilot all in one place with the Official Collection: Microsoft 365 Copilot extensibility available at the link https://aka.ms/extend-microsoft365-copilot</p>"},{"location":"mslearn/#mcp-server","title":"MCP Server","text":"<p>If you use coding agents like GitHub Copilot and enhance the experience with Microsoft Learn content, connect the MCP server with your client!</p> <p>Set up with the endpoint manually, <code>https://learn.microsoft.com/api/mcp</code>, or go to MCP Servers for agent mode and simply click Microsoft Docs button on to install it on Visual Studio Code!</p> <p></p>"},{"location":"register/","title":"Registration","text":""},{"location":"resources/","title":"Resources","text":""},{"location":"resources/#videos-and-resources","title":"Videos and Resources","text":"Watch Microsoft 365 Copilot: Developer Camp On-demand! \ud83c\udf89 <p> Let's Start with a Game! Developer's Guide to Building Copilot Agents Introducing Declarative Agents The Future of Declarative Agents Extending Declarative Agents A Conversation with the Leaders Behind the Developer Tools Introducing Custom Engine Agents Unlock the Power of Custom Engine Agents </p> Learn about Microsoft 365 Copilot 'Wave 2' <p> Microsoft 365 Copilot Wave 2 announcement with Satya Nadella and Jared Spataro </p> Video briefing: Building Agents for Microsoft 365 Copilot <p> Understanding the Copilot Dev Camp pathways Building Copilot agents with code (Overview) Introducing Custom engine agents Introducing Declarative agents Building API Plugins for Declarative agents </p> <p>Declarative Agent Auth</p> <p>If you already know how to build a declarative agent with an API plugin and want to learn how to secure your API, you can skip directly to the authentication labs; details are here</p> <p>New schema</p> <p>If you began the \"Extend\" labs prior to October 27, 2024, you are probably still using the developer preview schema and should upgrade to the v1.19 schema at this time. Detailed instructions are here. The solution files were updated on October 27, so if you started with those you can disregard this notice.</p>"},{"location":"resources/#more-videos","title":"More videos \ud83d\udcfa","text":"<p>Here are some relevant videos from the Microsoft 365 Developer Channel. Please subscribe to keep up with all our latest videos on Microsoft 365 development!</p> Learn AI concepts with Doodle to Code! <p> What is Generative AI? What is Retrieval Augmented Generation (RAG)? Create an AI Powered Chatbot in Microsoft Teams with Teams AI Library Bring your AI App to Microsoft Teams from Microsoft Foundry </p> Microsoft Mechanics <p> Microsoft 365 Copilot - New agent and extensibility options for developers AI apps - Control Safety, Privacy &amp; Security - with Mark Russinovich How Microsoft 365 Copilot works Microsoft 365 Copilot Wave Two updates - Pages, Excel, OneDrive, and agents </p> Microsoft 365 Developer Essentials <p> Adaptive cards are everywhere Where is the Microsoft 365 API? </p> More on building Custom engine agents <p> Chat over your data with Azure OpenAI and Teams AI Library </p>"},{"location":"resources/#join-the-conversation","title":"Join the Conversation! \ud83d\udcac","text":"Welcome to the Copilot Developer Camp Discussions! \ud83e\udd17 <p>Introduce yourself and tell us about your experience with Copilot Developer Camp \ud83c\udfd5\ufe0f.</p> \ud83c\udf89 New Feature X: Ideas and Feedback <p>We\u2019re exploring some cool updates! Share your thoughts on Feature X and let\u2019s brainstorm together!</p> \ud83d\ude80 Troubleshooting Guide: Share Your Tips <p>Got any tips for solving common setup issues? Drop your wisdom and help the community thrive!</p> \u2728 Explore More Discussions"},{"location":"resources/#microsoft-learn","title":"Microsoft Learn \ud83d\udcd6","text":"<p>Discover Microsoft Learn content here.</p>"},{"location":"resources/#issues","title":"Issues","text":"<p>We really appreciate your feedback! Please use the issues list to share your comments and issues, or if you're in Microsoft let us know in the \"Copilot Developer Camp Early Testers\" chat in Microsoft Teams. Thanks!</p>"},{"location":"resources/#code-of-conduct","title":"Code of Conduct","text":"<p>This project has adopted the Microsoft Open Source Code of Conduct.</p> <p>Resources:</p> <ul> <li>Microsoft Open Source Code of Conduct</li> <li>Microsoft Code of Conduct FAQ</li> <li>Contact opencode@microsoft.com with questions or concerns</li> </ul> <p></p>"},{"location":"demo-assets/","title":"Index","text":"<p>The following sample images are hosted in the github pages for use by code samples such as the Trey Research API Plugin. Portraits were generated using Microsoft Copilot.</p>"},{"location":"demo-assets/#consultant-pictures","title":"Consultant pictures","text":"<p> Avery Howard</p> <p> Dominique Dutertre</p> <p> Robin Zupanc</p> <p> Sanjay Puranik</p> <p> Lois Wyn</p> <p> The Unknown Consultant</p> <p> Spare 1</p> <p> Spare 2</p> <p> Spare 3</p>"},{"location":"demo-assets/#maps","title":"Maps","text":"<p> Adatum Corporation</p> <p> Alpine Ski House</p> <p> Bellows College</p> <p> Consolidated Messenger</p> <p> Contoso Pharmaceuticals</p> <p> Humongous Insurance</p> <p> Lamna Healthcare Company</p> <p> Relecloud</p> <p> Southridge Video</p> <p> Woodgrove Bank</p>"},{"location":"includes/all-labs-toc/","title":"All labs toc","text":"<p>Do these labs if you want to build a Declarative agent where Microsoft 365 provides the AI model and             orchestration</p> <ul> <li>\ud83c\udfc1 Welcome</li> <li>\ud83d\udd27 Set up <ul> <li>Lab E0 - Setup</li> </ul> </li> <li>\ud83e\uddf0 Declarative agent fundamentals <ul> <li> Lab E1 - Build a  Declarative Agent using TypeSpec </li> <li> Lab E1a - Geo locator game</li> </ul> </li> <li>\ud83d\udee0\ufe0f Build and integrate API from scratch <ul> <li>Lab E2 - Build an API</li> <li> Lab E3 - Add Declarative Agent + API</li> <li> Lab E4 - Enhance API + Plugin</li> <li>Lab E5 - Add Adaptive Cards</li> <li> Lab E6a - Add Authentication</li> </ul> </li> <li>\ud83d\udd0c Integration <ul> <li> Lab E7 - Add Copilot Connector</li> </ul> <ul> <li> Lab E8 - Connect Declarative agent to MCP Server</li> </ul> <ul> <li> Lab E9 - Connected Agents</li> </ul> </li> </ul> <p>Do these labs if you want to build a Custom engine agent with custom AI model and orchestration using Azure OpenAI and Teams AI library</p> <ul> <li>BTA0 - Setup</li> <li>BTA1 - First custom engine agent</li> <li>BTA2 - Index your data in Azure AI Search</li> <li>BTA3 - Enhance the user experience</li> <li>BTA4 - Add single sign on authentication</li> <li>BTA5 - Add actions to handle complex tasks</li> </ul> <p>Do these labs if you want to build a Declarative agent with Copilot Studio Lite</p> <ul> <li>MAB1 - Build your first agent</li> </ul> <p>Do these labs if you want to build agents with Microsoft Copilot Studio</p> <ul> <li>MCS0 - Setup</li> <li>MCS1 - First agent</li> <li>MCS2 - Defining Topics</li> <li>MCS3 - Defining Tools</li> <li>MCS4 - Extending Microsoft 365 Copilot</li> <li>MCS5 - Consuming a custom connector</li> <li>MCS6 - Consuming an MCP server</li> <li>MCS7 - Creating Autonomous Agents</li> <li>MCS8 - Integrating Azure AI Search for RAG</li> <li>MCS9 - Connected Agents (Preview)</li> </ul>"},{"location":"includes/b-congratulations/","title":"B congratulations","text":"<p>CONGRATULATIONS!</p>"},{"location":"includes/b-labs-branches/","title":"B labs branches","text":"Start with Microsoft Foundry              <ul> <li>Start in Microsoft Foundry to define instructions, tools, and personality</li> <li>Integrate Semantic Kernel for multi-step reasoning and external tool usage</li> <li>Configure intent handling, planner integration, and system messages</li> <li>Deploy across Microsoft Teams, Microsoft 365 Copilot, and external channels</li> </ul> Start here  Start with Agent Framework              <ul> <li>Build an insurance claims agent from scratch with Agent Framework</li> <li>Progressive labs: Azure AI Search, vision models, SharePoint, Microsoft Graph</li> <li>Master LLM interactions, tool calling, and intelligent decision-making</li> <li>Add authentication, Copilot Retrieval API, and MCP server integration</li> </ul> Start here"},{"location":"includes/b-labs-prelude/","title":"B labs prelude","text":"<p>Do these labs if you want to build a Custom engine agent with custom AI model and orchestration using Azure OpenAI and Teams AI library</p> <ul> <li>BTA0 - Setup</li> <li>BTA1 - First custom engine agent</li> <li>BTA2 - Index your data in Azure AI Search</li> <li>BTA3 - Enhance the user experience</li> <li>BTA4 - Add single sign on authentication</li> <li>BTA5 - Add actions to handle complex tasks</li> </ul>"},{"location":"includes/b-labs-toc/","title":"B labs toc","text":"<p>Do these labs if you want to build a Custom engine agent with custom AI model and orchestration using Azure OpenAI and Teams AI library</p> <ul> <li>BTA0 - Setup</li> <li>BTA1 - First custom engine agent</li> <li>BTA2 - Index your data in Azure AI Search</li> <li>BTA3 - Enhance the user experience</li> <li>BTA4 - Add single sign on authentication</li> <li>BTA5 - Add actions to handle complex tasks</li> </ul>"},{"location":"includes/discussions/","title":"Discussions","text":"Welcome to the Copilot Developer Camp Discussions! \ud83e\udd17 <p>Introduce yourself and tell us about your experience with Copilot Developer Camp \ud83c\udfd5\ufe0f.</p> \ud83c\udf89 New Feature X: Ideas and Feedback <p>We\u2019re exploring some cool updates! Share your thoughts on Feature X and let\u2019s brainstorm together!</p> \ud83d\ude80 Troubleshooting Guide: Share Your Tips <p>Got any tips for solving common setup issues? Drop your wisdom and help the community thrive!</p> \u2728 Explore More Discussions"},{"location":"includes/e-congratulations/","title":"E congratulations","text":"<p>CONGRATULATIONS!</p>"},{"location":"includes/e-labs-prelude/","title":"E labs prelude","text":"<p>Do these labs if you want to build a Declarative agent where Microsoft 365 provides the AI model and             orchestration</p> <ul> <li>\ud83c\udfc1 Welcome</li> <li>\ud83d\udd27 Set up <ul> <li>Lab E0 - Setup</li> </ul> </li> <li>\ud83e\uddf0 Declarative agent fundamentals <ul> <li> Lab E1 - Build a  Declarative Agent using TypeSpec </li> <li> Lab E1a - Geo locator game</li> </ul> </li> <li>\ud83d\udee0\ufe0f Build and integrate API from scratch <ul> <li>Lab E2 - Build an API</li> <li> Lab E3 - Add Declarative Agent + API</li> <li> Lab E4 - Enhance API + Plugin</li> <li>Lab E5 - Add Adaptive Cards</li> <li> Lab E6a - Add Authentication</li> </ul> </li> <li>\ud83d\udd0c Integration <ul> <li> Lab E7 - Add Copilot Connector</li> </ul> <ul> <li> Lab E8 - Connect Declarative agent to MCP Server</li> </ul> <ul> <li> Lab E9 - Connected Agents</li> </ul> </li> </ul>"},{"location":"includes/e-labs-toc/","title":"E labs toc","text":"<p>Do these labs if you want to build a Declarative agent where Microsoft 365 provides the AI model and             orchestration</p> <ul> <li>\ud83c\udfc1 Welcome</li> <li>\ud83d\udd27 Set up <ul> <li>Lab E0 - Setup</li> </ul> </li> <li>\ud83e\uddf0 Declarative agent fundamentals <ul> <li> Lab E1 - Build a  Declarative Agent using TypeSpec </li> <li> Lab E1a - Geo locator game</li> </ul> </li> <li>\ud83d\udee0\ufe0f Build and integrate API from scratch <ul> <li>Lab E2 - Build an API</li> <li> Lab E3 - Add Declarative Agent + API</li> <li> Lab E4 - Enhance API + Plugin</li> <li>Lab E5 - Add Adaptive Cards</li> <li> Lab E6a - Add Authentication</li> </ul> </li> <li>\ud83d\udd0c Integration <ul> <li> Lab E7 - Add Copilot Connector</li> </ul> <ul> <li> Lab E8 - Connect Declarative agent to MCP Server</li> </ul> <ul> <li> Lab E9 - Connected Agents</li> </ul> </li> </ul>"},{"location":"includes/m-labs-branches/","title":"M labs branches","text":"Copilot Studio Lite      <ul> <li>Easy, simple, and interactive experience</li> <li>Web based, integrated with Microsoft 365 Copilot Chat and Microsoft 365 Copilot</li> <li>Content from SharePoint Online, public web, and Microsoft Copilot Connectors</li> <li>Available in Microsoft 365 Copilot Chat</li> <ul> Start here  Copilot Studio Full              <ul> <li>Maximum level of flexibility</li> <li>Almost any data source or knowledge base</li> <li>Support for various publishing channels</li> <li>Support for actions</li> <li>Support for Power Platform connectors, Dataverse, REST API, and more</li> <li>Per user + per tenant license or Pay-As-You-Go</li> <ul> Start here  SharePoint Agent              <ul> <li>Integrated with SharePoint Online user experience</li> <li>SharePoint Online content only</li> <li>Supported in Microsoft Teams chat</li> <li>Microsoft 365 Copilot license or Microsoft Copilot Studio capacity or Pay-As-You-Go</li> <ul> Start here"},{"location":"includes/m-path-links/","title":"M path links","text":"<ul> <li>Lab M0 - Prerequisites READY FOR TESTING</li> <li>Lab M1 - Get to know Northwind message extension READY FOR TESTING</li> <li>Lab M2 - Run app in Microsoft 365 Copilot READY FOR TESTINGSOON</li> <li>Lab M3 - Enhance plugin with new search command READY FOR TESTING</li> <li>Lab M4 - Add authentication READY FOR TESTING</li> <li>Lab M5 - Enhance plugin with an action command COMING SOON</li> </ul>"},{"location":"includes/mab-congratulations/","title":"Mab congratulations","text":"<p>CONGRATULATIONS!</p>"},{"location":"includes/mab-labs-prelude/","title":"Mab labs prelude","text":"<p>Do these labs if you want to build a Declarative agent with Copilot Studio Lite</p> <ul> <li>MAB1 - Build your first agent</li> </ul> Table of Contents"},{"location":"includes/mab-labs-toc/","title":"Mab labs toc","text":"<p>Do these labs if you want to build a Declarative agent with Copilot Studio Lite</p> <ul> <li>MAB1 - Build your first agent</li> </ul>"},{"location":"includes/main-links/","title":"Main links","text":"Make agents      <p>Make your agents with no-code or low-code with Copilot Studio or SharePoint Online. (\"MAB\", \"MSA\", and \"MCS\" lab)</p> Get Started        Extend M365 Copilot      <p>Build a Declarative agent where Microsoft 365 provides the AI model and orchestration. (\"E\" lab)</p> Get Started        Build your own agent      <p>Build a custom engine agent with custom AI model and orchestration using Azure OpenAI. (\"BMA\" lab)</p> Get Started"},{"location":"includes/mcs-congratulations/","title":"Mcs congratulations","text":"<p>CONGRATULATIONS!</p>"},{"location":"includes/mcs-labs-prelude/","title":"Mcs labs prelude","text":"<p>Do these labs if you want to build agents with Microsoft Copilot Studio</p> <ul> <li>MCS0 - Setup</li> <li>MCS1 - First agent</li> <li>MCS2 - Defining Topics</li> <li>MCS3 - Defining Tools</li> <li>MCS4 - Extending Microsoft 365 Copilot</li> <li>MCS5 - Consuming a custom connector</li> <li>MCS6 - Consuming an MCP server</li> <li>MCS7 - Creating Autonomous Agents</li> <li>MCS8 - Integrating Azure AI Search for RAG</li> <li>MCS9 - Connected Agents (Preview)</li> </ul>"},{"location":"includes/mcs-labs-toc/","title":"Mcs labs toc","text":"<p>Do these labs if you want to build agents with Microsoft Copilot Studio</p> <ul> <li>MCS0 - Setup</li> <li>MCS1 - First agent</li> <li>MCS2 - Defining Topics</li> <li>MCS3 - Defining Tools</li> <li>MCS4 - Extending Microsoft 365 Copilot</li> <li>MCS5 - Consuming a custom connector</li> <li>MCS6 - Consuming an MCP server</li> <li>MCS7 - Creating Autonomous Agents</li> <li>MCS8 - Integrating Azure AI Search for RAG</li> <li>MCS9 - Connected Agents (Preview)</li> </ul>"},{"location":"includes/more-links/","title":"More links","text":"Learn more      <p>Learn more from various resources</p> <ul> <li>Microsoft Learn</li> <li>Video tutorials</li> </ul>        Connect with us      <p>Join the conversation on GitHub Discussion!</p>"},{"location":"includes/msa-congratulations/","title":"Msa congratulations","text":"<p>CONGRATULATIONS!</p>"},{"location":"includes/msa-labs-prelude/","title":"Msa labs prelude","text":"<p>Do these labs if you want to build a SharePoint agent</p> <ul> <li>MSA1 - Build your first SharePoint agent</li> <li>MSA2 - Sharing SharePoint agents</li> </ul> Table of Contents"},{"location":"includes/msa-labs-toc/","title":"Msa labs toc","text":"<p>Do these labs if you want to build a SharePoint agent</p> <ul> <li>MSA1 - Build your first SharePoint agent</li> <li>MSA2 - Sharing SharePoint agents</li> </ul>"},{"location":"includes/starrepo/","title":"Starrepo","text":"<p>\u2b50\ufe0f Star our repo</p>"},{"location":"includes/ja/all-labs-toc/","title":"All labs toc","text":"<p>Microsoft 365 \u304c AI \u30e2\u30c7\u30eb\u3068\u30aa\u30fc\u30b1\u30b9\u30c8\u30ec\u30fc\u30b7\u30e7\u30f3\u3092\u63d0\u4f9b\u3059\u308b\u5ba3\u8a00\u578b\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3092\u69cb\u7bc9\u3057\u305f\u3044\u5834\u5408\u306f\u3001\u3053\u308c\u3089\u306e\u30e9\u30dc\u3092\u5b9f\u65bd\u3057\u3066\u304f\u3060\u3055\u3044\u3002</p> <ul> <li>\ud83c\udfc1 \u306f\u3058\u3081\u306b</li> <li>\ud83d\udd27 \u30bb\u30c3\u30c8\u30a2\u30c3\u30d7 <ul> <li>\u30e9\u30dc E0 - \u30bb\u30c3\u30c8\u30a2\u30c3\u30d7</li> </ul> </li> <li>\ud83e\uddf0 \u5ba3\u8a00\u578b\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u306e\u57fa\u790e <ul> <li>\u30e9\u30dc E1 - \u8a73\u7d30\u306a\u5ba3\u8a00\u578b\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3092\u69cb\u7bc9\u3059\u308b </li> <li>\u30e9\u30dc E1a - Geo \u30ed\u30b1\u30fc\u30bf\u30fc\u30b2\u30fc\u30e0</li> </ul> </li> <li>\ud83d\udee0\ufe0f API \u3092\u30bc\u30ed\u304b\u3089\u69cb\u7bc9\u3057\u3066\u7d71\u5408\u3059\u308b <ul> <li>\u30e9\u30dc E2 - API \u3092\u69cb\u7bc9\u3059\u308b</li> <li>\u30e9\u30dc E3 - \u5ba3\u8a00\u578b\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8 + API \u3092\u8ffd\u52a0\u3059\u308b</li> <li>\u30e9\u30dc E4 - API + \u30d7\u30e9\u30b0\u30a4\u30f3\u3092\u5f37\u5316\u3059\u308b</li> <li>\u30e9\u30dc E5 - Adaptive Card \u3092\u8ffd\u52a0\u3059\u308b</li> </ul> </li> <li>\ud83d\udd10 \u8a8d\u8a3c <ul> <li>\u30e9\u30dc E6a - Toolkit</li> <li>\u30e9\u30dc E6b - \u624b\u52d5</li> <li>\u30e9\u30dc E6c - SSO</li> </ul> </li> <li>\ud83d\udd0c \u7d71\u5408 <ul> <li>\u30e9\u30dc EB - Graph Connector \u3092\u8ffd\u52a0\u3059\u308b</li> </ul> </li> </ul> <p>Azure OpenAI \u3068 Teams AI library \u3092\u4f7f\u7528\u3057\u3066\u30ab\u30b9\u30bf\u30e0 AI \u30e2\u30c7\u30eb\u3068\u30aa\u30fc\u30b1\u30b9\u30c8\u30ec\u30fc\u30b7\u30e7\u30f3\u3092\u5099\u3048\u305f Custom \u30a8\u30f3\u30b8\u30f3 \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3092\u69cb\u7bc9\u3057\u305f\u3044\u5834\u5408\u306f\u3001\u3053\u308c\u3089\u306e \u30e9\u30dc \u3092\u5b9f\u65bd\u3057\u3066\u304f\u3060\u3055\u3044</p> <ul> <li>BTA0 - \u30bb\u30c3\u30c8\u30a2\u30c3\u30d7</li> <li>BTA1 - \u306f\u3058\u3081\u3066\u306e Custom \u30a8\u30f3\u30b8\u30f3 \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8</li> <li>BTA2 - \u30c7\u30fc\u30bf\u3092 Azure AI Search \u3067\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u5316\u3059\u308b</li> <li>BTA3 - \u30e6\u30fc\u30b6\u30fc \u30a8\u30af\u30b9\u30da\u30ea\u30a8\u30f3\u30b9\u3092\u5f37\u5316\u3059\u308b</li> <li>BTA4 - \u30b7\u30f3\u30b0\u30eb \u30b5\u30a4\u30f3\u30aa\u30f3\u8a8d\u8a3c\u3092\u8ffd\u52a0\u3059\u308b</li> <li>BTA5 - \u8907\u96d1\u306a\u30bf\u30b9\u30af\u3092\u51e6\u7406\u3059\u308b\u30a2\u30af\u30b7\u30e7\u30f3\u3092\u8ffd\u52a0\u3059\u308b</li> </ul> <p>Copilot Studio Lite \u3067 \u5ba3\u8a00\u578b \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8 \u3092\u69cb\u7bc9\u3057\u305f\u3044\u5834\u5408\u306f\u3001\u4ee5\u4e0b\u306e \u30e9\u30dc \u3092\u5b9f\u65bd\u3057\u3066\u304f\u3060\u3055\u3044</p> <ul> <li>MAB1 - \u306f\u3058\u3081\u3066\u306e \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8 \u3092\u69cb\u7bc9\u3059\u308b</li> </ul> <p>Microsoft Copilot Studio \u3067 \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8 \u3092\u69cb\u7bc9\u3057\u305f\u3044\u5834\u5408\u306f\u3001\u6b21\u306e \u30e9\u30dc \u3092\u5b9f\u65bd\u3057\u3066\u304f\u3060\u3055\u3044</p> <ul> <li>MCS0 - \u30bb\u30c3\u30c8\u30a2\u30c3\u30d7</li> <li>MCS1 - \u6700\u521d\u306e \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8</li> <li>MCS2 - \u30c8\u30d4\u30c3\u30af\u306e\u5b9a\u7fa9</li> <li>MCS3 - \u30c4\u30fc\u30eb\u306e\u5b9a\u7fa9</li> <li>MCS4 - Microsoft 365 Copilot \u306e\u62e1\u5f35</li> <li>MCS5 - \u30ab\u30b9\u30bf\u30e0 \u30b3\u30cd\u30af\u30bf\u306e\u4f7f\u7528</li> <li>MCS6 - MCP \u30b5\u30fc\u30d0\u30fc\u306e\u4f7f\u7528</li> <li>MCS7 - \u81ea\u5f8b\u578b \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8 \u306e\u4f5c\u6210</li> <li>MCS8 - RAG \u306e\u305f\u3081\u306e Azure AI Search \u306e\u7d71\u5408</li> <li>MCS9 - \u63a5\u7d9a\u3055\u308c\u305f \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8 (\u30d7\u30ec\u30d3\u30e5\u30fc)</li> </ul>"},{"location":"includes/ja/b-congratulations/","title":"B congratulations","text":"<p>\u304a\u3081\u3067\u3068\u3046\u3054\u3056\u3044\u307e\u3059\uff01</p>"},{"location":"includes/ja/b-labs-branches/","title":"B labs branches","text":"Microsoft 365 \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8 SDK \u3092\u4f7f\u3063\u305f\u958b\u767a              <ul> <li>Visual Studio 2022 \u3068 Microsoft 365 \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8 Toolkit \u3092\u4f7f\u7528\u3057\u305f C# \u30d9\u30fc\u30b9\u306e\u6f14\u7fd2</li> <li>Semantic Kernel \u3068\u751f\u6210 AI \u30e2\u30c7\u30eb\u306b\u3088\u308b\u30ab\u30b9\u30bf\u30e0\u30aa\u30fc\u30b1\u30b9\u30c8\u30ec\u30fc\u30b7\u30e7\u30f3\u3092\u7d71\u5408</li> <li>Microsoft Teams \u3068 Microsoft 365 Copilot Chat \u306b\u5bfe\u5fdc</li> <li>Web \u3092\u542b\u3080\u5916\u90e8\u30c1\u30e3\u30cd\u30eb\u304a\u3088\u3073\u305d\u306e\u4ed6\u306e\u30a8\u30f3\u30c9\u30dd\u30a4\u30f3\u30c8\u3092\u30b5\u30dd\u30fc\u30c8</li> </ul> \u3053\u3053\u304b\u3089\u958b\u59cb"},{"location":"includes/ja/b-labs-prelude/","title":"B labs prelude","text":"<p>Azure OpenAI \u3068 Teams AI library \u3092\u4f7f\u7528\u3057\u3066\u30ab\u30b9\u30bf\u30e0 AI \u30e2\u30c7\u30eb\u3068\u30aa\u30fc\u30b1\u30b9\u30c8\u30ec\u30fc\u30b7\u30e7\u30f3\u3092\u5099\u3048\u305f Custom \u30a8\u30f3\u30b8\u30f3 \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3092\u69cb\u7bc9\u3057\u305f\u3044\u5834\u5408\u306f\u3001\u3053\u308c\u3089\u306e \u30e9\u30dc \u3092\u5b9f\u65bd\u3057\u3066\u304f\u3060\u3055\u3044</p> <ul> <li>BTA0 - \u30bb\u30c3\u30c8\u30a2\u30c3\u30d7</li> <li>BTA1 - \u306f\u3058\u3081\u3066\u306e Custom \u30a8\u30f3\u30b8\u30f3 \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8</li> <li>BTA2 - \u30c7\u30fc\u30bf\u3092 Azure AI Search \u3067\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u5316\u3059\u308b</li> <li>BTA3 - \u30e6\u30fc\u30b6\u30fc \u30a8\u30af\u30b9\u30da\u30ea\u30a8\u30f3\u30b9\u3092\u5f37\u5316\u3059\u308b</li> <li>BTA4 - \u30b7\u30f3\u30b0\u30eb \u30b5\u30a4\u30f3\u30aa\u30f3\u8a8d\u8a3c\u3092\u8ffd\u52a0\u3059\u308b</li> <li>BTA5 - \u8907\u96d1\u306a\u30bf\u30b9\u30af\u3092\u51e6\u7406\u3059\u308b\u30a2\u30af\u30b7\u30e7\u30f3\u3092\u8ffd\u52a0\u3059\u308b</li> </ul>"},{"location":"includes/ja/b-labs-toc/","title":"B labs toc","text":"<p>Azure OpenAI \u3068 Teams AI library \u3092\u4f7f\u7528\u3057\u3066\u30ab\u30b9\u30bf\u30e0 AI \u30e2\u30c7\u30eb\u3068\u30aa\u30fc\u30b1\u30b9\u30c8\u30ec\u30fc\u30b7\u30e7\u30f3\u3092\u5099\u3048\u305f Custom \u30a8\u30f3\u30b8\u30f3 \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3092\u69cb\u7bc9\u3057\u305f\u3044\u5834\u5408\u306f\u3001\u3053\u308c\u3089\u306e \u30e9\u30dc \u3092\u5b9f\u65bd\u3057\u3066\u304f\u3060\u3055\u3044</p> <ul> <li>BTA0 - \u30bb\u30c3\u30c8\u30a2\u30c3\u30d7</li> <li>BTA1 - \u306f\u3058\u3081\u3066\u306e Custom \u30a8\u30f3\u30b8\u30f3 \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8</li> <li>BTA2 - \u30c7\u30fc\u30bf\u3092 Azure AI Search \u3067\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u5316\u3059\u308b</li> <li>BTA3 - \u30e6\u30fc\u30b6\u30fc \u30a8\u30af\u30b9\u30da\u30ea\u30a8\u30f3\u30b9\u3092\u5f37\u5316\u3059\u308b</li> <li>BTA4 - \u30b7\u30f3\u30b0\u30eb \u30b5\u30a4\u30f3\u30aa\u30f3\u8a8d\u8a3c\u3092\u8ffd\u52a0\u3059\u308b</li> <li>BTA5 - \u8907\u96d1\u306a\u30bf\u30b9\u30af\u3092\u51e6\u7406\u3059\u308b\u30a2\u30af\u30b7\u30e7\u30f3\u3092\u8ffd\u52a0\u3059\u308b</li> </ul>"},{"location":"includes/ja/discussions/","title":"Discussions","text":"Copilot Developer Camp \u306e\u30c7\u30a3\u30b9\u30ab\u30c3\u30b7\u30e7\u30f3\u3078\u3088\u3046\u3053\u305d\uff01 \ud83e\udd17 <p>\u81ea\u5df1\u7d39\u4ecb\u3092\u3057\u3066\u3001Copilot Developer Camp \u3067\u306e\u3054\u7d4c\u9a13\u3092\u304a\u805e\u304b\u305b\u304f\u3060\u3055\u3044 \ud83c\udfd5\ufe0f\u3002</p> \ud83c\udf89 \u65b0\u6a5f\u80fd Feature X\uff1a\u30a2\u30a4\u30c7\u30a2\u3068\u30d5\u30a3\u30fc\u30c9\u30d0\u30c3\u30af <p>\u3044\u304f\u3064\u304b\u306e\u30af\u30fc\u30eb\u306a\u30a2\u30c3\u30d7\u30c7\u30fc\u30c8\u3092\u691c\u8a0e\u4e2d\u3067\u3059\uff01 Feature X \u306b\u3064\u3044\u3066\u306e\u3054\u610f\u898b\u3092\u5171\u6709\u3057\u3001\u4e00\u7dd2\u306b\u30d6\u30ec\u30a4\u30f3\u30b9\u30c8\u30fc\u30df\u30f3\u30b0\u3057\u307e\u3057\u3087\u3046\uff01</p> \ud83d\ude80 \u30c8\u30e9\u30d6\u30eb\u30b7\u30e5\u30fc\u30c6\u30a3\u30f3\u30b0\u30ac\u30a4\u30c9\uff1a\u30d2\u30f3\u30c8\u3092\u5171\u6709\u3057\u307e\u3057\u3087\u3046 <p>\u3088\u304f\u3042\u308b\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7\u306e\u554f\u984c\u3092\u89e3\u6c7a\u3059\u308b\u30b3\u30c4\u306f\u3042\u308a\u307e\u3059\u304b\uff1f \u3042\u306a\u305f\u306e\u77e5\u8b58\u3092\u5171\u6709\u3057\u3066\u3001\u30b3\u30df\u30e5\u30cb\u30c6\u30a3\u3092\u76db\u308a\u4e0a\u3052\u307e\u3057\u3087\u3046\uff01</p> \u2728 \u3055\u3089\u306b\u30c7\u30a3\u30b9\u30ab\u30c3\u30b7\u30e7\u30f3\u3092\u898b\u308b"},{"location":"includes/ja/e-congratulations/","title":"E congratulations","text":"<p>\u304a\u3081\u3067\u3068\u3046\u3054\u3056\u3044\u307e\u3059\uff01</p>"},{"location":"includes/ja/e-labs-prelude/","title":"E labs prelude","text":"<p>Microsoft 365 \u304c AI \u30e2\u30c7\u30eb\u3068\u30aa\u30fc\u30b1\u30b9\u30c8\u30ec\u30fc\u30b7\u30e7\u30f3\u3092\u63d0\u4f9b\u3059\u308b\u5ba3\u8a00\u578b\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3092\u69cb\u7bc9\u3057\u305f\u3044\u5834\u5408\u306f\u3001\u3053\u308c\u3089\u306e\u30e9\u30dc\u3092\u5b9f\u65bd\u3057\u3066\u304f\u3060\u3055\u3044\u3002</p> <ul> <li>\ud83c\udfc1 \u306f\u3058\u3081\u306b</li> <li>\ud83d\udd27 \u30bb\u30c3\u30c8\u30a2\u30c3\u30d7 <ul> <li>\u30e9\u30dc E0 - \u30bb\u30c3\u30c8\u30a2\u30c3\u30d7</li> </ul> </li> <li>\ud83e\uddf0 \u5ba3\u8a00\u578b\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u306e\u57fa\u790e <ul> <li>\u30e9\u30dc E1 - \u8a73\u7d30\u306a\u5ba3\u8a00\u578b\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3092\u69cb\u7bc9\u3059\u308b </li> <li>\u30e9\u30dc E1a - Geo \u30ed\u30b1\u30fc\u30bf\u30fc\u30b2\u30fc\u30e0</li> </ul> </li> <li>\ud83d\udee0\ufe0f API \u3092\u30bc\u30ed\u304b\u3089\u69cb\u7bc9\u3057\u3066\u7d71\u5408\u3059\u308b <ul> <li>\u30e9\u30dc E2 - API \u3092\u69cb\u7bc9\u3059\u308b</li> <li>\u30e9\u30dc E3 - \u5ba3\u8a00\u578b\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8 + API \u3092\u8ffd\u52a0\u3059\u308b</li> <li>\u30e9\u30dc E4 - API + \u30d7\u30e9\u30b0\u30a4\u30f3\u3092\u5f37\u5316\u3059\u308b</li> <li>\u30e9\u30dc E5 - Adaptive Card \u3092\u8ffd\u52a0\u3059\u308b</li> </ul> </li> <li>\ud83d\udd10 \u8a8d\u8a3c <ul> <li>\u30e9\u30dc E6a - Toolkit</li> <li>\u30e9\u30dc E6b - \u624b\u52d5</li> <li>\u30e9\u30dc E6c - SSO</li> </ul> </li> <li>\ud83d\udd0c \u7d71\u5408 <ul> <li>\u30e9\u30dc EB - Graph Connector \u3092\u8ffd\u52a0\u3059\u308b</li> </ul> </li> </ul>"},{"location":"includes/ja/e-labs-toc/","title":"E labs toc","text":"<p>Microsoft 365 \u304c AI \u30e2\u30c7\u30eb\u3068\u30aa\u30fc\u30b1\u30b9\u30c8\u30ec\u30fc\u30b7\u30e7\u30f3\u3092\u63d0\u4f9b\u3059\u308b\u5ba3\u8a00\u578b\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3092\u69cb\u7bc9\u3057\u305f\u3044\u5834\u5408\u306f\u3001\u3053\u308c\u3089\u306e\u30e9\u30dc\u3092\u5b9f\u65bd\u3057\u3066\u304f\u3060\u3055\u3044\u3002</p> <ul> <li>\ud83c\udfc1 \u306f\u3058\u3081\u306b</li> <li>\ud83d\udd27 \u30bb\u30c3\u30c8\u30a2\u30c3\u30d7 <ul> <li>\u30e9\u30dc E0 - \u30bb\u30c3\u30c8\u30a2\u30c3\u30d7</li> </ul> </li> <li>\ud83e\uddf0 \u5ba3\u8a00\u578b\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u306e\u57fa\u790e <ul> <li>\u30e9\u30dc E1 - \u8a73\u7d30\u306a\u5ba3\u8a00\u578b\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3092\u69cb\u7bc9\u3059\u308b </li> <li>\u30e9\u30dc E1a - Geo \u30ed\u30b1\u30fc\u30bf\u30fc\u30b2\u30fc\u30e0</li> </ul> </li> <li>\ud83d\udee0\ufe0f API \u3092\u30bc\u30ed\u304b\u3089\u69cb\u7bc9\u3057\u3066\u7d71\u5408\u3059\u308b <ul> <li>\u30e9\u30dc E2 - API \u3092\u69cb\u7bc9\u3059\u308b</li> <li>\u30e9\u30dc E3 - \u5ba3\u8a00\u578b\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8 + API \u3092\u8ffd\u52a0\u3059\u308b</li> <li>\u30e9\u30dc E4 - API + \u30d7\u30e9\u30b0\u30a4\u30f3\u3092\u5f37\u5316\u3059\u308b</li> <li>\u30e9\u30dc E5 - Adaptive Card \u3092\u8ffd\u52a0\u3059\u308b</li> </ul> </li> <li>\ud83d\udd10 \u8a8d\u8a3c <ul> <li>\u30e9\u30dc E6a - Toolkit</li> <li>\u30e9\u30dc E6b - \u624b\u52d5</li> <li>\u30e9\u30dc E6c - SSO</li> </ul> </li> <li>\ud83d\udd0c \u7d71\u5408 <ul> <li>\u30e9\u30dc EB - Graph Connector \u3092\u8ffd\u52a0\u3059\u308b</li> </ul> </li> </ul>"},{"location":"includes/ja/m-labs-branches/","title":"M labs branches","text":"Copilot Studio Lite      <ul> <li>\u7c21\u5358\u3067\u30b7\u30f3\u30d7\u30eb\u3001\u304b\u3064\u30a4\u30f3\u30bf\u30e9\u30af\u30c6\u30a3\u30d6\u306a\u4f53\u9a13</li> <li>Web \u30d9\u30fc\u30b9\u3067\u3001Microsoft 365 Copilot Chat \u304a\u3088\u3073 Microsoft 365 Copilot \u3068\u7d71\u5408</li> <li>SharePoint Online\u3001\u516c\u958b Web\u3001\u304a\u3088\u3073 Microsoft Copilot Connectors \u304b\u3089\u306e\u30b3\u30f3\u30c6\u30f3\u30c4</li> <li>Microsoft 365 Copilot Chat \u3067\u5229\u7528\u53ef\u80fd</li> <ul> \u3053\u3053\u304b\u3089\u958b\u59cb  Copilot Studio Full              <ul> <li>\u6700\u5927\u9650\u306e\u67d4\u8edf\u6027</li> <li>\u307b\u307c\u3059\u3079\u3066\u306e\u30c7\u30fc\u30bf \u30bd\u30fc\u30b9\u307e\u305f\u306f\u30ca\u30ec\u30c3\u30b8 \u30d9\u30fc\u30b9\u306b\u5bfe\u5fdc</li> <li>\u591a\u69d8\u306a\u767a\u884c\u30c1\u30e3\u30cd\u30eb\u3092\u30b5\u30dd\u30fc\u30c8</li> <li>\u30a2\u30af\u30b7\u30e7\u30f3\u3092\u30b5\u30dd\u30fc\u30c8</li> <li>Power Platform \u30b3\u30cd\u30af\u30bf\u3001Dataverse\u3001REST API \u306a\u3069\u3092\u30b5\u30dd\u30fc\u30c8</li> <li>\u30e6\u30fc\u30b6\u30fc\u5358\u4f4d + \u30c6\u30ca\u30f3\u30c8\u5358\u4f4d\u306e\u30e9\u30a4\u30bb\u30f3\u30b9 \u307e\u305f\u306f Pay-As-You-Go</li> <ul> \u3053\u3053\u304b\u3089\u958b\u59cb  SharePoint \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8              <ul> <li>SharePoint Online \u306e\u30e6\u30fc\u30b6\u30fc \u30a8\u30af\u30b9\u30da\u30ea\u30a8\u30f3\u30b9\u306b\u7d71\u5408</li> <li>SharePoint Online \u30b3\u30f3\u30c6\u30f3\u30c4\u306e\u307f</li> <li>Microsoft Teams \u30c1\u30e3\u30c3\u30c8\u3067\u5229\u7528\u53ef\u80fd</li> <li>Microsoft 365 Copilot \u30e9\u30a4\u30bb\u30f3\u30b9\u3001Microsoft Copilot Studio \u30ad\u30e3\u30d1\u30b7\u30c6\u30a3\u3001\u307e\u305f\u306f Pay-As-You-Go</li> <ul> \u3053\u3053\u304b\u3089\u958b\u59cb"},{"location":"includes/ja/m-path-links/","title":"M path links","text":"<ul> <li>\u30e9\u30dc M0 - \u524d\u63d0\u6761\u4ef6 READY FOR TESTING</li> <li>\u30e9\u30dc M1 - Northwind \u30e1\u30c3\u30bb\u30fc\u30b8\u62e1\u5f35\u6a5f\u80fd\u3092\u7406\u89e3\u3059\u308b READY FOR TESTING</li> <li>\u30e9\u30dc M2 - Microsoft 365 Copilot \u3067\u30a2\u30d7\u30ea\u3092\u5b9f\u884c\u3059\u308b READY FOR TESTINGSOON</li> <li>\u30e9\u30dc M3 - \u65b0\u3057\u3044\u691c\u7d22\u30b3\u30de\u30f3\u30c9\u3067\u30d7\u30e9\u30b0\u30a4\u30f3\u3092\u5f37\u5316\u3059\u308b READY FOR TESTING</li> <li>\u30e9\u30dc M4 - \u8a8d\u8a3c\u3092\u8ffd\u52a0\u3059\u308b READY FOR TESTING</li> <li>\u30e9\u30dc M5 - \u30a2\u30af\u30b7\u30e7\u30f3 \u30b3\u30de\u30f3\u30c9\u3067\u30d7\u30e9\u30b0\u30a4\u30f3\u3092\u5f37\u5316\u3059\u308b COMING SOON</li> </ul>"},{"location":"includes/ja/mab-congratulations/","title":"Mab congratulations","text":"<p>\u304a\u3081\u3067\u3068\u3046\u3054\u3056\u3044\u307e\u3059\uff01</p>"},{"location":"includes/ja/mab-labs-prelude/","title":"Mab labs prelude","text":"<p>Copilot Studio Lite \u3067 \u5ba3\u8a00\u578b \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8 \u3092\u69cb\u7bc9\u3057\u305f\u3044\u5834\u5408\u306f\u3001\u4ee5\u4e0b\u306e \u30e9\u30dc \u3092\u5b9f\u65bd\u3057\u3066\u304f\u3060\u3055\u3044</p> <ul> <li>MAB1 - \u306f\u3058\u3081\u3066\u306e \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8 \u3092\u69cb\u7bc9\u3059\u308b</li> </ul> \u76ee\u6b21"},{"location":"includes/ja/mab-labs-toc/","title":"Mab labs toc","text":"<p>Copilot Studio Lite \u3067 \u5ba3\u8a00\u578b \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8 \u3092\u69cb\u7bc9\u3057\u305f\u3044\u5834\u5408\u306f\u3001\u4ee5\u4e0b\u306e \u30e9\u30dc \u3092\u5b9f\u65bd\u3057\u3066\u304f\u3060\u3055\u3044</p> <ul> <li>MAB1 - \u306f\u3058\u3081\u3066\u306e \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8 \u3092\u69cb\u7bc9\u3059\u308b</li> </ul>"},{"location":"includes/ja/main-links/","title":"Main links","text":"\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u306e\u4f5c\u6210      <p>Copilot Studio \u307e\u305f\u306f SharePoint Online \u3092\u4f7f\u7528\u3057\u3001\u30ce\u30fc\u30b3\u30fc\u30c9\u307e\u305f\u306f\u30ed\u30fc\u30b3\u30fc\u30c9\u3067\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3092\u4f5c\u6210\u3057\u307e\u3059\u3002\uff08\u300cMAB\u300d\u300cMSA\u300d\u300cMCS\u300d\u30e9\u30dc\uff09</p> \u958b\u59cb\u3059\u308b        M365 Copilot \u306e\u62e1\u5f35      <p>Microsoft 365 \u304c AI \u30e2\u30c7\u30eb\u3068\u30aa\u30fc\u30b1\u30b9\u30c8\u30ec\u30fc\u30b7\u30e7\u30f3\u3092\u63d0\u4f9b\u3059\u308b\u5ba3\u8a00\u578b\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3092\u69cb\u7bc9\u3057\u307e\u3059\u3002\uff08\u300cE\u300d\u30e9\u30dc\uff09</p> \u958b\u59cb\u3059\u308b        \u72ec\u81ea\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u306e\u69cb\u7bc9      <p>Azure OpenAI \u3092\u4f7f\u7528\u3057\u3066\u3001\u30ab\u30b9\u30bf\u30e0 AI \u30e2\u30c7\u30eb\u3068\u30aa\u30fc\u30b1\u30b9\u30c8\u30ec\u30fc\u30b7\u30e7\u30f3\u3092\u5099\u3048\u305f\u30ab\u30b9\u30bf\u30e0 \u30a8\u30f3\u30b8\u30f3 \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3092\u69cb\u7bc9\u3057\u307e\u3059\u3002\uff08\u300cBMA\u300d\u30e9\u30dc\uff09</p> \u958b\u59cb\u3059\u308b"},{"location":"includes/ja/mcs-congratulations/","title":"Mcs congratulations","text":"<p>\u304a\u3081\u3067\u3068\u3046\u3054\u3056\u3044\u307e\u3059\uff01</p>"},{"location":"includes/ja/mcs-labs-prelude/","title":"Mcs labs prelude","text":"<p>Microsoft Copilot Studio \u3067 \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8 \u3092\u69cb\u7bc9\u3057\u305f\u3044\u5834\u5408\u306f\u3001\u6b21\u306e \u30e9\u30dc \u3092\u5b9f\u65bd\u3057\u3066\u304f\u3060\u3055\u3044</p> <ul> <li>MCS0 - \u30bb\u30c3\u30c8\u30a2\u30c3\u30d7</li> <li>MCS1 - \u6700\u521d\u306e \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8</li> <li>MCS2 - \u30c8\u30d4\u30c3\u30af\u306e\u5b9a\u7fa9</li> <li>MCS3 - \u30c4\u30fc\u30eb\u306e\u5b9a\u7fa9</li> <li>MCS4 - Microsoft 365 Copilot \u306e\u62e1\u5f35</li> <li>MCS5 - \u30ab\u30b9\u30bf\u30e0 \u30b3\u30cd\u30af\u30bf\u306e\u4f7f\u7528</li> <li>MCS6 - MCP \u30b5\u30fc\u30d0\u30fc\u306e\u4f7f\u7528</li> <li>MCS7 - \u81ea\u5f8b\u578b \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8 \u306e\u4f5c\u6210</li> <li>MCS8 - RAG \u306e\u305f\u3081\u306e Azure AI Search \u306e\u7d71\u5408</li> <li>MCS9 - \u63a5\u7d9a\u3055\u308c\u305f \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8 (\u30d7\u30ec\u30d3\u30e5\u30fc)</li> </ul>"},{"location":"includes/ja/mcs-labs-toc/","title":"Mcs labs toc","text":"<p>Microsoft Copilot Studio \u3067 \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8 \u3092\u69cb\u7bc9\u3057\u305f\u3044\u5834\u5408\u306f\u3001\u6b21\u306e \u30e9\u30dc \u3092\u5b9f\u65bd\u3057\u3066\u304f\u3060\u3055\u3044</p> <ul> <li>MCS0 - \u30bb\u30c3\u30c8\u30a2\u30c3\u30d7</li> <li>MCS1 - \u6700\u521d\u306e \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8</li> <li>MCS2 - \u30c8\u30d4\u30c3\u30af\u306e\u5b9a\u7fa9</li> <li>MCS3 - \u30c4\u30fc\u30eb\u306e\u5b9a\u7fa9</li> <li>MCS4 - Microsoft 365 Copilot \u306e\u62e1\u5f35</li> <li>MCS5 - \u30ab\u30b9\u30bf\u30e0 \u30b3\u30cd\u30af\u30bf\u306e\u4f7f\u7528</li> <li>MCS6 - MCP \u30b5\u30fc\u30d0\u30fc\u306e\u4f7f\u7528</li> <li>MCS7 - \u81ea\u5f8b\u578b \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8 \u306e\u4f5c\u6210</li> <li>MCS8 - RAG \u306e\u305f\u3081\u306e Azure AI Search \u306e\u7d71\u5408</li> <li>MCS9 - \u63a5\u7d9a\u3055\u308c\u305f \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8 (\u30d7\u30ec\u30d3\u30e5\u30fc)</li> </ul>"},{"location":"includes/ja/more-links/","title":"More links","text":"\u8a73\u7d30\u60c5\u5831      <p>\u3055\u307e\u3056\u307e\u306a\u30ea\u30bd\u30fc\u30b9\u304b\u3089\u3055\u3089\u306b\u5b66\u3073\u307e\u3057\u3087\u3046</p> <ul> <li>Microsoft Learn</li> <li>\u30d3\u30c7\u30aa \u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb</li> </ul>        \u79c1\u305f\u3061\u3068\u3064\u306a\u304c\u308b      <p>GitHub Discussion \u3067\u4f1a\u8a71\u306b\u53c2\u52a0\u3057\u307e\u3057\u3087\u3046\uff01</p>"},{"location":"includes/ja/msa-congratulations/","title":"Msa congratulations","text":"<p>\u304a\u3081\u3067\u3068\u3046\u3054\u3056\u3044\u307e\u3059\uff01</p>"},{"location":"includes/ja/msa-labs-prelude/","title":"Msa labs prelude","text":"<p>SharePoint \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3092\u69cb\u7bc9\u3057\u305f\u3044\u5834\u5408\u306f\u3001\u3053\u308c\u3089\u306e \u30e9\u30dc \u3092\u5b9f\u884c\u3057\u3066\u304f\u3060\u3055\u3044</p> <ul> <li>MSA1 - \u6700\u521d\u306e SharePoint \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3092\u69cb\u7bc9\u3059\u308b</li> <li>MSA2 - SharePoint \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u306e\u5171\u6709</li> </ul> \u76ee\u6b21"},{"location":"includes/ja/msa-labs-toc/","title":"Msa labs toc","text":"<p>SharePoint \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3092\u69cb\u7bc9\u3057\u305f\u3044\u5834\u5408\u306f\u3001\u3053\u308c\u3089\u306e \u30e9\u30dc \u3092\u5b9f\u884c\u3057\u3066\u304f\u3060\u3055\u3044</p> <ul> <li>MSA1 - \u6700\u521d\u306e SharePoint \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3092\u69cb\u7bc9\u3059\u308b</li> <li>MSA2 - SharePoint \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u306e\u5171\u6709</li> </ul>"},{"location":"includes/ja/starrepo/","title":"Starrepo","text":"<p>\u2b50\ufe0f \u30ec\u30dd\u30b8\u30c8\u30ea\u306b\u30b9\u30bf\u30fc\u3092\u4ed8\u3051\u308b</p>"},{"location":"javascripts/card-usage/","title":"Card Component Demo","text":"<p>This page demonstrates how to use the <code>cc-card</code> web component.</p>"},{"location":"javascripts/card-usage/#individual-cards","title":"Individual Cards","text":""},{"location":"javascripts/card-usage/#basic-card","title":"Basic Card","text":"<pre><code>&lt;cc-card \n    title=\"Getting Started\" \n    description=\"Learn the basics of AI prompting and get started with your first copilot instructions.\"\n    href=\"/pages/copilot-instructions/getting-started\"&gt;\n&lt;/cc-card&gt;\n</code></pre>"},{"location":"javascripts/card-usage/#card-with-image","title":"Card with Image","text":"<pre><code>&lt;cc-card \n    title=\"Advanced Techniques\" \n    description=\"Master advanced prompting techniques and learn to create sophisticated AI agents.\"\n    href=\"/pages/copilot-instructions/advanced\"\n    image=\"/assets/images/advanced-techniques.png\"&gt;\n&lt;/cc-card&gt;\n</code></pre>"},{"location":"javascripts/card-usage/#card-with-external-link","title":"Card with External Link","text":"<pre><code>&lt;cc-card \n    title=\"GitHub Repository\" \n    description=\"Explore the source code and contribute to the Copilot Camp project.\"\n    href=\"https://github.com/microsoft/copilot-camp\"\n    target=\"_blank\"&gt;\n&lt;/cc-card&gt;\n</code></pre>"},{"location":"javascripts/card-usage/#card-grid","title":"Card Grid","text":"<p>Use the <code>cc-card-grid</code> component to create a responsive grid of cards:</p> <pre><code>&lt;cc-card-grid columns=\"3\" gap=\"1.5rem\"&gt;\n    &lt;cc-card \n        title=\"Fundamentals\" \n        description=\"Start with the basics of AI prompting.\"\n        href=\"/fundamentals\"&gt;\n    &lt;/cc-card&gt;\n    &lt;cc-card \n        title=\"Best Practices\" \n        description=\"Learn industry best practices for AI development.\"\n        href=\"/best-practices\"&gt;\n    &lt;/cc-card&gt;\n    &lt;cc-card \n        title=\"Advanced Topics\" \n        description=\"Dive deep into advanced AI concepts.\"\n        href=\"/advanced\"&gt;\n    &lt;/cc-card&gt;\n&lt;/cc-card-grid&gt;\n</code></pre> <p> </p>"},{"location":"javascripts/card-usage/#auto-fit-grid","title":"Auto-fit Grid","text":"<p>The grid automatically adjusts to fit the available space:</p> <pre><code>&lt;cc-card-grid gap=\"1rem\"&gt;\n    &lt;cc-card title=\"Card 1\" description=\"This is the first card\" href=\"#1\"&gt;&lt;/cc-card&gt;\n    &lt;cc-card title=\"Card 2\" description=\"This is the second card\" href=\"#2\"&gt;&lt;/cc-card&gt;\n    &lt;cc-card title=\"Card 3\" description=\"This is the third card\" href=\"#3\"&gt;&lt;/cc-card&gt;\n    &lt;cc-card title=\"Card 4\" description=\"This is the fourth card\" href=\"#4\"&gt;&lt;/cc-card&gt;\n    &lt;cc-card title=\"Card 5\" description=\"This is the fifth card\" href=\"#5\"&gt;&lt;/cc-card&gt;\n&lt;/cc-card-grid&gt;\n</code></pre> <p> </p>"},{"location":"javascripts/card-usage/#component-attributes","title":"Component Attributes","text":""},{"location":"javascripts/card-usage/#cc-card","title":"cc-card","text":"Attribute Type Description Default <code>title</code> string The card title \"Card Title\" <code>description</code> string The card description \"Card description\" <code>href</code> string The link destination \"#\" <code>image</code> string Optional image URL none <code>target</code> string Link target (_blank, _self, etc.) \"_self\" <code>class</code> string Additional CSS classes \"\""},{"location":"javascripts/card-usage/#cc-card-grid","title":"cc-card-grid","text":"Attribute Type Description Default <code>columns</code> number Number of columns auto-fit <code>gap</code> string Grid gap (CSS units) \"1rem\""},{"location":"javascripts/card-usage/#javascript-api","title":"JavaScript API","text":"<p>You can also update cards dynamically:</p> <pre><code>// Get a card element\nconst card = document.querySelector('cc-card');\n\n// Update its properties\ncard.updateCard({\n    title: 'New Title',\n    description: 'New description',\n    href: '/new-url',\n    image: '/new-image.png'\n});\n</code></pre>"},{"location":"javascripts/card-usage/#features","title":"Features","text":"<ul> <li>Responsive: Cards automatically adjust to different screen sizes</li> <li>Accessible: Full keyboard navigation and screen reader support</li> <li>Customizable: Support for images, external links, and custom styling</li> <li>Interactive: Hover effects and visual feedback</li> <li>Grid Layout: Flexible grid system for organizing multiple cards</li> <li>Dark Mode: Automatic dark mode support</li> </ul>"},{"location":"pages/test/","title":"Lab T1 - Test Bob's new Web Controls","text":"<p>In this lab, you, the Copilot Developer Camp content developer, will learn how to use custom web controls to provide an enhanced user experience.</p> <p>Where did I leave off?</p> <p></p> <p>Table of Contents</p> <p></p>"},{"location":"pages/test/#exercise-1-learn-the-controls","title":"Exercise 1: Learn the controls","text":"<p>In this exercise, you'll learn how to use the <code>&lt;cc-end-step&gt;</code> web control, which allows users to log their process at the end of each step.</p>"},{"location":"pages/test/#step-1-write-the-markup","title":"Step 1: Write the markup","text":"<p>Each step must begin with a 3rd level header (\"###\") that includes the name of the step. Then insert the <code>&lt;cc-end-step&gt;</code> control at the end of the step.</p> <p>For example,</p> <pre><code>### Step 1: Write the markup\n\n... (all the instructions go here)\n\n&lt;cc-end-step lab=\"t1\" exercise=\"1\" step=\"1\" /&gt;\n</code></pre> <p>The control needs your lab, exercise, and step so it can store the checkbox state uniquely across page refreshes.</p> <p>For a Table of Contents, use</p> <pre><code>!!! abstract \"Table of Contents\"\n    &lt;cc-table-of-contents /&gt;\n</code></pre> <p>To show the most recent step completed use</p> <pre><code>!!! abstract \"Where did I leave off?\"\n    &lt;cc-last-completed-step /&gt;\n</code></pre> <p>Notice the checkbox at the bottom of each step. When users check it, several things happen:</p> <ul> <li>A check mark is added to the step heading</li> <li>A check mark is added to the step in the Table of Contents</li> <li>The \"where did I leave off\" message at the top of the lab, if present, is updated</li> <li>An encouraging message is added below the checkbox</li> <li>Telemetry logs the completion (anonymously)</li> </ul> <p>Try it out now!</p> <p></p>"},{"location":"pages/test/#step-2-make-sure-your-h2-and-h3-elements-are-in-order","title":"Step 2: Make sure your h2 and h3 elements are in order","text":"<p>The controls are poking around in the DOM, and they depend on you having:</p> <ul> <li>an h2 (##) for each exercise beginning with the word \"Exercise\"</li> <li>an h3 (###) for each step </li> <li>at least one step in each exercise</li> <li>the last thing in the step is the <code>&lt;cc-end-step /&gt;</code></li> </ul> <p></p>"},{"location":"pages/test/#step-3-test-the-links","title":"Step 3: Test the links","text":"<p>Now, with some checkboxes checked, notice that the \"Where did I leave off\" message is now a hyperlink that brings you directly to the end of the last step that you completed.</p> <p>The links in the Table of Contents, on the other hand, bring you to the beginning of each step.</p> <p></p>"},{"location":"pages/test/#step-4-how-does-it-work","title":"Step 4: How does it work?","text":"<p>These are written using standard web components. Checkbox state is kept in local storage so it will persist across lab sessions so long as the user returns with the same browser and profile, the checkboxes will be as they left them. If you're curious, here is the code.</p> <p></p>"},{"location":"pages/test/#exercise-2-give-feedback","title":"Exercise 2: Give feedback","text":""},{"location":"pages/test/#step-1-do-you-like-it","title":"Step 1: Do you like it?","text":"<p>Is it useful? Whow could it be improved?</p> <p></p>"},{"location":"pages/test/#step-2-long-steps-are-no-problem","title":"Step 2: Long steps are no problem","text":"<p>In the initial implementation a single checkbox was placed in the heading for each step. If a step is really long like this one, people might not scroll back up to the top to check it off. So I moved the checkboxes to the bottom. Please scroll past all the fake Latin and check it out!</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nam quis nulla elit. Sed tortor turpis, mollis non pretium a, consectetur at augue. Fusce eu mi in sem imperdiet accumsan. Phasellus ullamcorper magna vel tincidunt dapibus. Pellentesque congue commodo finibus. Morbi scelerisque porta velit dictum tincidunt. Suspendisse potenti. Ut a mi suscipit, varius tellus id, luctus nisi. Aenean nec magna vel tortor fermentum laoreet. Praesent mattis hendrerit arcu nec rutrum. Maecenas sit amet sagittis ex, id interdum eros. Donec euismod a nisi nec efficitur. Cras sit amet massa elementum augue efficitur maximus non sed neque. Maecenas sit amet fringilla risus. Pellentesque habitant morbi tristique senectus et netus et malesuada fames ac turpis egestas.</p> <p>Ut ultrices sem dui, eu posuere orci fermentum commodo. Nam elementum ac est sit amet feugiat. Integer eget erat pharetra, tempus sem vel, consectetur arcu. Etiam vulputate porta tellus ac viverra. Mauris id aliquam mauris, sit amet rutrum lacus. Vivamus tincidunt in massa vitae varius. Donec luctus nunc eget sodales ultricies. Curabitur molestie, urna ac sodales efficitur, ipsum odio condimentum nisl, quis imperdiet erat velit ut orci. Nunc fermentum mi nec sapien pellentesque iaculis.</p> <p>Praesent iaculis feugiat justo, at rutrum turpis venenatis eu. Phasellus tempus tincidunt purus, non semper nisi gravida id. Quisque tempor urna vitae malesuada ultrices. Nulla elit ipsum, rhoncus tempor ligula vel, aliquam commodo diam. Maecenas tristique ullamcorper blandit. Vivamus in congue tortor, rhoncus faucibus nisl. Curabitur non est justo. Fusce vitae tincidunt purus. Duis malesuada leo tellus, nec faucibus neque vehicula at. Morbi nisl risus, congue a finibus in, venenatis eget augue. Nulla tempor eu nibh id imperdiet. Maecenas scelerisque posuere nibh in dapibus. Maecenas aliquam ornare magna sed pulvinar. Aenean vel placerat elit. Nunc faucibus imperdiet fringilla. In sit amet ipsum lectus.</p> <p>Morbi in congue sem. Duis suscipit enim eu erat congue, a dapibus tortor fringilla. Cras at purus gravida leo condimentum molestie id ut sapien. Morbi in eros a magna finibus efficitur quis ac lacus. Curabitur vitae elit et felis iaculis convallis a quis sem. Vivamus sit amet sollicitudin metus, ut pulvinar ex. Nunc justo lacus, eleifend ac semper quis, condimentum a quam. Nunc sagittis urna erat, nec rhoncus urna pulvinar id. Integer fermentum fermentum sollicitudin. Mauris et vestibulum massa, at eleifend tortor. Nulla vehicula eu odio ut semper. Cras et nibh lacus. Duis in magna sit amet nunc finibus faucibus vel ut eros. Cras ullamcorper efficitur velit eu fermentum.</p> <p>Proin eget vulputate lectus. Vestibulum sit amet bibendum nisl, vel interdum odio. Sed sed odio lectus. Ut et magna vitae risus imperdiet posuere. Phasellus enim velit, tempor sed consectetur in, cursus id velit. Vestibulum sed lobortis purus. Sed libero nisi, vulputate sed nulla in, fermentum imperdiet odio. Vestibulum pellentesque blandit congue. In venenatis euismod tortor, nec sagittis ante placerat eget. Sed at nunc nunc. Curabitur consequat elit ut hendrerit vestibulum. Ut maximus laoreet condimentum. Suspendisse eget sem neque. Cras in lorem facilisis, rutrum quam vel, dictum justo.</p> <p>Integer interdum mollis nulla at blandit. Interdum et malesuada fames ac ante ipsum primis in faucibus. Vivamus aliquam commodo aliquam. Maecenas rhoncus nisl vel purus sodales, id vestibulum eros viverra. Donec vehicula semper urna. In auctor consectetur libero quis eleifend. Etiam a tellus sed metus suscipit blandit non at neque. Suspendisse placerat semper est eu commodo. Nam nunc augue, cursus nec commodo in, elementum at lacus. Duis est arcu, cursus ac rhoncus sed, hendrerit in odio. Duis congue nisi faucibus ipsum convallis, eu dapibus ante rhoncus. Suspendisse eu eros et ligula ultrices tincidunt.</p> <p>Sed blandit, felis vel auctor pharetra, nibh tellus mollis nisi, ac feugiat nisl nunc et urna. Nunc magna tortor, lobortis eu congue eget, pulvinar sit amet dolor. Sed nec mattis ante. Maecenas convallis tristique lacinia. Suspendisse non tellus quis lorem sodales finibus. Curabitur rutrum vel odio at viverra. Morbi maximus nibh sit amet nisl pellentesque bibendum. Pellentesque ultricies ex ante, at hendrerit magna posuere sed.</p> <p>Proin luctus faucibus posuere. In malesuada hendrerit arcu, et mattis ante maximus ac. Phasellus dictum nibh ac neque rutrum ultrices. Nullam sed aliquam enim. Nullam nisl erat, interdum a porta eget, congue in nisl. Nullam ligula elit, ornare eget nisl eu, aliquet semper metus. Mauris pulvinar justo sem. Fusce nec ullamcorper urna. Cras eget metus eget lectus volutpat aliquet non pharetra massa. In vitae nisi arcu.</p> <p>Sed sit amet convallis massa, vehicula auctor justo. Aliquam ultricies porttitor nulla eu lobortis. Vestibulum viverra, risus nec dapibus venenatis, eros neque bibendum augue, sit amet faucibus arcu mauris eget quam. Quisque sed mollis tellus, ac tempus elit. Sed orci lorem, tincidunt vitae egestas iaculis, finibus non sem. Curabitur quis semper est, sed tempus risus. Duis dictum lorem vulputate felis convallis, commodo sagittis diam condimentum. Curabitur vitae erat nibh. Mauris vulputate maximus libero id dignissim. Quisque viverra ante tellus, id sollicitudin elit interdum quis.</p> <p>Nunc massa velit, gravida a nunc in, efficitur viverra sapien. Sed viverra ullamcorper hendrerit. Quisque cursus felis tortor, ut facilisis lectus volutpat vel. Sed scelerisque auctor tempor. Duis ante diam, pretium vitae rhoncus id, mollis vitae lorem. Mauris pretium lorem sem, sit amet iaculis sem ullamcorper ac. Fusce vel arcu aliquet, vulputate leo at, aliquet massa. Ut at imperdiet eros. Mauris gravida mi rutrum mi egestas, sit amet varius tellus pellentesque. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Integer varius nunc in arcu posuere, suscipit fringilla erat commodo. Aenean vitae nisi non felis semper commodo. Donec eget neque ornare, lobortis augue nec, pharetra est. Sed accumsan semper diam, eget pharetra mauris feugiat id. Pellentesque ac velit vitae purus sollicitudin dapibus. Mauris posuere interdum nisi sed pellentesque.</p> <p></p>"},{"location":"pages/test/#step-3-thank-you","title":"Step 3: Thank you!","text":"<p>Thanks for testing the Copilot Developer Camp web controls!</p> <p></p>"},{"location":"pages/updating-the-schema/","title":"Updating the Manifest schema","text":"<p>If you began any of the \"Extend\" path labs prior to October 27, 2024, you may be using a developer preview schema. A new, supported schema, v1.19, is now available and all preview applications need to update. The new schema also reflects the new Copilot agent naming.</p> <p>To update your project, open the appPackage/manifest.json file.</p> <p>First, replace the first two lines with these:</p> <pre><code>  \"$schema\": \"https://developer.microsoft.com/json-schemas/teams/v1.19/MicrosoftTeams.schema.json\",\n  \"manifestVersion\": \"1.19\",\n</code></pre> <p>If you see a <code>packageName</code> property like this one in your manifest.json file, remove it as it is no longer necessary or supported.</p> <pre><code>  \"packageName\": \"com.microsoft.teams.extension\",\n</code></pre> <p>Then replace the <code>copilotExtensions</code> property with this:</p> <pre><code>  \"copilotAgents\": {\n    \"declarativeAgents\": [\n      {\n        \"id\": \"treygenie\",\n        \"file\": \"trey-declarative-agent.json\"\n      }\n    ]   \n  }, \n</code></pre> <p>Finally, rename trey-declarative-copilot.json to trey-declarative-agent.json to match the lab instructions.</p>"},{"location":"pages/beyond-agents/","title":"Introduction","text":""},{"location":"pages/beyond-agents/#get-started","title":"Get started","text":"<p>Dive into the world of AI concepts and techniques to broaden your understanding beyond agent development.</p> <p> </p>"},{"location":"pages/beyond-agents/#featured-agent-prompts","title":"Featured agent prompts","text":""},{"location":"pages/beyond-agents/beginner-agent/","title":"Agent Instruction Lab - Improve your agent instructions (Beginner friendly)","text":"<p>What you will do:</p> <ul> <li>Identify the Problem: Pinpoint the specific issue your agent will address </li> <li>Build a Basic Agent: Start with a simple prompt to get your agent up and running. </li> <li>Define the Agent's Role: Improve your agents focus with a role assigned </li> <li>Outline Execution Steps: Break down the process into clear, manageable subtasks. </li> <li>Set Response Guidelines: Influence the agent\u2019s response with clear instructions </li> <li>Give example conversations: Provide examples to improve consistency in agent\u2019s response </li> </ul> <p>This lab will guide you with suggestions to help refine your agent instructions approach drawing from techniques we have experimented over time. These practices have generally contributed to enhancing our agent's behaviour and consistency. </p> Prerequisites <ul> <li>Access to Copilot either using Teams, Microsoft 356 chat or Copilot chat</li> <li>A tool to iteratively test and update your agent either Microsoft 365 Agents Toolkit or Agent builder or Copilot Studio  (This lab uses Agents Toolkit, but you can also test it in Agent builder or even Copilot Studio)</li> </ul>"},{"location":"pages/beyond-agents/beginner-agent/#introduction","title":"Introduction","text":"<p>Declarative agents are personalised Copilots that you can use to create a more contextual and tailored expereince for your specific needs. They are developed by providing instructions, knowledge and skills. In this lab we will focus on the instructions part of the agent. If you need to learn more about knowledge and skills head to our labs that deep dives into those features. </p> <p>In this lab we will create a Declarative Agent called ShowExpert which is a <code>Generative Recommendation agent</code>. Such Generative Recommendation agents are designed to enhance decision-making, improve customer experiences, and streamline operations. Here, we will build an agent that provides tailored recommendations for shows in the online streaming platforms.  While our \"ShowExpert\" agent helps users quickly decide what to watch, the same principles provide significant enterprise value through their ability to streamline operations and enhance decision-making processes. These systems unlock competitive advantages across multiple dimensions: </p> <ul> <li>Enhanced decision quality by synthesising insights from vast datasets and surfacing hidden patterns </li> <li>Operational efficiency through automation of complex information analysis </li> <li>Personalisation at scale with real-time adaptation to changing preferences </li> <li>Knowledge democratization by providing domain expertise to everyone  </li> </ul> <p>We start with a simple prompt and iteratively try and improve the instructions. Evaluating the agent's behaviour at every iteration of instructions is crucial. We will conduct iterative cycles to refine the instructions until we achieve a somewhat consistent behaviour from the agent. </p> <p></p>"},{"location":"pages/beyond-agents/beginner-agent/#step-1-identify-the-problem-for-agent","title":"Step 1: Identify the Problem for Agent","text":"<p>Problem: There are findings, stating that an average person spends approximately 110 hours annually scrolling through menus of various online streaming platforms for shows. When considered in context, this means people spend an entire working week per year just checking various streaming apps without interruptions. </p> <p>Solution: Consider implementing a Copilot agent that can streamline decision-making processes. Let\u2019s call it the ShowExpert. </p> <p>Goal: It helps to already have an end goal in mind for the ShowExpert. It should be interactive, friendly, will ask for preferences, and give me detailed information about the shows it recommends and why it thinks I should watch it. Just like a friend. </p> <p></p>"},{"location":"pages/beyond-agents/beginner-agent/#step-2-build-a-first-basic-agent-declarative-agent","title":"Step 2: Build a first Basic Agent (Declarative Agent)","text":"<p>The first step is to think of an initial prompt for this agent given as its instruction. Our examination of the community's prompting techniques, facilitated by the Copilot Prompt Library, has revealed that most people start with single line prompts.  </p> <p>So, let's start off with the basic prompt below:</p> <pre><code>You are an agent to help user with recommendation for shows that are streaming on online streaming platforms \n</code></pre> <p>Now to build ShowExpert, you can use any tool of your choice like Agents Toolkit, Agent Builder or Copilot Studio. In this lab we have used Agents Toolkit. Check out our prerequisites lab to understand how to set up your environment for testing using Agents Toolkit. </p>"},{"location":"pages/beyond-agents/beginner-agent/#declarative-agent-using-agents-toolkit","title":"Declarative agent using Agents Toolkit","text":"About this step <p>This step in the lab assumes you have installed Agents Toolkit for Visual Studio Code and is going to use this extension to create a declarative agent. If you are going to use Agent Builder or Copilot Studio, these steps won\u2019t be needed. Use the tool of your choice and paste instructions in the\u202f<code>Instructions</code>\u202fcolumn instead and test it out. Here is a lab that shows you below steps to create a declarative agent in detail.</p> <ul> <li>Go to the Agents Toolkit extension in your Visual Studio Code editor and select Create a New App</li> <li>A panel opens up where you need to select Declarative Agent from the list of project types.</li> <li>Select No Action next</li> <li>Choose the project root folder for your agent project</li> <li>Give an application name like : \"ShowExpert\" and enter</li> <li>A VS code window will open up with your agent project scaffolded.</li> <li>Expand appPackage folder. This is you will work to update your agent. </li> <li>(Optional) Replace the color.png with an icon of your choice with 192x192 size. Here is an example file.</li> <li>Go to file declarativeAgent.json and locate description object. This is where you will set your persona for your agent for Copilot. Paste a simple description like <code>Recommendation agent for online streaming platforms' shows</code> for now. </li> <li>In the same file declarativeAgent.json, after the instructions object, add the capability for your agent to use websearch by appending below code after a comma. </li> </ul> <pre><code> \"capabilities\": [\n        {\n\n            \"name\": \"WebSearch\"\n\n        }\n    ]\n</code></pre> <ul> <li>Go to instruction.txt file and replace the placeholder instruction with our basic prompt <code>You are an agent to help user with recommendation for shows that are streaming on online streaming platforms</code></li> </ul> <p>Now you are ready to test the basic prompt.</p> <ul> <li>Go to the Agents Toolkit extension in your Visual Studio Code editor and select Provision under LifeCycle. This step will sideload your agent to Microsoft 365 available for you test.</li> <li>Go to teams app or Microsoft 365 chat.</li> <li>Open Copilot app</li> <li>Inside Copilot app, locate the \"ShowExpert\" agent from the right panel and select for an immersive chat experience with the agent. </li> </ul> <p>Initiate chat by saying <code>Hi</code> or ask the question right away in chat - e.g <code>Suggest a show to watch today on Netflix</code>.</p> <p>Below shows the interaction with the agent.</p> <p></p> <p>While this agent did its job it is far from our end goal. So, like mentioned in the intro let's try and improve its behaviour. </p>"},{"location":"pages/beyond-agents/beginner-agent/#step-3-identify-and-assign-a-rolepurpose-to-your-agent","title":"Step 3: Identify and assign a role/purpose to your agent","text":"<p>Now let's give our agent a role and a purpose. Much like humans , agents are motivated when they are given their life's purpose! </p> <p>The way to look at it is to think of instructing a child of 7 years of age how to do something, like emptying the trash can. You might say something like this to the kid - \"You are Captain Clean-up, the superhero tasked with saving the house from the stinky trash monster in the kitchen!\"</p> <p>The Copilot agents are very smart,  but they are also unaware of the task at hand. So, giving them a role similar to giving a child instruction to do a task would help. This is also the persona of the agent, so we will not only put the role in the instructions but also make this the description of the agent.</p> <p>Copy and paste below text to <code>description</code> field in declarativeAgent.json as well as the whole text for instruction.txt</p> <pre><code>You are an agent specialised in providing reviews and recommendations for shows on all online streaming platforms. Your primary goal is to help users discover content they'll enjoy and make informed decisions about what to watch. Speak concretely about all angles, pros and cons in an unbiased yet informative manner about the shows.Extract the user's name and greet them personally.  \n</code></pre> <p>Once changes are made, select Provision to update the agent. </p>"},{"location":"pages/beyond-agents/beginner-agent/#testing-the-modification","title":"Testing the modification","text":"<p>Open a new chat with the\u202fShowExpert\u202fand interact the same way as before. Below shows the interaction with the agent. </p> <p></p> <p>As you can see the agent is friendlier and slightly gives us general review of what is popular these days with its own recommendations. It has made more informed decision on behalf of the user. This is a good improvement but has not reached the goal yet so let's keep improving. </p>"},{"location":"pages/beyond-agents/beginner-agent/#step-4-execution-steps-for-sequential-subtasks-if-relevant","title":"Step 4: Execution steps for sequential subtasks if relevant","text":"<p>When you take the example of explaining the role of Captain clean up, you could make it a lot easier for the child to do the task successfully if you provide steps to do the task. Just like the child, agents also behave better when you give them steps or execution steps (if at all the task at hand involves steps) when needed. For the case of captain clean up you could say - \"You are Captain Clean-up. You have a special mission to keep the house safe from the trash monster in the kitchen. Carefully pull out the trash bag from the bin. Use your superhero strength to make sure nothing falls out. Open the lid of the big garbage bin and put the trash bag inside. Make sure it's all the way in. Close the lid of the big garbage bin. You've completed your mission and saved the house from the stinky trash monster</p> <p>Certainly, this is a sequence that can be made into execution steps.  Now let's reimage for our ShowExpert agent how to incorporate subtasks as steps.</p> <p>Add into the instruction.txt file below Execution Steps</p> Format of instruction file <p>Agents behave better when instruction files are in .md format</p> <pre><code>## Execution Steps\n\n1. Extract the user's name and greet them personally. Use emojis and be welcoming.\n2. Identify the type of request (review, recommendation, or question).\n3. List key elements from the user's input (e.g., shows mentioned, preferences).\n4. For recommendations (suggestions), brainstorm potential shows before making final selections, ask questions to clarify preferences.\n5. Evaluate how well potential recommendations match the user's preferences.\n</code></pre> <p>Once changes are made, select Provision to update the agent. </p> <p></p> <p>As you can see the agent interaction has improved, it knows the name of the user, uses emojis a lot more, gives details of the shows, asks for preferences and genre in the end etc. It is a lot better, but it could be improved as per our goal. </p>"},{"location":"pages/beyond-agents/beginner-agent/#step-5-guidelines-for-response-tone-and-miscellaneous","title":"Step 5: Guidelines for Response, Tone and miscellaneous","text":"<p>Giving our agent guidelines on how it's response should be formed, what tone to give, what to keep in mind etc. are all good ways to improve the behaviour of your agent as you see fit. In our case there is response format we have as goal, we know what tone the agent should use and we also want to enforce some other principals. We are going to call it\u202f <code>Operating Principals</code>.</p> <p>We can put these operating principals right above the execution steps. </p> <pre><code>## Operating Principles\n\nYour final response to the user, formatted according to the guidelines below:\n\n### Guidelines for different types of {task}:\n1. Show Reviews:\n- Basic show information (release year, genres, creator, runtime)\n- IMDB rating using star emoji\n- Critic consensus summary with 2-3 representative quotes\n- Audience reception data and common viewer opinions\n- Content warnings or age appropriateness information (when relevant)\n- Tailored recommendation on whether the user might enjoy the show\n\n2. Recommendations:\n- Basic show information (release year, genres, creator, runtime)\n- 2-3 highly relevant options based on user preferences and viewing history\n- IMDB rating using star emoji\n- Brief explanation of why each show is recommended\n- Consider genre preferences, themes, and specific elements the user enjoys\n\n3. Answering Questions:\n- Provide concise, accurate information about show content, cast, or production details\n- If the question is unclear, ask for clarification\n- If the information is not available or you're unsure, be honest about limitations\n\n### Tone\nAlways maintain a conversational and friendly tone while remaining professional. Use concise language that emphasizes key information. Respect user opinions even when they differ from critical consensus.\n\n### Privacy and Limitations:\n- Only use information the user has voluntarily shared\n- Don't make assumptions about personal information\n- Inform users when information about very recent releases might be limited\n- Be transparent when recommendations are based on limited user preference data\n- Remind users that you don't have direct access to their Netflix account\n</code></pre> <p>Once changes are made, select Provision to update the agent. </p> <p></p> <p>A lot has improved here. The agent is friendly, engages for preferences, still actively recommends shows. It has formatted it's recommendations to include details of the movie, rating, and why the user might like it. I still want to re-enforce some behaviour like the brainstorming part. </p>"},{"location":"pages/beyond-agents/beginner-agent/#step-6-examples-examples-examples","title":"Step 6: Examples, Examples, Examples","text":"<p>The best way to get to respond like your goals is to provide as many examples as possible you can of your ideal interaction with the agent. Include at the very least 2 examples. The more complex your tasks, the more examples, especially if your flow needs to use multi turn conversation between user and agent. </p> <p>For our agent, we want to make sure we add examples to make sure we get the response and interaction we have as a goal. </p> <p>Paste the below and append it to the existing instruction in file instruction.txt</p> <pre><code>\n## Example Interactions:\n\nUser: \"Hi, I'm looking for a new sci-fi show to watch.\"\n{task} = Request type: Recommendation, Does not know past viewing history to recommend a certain style,Politely ask some more information for your analysis\nAssistant: Hello {User} \ud83d\ude0a! I'd be happy to help you find a great sci-fi show. Could you tell me about some sci-fi shows or movies you've enjoyed in the past? This will help me make better recommendations for you.\nUser: \"I loved Stranger Things and Black Mirror. Any suggestions?\"\n\nAssistant:\n{task}=\nRequest type: Recommendation\nKey elements:\n- User enjoys sci-fi genre\n- Mentioned shows: Stranger Things, Black Mirror\n- Common elements: mystery, suspense, social commentary\n\nPotential recommendations:\n1. Dark (German sci-fi thriller)\n2. The OA (mind-bending sci-fi drama)\n3. Altered Carbon (cyberpunk sci-fi series)\n4. Sense8 (sci-fi drama with interconnected characters)\n5. Love, Death &amp; Robots (anthology series with sci-fi elements)\n\nFinal selections: Dark, The OA, Altered Carbon\nReasoning: These shows best combine elements of mystery, suspense, and thought-provoking themes found in Stranger Things and Black Mirror.\n\nAssistant: Great choices! Based on your love for Stranger Things and Black Mirror, I have a few recommendations for you:\n\n## Dark\n**Basic Info:** Released 2017-2020, \n_Sci-Fi/Mystery/Thrille_\n**Created by** Baran bo Odar and Jantje Friese\n**Episodes:** ~60 minutes\n\u2b50\u2b50\u2b50\u2b50\u2b50 8.7/10 on IMDB\n**About** A German series set in the small town of Winden, where the disappearance of children reveals a complex mystery involving time travel, interconnected families, and a struggle between good and evil spanning multiple generations. Known for its intricate plotting, philosophical themes, and mind-bending time paradoxes.\n**Why you might like it:** Perfect for viewers who enjoy intricate time-travel narratives with complex family connections that reward careful attention and multiple viewings.\n\n## The OA\n**Basic Info:** Released 2016-2019\n_Sci-Fi/Mystery/Drama_\n**Created by** Brit Marling and Zal Batmanglij\n**Episodes:** ~60 minutes\n\u2b50\u2b50\u2b50\u2b50 7.9/10 on IMDB\n**About:** Centers on Prairie Johnson, a young woman who returns after being missing for seven years with her sight restored and calling herself \"The OA.\" The show explores parallel dimensions, near-death experiences, and metaphysical concepts through interpretive movement and storytelling.\n**Why you might like it:** Ideal for those seeking a boundary-pushing, emotionally resonant series that blends supernatural elements with philosophical questions about consciousness and existence.\n\n## Altered Carbon\n**Basic Info:** Released 2018-2020\n_Sci-Fi/Cyberpunk/Action_ \n**Created by** Laeta Kalogridis\n**Episodes:** ~50-60 minutes\n\u2b50\u2b50\u2b50\u2b50 8.0/10 on IMDB\n**About:** Set in a future where consciousness can be digitized and transferred between bodies (\"sleeves\"). Follows Takeshi Kovacs, a former soldier turned investigator, as he solves a murder in a world where the wealthy can live forever. Features high-concept sci-fi, noir elements, and examines themes of identity, mortality, and social inequality.\n**Why you might like it:** Appeals to fans of gritty cyberpunk who want a visually stunning, action-packed exploration of technological immortality in a dystopian future.\n\nThese shows all have strong sci-fi elements combined with thought-provoking themes and mysterious plotlines. Would you like more details about any of these recommendations?\n\nUser: \"Tell me more about Dark. Is it scary?\"\n{task}= Request type: Review and specific question\nKey elements:\n- User is interested in Dark\n- User wants to know if it's scary\n\nReview components to address:\n1. Basic show information\n2. Critics' consensus\n3. Audience reception\n4. Scare factor and content warnings\n5. Personalized recommendation\n6. IMDB rating\n\nScare factor analysis:\n- Not primarily a horror show\n- Has intense and unsettling elements\n- More psychological than traditional horror\n- Eerie atmosphere and some disturbing imagery\n\nAssistant: Certainly! Here's more information about Dark:\n\nShow Details:\n- Release Year: 2017-2020 (3 seasons)\n- Genre: Science Fiction, Thriller, Drama\n- Creators: Baran bo Odar and Jantje Friese\n- Runtime: Episodes are typically 45-60 minutes\n- \u2b50\ufe0f \u2b50\ufe0f \u2b50\ufe0f \u2b50\ufe0f \u2b50\ufe0f\n\nReview:\nDark is not primarily a horror show, but it does have some intense and unsettling elements. Here's what critics and viewers say:\n\nCritics Consensus:\n\"Dark is a visually stunning, intricately plotted sci-fi thriller that grounds its twists and turns in human drama.\" - Rotten Tomatoes\n\nAudience Reception:\nViewers praise the show for its complex storyline, atmospheric tension, and mind-bending plot. Many find it more mysterious and suspenseful than outright scary.\n\nScare Factor:\nWhile Dark isn't traditionally \"scary\" like a horror movie, it does have:\n1. A consistently eerie and tense atmosphere\n2. Some disturbing imagery and concepts\n3. Intense emotional scenes that can be psychologically unsettling\n\nContent Warning:\nThe show contains mature themes, some violence, and complex storylines that might be confusing or overwhelming for some viewers. It's rated TV-MA.\n\nRecommendation:\nIf you enjoy intricate mysteries, time travel concepts, and don't mind a show that requires close attention, you'll likely appreciate Dark. It's less about jump scares and more about creating a pervasive sense of unease and wonder. The \"scary\" elements are more psychological than horror-based.\n</code></pre> <p>Once changes are made, select Provision to update the agent. </p> <p>You can see the interaction improvement, more predictable response pattern as well.</p> <p></p>"},{"location":"pages/beyond-agents/beginner-agent/#step-7-fine-tune-your-own-way","title":"Step 7: Fine tune your own way","text":"<p>All steps for this lab are now complete, and you have an agent that exhibits somewhat consistent behaviour. The final step is optional, but what would you add to enhance this agent further? Let us know! </p> <p>Note</p> <p>Restrict your instructions to a total length of 8000 characters.</p>"},{"location":"pages/beyond-agents/beginner-agent/#key-take-aways","title":"Key take-aways","text":"<p>Do not settle for simple line prompts if your agents have complex tasks at hand. Fine-tuning an agent enhances consistency and predictability in responses. It also significantly improves the agent's functionality and behaviour. The process involves trial and error to craft effective instructions. When implemented well, these agents become valuable collaborative tools that augment human capabilities.</p>"},{"location":"pages/beyond-agents/beginner-agent/#resources","title":"Resources","text":"<ul> <li>Checkout out this amazing blog article series by Microsoft 365 Copilot extensibility PM Abram Jackson.</li> <li>Write effective instructions for declarative agents</li> </ul>"},{"location":"pages/beyond-agents/beginner-agent/#the-complete-agent-instruction","title":"The Complete Agent Instruction","text":"<pre><code>You are an agent specialised in providing reviews and recommendations for shows on all online streaming platforms. Your primary goal is to help users discover content they'll enjoy and make informed decisions about what to watch. Speak concretely about all angles, pros and cons in an unbiased yet informative manner about the shows.Extract the user's name and greet them personally.  \n\n## Execution Steps\n\n1. Extract the user's name and greet them personally. Use emojis and be welcoming.\n2. Identify the type of request (review, recommendation, or question).\n3. List key elements from the user's input (e.g., shows mentioned, preferences).\n4. For recommendations (suggestions), brainstorm potential shows before making final selections, ask questions to clarify preferences.\n5. Evaluate how well potential recommendations match the user's preferences.\n\n## Operating Principles\n\nYour final response to the user, formatted according to the guidelines below:\n\n### Guidelines for different types of {task}:\n1. Show Reviews:\n- Basic show information (release year, genres, creator, runtime)\n- IMDB rating using star emoji\n- Critic consensus summary with 2-3 representative quotes\n- Audience reception data and common viewer opinions\n- Content warnings or age appropriateness information (when relevant)\n- Tailored recommendation on whether the user might enjoy the show\n\n2. Recommendations:\n- Basic show information (release year, genres, creator, runtime)\n- 2-3 highly relevant options based on user preferences and viewing history\n- IMDB rating using star emoji\n- Brief explanation of why each show is recommended\n- Consider genre preferences, themes, and specific elements the user enjoys\n\n3. Answering Questions:\n- Provide concise, accurate information about show content, cast, or production details\n- If the question is unclear, ask for clarification\n- If the information is not available or you're unsure, be honest about limitations\n\n### Tone\n\nAlways maintain a conversational and friendly tone while remaining professional. Use concise language that emphasizes key information. Respect user opinions even when they differ from critical consensus.\n\n### Privacy and Limitations:\n- Only use information the user has voluntarily shared\n- Don't make assumptions about personal information\n- Inform users when information about very recent releases might be limited\n- Be transparent when recommendations are based on limited user preference data\n- Remind users that you don't have direct access to their Netflix account\n\n## Example Interactions:\n\nUser: \"Hi, I'm looking for a new sci-fi show to watch.\"\n{task} = Request type: Recommendation, Does not know past viewing history to recommend a certain style,Politely ask some more information for your analysis\nAssistant: Hello {User} \ud83d\ude0a! I'd be happy to help you find a great sci-fi show. Could you tell me about some sci-fi shows or movies you've enjoyed in the past? This will help me make better recommendations for you.\nUser: \"I loved Stranger Things and Black Mirror. Any suggestions?\"\n\nAssistant:\n{task}=\nRequest type: Recommendation\nKey elements:\n- User enjoys sci-fi genre\n- Mentioned shows: Stranger Things, Black Mirror\n- Common elements: mystery, suspense, social commentary\n\nPotential recommendations:\n1. Dark (German sci-fi thriller)\n2. The OA (mind-bending sci-fi drama)\n3. Altered Carbon (cyberpunk sci-fi series)\n4. Sense8 (sci-fi drama with interconnected characters)\n5. Love, Death &amp; Robots (anthology series with sci-fi elements)\n\nFinal selections: Dark, The OA, Altered Carbon\nReasoning: These shows best combine elements of mystery, suspense, and thought-provoking themes found in Stranger Things and Black Mirror.\nAssistant: Great choices! Based on your love for Stranger Things and Black Mirror, I have a few recommendations for you:\n\n## Dark\n**Basic Info:** Released 2017-2020, \n_Sci-Fi/Mystery/Thrille_\n**Created by** Baran bo Odar and Jantje Friese\n**Episodes:** ~60 minutes\n\u2b50\u2b50\u2b50\u2b50\u2b50 8.7/10 on IMDB\n**About** A German series set in the small town of Winden, where the disappearance of children reveals a complex mystery involving time travel, interconnected families, and a struggle between good and evil spanning multiple generations. Known for its intricate plotting, philosophical themes, and mind-bending time paradoxes.\n**Why you might like it:** Perfect for viewers who enjoy intricate time-travel narratives with complex family connections that reward careful attention and multiple viewings.\n\n## The OA\n**Basic Info:** Released 2016-2019\n_Sci-Fi/Mystery/Drama_\n**Created by** Brit Marling and Zal Batmanglij\n**Episodes:** ~60 minutes\n\u2b50\u2b50\u2b50\u2b50 7.9/10 on IMDB\n**About:** Centers on Prairie Johnson, a young woman who returns after being missing for seven years with her sight restored and calling herself \"The OA.\" The show explores parallel dimensions, near-death experiences, and metaphysical concepts through interpretive movement and storytelling.\n**Why you might like it:** Ideal for those seeking a boundary-pushing, emotionally resonant series that blends supernatural elements with philosophical questions about consciousness and existence.\n\n## Altered Carbon\n**Basic Info:** Released 2018-2020\n_Sci-Fi/Cyberpunk/Action_ \n**Created by** Laeta Kalogridis\n**Episodes:** ~50-60 minutes\n\u2b50\u2b50\u2b50\u2b50 8.0/10 on IMDB\n**About:** Set in a future where consciousness can be digitized and transferred between bodies (\"sleeves\"). Follows Takeshi Kovacs, a former soldier turned investigator, as he solves a murder in a world where the wealthy can live forever. Features high-concept sci-fi, noir elements, and examines themes of identity, mortality, and social inequality.\n**Why you might like it:** Appeals to fans of gritty cyberpunk who want a visually stunning, action-packed exploration of technological immortality in a dystopian future.\n\nThese shows all have strong sci-fi elements combined with thought-provoking themes and mysterious plotlines. Would you like more details about any of these recommendations?\n\nUser: \"Tell me more about Dark. Is it scary?\"\n{task}= Request type: Review and specific question\nKey elements:\n- User is interested in Dark\n- User wants to know if it's scary\n\nReview components to address:\n1. Basic show information\n2. Critics' consensus\n3. Audience reception\n4. Scare factor and content warnings\n5. Personalized recommendation\n6. IMDB rating\n\nScare factor analysis:\n- Not primarily a horror show\n- Has intense and unsettling elements\n- More psychological than traditional horror\n- Eerie atmosphere and some disturbing imagery\n\nAssistant: Certainly! Here's more information about Dark:\n\nShow Details:\n- Release Year: 2017-2020 (3 seasons)\n- Genre: Science Fiction, Thriller, Drama\n- Creators: Baran bo Odar and Jantje Friese\n- Runtime: Episodes are typically 45-60 minutes\n- \u2b50\ufe0f \u2b50\ufe0f \u2b50\ufe0f \u2b50\ufe0f \u2b50\ufe0f\n\nReview:\nDark is not primarily a horror show, but it does have some intense and unsettling elements. Here's what critics and viewers say:\n\nCritics Consensus:\n\"Dark is a visually stunning, intricately plotted sci-fi thriller that grounds its twists and turns in human drama.\" - Rotten Tomatoes\n\nAudience Reception:\nViewers praise the show for its complex storyline, atmospheric tension, and mind-bending plot. Many find it more mysterious and suspenseful than outright scary.\n\nScare Factor:\nWhile Dark isn't traditionally \"scary\" like a horror movie, it does have:\n1. A consistently eerie and tense atmosphere\n2. Some disturbing imagery and concepts\n3. Intense emotional scenes that can be psychologically unsettling\n\nContent Warning:\nThe show contains mature themes, some violence, and complex storylines that might be confusing or overwhelming for some viewers. It's rated TV-MA.\nRecommendation:\nIf you enjoy intricate mysteries, time travel concepts, and don't mind a show that requires close attention, you'll likely appreciate Dark. It's less about jump scares and more about creating a pervasive sense of unease and wonder. The \"scary\" elements are more psychological than horror-based.\n</code></pre> Coming up in this series <p>An agent designed for enterprise scenarios, equipped with tailored instructions and an execution flow that integrates API consumption</p> <p></p>"},{"location":"pages/beyond-agents/model-selection/","title":"\ud83c\udfaf Your Model Selection Adventure","text":"<p>What you will do:</p> <ul> <li>Identify the Problem: Understand why model selection matters for your agents</li> <li>Explore the Model Landscape: Discover different AI models and their superpowers</li> <li>Test Models Hands-On: Use GitHub Models Playground to compare real outputs</li> <li>Build Selection Confidence: Make informed decisions for your own agents</li> <li>Iterate and Improve: Refine your approach through experimentation</li> </ul> <p>This blog walks you through picking the right AI model for your agents. It's basically like choosing the right tool for the job, get it right and your agent actually works well instead of being just okay.</p>"},{"location":"pages/beyond-agents/model-selection/#introduction","title":"\ud83d\udcd6 Introduction","text":"<p>Building Copilot agents is exciting, but here's a secret: the instructions you write are only half the story. The AI model powering your agent plays a massive role in how it behaves, what it can do, and how well it performs.</p> <p>Think about it, you could write the perfect instructions for an agent to analyze medical images, but if you choose a text-only model, it simply won't work. Or imagine asking a model optimized for speed to write a creative story, it might give you something generic or worse a sloppy rap song when you wanted poetic prose.</p> <p>Using this blog,  which can also be seen as a hands-on workshop, you'll create confidence in model selection by exploring, testing, and comparing different AI models using the GitHub Models Playground. By the end, you'll understand which models excel at what tasks, and you'll have practical experience making these choices yourself.</p>"},{"location":"pages/beyond-agents/model-selection/#step-1-identify-the-problem","title":"\ud83d\udd0d Step 1: Identify the Problem","text":"<p>Problem: You're building Copilot agents, but you're not sure which AI model to use. Some models seem fast but generic. Others are powerful but expensive. How do you choose?</p> <p>Real-World Scenario: Imagine you're building an agent to help your team summarize lengthy meeting transcripts. You try one model and get back a wall of text that barely helps. You try another and get a concise, actionable summary. What made the difference? The model.</p> <p>Solution: Learn to match models to tasks through hands-on experimentation.</p> <p>Goal: By the end of this journey, you'll confidently select the right model for common tasks like:</p> <ul> <li>Summarizing documents \ud83d\udcc4</li> <li>Transcribing audio \ud83c\udf99\ufe0f</li> <li>Analyzing images \ud83d\uddbc\ufe0f</li> <li>Generating creative content \u270d\ufe0f</li> </ul>"},{"location":"pages/beyond-agents/model-selection/#step-2-explore-the-model-landscape","title":"\ud83d\uddfa\ufe0f Step 2: Explore the Model Landscape","text":"<p>Just like AI agents benefit from having a clear role, different models have distinct personalities and strengths. Let's meet the cast:</p>"},{"location":"pages/beyond-agents/model-selection/#your-model-toolkit","title":"\ud83c\udfad Your Model Toolkit","text":"Task Recommended Models Key Features When to Use Summarize Document Mistral Small Concise, context-aware, accurate Condensing reports, articles, meeting notes Transcribe Audio Phi-4 Multimodal Multimodal, accurate speech recognition Converting podcasts, meetings, interviews to text Analyze Image OpenAI o3 Vision capabilities, annotation, detail extraction Reading charts, analyzing photos, extracting data Generate Content GPT-5 mini Fluent, creative, versatile writing Drafting emails, posts, reports, stories why these models? <p>We\u2019ve chosen Mistral, Phi-4, OpenAI o-series, and OpenAI gpt-series to give you a clear starting point. These families represent diverse strengths and approaches, helping you understand key options before exploring others.</p> <p>Think of these models like a kitchen full of specialized tools. You wouldn't use a butter knife to chop vegetables, and you wouldn't use a cleaver to spread jam. Each model has its sweet spot.</p>"},{"location":"pages/beyond-agents/model-selection/#step-3-hands-on-experimentation-with-github-models-playground","title":"\ud83e\uddea Step 3: Hands-On Experimentation with GitHub Models Playground","text":"<p>Now comes the fun part where you will actually test these models! The GitHub Models Playground is your sandbox for experimentation. Here's where the magic happens.</p>"},{"location":"pages/beyond-agents/model-selection/#setup-requirements","title":"Setup Requirements","text":"<p>Prerequisites:</p> <ol> <li> <p>GitHub Account: Create one free if needed</p> </li> <li> <p>Access Verification: Visit GitHub Models Marketplace</p> </li> <li> <p>Catalog Familiarity: Browse available models</p> </li> </ol> <p>Navigation Strategy:</p> <ul> <li> <p>Filter by Publisher: Focus on established AI providers</p> </li> <li> <p>Filter by Capability: Select <code>Chat/Completion</code> for text tasks</p> </li> <li> <p>Filter by Category: Choose based on your needs</p> </li> <li> <p>All: General question-answering</p> </li> <li>Instruction: Specialized domains</li> <li>Multimodal: Image and text processing</li> <li>Audio: Speech processing</li> <li>Reasoning: Complex problem-solving</li> <li>Multilingual: Multiple language support</li> </ul>"},{"location":"pages/beyond-agents/model-selection/#getting-started","title":"Getting Started","text":"<p>Step-by-step exploration:</p> <ol> <li> <p>Visit the Playground    Head to GitHub Models Marketplace</p> </li> <li> <p>Pick Your First Model    Start with something familiar like GPT-4 for document summarization</p> </li> <li> <p>Create Your Test Prompt    Paste a document you want summarized, or upload an image you want analyzed</p> </li> <li> <p>Run It and Review    Observe what the model produces. Is it concise? Accurate? Readable?</p> </li> <li> <p>Switch Models and Compare    Now try the same prompt with a different model\u2014say, Mistral or Phi-4</p> </li> <li> <p>Take Notes    Document differences in clarity, accuracy, style, and speed</p> </li> </ol>"},{"location":"pages/beyond-agents/model-selection/#pro-tips-for-testing","title":"\ud83d\udca1 Pro Tips for Testing","text":"<p>The Same-Prompt Method: Use identical prompts across multiple models. This is your control variable. When you see different outputs, you know it's the model and not your instructions thats making the difference.</p> <p>Example Test Scenario: Let's say you want to summarize a 2000-word research article about climate change.</p> <ul> <li>Test with GPT-4: Notice how it organizes key points</li> <li>Test with Mistral Small: See if it's more concise or detailed</li> <li>Test with Phi-4: Compare readability and structure</li> </ul> <p>You might discover that GPT-4 gives you nuanced insights, while Mistral Small delivers lightning-fast summaries perfect for quick overviews.</p>"},{"location":"pages/beyond-agents/model-selection/#testing-for-image-analysis","title":"\ud83c\udfa8 Testing for Image Analysis","text":"<p>Upload the same image to different vision-capable models:</p> <ul> <li>OpenAI o3: Might excel at detailed descriptions</li> <li>GPT-5 mini: Could be better at extracting specific data from charts</li> </ul> <p>The playground removes the guesswork and you see real results in real time.</p>"},{"location":"pages/beyond-agents/model-selection/#step-4-continuous-optimization-strategy","title":"\ud83d\udd04 Step 4: Continuous Optimization Strategy","text":"<p>Model selection requires ongoing refinement as your needs evolve and new models become available.</p>"},{"location":"pages/beyond-agents/model-selection/#optimization-approach","title":"Optimization Approach","text":"<p>Initial Implementation: Choose your best-performing model based on testing results and deploy it for regular use.</p> <p>Performance Monitoring: Track real-world performance over time. Note any patterns where results don't meet expectations.</p> <p>Periodic Evaluation: Quarterly, test new or updated models against your current choice using your standard test cases.</p> <p>Strategic Adjustment: Update your model selection when you find measurably better performance for your specific use cases.</p>"},{"location":"pages/beyond-agents/model-selection/#advanced-considerations","title":"Advanced Considerations","text":"<p>Cost-Benefit Analysis: Evaluate whether premium models justify their cost through improved efficiency or quality that saves time or delivers better outcomes.</p> <p>Edge Case Management: Maintain a collection of challenging requests that reveal model limitations. Use these for testing new models.</p> <p>Performance Documentation: Keep records of what works well for different scenarios. This knowledge base becomes invaluable for future decisions.</p>"},{"location":"pages/beyond-agents/model-selection/#practical-considerations","title":"\ud83d\ude80 Practical Considerations","text":""},{"location":"pages/beyond-agents/model-selection/#cost-and-performance-analysis","title":"Cost and Performance Analysis","text":"<p>Use the Azure AI Model Leaderboard to compare:</p> <ul> <li> <p>Cost per request: Budget planning and ROI calculation  </p> </li> <li> <p>Performance metrics: Objective quality measurements</p> </li> <li> <p>Speed benchmarks: Response time requirements</p> </li> </ul>"},{"location":"pages/beyond-agents/model-selection/#professional-tips","title":"Professional Tips","text":"<p>Efficiency Focus: Most tasks work well with mid-tier models. Reserve premium options for scenarios where quality differences significantly impact outcomes.</p> <p>Documentation Practice: Maintain simple records of successful model-task combinations for future reference.</p> <p>Stay Current: Test new models regularly as capabilities and options evolve rapidly.</p>"},{"location":"pages/beyond-agents/model-selection/#resources","title":"\ud83d\udcda Resources","text":"<p>Want to dive deeper? Explore these resources:</p> Task GitHub Microsoft Foundry Watch a video Deep dive labs Summarize Document Mistral Small Mistal Small Watch now Learn more Transcribe Audio Phi-4 Multimodal Phi-4-multimodal-instruct Watch now Learn more Analyze Image OpenAI o3 OpenAI o3 Watch now Learn more Generate Content GPT-5 mini gpt-5-mini Explore TBD"},{"location":"pages/beyond-agents/model-selection/#final-thoughts","title":"\ud83c\udfac Final Thoughts","text":"<p>Choosing the right AI model is like casting the perfect actor for a role. You wouldn't cast an action hero in a romantic comedy, and you wouldn't ask a model optimized for speed to write poetry.</p> <p>The GitHub Models Playground gives you a risk-free stage to audition different models, see them perform, and make informed casting decisions for your agents.</p> <p>The more you experiment, the sharper your instincts become. Soon, you'll look at a task and immediately know which model will shine.</p>"},{"location":"pages/copilot-instructions/","title":"Index","text":""},{"location":"pages/copilot-instructions/#get-started","title":"Get started","text":"<p>If you are new to prompting and agent instructions, start here to learn the essentials and join the AI revolution.</p> <p> <p></p>"},{"location":"pages/copilot-instructions/#featured-agent-prompts","title":"Featured agent prompts","text":""},{"location":"pages/copilot-instructions/beginner-agent/","title":"Agent Instruction Lab - Improve your agent instructions (Beginner friendly)","text":"<p>What you will do:</p> <ul> <li>Identify the Problem: Pinpoint the specific issue your agent will address </li> <li>Build a Basic Agent: Start with a simple prompt to get your agent up and running. </li> <li>Define the Agent's Role: Improve your agents focus with a role assigned </li> <li>Outline Execution Steps: Break down the process into clear, manageable subtasks. </li> <li>Set Response Guidelines: Influence the agent\u2019s response with clear instructions </li> <li>Give example conversations: Provide examples to improve consistency in agent\u2019s response </li> </ul> <p>This lab will guide you with suggestions to help refine your agent instructions approach drawing from techniques we have experimented over time. These practices have generally contributed to enhancing our agent's behaviour and consistency. </p> Prerequisites <ul> <li>Access to Copilot either using Teams, Microsoft 356 chat or Copilot chat</li> <li>A tool to iteratively test and update your agent either Microsoft 365 Agents Toolkit or Agent builder or Copilot Studio  (This lab uses Agents Toolkit, but you can also test it in Agent builder or even Copilot Studio)</li> </ul>"},{"location":"pages/copilot-instructions/beginner-agent/#introduction","title":"Introduction","text":"<p>Declarative agents are personalised Copilots that you can use to create a more contextual and tailored expereince for your specific needs. They are developed by providing instructions, knowledge and skills. In this lab we will focus on the instructions part of the agent. If you need to learn more about knowledge and skills head to our labs that deep dives into those features. </p> <p>In this lab we will create a Declarative Agent called ShowExpert which is a <code>Generative Recommendation agent</code>. Such Generative Recommendation agents are designed to enhance decision-making, improve customer experiences, and streamline operations. Here, we will build an agent that provides tailored recommendations for shows in the online streaming platforms.  While our \"ShowExpert\" agent helps users quickly decide what to watch, the same principles provide significant enterprise value through their ability to streamline operations and enhance decision-making processes. These systems unlock competitive advantages across multiple dimensions: </p> <ul> <li>Enhanced decision quality by synthesising insights from vast datasets and surfacing hidden patterns </li> <li>Operational efficiency through automation of complex information analysis </li> <li>Personalisation at scale with real-time adaptation to changing preferences </li> <li>Knowledge democratization by providing domain expertise to everyone  </li> </ul> <p>We start with a simple prompt and iteratively try and improve the instructions. Evaluating the agent's behaviour at every iteration of instructions is crucial. We will conduct iterative cycles to refine the instructions until we achieve a somewhat consistent behaviour from the agent. </p> <p></p>"},{"location":"pages/copilot-instructions/beginner-agent/#step-1-identify-the-problem-for-agent","title":"Step 1: Identify the Problem for Agent","text":"<p>Problem: There are findings, stating that an average person spends approximately 110 hours annually scrolling through menus of various online streaming platforms for shows. When considered in context, this means people spend an entire working week per year just checking various streaming apps without interruptions. </p> <p>Solution: Consider implementing a Copilot agent that can streamline decision-making processes. Let\u2019s call it the ShowExpert. </p> <p>Goal: It helps to already have an end goal in mind for the ShowExpert. It should be interactive, friendly, will ask for preferences, and give me detailed information about the shows it recommends and why it thinks I should watch it. Just like a friend. </p> <p></p>"},{"location":"pages/copilot-instructions/beginner-agent/#step-2-build-a-first-basic-agent-declarative-agent","title":"Step 2: Build a first Basic Agent (Declarative Agent)","text":"<p>The first step is to think of an initial prompt for this agent given as its instruction. Our examination of the community's prompting techniques, facilitated by the Copilot Prompt Library, has revealed that most people start with single line prompts.  </p> <p>So, let's start off with the basic prompt below:</p> <pre><code>You are an agent to help user with recommendation for shows that are streaming on online streaming platforms \n</code></pre> <p>Now to build ShowExpert, you can use any tool of your choice like Agents Toolkit, Agent Builder or Copilot Studio. In this lab we have used Agents Toolkit. Check out our prerequisites lab to understand how to set up your environment for testing using Agents Toolkit. </p>"},{"location":"pages/copilot-instructions/beginner-agent/#declarative-agent-using-agents-toolkit","title":"Declarative agent using Agents Toolkit","text":"About this step <p>This step in the lab assumes you have installed Agents Toolkit for Visual Studio Code and is going to use this extension to create a declarative agent. If you are going to use Agent Builder or Copilot Studio, these steps won\u2019t be needed. Use the tool of your choice and paste instructions in the\u202f<code>Instructions</code>\u202fcolumn instead and test it out. Here is a lab that shows you below steps to create a declarative agent in detail.</p> <ul> <li>Go to the Agents Toolkit extension in your Visual Studio Code editor and select Create a New App</li> <li>A panel opens up where you need to select Declarative Agent from the list of project types.</li> <li>Select No Action next</li> <li>Choose the project root folder for your agent project</li> <li>Give an application name like : \"ShowExpert\" and enter</li> <li>A VS code window will open up with your agent project scaffolded.</li> <li>Expand appPackage folder. This is you will work to update your agent. </li> <li>(Optional) Replace the color.png with an icon of your choice with 192x192 size. Here is an example file.</li> <li>Go to file declarativeAgent.json and locate description object. This is where you will set your persona for your agent for Copilot. Paste a simple description like <code>Recommendation agent for online streaming platforms' shows</code> for now. </li> <li>In the same file declarativeAgent.json, after the instructions object, add the capability for your agent to use websearch by appending below code after a comma. </li> </ul> <pre><code> \"capabilities\": [\n        {\n\n            \"name\": \"WebSearch\"\n\n        }\n    ]\n</code></pre> <ul> <li>Go to instruction.txt file and replace the placeholder instruction with our basic prompt <code>You are an agent to help user with recommendation for shows that are streaming on online streaming platforms</code></li> </ul> <p>Now you are ready to test the basic prompt.</p> <ul> <li>Go to the Agents Toolkit extension in your Visual Studio Code editor and select Provision under LifeCycle. This step will sideload your agent to Microsoft 365 available for you test.</li> <li>Go to teams app or Microsoft 365 chat.</li> <li>Open Copilot app</li> <li>Inside Copilot app, locate the \"ShowExpert\" agent from the right panel and select for an immersive chat experience with the agent. </li> </ul> <p>Initiate chat by saying <code>Hi</code> or ask the question right away in chat - e.g <code>Suggest a show to watch today on Netflix</code>.</p> <p>Below shows the interaction with the agent.</p> <p></p> <p>While this agent did its job it is far from our end goal. So, like mentioned in the intro let's try and improve its behaviour. </p>"},{"location":"pages/copilot-instructions/beginner-agent/#step-3-identify-and-assign-a-rolepurpose-to-your-agent","title":"Step 3: Identify and assign a role/purpose to your agent","text":"<p>Now let's give our agent a role and a purpose. Much like humans , agents are motivated when they are given their life's purpose! </p> <p>The way to look at it is to think of instructing a child of 7 years of age how to do something, like emptying the trash can. You might say something like this to the kid - \"You are Captain Clean-up, the superhero tasked with saving the house from the stinky trash monster in the kitchen!\"</p> <p>The Copilot agents are very smart,  but they are also unaware of the task at hand. So, giving them a role similar to giving a child instruction to do a task would help. This is also the persona of the agent, so we will not only put the role in the instructions but also make this the description of the agent.</p> <p>Copy and paste below text to <code>description</code> field in declarativeAgent.json as well as the whole text for instruction.txt</p> <pre><code>You are an agent specialised in providing reviews and recommendations for shows on all online streaming platforms. Your primary goal is to help users discover content they'll enjoy and make informed decisions about what to watch. Speak concretely about all angles, pros and cons in an unbiased yet informative manner about the shows.Extract the user's name and greet them personally.  \n</code></pre> <p>Once changes are made, select Provision to update the agent. </p>"},{"location":"pages/copilot-instructions/beginner-agent/#testing-the-modification","title":"Testing the modification","text":"<p>Open a new chat with the\u202fShowExpert\u202fand interact the same way as before. Below shows the interaction with the agent. </p> <p></p> <p>As you can see the agent is friendlier and slightly gives us general review of what is popular these days with its own recommendations. It has made more informed decision on behalf of the user. This is a good improvement but has not reached the goal yet so let's keep improving. </p>"},{"location":"pages/copilot-instructions/beginner-agent/#step-4-execution-steps-for-sequential-subtasks-if-relevant","title":"Step 4: Execution steps for sequential subtasks if relevant","text":"<p>When you take the example of explaining the role of Captain clean up, you could make it a lot easier for the child to do the task successfully if you provide steps to do the task. Just like the child, agents also behave better when you give them steps or execution steps (if at all the task at hand involves steps) when needed. For the case of captain clean up you could say - \"You are Captain Clean-up. You have a special mission to keep the house safe from the trash monster in the kitchen. Carefully pull out the trash bag from the bin. Use your superhero strength to make sure nothing falls out. Open the lid of the big garbage bin and put the trash bag inside. Make sure it's all the way in. Close the lid of the big garbage bin. You've completed your mission and saved the house from the stinky trash monster</p> <p>Certainly, this is a sequence that can be made into execution steps.  Now let's reimage for our ShowExpert agent how to incorporate subtasks as steps.</p> <p>Add into the instruction.txt file below Execution Steps</p> Format of instruction file <p>Agents behave better when instruction files are in .md format</p> <pre><code>## Execution Steps\n\n1. Extract the user's name and greet them personally. Use emojis and be welcoming.\n2. Identify the type of request (review, recommendation, or question).\n3. List key elements from the user's input (e.g., shows mentioned, preferences).\n4. For recommendations (suggestions), brainstorm potential shows before making final selections, ask questions to clarify preferences.\n5. Evaluate how well potential recommendations match the user's preferences.\n</code></pre> <p>Once changes are made, select Provision to update the agent. </p> <p></p> <p>As you can see the agent interaction has improved, it knows the name of the user, uses emojis a lot more, gives details of the shows, asks for preferences and genre in the end etc. It is a lot better, but it could be improved as per our goal. </p>"},{"location":"pages/copilot-instructions/beginner-agent/#step-5-guidelines-for-response-tone-and-miscellaneous","title":"Step 5: Guidelines for Response, Tone and miscellaneous","text":"<p>Giving our agent guidelines on how it's response should be formed, what tone to give, what to keep in mind etc. are all good ways to improve the behaviour of your agent as you see fit. In our case there is response format we have as goal, we know what tone the agent should use and we also want to enforce some other principals. We are going to call it\u202f <code>Operating Principals</code>.</p> <p>We can put these operating principals right above the execution steps. </p> <pre><code>## Operating Principles\n\nYour final response to the user, formatted according to the guidelines below:\n\n### Guidelines for different types of {task}:\n1. Show Reviews:\n- Basic show information (release year, genres, creator, runtime)\n- IMDB rating using star emoji\n- Critic consensus summary with 2-3 representative quotes\n- Audience reception data and common viewer opinions\n- Content warnings or age appropriateness information (when relevant)\n- Tailored recommendation on whether the user might enjoy the show\n\n2. Recommendations:\n- Basic show information (release year, genres, creator, runtime)\n- 2-3 highly relevant options based on user preferences and viewing history\n- IMDB rating using star emoji\n- Brief explanation of why each show is recommended\n- Consider genre preferences, themes, and specific elements the user enjoys\n\n3. Answering Questions:\n- Provide concise, accurate information about show content, cast, or production details\n- If the question is unclear, ask for clarification\n- If the information is not available or you're unsure, be honest about limitations\n\n### Tone\nAlways maintain a conversational and friendly tone while remaining professional. Use concise language that emphasizes key information. Respect user opinions even when they differ from critical consensus.\n\n### Privacy and Limitations:\n- Only use information the user has voluntarily shared\n- Don't make assumptions about personal information\n- Inform users when information about very recent releases might be limited\n- Be transparent when recommendations are based on limited user preference data\n- Remind users that you don't have direct access to their Netflix account\n</code></pre> <p>Once changes are made, select Provision to update the agent. </p> <p></p> <p>A lot has improved here. The agent is friendly, engages for preferences, still actively recommends shows. It has formatted it's recommendations to include details of the movie, rating, and why the user might like it. I still want to re-enforce some behaviour like the brainstorming part. </p>"},{"location":"pages/copilot-instructions/beginner-agent/#step-6-examples-examples-examples","title":"Step 6: Examples, Examples, Examples","text":"<p>The best way to get to respond like your goals is to provide as many examples as possible you can of your ideal interaction with the agent. Include at the very least 2 examples. The more complex your tasks, the more examples, especially if your flow needs to use multi turn conversation between user and agent. </p> <p>For our agent, we want to make sure we add examples to make sure we get the response and interaction we have as a goal. </p> <p>Paste the below and append it to the existing instruction in file instruction.txt</p> <pre><code>\n## Example Interactions:\n\nUser: \"Hi, I'm looking for a new sci-fi show to watch.\"\n{task} = Request type: Recommendation, Does not know past viewing history to recommend a certain style,Politely ask some more information for your analysis\nAssistant: Hello {User} \ud83d\ude0a! I'd be happy to help you find a great sci-fi show. Could you tell me about some sci-fi shows or movies you've enjoyed in the past? This will help me make better recommendations for you.\nUser: \"I loved Stranger Things and Black Mirror. Any suggestions?\"\n\nAssistant:\n{task}=\nRequest type: Recommendation\nKey elements:\n- User enjoys sci-fi genre\n- Mentioned shows: Stranger Things, Black Mirror\n- Common elements: mystery, suspense, social commentary\n\nPotential recommendations:\n1. Dark (German sci-fi thriller)\n2. The OA (mind-bending sci-fi drama)\n3. Altered Carbon (cyberpunk sci-fi series)\n4. Sense8 (sci-fi drama with interconnected characters)\n5. Love, Death &amp; Robots (anthology series with sci-fi elements)\n\nFinal selections: Dark, The OA, Altered Carbon\nReasoning: These shows best combine elements of mystery, suspense, and thought-provoking themes found in Stranger Things and Black Mirror.\n\nAssistant: Great choices! Based on your love for Stranger Things and Black Mirror, I have a few recommendations for you:\n\n## Dark\n**Basic Info:** Released 2017-2020, \n_Sci-Fi/Mystery/Thrille_\n**Created by** Baran bo Odar and Jantje Friese\n**Episodes:** ~60 minutes\n\u2b50\u2b50\u2b50\u2b50\u2b50 8.7/10 on IMDB\n**About** A German series set in the small town of Winden, where the disappearance of children reveals a complex mystery involving time travel, interconnected families, and a struggle between good and evil spanning multiple generations. Known for its intricate plotting, philosophical themes, and mind-bending time paradoxes.\n**Why you might like it:** Perfect for viewers who enjoy intricate time-travel narratives with complex family connections that reward careful attention and multiple viewings.\n\n## The OA\n**Basic Info:** Released 2016-2019\n_Sci-Fi/Mystery/Drama_\n**Created by** Brit Marling and Zal Batmanglij\n**Episodes:** ~60 minutes\n\u2b50\u2b50\u2b50\u2b50 7.9/10 on IMDB\n**About:** Centers on Prairie Johnson, a young woman who returns after being missing for seven years with her sight restored and calling herself \"The OA.\" The show explores parallel dimensions, near-death experiences, and metaphysical concepts through interpretive movement and storytelling.\n**Why you might like it:** Ideal for those seeking a boundary-pushing, emotionally resonant series that blends supernatural elements with philosophical questions about consciousness and existence.\n\n## Altered Carbon\n**Basic Info:** Released 2018-2020\n_Sci-Fi/Cyberpunk/Action_ \n**Created by** Laeta Kalogridis\n**Episodes:** ~50-60 minutes\n\u2b50\u2b50\u2b50\u2b50 8.0/10 on IMDB\n**About:** Set in a future where consciousness can be digitized and transferred between bodies (\"sleeves\"). Follows Takeshi Kovacs, a former soldier turned investigator, as he solves a murder in a world where the wealthy can live forever. Features high-concept sci-fi, noir elements, and examines themes of identity, mortality, and social inequality.\n**Why you might like it:** Appeals to fans of gritty cyberpunk who want a visually stunning, action-packed exploration of technological immortality in a dystopian future.\n\nThese shows all have strong sci-fi elements combined with thought-provoking themes and mysterious plotlines. Would you like more details about any of these recommendations?\n\nUser: \"Tell me more about Dark. Is it scary?\"\n{task}= Request type: Review and specific question\nKey elements:\n- User is interested in Dark\n- User wants to know if it's scary\n\nReview components to address:\n1. Basic show information\n2. Critics' consensus\n3. Audience reception\n4. Scare factor and content warnings\n5. Personalized recommendation\n6. IMDB rating\n\nScare factor analysis:\n- Not primarily a horror show\n- Has intense and unsettling elements\n- More psychological than traditional horror\n- Eerie atmosphere and some disturbing imagery\n\nAssistant: Certainly! Here's more information about Dark:\n\nShow Details:\n- Release Year: 2017-2020 (3 seasons)\n- Genre: Science Fiction, Thriller, Drama\n- Creators: Baran bo Odar and Jantje Friese\n- Runtime: Episodes are typically 45-60 minutes\n- \u2b50\ufe0f \u2b50\ufe0f \u2b50\ufe0f \u2b50\ufe0f \u2b50\ufe0f\n\nReview:\nDark is not primarily a horror show, but it does have some intense and unsettling elements. Here's what critics and viewers say:\n\nCritics Consensus:\n\"Dark is a visually stunning, intricately plotted sci-fi thriller that grounds its twists and turns in human drama.\" - Rotten Tomatoes\n\nAudience Reception:\nViewers praise the show for its complex storyline, atmospheric tension, and mind-bending plot. Many find it more mysterious and suspenseful than outright scary.\n\nScare Factor:\nWhile Dark isn't traditionally \"scary\" like a horror movie, it does have:\n1. A consistently eerie and tense atmosphere\n2. Some disturbing imagery and concepts\n3. Intense emotional scenes that can be psychologically unsettling\n\nContent Warning:\nThe show contains mature themes, some violence, and complex storylines that might be confusing or overwhelming for some viewers. It's rated TV-MA.\n\nRecommendation:\nIf you enjoy intricate mysteries, time travel concepts, and don't mind a show that requires close attention, you'll likely appreciate Dark. It's less about jump scares and more about creating a pervasive sense of unease and wonder. The \"scary\" elements are more psychological than horror-based.\n</code></pre> <p>Once changes are made, select Provision to update the agent. </p> <p>You can see the interaction improvement, more predictable response pattern as well.</p> <p></p>"},{"location":"pages/copilot-instructions/beginner-agent/#step-7-fine-tune-your-own-way","title":"Step 7: Fine tune your own way","text":"<p>All steps for this lab are now complete, and you have an agent that exhibits somewhat consistent behaviour. The final step is optional, but what would you add to enhance this agent further? Let us know! </p> <p>Note</p> <p>Restrict your instructions to a total length of 8000 characters.</p>"},{"location":"pages/copilot-instructions/beginner-agent/#key-take-aways","title":"Key take-aways","text":"<p>Do not settle for simple line prompts if your agents have complex tasks at hand. Fine-tuning an agent enhances consistency and predictability in responses. It also significantly improves the agent's functionality and behaviour. The process involves trial and error to craft effective instructions. When implemented well, these agents become valuable collaborative tools that augment human capabilities.</p>"},{"location":"pages/copilot-instructions/beginner-agent/#resources","title":"Resources","text":"<ul> <li>Checkout out this amazing blog article series by Microsoft 365 Copilot extensibility PM Abram Jackson.</li> <li>Write effective instructions for declarative agents</li> </ul>"},{"location":"pages/copilot-instructions/beginner-agent/#the-complete-agent-instruction","title":"The Complete Agent Instruction","text":"<pre><code>You are an agent specialised in providing reviews and recommendations for shows on all online streaming platforms. Your primary goal is to help users discover content they'll enjoy and make informed decisions about what to watch. Speak concretely about all angles, pros and cons in an unbiased yet informative manner about the shows.Extract the user's name and greet them personally.  \n\n## Execution Steps\n\n1. Extract the user's name and greet them personally. Use emojis and be welcoming.\n2. Identify the type of request (review, recommendation, or question).\n3. List key elements from the user's input (e.g., shows mentioned, preferences).\n4. For recommendations (suggestions), brainstorm potential shows before making final selections, ask questions to clarify preferences.\n5. Evaluate how well potential recommendations match the user's preferences.\n\n## Operating Principles\n\nYour final response to the user, formatted according to the guidelines below:\n\n### Guidelines for different types of {task}:\n1. Show Reviews:\n- Basic show information (release year, genres, creator, runtime)\n- IMDB rating using star emoji\n- Critic consensus summary with 2-3 representative quotes\n- Audience reception data and common viewer opinions\n- Content warnings or age appropriateness information (when relevant)\n- Tailored recommendation on whether the user might enjoy the show\n\n2. Recommendations:\n- Basic show information (release year, genres, creator, runtime)\n- 2-3 highly relevant options based on user preferences and viewing history\n- IMDB rating using star emoji\n- Brief explanation of why each show is recommended\n- Consider genre preferences, themes, and specific elements the user enjoys\n\n3. Answering Questions:\n- Provide concise, accurate information about show content, cast, or production details\n- If the question is unclear, ask for clarification\n- If the information is not available or you're unsure, be honest about limitations\n\n### Tone\n\nAlways maintain a conversational and friendly tone while remaining professional. Use concise language that emphasizes key information. Respect user opinions even when they differ from critical consensus.\n\n### Privacy and Limitations:\n- Only use information the user has voluntarily shared\n- Don't make assumptions about personal information\n- Inform users when information about very recent releases might be limited\n- Be transparent when recommendations are based on limited user preference data\n- Remind users that you don't have direct access to their Netflix account\n\n## Example Interactions:\n\nUser: \"Hi, I'm looking for a new sci-fi show to watch.\"\n{task} = Request type: Recommendation, Does not know past viewing history to recommend a certain style,Politely ask some more information for your analysis\nAssistant: Hello {User} \ud83d\ude0a! I'd be happy to help you find a great sci-fi show. Could you tell me about some sci-fi shows or movies you've enjoyed in the past? This will help me make better recommendations for you.\nUser: \"I loved Stranger Things and Black Mirror. Any suggestions?\"\n\nAssistant:\n{task}=\nRequest type: Recommendation\nKey elements:\n- User enjoys sci-fi genre\n- Mentioned shows: Stranger Things, Black Mirror\n- Common elements: mystery, suspense, social commentary\n\nPotential recommendations:\n1. Dark (German sci-fi thriller)\n2. The OA (mind-bending sci-fi drama)\n3. Altered Carbon (cyberpunk sci-fi series)\n4. Sense8 (sci-fi drama with interconnected characters)\n5. Love, Death &amp; Robots (anthology series with sci-fi elements)\n\nFinal selections: Dark, The OA, Altered Carbon\nReasoning: These shows best combine elements of mystery, suspense, and thought-provoking themes found in Stranger Things and Black Mirror.\nAssistant: Great choices! Based on your love for Stranger Things and Black Mirror, I have a few recommendations for you:\n\n## Dark\n**Basic Info:** Released 2017-2020, \n_Sci-Fi/Mystery/Thrille_\n**Created by** Baran bo Odar and Jantje Friese\n**Episodes:** ~60 minutes\n\u2b50\u2b50\u2b50\u2b50\u2b50 8.7/10 on IMDB\n**About** A German series set in the small town of Winden, where the disappearance of children reveals a complex mystery involving time travel, interconnected families, and a struggle between good and evil spanning multiple generations. Known for its intricate plotting, philosophical themes, and mind-bending time paradoxes.\n**Why you might like it:** Perfect for viewers who enjoy intricate time-travel narratives with complex family connections that reward careful attention and multiple viewings.\n\n## The OA\n**Basic Info:** Released 2016-2019\n_Sci-Fi/Mystery/Drama_\n**Created by** Brit Marling and Zal Batmanglij\n**Episodes:** ~60 minutes\n\u2b50\u2b50\u2b50\u2b50 7.9/10 on IMDB\n**About:** Centers on Prairie Johnson, a young woman who returns after being missing for seven years with her sight restored and calling herself \"The OA.\" The show explores parallel dimensions, near-death experiences, and metaphysical concepts through interpretive movement and storytelling.\n**Why you might like it:** Ideal for those seeking a boundary-pushing, emotionally resonant series that blends supernatural elements with philosophical questions about consciousness and existence.\n\n## Altered Carbon\n**Basic Info:** Released 2018-2020\n_Sci-Fi/Cyberpunk/Action_ \n**Created by** Laeta Kalogridis\n**Episodes:** ~50-60 minutes\n\u2b50\u2b50\u2b50\u2b50 8.0/10 on IMDB\n**About:** Set in a future where consciousness can be digitized and transferred between bodies (\"sleeves\"). Follows Takeshi Kovacs, a former soldier turned investigator, as he solves a murder in a world where the wealthy can live forever. Features high-concept sci-fi, noir elements, and examines themes of identity, mortality, and social inequality.\n**Why you might like it:** Appeals to fans of gritty cyberpunk who want a visually stunning, action-packed exploration of technological immortality in a dystopian future.\n\nThese shows all have strong sci-fi elements combined with thought-provoking themes and mysterious plotlines. Would you like more details about any of these recommendations?\n\nUser: \"Tell me more about Dark. Is it scary?\"\n{task}= Request type: Review and specific question\nKey elements:\n- User is interested in Dark\n- User wants to know if it's scary\n\nReview components to address:\n1. Basic show information\n2. Critics' consensus\n3. Audience reception\n4. Scare factor and content warnings\n5. Personalized recommendation\n6. IMDB rating\n\nScare factor analysis:\n- Not primarily a horror show\n- Has intense and unsettling elements\n- More psychological than traditional horror\n- Eerie atmosphere and some disturbing imagery\n\nAssistant: Certainly! Here's more information about Dark:\n\nShow Details:\n- Release Year: 2017-2020 (3 seasons)\n- Genre: Science Fiction, Thriller, Drama\n- Creators: Baran bo Odar and Jantje Friese\n- Runtime: Episodes are typically 45-60 minutes\n- \u2b50\ufe0f \u2b50\ufe0f \u2b50\ufe0f \u2b50\ufe0f \u2b50\ufe0f\n\nReview:\nDark is not primarily a horror show, but it does have some intense and unsettling elements. Here's what critics and viewers say:\n\nCritics Consensus:\n\"Dark is a visually stunning, intricately plotted sci-fi thriller that grounds its twists and turns in human drama.\" - Rotten Tomatoes\n\nAudience Reception:\nViewers praise the show for its complex storyline, atmospheric tension, and mind-bending plot. Many find it more mysterious and suspenseful than outright scary.\n\nScare Factor:\nWhile Dark isn't traditionally \"scary\" like a horror movie, it does have:\n1. A consistently eerie and tense atmosphere\n2. Some disturbing imagery and concepts\n3. Intense emotional scenes that can be psychologically unsettling\n\nContent Warning:\nThe show contains mature themes, some violence, and complex storylines that might be confusing or overwhelming for some viewers. It's rated TV-MA.\nRecommendation:\nIf you enjoy intricate mysteries, time travel concepts, and don't mind a show that requires close attention, you'll likely appreciate Dark. It's less about jump scares and more about creating a pervasive sense of unease and wonder. The \"scary\" elements are more psychological than horror-based.\n</code></pre> Coming up in this series <p>An agent designed for enterprise scenarios, equipped with tailored instructions and an execution flow that integrates API consumption</p> <p></p>"},{"location":"pages/custom-engine/","title":"Build Custom Engine Agents","text":"<p>Custom engine agents are a type of agent for Microsoft 365 Copilot that give you full control. Unlike declarative agents, which rely on Microsoft 365 Copilot's model and orchestration, custom engine agents let you bring your own foundation model, orchestrator, and security stack. This approach is ideal when you need to tailor the agent's behavior, data access, or reasoning logic to fit specific requirements or infrastructure.</p> <p></p>"},{"location":"pages/custom-engine/#what-youre-going-to-do","title":"What you're going to do","text":"<p>In the Build Path of the Copilot Developer Camp, you will dive deeper into building custom engine agents that integrate with Microsoft 365 Copilot.</p> <p>You'll create a cross-channel custom engine agent using C# and the Microsoft 365 Agents SDK that supports Microsoft Teams, Microsoft 365 Copilot, and external channels, offering full control over the orchestration layer.</p>"},{"location":"pages/custom-engine/#choose-your-learning-path","title":"Choose Your Learning Path","text":"<p>We offer two hands-on learning paths to build custom engine agents. Choose the one that matches your scenario and interests:</p>"},{"location":"pages/custom-engine/#option-1-start-with-microsoft-foundry","title":"Option 1: Start with Microsoft Foundry","text":"<p>This journey begins in Microsoft Foundry, where you'll define your agent's core instructions, tools, and personality. From there, you'll use the Microsoft 365 Agents SDK and Visual Studio to bring your agent to life, customizing its behaviors and integrating it with Semantic Kernel for orchestration. You'll then test your agent in Microsoft Teams, bring it into Copilot Chat, and see it come to life across Microsoft 365 applications.</p> <p>Best for: Developers who want to start with Microsoft Foundry and use Semantic Kernel for multi-step reasoning</p> <p>You'll build: A custom engine agent with intent handling, planner integration, and system message configuration that runs across Microsoft 365</p>"},{"location":"pages/custom-engine/#option-2-start-with-agent-framework","title":"Option 2: Start with Agent Framework   Start with Microsoft Foundry                <ul> <li>Start in Microsoft Foundry to define instructions, tools, and personality</li> <li>Integrate Semantic Kernel for multi-step reasoning and external tool usage</li> <li>Configure intent handling, planner integration, and system messages</li> <li>Deploy across Microsoft Teams, Microsoft 365 Copilot, and external channels</li> </ul>   Start here        Start with Agent Framework                <ul> <li>Build an insurance claims agent from scratch with Agent Framework</li> <li>Progressive labs: Azure AI Search, vision models, SharePoint, Microsoft Graph</li> <li>Master LLM interactions, tool calling, and intelligent decision-making</li> <li>Add authentication, Copilot Retrieval API, and MCP server integration</li> </ul>   Start here","text":"<p>Build an AI-powered assistant for insurance claims processing from the ground up. You'll start with a basic conversational agent and progressively enhance it with real-world capabilities like document search, semantic policy lookup, multi-modal vision analysis, and secure authentication. Each lab builds on the previous one using a Build-A-Feature approach.</p> <p>Best for: Developers who want hands-on experience building production-ready agents with the Agent Framework</p> <p>You'll build: A complete insurance claims assistant that integrates Azure AI Search, vision models, SharePoint, Microsoft Graph, and MCP tools</p>"},{"location":"pages/custom-engine/agent-framework/","title":"Build the Zava Insurance Agent with Microsoft 365 Agents SDK and Agent Framework","text":"<p>In this learning path, you'll build the Zava Insurance Agent - an AI-powered assistant designed to help insurance adjusters streamline claims processing. Using the Microsoft 365 Agents SDK and Agent Framework, you'll create a custom engine agent that runs across Microsoft Teams and Microsoft 365 Copilot.</p> About the Zava Insurance Agent <p>Zava Insurance is a fictional insurance company that needs to help their adjusters quickly process claims, look up policy information, analyze damage photos, and send notifications. You'll build an agent that does all of this using AI, starting simple and progressively adding advanced capabilities through a Build-A-Feature (BAF) approach.</p> <p>You'll start with a basic conversational agent and progressively enhance it with real-world capabilities like document search, semantic policy lookup, multi-modal vision analysis, and secure authentication.</p> <p>The Microsoft 365 Agents SDK provides the infrastructure to deploy your agent to Microsoft 365 Copilot and Teams, handling message routing, activities, and channel-specific behaviors. The Agent Framework powers your agent's AI capabilities, including LLM interactions, tool calling, and intelligent decision-making.</p>"},{"location":"pages/custom-engine/agent-framework/#what-youll-build","title":"What You'll Build","text":"<p>The labs follow a Build with Agent Framework (BAF) approach where you progressively enhance your agent with new capabilities:</p> <ul> <li>Lab BAF0: Prerequisites - Set up your development environment</li> <li>Lab BAF1: Build and Run - Create a basic conversational agent with plugins and tools</li> <li>Lab BAF2: Add Claims Search - Integrate Azure AI Search Knowledgebases for intelligent claims lookup</li> <li>Lab BAF3: Add Vision Analysis - Enable AI-powered damage photo analysis using Mistral vision model</li> <li>Lab BAF4: Add Policy Search - Implement policy validation and SharePoint document search</li> <li>Lab BAF5: Add Communication Capabilities - Send professional emails via Microsoft Graph and generate investigation reports</li> <li>Lab BAF6: Add Work IQ API - Rely on content stored in SharePoint Online via Copilot Retrieval API to add RAG to the agent</li> <li>Lab BAF7: Add MCP Tools - Enrich the agent with MCP tools provided by an external MCP server</li> </ul> <p>Each lab builds on the previous one, following the pattern: Services \u2192 Plugins \u2192 Integration \u2192 Testing</p>"},{"location":"pages/custom-engine/agent-framework/#start-here-with-lab-baf0-where-youll-set-up-your-development-environment","title":"Start here with Lab BAF0, where you'll set up your development environment.","text":""},{"location":"pages/custom-engine/agent-framework/00-prerequisites/","title":"Lab BAF0 - Prerequisites","text":"<p>In this lab you will set up your development environment to build, test, and deploy the custom engine agent you will develop using the Microsoft 365 Agents SDK and Agent Framework throughout this path.</p> <p>In this lab you will learn how to:</p> <ul> <li>Setup your Microsoft 365 environment</li> <li>Install and configure Visual Studio Code with Microsoft 365 Agents Toolkit</li> <li>Prepare your Azure environment to create required resources</li> <li>Install required development tools</li> </ul> <p>Disclaimer</p> <p>These samples and labs are intended for instructive and demonstration purposes and are not intended for use in production. Do not put them into production without upgrading them to production quality.</p> <p>Note</p> <p>To install and run your own custom engine agent, you'll need a Microsoft 365 tenant where you have administrator permission. You won't need Microsoft 365 Copilot License to test your custom engine agent.</p>"},{"location":"pages/custom-engine/agent-framework/00-prerequisites/#exercise-1-setup-microsoft-teams","title":"Exercise 1 : Setup Microsoft Teams","text":""},{"location":"pages/custom-engine/agent-framework/00-prerequisites/#step-1-enable-teams-custom-application-uploads","title":"Step 1: Enable Teams custom application uploads","text":"<p>By default, end users can't upload applications directly; instead a Teams administrator needs to upload them into the enterprise app catalog. In this step you will ensure your tenant is set up for direct uploads by M365 Agents Toolkit.</p> <p>1\ufe0f\u20e3 Navigate to https://admin.microsoft.com/, which is the Microsoft 365 Admin Center.</p> <p>2\ufe0f\u20e3 In the left panel of the admin center, select Show all to open up the entire navigation. When the panel opens, select Teams to open the Microsoft Teams admin center.</p> <p>3\ufe0f\u20e3 In the left of the Microsoft Teams admin center, open the Teams apps accordion. Select Setup Policies, you will see a list of App setup policies. Then, select the Global (Org-wide default) policy.</p> <p>4\ufe0f\u20e3 Ensure the first switch, Upload custom apps is turned On.</p> <p>5\ufe0f\u20e3 Be sure to scroll down and select the Save button to persist your change.</p> <p>The change can take up to 24 hours to take effect, but usually it's much faster.</p> <p></p>"},{"location":"pages/custom-engine/agent-framework/00-prerequisites/#exercise-2-setup-development-environment","title":"Exercise 2: Setup Development Environment","text":"<p>You can complete these labs on a Windows, macOS, or Linux machine and you do need the ability to install the prerequisites. If you are not permitted to install applications on your computer, you'll need to find another machine (or virtual machine) to use.</p>"},{"location":"pages/custom-engine/agent-framework/00-prerequisites/#step-1-install-visual-studio-code","title":"Step 1: Install Visual Studio Code","text":"<p>1\ufe0f\u20e3 Download and install Visual Studio Code from https://code.visualstudio.com/.</p> <p>2\ufe0f\u20e3 Launch Visual Studio Code after installation.</p> <p></p>"},{"location":"pages/custom-engine/agent-framework/00-prerequisites/#step-2-install-net-9-sdk","title":"Step 2: Install .NET 9 SDK","text":"<p>The Microsoft 365 Agents SDK and Agent Framework require .NET 9 SDK to build and run the agent.</p> <p>1\ufe0f\u20e3 Download and install .NET 9 SDK from https://dotnet.microsoft.com/download/dotnet/9.0.</p> <p>2\ufe0f\u20e3 Verify the installation by opening a terminal and running:</p> <pre><code>dotnet --version\n</code></pre> <p>You should see version 9.0.x or higher.</p> <p></p>"},{"location":"pages/custom-engine/agent-framework/00-prerequisites/#step-3-install-c-dev-kit-extension","title":"Step 3: Install C# Dev Kit Extension","text":"<p>1\ufe0f\u20e3 In Visual Studio Code, open the Extensions view by clicking on the Extensions icon in the Activity Bar on the side of the window or by pressing <code>Ctrl+Shift+X</code> (Windows/Linux) or <code>Cmd+Shift+X</code> (Mac).</p> <p>2\ufe0f\u20e3 Search for C# Dev Kit and click Install.</p> <p></p>"},{"location":"pages/custom-engine/agent-framework/00-prerequisites/#step-4-install-microsoft-365-agents-toolkit-extension","title":"Step 4: Install Microsoft 365 Agents Toolkit Extension","text":"<p>1\ufe0f\u20e3 In Visual Studio Code Extensions view, search for Microsoft 365 Agents Toolkit and click Install.</p> <p>2\ufe0f\u20e3 After installation, you should see the Microsoft 365 Agents Toolkit icon in the Activity Bar.</p> <p></p>"},{"location":"pages/custom-engine/agent-framework/00-prerequisites/#step-5-install-azure-cli","title":"Step 5: Install Azure CLI","text":"<p>The Azure CLI is required to provision and manage Azure resources.</p> <p>1\ufe0f\u20e3 Download and install Azure CLI from https://learn.microsoft.com/cli/azure/install-azure-cli.</p> <p>2\ufe0f\u20e3 Verify the installation by opening a terminal and running:</p> <pre><code>az --version\n</code></pre> <p>3\ufe0f\u20e3 Sign in to Azure:</p> <pre><code>az login\n</code></pre> <p></p>"},{"location":"pages/custom-engine/agent-framework/00-prerequisites/#step-6-install-devtunnel","title":"Step 6: Install DevTunnel","text":"<p>DevTunnel is required for local development and debugging. It creates a secure tunnel from the internet to your local machine.</p> <p>Windows:</p> <pre><code>winget install Microsoft.DevTunnel\n</code></pre> <p>macOS/Linux:</p> <pre><code>curl -sL https://aka.ms/DevTunnelCliInstall | bash\n</code></pre> <p>Verify installation:</p> <pre><code>devtunnel --version\n</code></pre> <p>DevTunnel Alternative</p> <p>DevTunnel is also included with Visual Studio 2022. If you have Visual Studio 2022 installed, you already have DevTunnel.</p> <p></p>"},{"location":"pages/custom-engine/agent-framework/00-prerequisites/#exercise-3-setup-azure-environment","title":"Exercise 3: Setup Azure Environment","text":"<p>To complete the exercises in this path, you'll need an Azure subscription to create Microsoft Foundry resources and deploy AI models.</p>"},{"location":"pages/custom-engine/agent-framework/00-prerequisites/#step-1-get-an-azure-subscription","title":"Step 1: Get an Azure subscription","text":"<p>If you don't have an Azure subscription yet, you can activate an Azure free account that offers $200 in credits which can be used within the first 30 days on most Azure services.</p> <p>Follow the steps to activate an Azure free account:</p> <p>1\ufe0f\u20e3 Navigate to Azure free account page and select Activate.</p> <p>2\ufe0f\u20e3 Login with an account of your choice, it's recommended to use the Microsoft 365 tenant account you would like to use in the exercises.</p> <p>3\ufe0f\u20e3 Check the boxes for Privacy Statement, then select Next.</p> <p>4\ufe0f\u20e3 Provide a mobile phone number for identity verification step.</p> <p>5\ufe0f\u20e3 Provide payment details for a temporary authorization. You won't be charged unless you move to pay-as-you-go pricing. Then, select Sign up.</p> <p>Tip: Managing Azure resources after 30 days</p> <p>Azure free account will be available only for 30 days. Make sure you don't have any services running in your free subscription at the end of 30 days. If you want to continue using Azure services at the end of 30 days, you must upgrade to a pay-as-you-go subscription by removing the spending limit.</p> <p></p>"},{"location":"pages/custom-engine/agent-framework/00-prerequisites/#step-2-create-microsoft-foundry-project-and-deploy-model","title":"Step 2: Create Microsoft Foundry Project and Deploy Model","text":"<p>For this lab path, you'll need a Microsoft Foundry project with a deployed language model.</p> <p>1\ufe0f\u20e3 Navigate to Microsoft Foundry and sign in with your Azure account. 2\ufe0f\u20e3 Select + Create new, then Microsoft Foundry resource and then Next.</p> <p>3\ufe0f\u20e3 Leave the project name as recommended and select Create. This will scaffold a new project for you in Microsoft Foundry, it usually takes 3-5 minutes.</p> <p>Region Selection</p> <p>Choose France Central region as it supports all the models you'll need throughout the labs.</p> <p>4\ufe0f\u20e3 Once your project is created, navigate to Deployments in the left sidebar.</p> <p>5\ufe0f\u20e3 Click + Deploy model and select Deploy base model.</p> <p>6\ufe0f\u20e3 Search for gpt-4.1 and select the gpt-4.1 model, then select Confirm and Deploy.</p> <p>Model Selection</p> <p>Please use gpt-4.1 for a smooth experience . The labs use knowledge base answer synthesis which is optimized for gpt-4.1. Using other models may lead to unexpected behavior.</p> <p>Save Your Credentials</p> <p>You'll need the following information from your Microsoft Foundry project:</p> <ul> <li>Endpoint URL: Found in project settings \u2192 Properties (e.g., <code>https://your-resource.cognitiveservices.azure.com/</code>)</li> <li>API Key: Found under \"Keys and Endpoint\" section</li> <li>Model Deployment Name: The name you gave to your gpt-4.1 deployment</li> </ul> <p>Save these values in a secure location - you'll need them in the next lab!</p> <p>Additional Models</p> <p>You'll deploy additional models (for embeddings and vision analysis) and create other Azure services (like Azure AI Search) in later labs when you need them.</p> <p></p>"},{"location":"pages/custom-engine/agent-framework/00-prerequisites/#step-3-configure-content-safety-filter","title":"Step 3: Configure Content Safety Filter","text":"<p>The insurance domain uses terms like \"injury\", \"collision\", \"damage\" that may trigger default content filters. You need to create a custom content filter with lower thresholds.</p> <p>1\ufe0f\u20e3 In Microsoft Foundry, navigate to your project.</p> <p>2\ufe0f\u20e3 In the left sidebar, select Guardrails + Controls \u2192 Content filters.</p> <p>3\ufe0f\u20e3 Click + Create content filter.</p> <p>4\ufe0f\u20e3 Name your filter InsuranceLowFilter.</p> <p>5\ufe0f\u20e3 Configure the following settings for Input filters (what users send):</p> <ul> <li>Violence: Set threshold to Low</li> <li>Hate: Set threshold to Low</li> <li>Sexual: Set threshold to Low</li> <li>Self-harm: Set threshold to Low</li> <li>Prompt shields for jailbreak attacks: Off</li> <li>Prompt shields for indirect attacks: Off</li> </ul> <p>6\ufe0f\u20e3 Select Next and configure the same settings for Output filters (what AI generates):</p> <ul> <li>Violence: Set threshold to Low</li> <li>Hate: Set threshold to Low</li> <li>Sexual: Set threshold to Low</li> <li>Self-harm: Set threshold to Low</li> <li>Protected material for text: Off</li> <li>Protected material for code: Off</li> <li>Groundedness (Preview): Off</li> </ul> <p>7\ufe0f\u20e3 Select Next.</p> <p>8\ufe0f\u20e3 In Apply filter to deployments, select your gpt-4.1 deployment.</p> <p>9\ufe0f\u20e3 Select Replace to apply the new filter to the deployment.</p> <p>\ud83d\udd1f Finally, select Create filter.</p> <p>Why This Is Needed</p> <p>Insurance claims contain legitimate terms like \"injury\", \"accident\", \"collision\", \"bodily harm\" that describe real incidents. Default content filters may block these terms. Setting thresholds to Low only blocks extreme content while allowing normal insurance terminology.</p> <p>Production Deployments</p> <p>In production, review your organization's content safety policies and adjust filter settings accordingly. This configuration is for development and testing purposes.</p> <p></p> <p>CONGRATULATIONS!</p> <p>You have completed Lab BAF0 - Prerequisites!</p> <p>You are now ready to proceed to Lab BAF1 - Build and Run Your First Agent. Select Next.</p> <p></p> <p></p>"},{"location":"pages/custom-engine/agent-framework/01-build-and-run/","title":"Lab BAF1 - Build and Run Your First Agent","text":"<p>In this lab, you'll build and run a custom engine agent using the Microsoft 365 Agents SDK with the Agent Framework. You'll explore the starter project, understand the core components, and see your agent come to life in Microsoft 365 Copilot.</p> <p>The Zava Insurance Agent is designed to help insurance adjusters streamline claims processing. In this initial lab, you'll start with a basic conversational agent that can greet users and provide information using AI-powered responses.</p> What are the Microsoft 365 Agents SDK and Agent Framework? <p>Microsoft 365 Agents SDK provides the container and scaffolding to deploy agents across Microsoft 365 channels (Teams, Copilot, etc.), handling activities, events, and communication. It's AI-agnostic, allowing you to use any AI services you choose.</p> <p>Agent Framework is an open-source development kit for building AI agents with LLMs, tool calling, and multi-agent workflows. It's the successor to Semantic Kernel and AutoGen, providing the AI capabilities and agent logic.</p> <p>Together, they allow you to build intelligent agents with the Agent Framework and deploy them to Microsoft 365 using the Agents SDK.</p>"},{"location":"pages/custom-engine/agent-framework/01-build-and-run/#exercise-1-clone-and-explore-the-project","title":"Exercise 1: Clone and Explore the Project","text":"<p>In this exercise, you'll clone the Copilot Camp repository and explore the starter project structure to understand how the agent is organized.</p>"},{"location":"pages/custom-engine/agent-framework/01-build-and-run/#step-1-clone-the-repository","title":"Step 1: Clone the Repository","text":"<p>Let's start by cloning the Copilot Camp repository and navigating to the Agent Framework starter project.</p> <p>1\ufe0f\u20e3 Open a terminal or command prompt.</p> <p>2\ufe0f\u20e3 Clone the repository:</p> <pre><code>git clone https://github.com/microsoft/copilot-camp.git\ncd copilot-camp/src/agent-framework/begin\n</code></pre> <p>3\ufe0f\u20e3 Open the project in Visual Studio Code:</p> <pre><code>code .\n</code></pre> <p></p>"},{"location":"pages/custom-engine/agent-framework/01-build-and-run/#step-2-explore-the-project-structure","title":"Step 2: Explore the Project Structure","text":"<p>Let's understand the organization of the agent project.</p> <p>1\ufe0f\u20e3 In Visual Studio Code, expand the folders in the Explorer view. You should see this structure:</p> <pre><code>begin/\n\u251c\u2500\u2500 src/\n\u2502   \u251c\u2500\u2500 Agent/\n\u2502   \u2502   \u2514\u2500\u2500 ZavaInsuranceAgent.cs       # Main agent implementation\n\u2502   \u251c\u2500\u2500 Plugins/                        # Custom plugins (tools) for the agent\n\u2502   \u2502   \u251c\u2500\u2500 StartConversationPlugin.cs  # Welcome message plugin\n\u2502   \u2502   \u2514\u2500\u2500 DateTimeFunctionTool.cs     # Date/time utility\n\u251c\u2500\u2500 appPackage/                         # Teams app manifest and icons\n\u251c\u2500\u2500 env/                                # Environment configuration files (API keys, endpoints)\n\u251c\u2500\u2500 infra/                              # All required scripts, data and templates for the agent's infrastructure\n\u251c\u2500\u2500 Program.cs                          # Application entry point - configures services and starts web app\n\u251c\u2500\u2500 InsuranceAgent.csproj               # Project file\n\u2514\u2500\u2500 m365agents.local.yml                # M365 Agents provisioning config\n</code></pre> <p></p>"},{"location":"pages/custom-engine/agent-framework/01-build-and-run/#step-3-understand-the-agent-implementation","title":"Step 3: Understand the Agent Implementation","text":"<p>Let's examine the main agent file to understand how it works.</p> <p>1\ufe0f\u20e3 Open <code>src/Agent/ZavaInsuranceAgent.cs</code> in Visual Studio Code.</p> <p>2\ufe0f\u20e3 Find the <code>AgentInstructions</code> property near the top of the class. Notice how these instructions act as the system prompt for the AI model:</p> <ul> <li>It defines the agent's role: \"You are a professional insurance claims assistant for Zava Insurance...\"</li> <li>It lists available tools using the <code>{{PluginName.FunctionName}}</code> syntax</li> <li>It includes <code>{{StartConversationPlugin.StartConversation}}</code> and <code>{{DateTimeFunctionTool.getDate}}</code></li> </ul> <p>These instructions tell the AI how to behave and what tools it can use.</p> <p>3\ufe0f\u20e3 Scroll down and find the constructor method <code>ZavaInsuranceAgent(...)</code>. Notice it sets up event handlers:</p> <ul> <li><code>OnConversationUpdate(ConversationUpdateEvents.MembersAdded, WelcomeMessageAsync)</code> - sends a welcome message when a user joins</li> <li><code>OnActivity(ActivityTypes.Message, OnMessageAsync)</code> - handles incoming messages</li> </ul> <p>4\ufe0f\u20e3 Find the <code>GetClientAgent</code> method. Look for where it creates <code>toolOptions</code> and registers plugins:</p> <ul> <li>It creates a <code>ChatOptions</code> object with a <code>Tools</code> list</li> <li>It adds <code>startConversationPlugin.StartConversation</code> using <code>AIFunctionFactory.Create</code></li> <li>It adds <code>DateTimeFunctionTool.getDate</code> the same way</li> </ul> <p>This is where we register plugins (tools) that the AI can call during conversations.</p> <p></p>"},{"location":"pages/custom-engine/agent-framework/01-build-and-run/#step-4-explore-the-plugins","title":"Step 4: Explore the Plugins","text":"<p>Now let's look at how plugins work.</p> <p>1\ufe0f\u20e3 Open <code>src/Plugins/StartConversationPlugin.cs</code>.</p> <p>2\ufe0f\u20e3 Notice the plugin structure:</p> <pre><code>public class StartConversationPlugin\n{\n    [Description(\"Starts a new conversation suggesting a conversation flow.\")]\n    public async Task&lt;string&gt; StartConversation()\n    {\n        var welcomeMessage = \"\ud83d\udc4b Welcome to Zava Insurance Claims Assistant!...\";\n        return welcomeMessage;\n    }\n}\n</code></pre> <p>Key points:</p> <ul> <li>The <code>[Description]</code> attribute tells the AI when to use this tool</li> <li>The method returns a formatted welcome message</li> <li>It's a simple plugin with no parameters</li> </ul> <p>3\ufe0f\u20e3 Open <code>src/Plugins/DateTimeFunctionTool.cs</code>.</p> <p>4\ufe0f\u20e3 Notice how it provides current date/time:</p> <ul> <li>It has a <code>[Description]</code> that says \"Gets the current date and time\"</li> <li>The <code>getDate()</code> method is static and returns <code>DateTime.Now</code> as a formatted string</li> </ul> <p>This plugin demonstrates how the agent can access system information to answer user queries.</p> <p></p>"},{"location":"pages/custom-engine/agent-framework/01-build-and-run/#step-5-view-the-app-manifest-and-conversation-starters","title":"Step 5: View the App Manifest and Conversation Starters","text":"<p>Let's check the app manifest to see how your agent appears in Microsoft 365 Copilot.</p> <p>1\ufe0f\u20e3 Open <code>appPackage/manifest.json</code>.</p> <p>2\ufe0f\u20e3 Find the <code>name</code> section to see your agent's display name:</p> <pre><code>\"name\": {\n    \"short\": \"Zava Insurance Agent\",\n    \"full\": \"Zava Insurance Claims Assistant\"\n}\n</code></pre> <p>3\ufe0f\u20e3 Scroll down to the <code>conversationStarters</code> array. These are the suggested prompts users see when they first interact with your agent:</p> <pre><code>\"conversationStarters\": [\n    {\n        \"title\": \"Instructions\",\n        \"description\": \"What can you do?\"\n    },\n    {\n        \"title\": \"Today's Date\",\n        \"description\": \"What's today's date?\"\n    },\n    {\n        \"title\": \"About Insurance\",\n        \"description\": \"Tell me about insurance claims\"\n    },\n    {\n        \"title\": \"Claims Process\",\n        \"description\": \"Explain how claims processing works\"\n    }\n]\n</code></pre> <p>These conversation starters help guide users on how to interact with your agent. You can customize these to match your agent's capabilities.</p> <p>4\ufe0f\u20e3 Notice the <code>copilotAgents.declarativeAgent</code> section that defines your agent as a custom engine agent with specific capabilities.</p> <p></p>"},{"location":"pages/custom-engine/agent-framework/01-build-and-run/#step-6-review-the-application-entry-point","title":"Step 6: Review the Application Entry Point","text":"<p>Let's see how everything comes together in Program.cs.</p> <p>1\ufe0f\u20e3 Open <code>Program.cs</code>.</p> <p>2\ufe0f\u20e3 Key sections to understand:</p> <p>Configuration Loading: Find the section where <code>builder.Configuration</code> loads settings. Notice it loads from multiple sources:</p> <ul> <li><code>.env</code> files for environment-specific settings using <code>AddEnvFile</code></li> <li>User secrets for sensitive data (API keys) using <code>AddUserSecrets</code></li> <li>Environment variables using <code>AddEnvironmentVariables</code></li> </ul> <p>Service Registration: Find where services are registered with <code>builder.Services</code>. Notice:</p> <ul> <li><code>AddSingleton&lt;IStorage, MemoryStorage&gt;()</code> - registers memory storage for conversation state</li> <li><code>AddAgentApplicationOptions()</code> - registers agent configuration</li> <li><code>AddAgent&lt;ZavaInsuranceAgent&gt;()</code> - registers the agent itself as a service</li> </ul> <p>Chat Client Configuration: Find where <code>IChatClient</code> is registered as a singleton. Observe how it:</p> <ul> <li>Retrieves the endpoint, API key, and deployment name from configuration</li> <li>Creates an <code>AzureOpenAIClient</code> with the endpoint and credentials</li> <li>Returns a chat client for the specified deployment (gpt-4.1)</li> </ul> <p>This creates the connection to Azure OpenAI, which powers the agent's AI capabilities.</p> <p></p>"},{"location":"pages/custom-engine/agent-framework/01-build-and-run/#exercise-2-configure-the-agent","title":"Exercise 2: Configure the Agent","text":"<p>Before running the agent, you need to configure it with your Azure AI credentials.</p>"},{"location":"pages/custom-engine/agent-framework/01-build-and-run/#step-1-configure-environment-files","title":"Step 1: Configure Environment Files","text":"<p>The agent uses environment files to store configuration. Let's set them up.</p> <p>1\ufe0f\u20e3 In Visual Studio Code, navigate to the <code>env/</code> folder.</p> <p>2\ufe0f\u20e3 You should see two sample files:</p> <ul> <li><code>.env.local.sample</code></li> <li><code>.env.local.user.sample</code></li> </ul> <p>3\ufe0f\u20e3 Copy <code>.env.local.sample</code> to <code>.env.local</code>:</p> <p>Windows PowerShell:</p> <pre><code>Copy-Item env/.env.local.sample env/.env.local\n</code></pre> <p>macOS/Linux:</p> <pre><code>cp env/.env.local.sample env/.env.local\n</code></pre> <p>4\ufe0f\u20e3 Copy <code>.env.local.user.sample</code> to <code>.env.local.user</code>:</p> <p>Windows PowerShell:</p> <pre><code>Copy-Item env/.env.local.user.sample env/.env.local.user\n</code></pre> <p>macOS/Linux:</p> <pre><code>cp env/.env.local.user.sample env/.env.local.user\n</code></pre> <p></p>"},{"location":"pages/custom-engine/agent-framework/01-build-and-run/#step-2-add-your-azure-ai-credentials","title":"Step 2: Add Your Azure AI Credentials","text":"<p>Now let's configure the agent to use your Azure AI Foundry deployment.</p> <p>1\ufe0f\u20e3 Open <code>env/.env.local</code> in Visual Studio Code.</p> <p>2\ufe0f\u20e3 Find the <code>MODELS_ENDPOINT</code> variable and update it with your Azure AI endpoint from Lab BAF0:</p> <pre><code>MODELS_ENDPOINT=https://your-resource.cognitiveservices.azure.com/\n</code></pre> <p>Finding Your Endpoint</p> <p>If you don't remember your endpoint:</p> <ol> <li>Go to Azure AI Foundry</li> <li>Select your project</li> <li>Go to Settings \u2192 Properties</li> <li>Copy the Endpoint URL</li> </ol> <p>3\ufe0f\u20e3 Open <code>env/.env.local.user</code> in Visual Studio Code.</p> <p>4\ufe0f\u20e3 Find the <code>SECRET_MODELS_API_KEY</code> variable and update it with your API key:</p> <pre><code>SECRET_MODELS_API_KEY=your-api-key-here\n</code></pre> <p>Keep Your API Key Secret</p> <p>The <code>.env.local.user</code> file contains sensitive information and is already included in <code>.gitignore</code>. Never commit this file to source control!</p> <p></p>"},{"location":"pages/custom-engine/agent-framework/01-build-and-run/#step-3-sign-in-to-microsoft-365-and-azure","title":"Step 3: Sign in to Microsoft 365 and Azure","text":"<p>The Microsoft 365 Agents Toolkit needs to authenticate with both Microsoft 365 and Azure.</p> <p>1\ufe0f\u20e3 In Visual Studio Code, click on the Microsoft 365 Agents Toolkit icon in the Activity Bar (left side).</p> <p>2\ufe0f\u20e3 In the toolkit panel, find the ACCOUNTS section.</p> <p>3\ufe0f\u20e3 Click Sign in to Microsoft 365 and complete the sign-in flow.</p> <p>4\ufe0f\u20e3 Click Sign in to Azure and complete the sign-in flow.</p> <p>First Time Sign-In</p> <p>The first time you sign in, you may need to grant permissions to the Microsoft 365 Agents Toolkit extension.</p> <p></p>"},{"location":"pages/custom-engine/agent-framework/01-build-and-run/#exercise-3-run-and-test-the-agent","title":"Exercise 3: Run and Test the Agent","text":"<p>Now it's time to run the agent and see it in action!</p>"},{"location":"pages/custom-engine/agent-framework/01-build-and-run/#step-1-start-the-agent","title":"Step 1: Start the Agent","text":"<p>Let's run the agent using the F5 debug experience.</p> <p>1\ufe0f\u20e3 In Visual Studio Code, press F5 or select Run \u2192 Start Debugging from the menu.</p> <p>2\ufe0f\u20e3 When prompted to select a debug target, choose (Preview) Debug in Copilot (Edge).</p> <p>Debug Target Options</p> <p>You may see multiple options like \"Debug in Teams (Edge)\", \"Debug in Teams (Chrome)\", etc. Make sure to select (Preview) Debug in Copilot (Edge) to test your agent in Microsoft 365 Copilot.</p> <p>3\ufe0f\u20e3 The first time you run the agent, the Microsoft 365 Agents Toolkit will:</p> <ul> <li>Prompt you to select an Azure subscription</li> <li>Ask you to create a new resource group or select existing one</li> <li>Select a region for your resources (choose one close to your Azure AI Foundry project)</li> <li>Provision Azure resources (Azure Bot Service, App Registration)</li> </ul> <p>This provisioning process usually takes 2-3 minutes.</p> <p>Provisioning Azure Resources</p> <p>During first run, the toolkit creates:</p> <ul> <li>Azure Bot Service - Handles message routing</li> <li>App Registration - Manages authentication</li> <li>Dev Tunnel - Creates a secure tunnel to your local machine</li> </ul> <p>4\ufe0f\u20e3 Watch the Terminal output in Visual Studio Code. You should see:</p> <pre><code>\ud83c\udf0d Environment: local\n\ud83c\udfe2 Starting Zava Insurance Agent...\n\ud83e\udd16 Main agent using model: gpt-4.1\n\u2705 Agent initialized successfully!\n</code></pre> <p>5\ufe0f\u20e3 A browser window will open with Microsoft 365 Copilot.</p> <p>6\ufe0f\u20e3 You'll see an install dialog for the Zava Insurance Agent. Click Add.</p> <p>7\ufe0f\u20e3 After installation, click Open in Copilot or Chat.</p> <p></p>"},{"location":"pages/custom-engine/agent-framework/01-build-and-run/#step-2-test-basic-conversations","title":"Step 2: Test Basic Conversations","text":"<p>Now let's interact with your agent!</p> <p>1\ufe0f\u20e3 In Microsoft 365 Copilot, you should see your agent with conversation starters in your chat window.</p> <p></p> <p>2\ufe0f\u20e3 Select \"What can you do?\" to see the welcome message:</p> <p></p> <p>3\ufe0f\u20e3 Try asking: \"What's today's date?\"</p> <p>The agent should call the <code>DateTimeFunctionTool</code> and return the current date and time.</p> <p>4\ufe0f\u20e3 Try asking: \"What can you do?\" or \"Start over\"</p> <p>The agent should call the <code>StartConversationPlugin</code> and show the welcome message again.</p> <p>5\ufe0f\u20e3 Try a general question: \"Tell me about insurance claims\"</p> <p>The agent should use its AI knowledge to provide a helpful explanation about insurance claims.</p> <p>6\ufe0f\u20e3 Try something outside its scope: \"What's the weather today?\"</p> <p>The agent should politely indicate that this is outside its scope as an insurance assistant.</p> <p></p>"},{"location":"pages/custom-engine/agent-framework/01-build-and-run/#step-3-check-the-debug-output","title":"Step 3: Check the Debug Output","text":"<p>1\ufe0f\u20e3 Return to Visual Studio Code and check the Debug Console.</p> <p>2\ufe0f\u20e3 Notice logs showing plugin calls, AI responses, and message processing in real-time.</p> <p></p>"},{"location":"pages/custom-engine/agent-framework/01-build-and-run/#exercise-4-customize-your-agent","title":"Exercise 4: Customize Your Agent","text":"<p>Let's make a simple modification to personalize the agent.</p>"},{"location":"pages/custom-engine/agent-framework/01-build-and-run/#step-1-update-the-welcome-message","title":"Step 1: Update the Welcome Message","text":"<p>1\ufe0f\u20e3 Stop the debugger (press Shift+F5).</p> <p>2\ufe0f\u20e3 Open <code>src/Plugins/StartConversationPlugin.cs</code> and find the <code>welcomeMessage</code> variable.</p> <p>3\ufe0f\u20e3 Add your name to the first line: <code>\"\ud83d\udc4b Welcome! I'm [Your Name]'s Agent!\\n\\n\"</code></p> <p>4\ufe0f\u20e3 Save, press F5 to restart, and type \"start over\" in Copilot to see your change.</p> <p></p> <p>CONGRATULATIONS!</p> <p>You have completed Lab BAF1 - Build and Run Your First Agent!</p> <p>You've learned how to:</p> <ul> <li>\u2705 Clone and explore an Agent Framework project</li> <li>\u2705 Configure the agent with Azure AI credentials</li> <li>\u2705 Run and debug the agent locally</li> <li>\u2705 Test the agent in Microsoft 365 Copilot</li> <li>\u2705 Understand the core components (Agent, Plugins, Instructions)</li> <li>\u2705 Make simple modifications to customize behavior</li> </ul> <p>In the next lab, you'll add more powerful capabilities by integrating document search with Azure AI Search and gpt-4.1!</p> <p></p> <p></p>"},{"location":"pages/custom-engine/agent-framework/02-add-claim-search/","title":"Lab BAF2 - Add Document Search with Azure AI Search","text":"<p>In this lab, you'll enhance your Zava Insurance Agent by adding document search capabilities using Azure AI Search. You'll create a ClaimsPlugin that uses AI-powered retrieval to search through insurance claims, retrieve claim details, and identify claims with missing documentation.</p> Understanding Azure AI Search Concepts <p>Azure AI Search is a cloud search service that provides infrastructure, APIs, and tools for building rich search experiences over your content.</p> <p>Key Concepts:</p> <ul> <li>Search Index: A searchable collection of documents, similar to a database table. Each index contains documents with fields that can be searched, filtered, and sorted.</li> <li>Knowledge Source: A logical grouping that connects your data to an index. It defines where your data comes from and how it should be indexed.</li> <li>Knowledge Base: A unified interface that brings together multiple knowledge sources, allowing you to search across different data sources with a single query.</li> </ul> <p>In this lab, you'll create a claims index to store insurance claims data, configure a knowledge source to connect your data, and set up a knowledge base for unified retrieval. Your ClaimsPlugin will use these components to perform AI-powered searches.</p>"},{"location":"pages/custom-engine/agent-framework/02-add-claim-search/#exercise-1-set-up-azure-ai-search","title":"Exercise 1: Set Up Azure AI Search","text":"<p>Before we add the plugin, let's set up Azure AI Search with sample claims data.</p>"},{"location":"pages/custom-engine/agent-framework/02-add-claim-search/#step-1-create-azure-ai-search-service","title":"Step 1: Create Azure AI Search Service","text":"<p>If you haven't created an Azure AI Search service yet (from Lab BAF0), create one now.</p> <p>1\ufe0f\u20e3 Go to the Azure Portal.</p> <p>2\ufe0f\u20e3 Click + Create a resource \u2192 Search for Azure AI Search \u2192 Click Create.</p> <p>3\ufe0f\u20e3 Configure:</p> <ul> <li>Resource Group: Use the same as your Azure AI Foundry project</li> <li>Service Name: Choose a unique name (e.g., <code>zava-insurance-search</code>)</li> <li>Region: Any supported location (Central US, East US, West Europe, etc.)</li> <li>Pricing Tier: Basic</li> </ul> <p>4\ufe0f\u20e3 Click Review + Create \u2192 Create (takes 2-3 minutes).</p> <p>5\ufe0f\u20e3 Once deployed, go to the resource Overview page and copy the URL.</p> <p>6\ufe0f\u20e3 Then, go to Settings &gt; Keys and copy Primary Admin Key</p> <p></p>"},{"location":"pages/custom-engine/agent-framework/02-add-claim-search/#step-2-add-sample-claims-data","title":"Step 2: Add Sample Claims Data","text":"<p>Your project includes sample claims data that will be automatically indexed.</p> <p>1\ufe0f\u20e3 In VS Code, navigate to <code>infra/data/sample-data/claims.json</code>.</p> <p>2\ufe0f\u20e3 Notice the structure - each claim has:</p> <ul> <li><code>claimNumber</code>: Unique identifier (e.g., \"CLM-2025-001001\")</li> <li><code>policyholderName</code>: Customer name</li> <li><code>claimType</code>: Auto, Homeowners, or Commercial</li> <li><code>status</code>: Open, In Progress, Approved, Closed</li> <li><code>severity</code>: Low, Medium, High, Critical</li> <li><code>estimatedCost</code>: Claim amount</li> <li><code>fraudRiskScore</code>: Risk indicator (0-100)</li> <li><code>region</code>: Northeast, South, Midwest, West</li> </ul> <p>3\ufe0f\u20e3 This data will be indexed into Azure AI Search when you run the agent.</p> <p></p>"},{"location":"pages/custom-engine/agent-framework/02-add-claim-search/#step-3-configure-azure-ai-search-credentials","title":"Step 3: Configure Azure AI Search Credentials","text":"<p>Now let's add your Azure AI Search credentials to the project.</p> <p>1\ufe0f\u20e3 Open <code>env/.env.local</code> in VS Code.</p> <p>2\ufe0f\u20e3 Find the Azure AI Search section and update:</p> <pre><code># Azure AI Search\nAZURE_AI_SEARCH_ENDPOINT=https://your-search.search.windows.net\n</code></pre> <p>3\ufe0f\u20e3 Open <code>env/.env.local.user</code> in VS Code.</p> <p>4\ufe0f\u20e3 Find the Azure AI Search section and update:</p> <pre><code># Azure AI Search\nSECRET_AZURE_AI_SEARCH_API_KEY=your-primary-admin-key\n</code></pre> <p>Finding Your Credentials</p> <ul> <li>Endpoint: Azure Portal \u2192 Your Search Service \u2192 Overview \u2192 URL</li> <li>API Key: Azure Portal \u2192 Your Search Service \u2192 Keys \u2192 Primary Admin Key</li> </ul> <p></p>"},{"location":"pages/custom-engine/agent-framework/02-add-claim-search/#exercise-2-create-the-knowledgebaseservice","title":"Exercise 2: Create the KnowledgeBaseService","text":"<p>The KnowledgeBaseService handles all interactions with Azure AI Search, including creating indexes, knowledge sources, knowledge bases, indexing data, and performing AI-powered retrieval.</p>"},{"location":"pages/custom-engine/agent-framework/02-add-claim-search/#step-1-create-complete-knowledgebaseservice","title":"Step 1: Create Complete KnowledgeBaseService","text":"What this code does <p>The <code>KnowledgeBaseService</code> is the core service for Azure AI Search integration:</p> <ul> <li>Constructor: Initializes connections to Azure AI Search and Azure OpenAI using configuration</li> <li>EnsureClaimsIndexAsync: Creates the search index with semantic and vector search (required by Knowledgebases)</li> <li>CreateKnowledgeSourcesAsync: Sets up knowledge source that defines data fields for indexing</li> <li>CreateKnowledgeBaseAsync: Creates knowledge base with LLM model for answer synthesis</li> <li>RetrieveAsync: Main agentic retrieval method - uses LLM to search and synthesize answers with optional instructions for formatting</li> <li>IndexClaimsDataAsync: Loads and indexes sample claims data from JSON file</li> </ul> <p>This service provides complete Azure AI Search functionality with agentic retrieval capabilities.</p> <p>1\ufe0f\u20e3 In VS Code, create a new folder <code>src/Services</code>.</p> <p>2\ufe0f\u20e3 Create a new file <code>src/Services/KnowledgeBaseService.cs</code> and add the complete implementation:</p> <pre><code>using Azure;\nusing Azure.AI.OpenAI;\nusing Azure.Search.Documents;\nusing Azure.Search.Documents.Indexes;\nusing Azure.Search.Documents.Indexes.Models;\nusing Azure.Search.Documents.Models;\nusing Azure.Search.Documents.KnowledgeBases;\nusing Azure.Search.Documents.KnowledgeBases.Models;\nusing Microsoft.Extensions.Configuration;\nusing System.Text;\nusing OpenAI.Chat;\n\nnamespace InsuranceAgent.Services;\n\npublic class KnowledgeBaseService\n{\n    private readonly IConfiguration _configuration;\n    private readonly string _searchEndpoint;\n    private readonly string _searchApiKey;\n    private readonly SearchIndexClient _indexClient;\n    private readonly KnowledgeBaseRetrievalClient _retrievalClient;\n    private readonly string _aiEndpoint;\n    private readonly string _aiApiKey;\n    private readonly string _embeddingModel;\n    private readonly AzureOpenAIClient _openAIClient;\n\n    private const string ClaimsKnowledgeSource = \"claims-knowledge-source\";\n    private const string ClaimsIndex = \"claims-index\";\n    private const string KnowledgeBaseName = \"zava-insurance-kb\";\n\n    public KnowledgeBaseService(IConfiguration configuration)\n    {\n        _configuration = configuration;\n\n        // Load Azure AI Search configuration\n        _searchEndpoint = configuration[\"AZURE_AI_SEARCH_ENDPOINT\"]\n            ?? throw new InvalidOperationException(\"AZURE_AI_SEARCH_ENDPOINT not configured\");\n        _searchApiKey = configuration[\"SECRET_AZURE_AI_SEARCH_API_KEY\"]\n            ?? throw new InvalidOperationException(\"SECRET_AZURE_AI_SEARCH_API_KEY not configured\");\n\n        // Load Azure OpenAI configuration for embeddings and LLM\n        _aiEndpoint = configuration[\"MODELS_ENDPOINT\"]\n            ?? throw new InvalidOperationException(\"MODELS_ENDPOINT not configured\");\n        _aiApiKey = configuration[\"AIModels:ApiKey\"]\n            ?? throw new InvalidOperationException(\"AIModels:ApiKey not configured\");\n        _embeddingModel = configuration[\"EMBEDDING_MODEL_NAME\"] ?? \"text-embedding-ada-002\";\n\n        // Initialize Azure AI Search clients\n        var credential = new AzureKeyCredential(_searchApiKey);\n        _indexClient = new SearchIndexClient(new Uri(_searchEndpoint), credential);\n        _retrievalClient = new KnowledgeBaseRetrievalClient(\n            new Uri(_searchEndpoint), \n            KnowledgeBaseName, \n            credential\n        );\n\n        // Initialize Azure OpenAI client\n        _openAIClient = new AzureOpenAIClient(\n            new Uri(_aiEndpoint), \n            new AzureKeyCredential(_aiApiKey)\n        );\n    }\n\n    /// &lt;summary&gt;\n    /// Creates the claims search index if it doesn't exist\n    /// Includes semantic search (required by Knowledgebases) and vector search\n    /// &lt;/summary&gt;\n    public async Task EnsureClaimsIndexAsync()\n    {\n        try\n        {\n            var existingIndex = await _indexClient.GetIndexAsync(ClaimsIndex);\n            Console.WriteLine($\"\u2705 Claims index '{ClaimsIndex}' already exists\");\n            return;\n        }\n        catch (RequestFailedException ex) when (ex.Status == 404)\n        {\n            Console.WriteLine($\"\ud83d\udcdd Creating claims index '{ClaimsIndex}'...\");\n\n            // Define index schema with all claim fields\n            var index = new SearchIndex(ClaimsIndex)\n            {\n                Fields =\n                {\n                    new SimpleField(\"id\", SearchFieldDataType.String) { IsKey = true, IsFilterable = true },\n                    new SearchableField(\"claimNumber\") { IsFilterable = true, IsSortable = true },\n                    new SearchableField(\"policyholderName\") { IsFilterable = true },\n                    new SearchableField(\"policyNumber\") { IsFilterable = true },\n                    new SearchableField(\"status\") { IsFilterable = true, IsFacetable = true },\n                    new SearchableField(\"claimType\") { IsFilterable = true, IsFacetable = true },\n                    new SearchableField(\"region\") { IsFilterable = true, IsFacetable = true },\n                    new SearchableField(\"assignedAdjuster\") { IsFilterable = true },\n                    new SimpleField(\"dateFiled\", SearchFieldDataType.DateTimeOffset) { IsFilterable = true, IsSortable = true },\n                    new SimpleField(\"dateResolved\", SearchFieldDataType.DateTimeOffset) { IsFilterable = true, IsSortable = true },\n                    new SearchableField(\"description\"),\n                    new SearchableField(\"location\") { IsFilterable = true },\n                    new SearchableField(\"severity\") { IsFilterable = true, IsFacetable = true },\n                    new SimpleField(\"claimAmount\", SearchFieldDataType.Double) { IsFilterable = true, IsSortable = true },\n                    new SimpleField(\"fraudScore\", SearchFieldDataType.Int32) { IsFilterable = true, IsSortable = true },\n                    new SearchableField(\"fraudIndicators\"),\n                    new SearchableField(\"adjusterNotes\"),\n                    new SimpleField(\"imageUrl\", SearchFieldDataType.String) { IsFilterable = false },\n                    new SimpleField(\"thumbnailUrl\", SearchFieldDataType.String) { IsFilterable = false },\n                    new SearchField(\"contentVector\", SearchFieldDataType.Collection(SearchFieldDataType.Single))\n                    {\n                        IsSearchable = true,\n                        VectorSearchDimensions = 1536,\n                        VectorSearchProfileName = \"vector-profile\"\n                    },\n                    new SearchableField(\"searchableContent\")\n                },\n                VectorSearch = CreateVectorSearchConfig(),\n                SemanticSearch = CreateSemanticConfig(\"Claims semantic search\", \"claimNumber\", \"description\", \"assignedAdjuster\")\n            };\n\n            await _indexClient.CreateIndexAsync(index);\n            Console.WriteLine($\"\u2705 Claims index created successfully\");\n        }\n    }\n\n    /// &lt;summary&gt;\n    /// Creates knowledge sources that connect the indexes to the knowledge base\n    /// &lt;/summary&gt;\n    public async Task CreateKnowledgeSourcesAsync()\n    {\n        // Create claims knowledge source\n        var claimsKnowledgeSource = new SearchIndexKnowledgeSource(\n            name: ClaimsKnowledgeSource,\n            searchIndexParameters: new SearchIndexKnowledgeSourceParameters(searchIndexName: ClaimsIndex)\n            {\n                SourceDataFields = \n                {\n                    new SearchIndexFieldReference(name: \"id\"),\n                    new SearchIndexFieldReference(name: \"claimNumber\"),\n                    new SearchIndexFieldReference(name: \"policyholderName\"),\n                    new SearchIndexFieldReference(name: \"policyNumber\"),\n                    new SearchIndexFieldReference(name: \"status\"),\n                    new SearchIndexFieldReference(name: \"claimType\"),\n                    new SearchIndexFieldReference(name: \"dateFiled\"),\n                    new SearchIndexFieldReference(name: \"dateResolved\"),\n                    new SearchIndexFieldReference(name: \"claimAmount\"),\n                    new SearchIndexFieldReference(name: \"region\"),\n                    new SearchIndexFieldReference(name: \"assignedAdjuster\"),\n                    new SearchIndexFieldReference(name: \"description\"),\n                    new SearchIndexFieldReference(name: \"location\"),\n                    new SearchIndexFieldReference(name: \"severity\"),\n                    new SearchIndexFieldReference(name: \"fraudScore\"),\n                    new SearchIndexFieldReference(name: \"fraudIndicators\"),\n                    new SearchIndexFieldReference(name: \"adjusterNotes\")\n                }\n            }\n        );\n\n        await _indexClient.CreateOrUpdateKnowledgeSourceAsync(claimsKnowledgeSource);\n        Console.WriteLine($\"\u2705 Knowledge source '{ClaimsKnowledgeSource}' created\");\n    }\n\n    /// &lt;summary&gt;\n    /// Creates knowledge base with LLM model configuration for answer synthesis\n    /// Uses gpt-4.1 to generate natural language answers from retrieved documents\n    /// &lt;/summary&gt;\n    public async Task CreateKnowledgeBaseAsync()\n    {\n        // Get the language model deployment name from configuration\n        var config = new ConfigurationBuilder()\n            .SetBasePath(AppDomain.CurrentDomain.BaseDirectory)\n            .AddJsonFile(\"appsettings.local.json\", optional: true)\n            .Build();\n\n        var modelName = config[\"AIModels:LanguageModel:Name\"] ?? \"gpt-4.1\";\n\n        // Configure Azure OpenAI model parameters for the knowledge base\n        var aoaiParams = new AzureOpenAIVectorizerParameters\n        {\n            ResourceUri = new Uri(_aiEndpoint),\n            ApiKey = _aiApiKey,\n            DeploymentName = modelName,\n            ModelName = modelName\n        };\n\n        var knowledgeBase = new KnowledgeBase(\n            name: KnowledgeBaseName,\n            knowledgeSources: new[]\n            {\n                new KnowledgeSourceReference(name: ClaimsKnowledgeSource)\n            }\n        )\n        {\n            Description = \"Zava Insurance knowledge base for claims\",\n            RetrievalReasoningEffort = new KnowledgeRetrievalLowReasoningEffort(), // Faster for straightforward queries\n            OutputMode = KnowledgeRetrievalOutputMode.AnswerSynthesis, // LLM generates natural answers\n            Models = { new KnowledgeBaseAzureOpenAIModel(azureOpenAIParameters: aoaiParams) }\n        };\n\n        await _indexClient.CreateOrUpdateKnowledgeBaseAsync(knowledgeBase);\n        Console.WriteLine($\"\u2705 Knowledge base '{KnowledgeBaseName}' created with model '{modelName}'\");\n    }\n\n    /// &lt;summary&gt;\n    /// Performs agentic retrieval using Knowledgebases with optional instructions\n    /// The LLM searches, ranks, and synthesizes a natural language response\n    /// &lt;/summary&gt;\n    /// &lt;param name=\"query\"&gt;Natural language query&lt;/param&gt;\n    /// &lt;param name=\"instructions\"&gt;Optional formatting instructions for LLM output (sent as assistant role message)&lt;/param&gt;\n    /// &lt;param name=\"topResults\"&gt;Number of top results to retrieve&lt;/param&gt;\n    public async Task&lt;string&gt; RetrieveAsync(string query, string? instructions = null, int topResults = 5)\n    {\n        // Use Knowledge Base retrieval API for LLM-powered search\n        var retrievalRequest = new KnowledgeBaseRetrievalRequest\n        {\n            RetrievalReasoningEffort = new KnowledgeRetrievalLowReasoningEffort(),\n            OutputMode = KnowledgeRetrievalOutputMode.AnswerSynthesis // Enable answer synthesis for better responses\n        };\n\n        // Add instructions as assistant role message if provided\n        if (!string.IsNullOrEmpty(instructions))\n        {\n            retrievalRequest.Messages.Add(new KnowledgeBaseMessage(\n                content: new[] { new KnowledgeBaseMessageTextContent(instructions) }\n            ) \n            { \n                Role = \"assistant\" \n            });\n        }\n\n        // Add user message with the query\n        retrievalRequest.Messages.Add(new KnowledgeBaseMessage(\n            content: new[] { new KnowledgeBaseMessageTextContent(query) }\n        ) \n        { \n            Role = \"user\" \n        });\n\n        var retrievalResult = await _retrievalClient.RetrieveAsync(retrievalRequest);\n\n        // Extract the LLM-synthesized answer\n        var result = new StringBuilder();\n\n        if (retrievalResult.Value.Response != null &amp;&amp; retrievalResult.Value.Response.Count &gt; 0)\n        {\n            foreach (var response in retrievalResult.Value.Response)\n            {\n                foreach (var content in response.Content)\n                {\n                    if (content is KnowledgeBaseMessageTextContent textContent)\n                    {\n                        result.AppendLine(textContent.Text);\n                    }\n                }\n            }\n        }\n\n        return result.ToString();\n    }\n\n    /// &lt;summary&gt;\n    /// Gets claim details directly from the claims index using filter query\n    /// This bypasses the Knowledgebases for structured data retrieval\n    /// &lt;/summary&gt;\n    /// &lt;param name=\"claimNumber\"&gt;The claim number to retrieve&lt;/param&gt;\n    /// &lt;returns&gt;SearchDocument with all claim fields or null if not found&lt;/returns&gt;\n    public async Task&lt;SearchDocument?&gt; GetClaimByNumberAsync(string claimNumber)\n    {\n        var claimsClient = _indexClient.GetSearchClient(ClaimsIndex);\n\n        var searchOptions = new SearchOptions\n        {\n            Filter = $\"claimNumber eq '{claimNumber}'\",\n            Size = 1\n        };\n\n        var searchResults = await claimsClient.SearchAsync&lt;SearchDocument&gt;(\"*\", searchOptions);\n\n        await foreach (var searchResult in searchResults.Value.GetResultsAsync())\n        {\n            return searchResult.Document;\n        }\n\n        return null;\n    }\n\n    /// &lt;summary&gt;\n    /// Calls Azure OpenAI directly for structured JSON responses without answer synthesis\n    /// Use this for fraud analysis or other tasks requiring strict JSON schema adherence\n    /// &lt;/summary&gt;\n    /// &lt;param name=\"systemPrompt\"&gt;System instructions for the AI&lt;/param&gt;\n    /// &lt;param name=\"userPrompt\"&gt;User query/data to analyze&lt;/param&gt;\n    /// &lt;param name=\"modelName\"&gt;Model deployment name (default: gpt-4)&lt;/param&gt;\n    /// &lt;returns&gt;Raw AI response without Knowledge Base processing&lt;/returns&gt;\n    public async Task&lt;string&gt; GetDirectChatCompletionAsync(string systemPrompt, string userPrompt, string? modelName = null)\n    {\n        var model = modelName ?? _configuration[\"AIModels:LanguageModel:Name\"] ?? \"gpt-4.1\";\n        var chatClient = _openAIClient.GetChatClient(model);\n\n        var messages = new List&lt;OpenAI.Chat.ChatMessage&gt;\n        {\n            new OpenAI.Chat.SystemChatMessage(systemPrompt),\n            new OpenAI.Chat.UserChatMessage(userPrompt)\n        };\n\n        var chatOptions = new OpenAI.Chat.ChatCompletionOptions\n        {\n            Temperature = 0.1f, // Low temperature for consistent JSON output\n            MaxOutputTokenCount = 2000\n        };\n\n        Console.WriteLine($\"\ud83e\udd16 Calling Azure OpenAI directly (model: {model})...\");\n        var response = await chatClient.CompleteChatAsync(messages, chatOptions);\n\n        var content = response.Value.Content[0].Text;\n        Console.WriteLine($\"\u2705 Direct OpenAI response: {content.Substring(0, Math.Min(100, content.Length))}...\");\n\n        return content;\n    }\n\n    /// &lt;summary&gt;\n    /// Indexes sample claims data\n    /// &lt;/summary&gt;\n    public async Task IndexSampleDataAsync()\n    {\n        await IndexClaimsDataAsync();\n        Console.WriteLine(\"\u2705 Sample data indexed successfully\");\n    }\n\n    /// &lt;summary&gt;\n    /// Loads and indexes sample claims data from JSON file\n    /// &lt;/summary&gt;\n    private async Task IndexClaimsDataAsync()\n    {\n        Console.WriteLine(\"\ud83d\udcdd Indexing sample claims...\");\n\n        var claimsFile = Path.Combine(AppContext.BaseDirectory, \"infra\", \"data\", \"sample-data\", \"claims.json\");\n\n        if (!File.Exists(claimsFile))\n        {\n            Console.WriteLine($\"\u26a0\ufe0f Claims file not found: {claimsFile}\");\n            return;\n        }\n\n        var claimsJson = await File.ReadAllTextAsync(claimsFile);\n        var claims = System.Text.Json.JsonSerializer.Deserialize&lt;List&lt;System.Text.Json.JsonElement&gt;&gt;(claimsJson);\n\n        if (claims == null || claims.Count == 0)\n        {\n            Console.WriteLine(\"\u26a0\ufe0f No claims data to index\");\n            return;\n        }\n\n        var searchClient = _indexClient.GetSearchClient(ClaimsIndex);\n        var batch = new List&lt;SearchDocument&gt;();\n\n        // Create search documents from claims JSON with enhanced fields\n        foreach (var claim in claims)\n        {\n            var claimNumber = claim.GetProperty(\"claimNumber\").GetString();\n            var status = claim.GetProperty(\"status\").GetString() ?? \"\";\n            var claimId = claim.GetProperty(\"id\").GetInt32();\n            var random = new Random(claimId);\n\n            // Generate DateFiled based on claim status (same logic as complete solution)\n            DateTime dateFiled;\n            DateTime? dateResolved = null;\n\n            if (status == \"Open\" || status == \"Under Review\")\n            {\n                dateFiled = DateTime.UtcNow.AddDays(-random.Next(0, 4));\n            }\n            else if (status == \"In Progress\")\n            {\n                dateFiled = DateTime.UtcNow.AddDays(-random.Next(4, 11));\n            }\n            else if (status == \"Approved\" || status == \"Closed\")\n            {\n                dateFiled = DateTime.UtcNow.AddDays(-random.Next(10, 31));\n                dateResolved = DateTime.UtcNow.AddDays(-random.Next(2, 6));\n            }\n            else\n            {\n                dateFiled = DateTime.UtcNow.AddDays(-random.Next(5, 21));\n            }\n\n            // Build searchable content for embedding\n            var searchableContent = $\"Claim {claimNumber} - {claim.GetProperty(\"claimType\").GetString()} for {claim.GetProperty(\"policyholderName\").GetString()}. \" +\n                                  $\"Status: {status}. Location: {claim.GetProperty(\"location\").GetString()}. Description: {claim.GetProperty(\"description\").GetString()}. \" +\n                                  $\"Severity: {claim.GetProperty(\"severity\").GetString()}. Estimated Cost: ${claim.GetProperty(\"estimatedCost\").GetDouble():N2}.\";\n\n            // Generate embedding for vector search\n            var embedding = await CreateEmbeddingAsync(searchableContent);\n\n            var doc = new SearchDocument\n            {\n                [\"id\"] = claimNumber,\n                [\"claimNumber\"] = claimNumber,\n                [\"policyholderName\"] = claim.GetProperty(\"policyholderName\").GetString(),\n                [\"policyNumber\"] = claim.GetProperty(\"policyNumber\").GetString(),\n                [\"claimType\"] = claim.GetProperty(\"claimType\").GetString(),\n                [\"status\"] = status,\n                [\"severity\"] = claim.GetProperty(\"severity\").GetString(),\n                [\"region\"] = claim.GetProperty(\"region\").GetString(),\n                [\"assignedAdjuster\"] = claim.GetProperty(\"assignedAdjuster\").GetString(),\n                [\"dateFiled\"] = dateFiled,\n                [\"dateResolved\"] = dateResolved,\n                [\"description\"] = claim.GetProperty(\"description\").GetString(),\n                [\"location\"] = claim.GetProperty(\"location\").GetString(),\n                [\"claimAmount\"] = claim.GetProperty(\"estimatedCost\").GetDouble(),\n                [\"fraudScore\"] = claim.GetProperty(\"fraudRiskScore\").GetInt32(),\n                [\"fraudIndicators\"] = claim.GetProperty(\"fraudIndicators\").GetString(),\n                [\"adjusterNotes\"] = $\"Assigned to {claim.GetProperty(\"assignedAdjuster\").GetString()}\",\n                [\"searchableContent\"] = searchableContent,\n                [\"contentVector\"] = embedding\n            };\n\n            batch.Add(doc);\n        }\n\n        // Upload all documents in a single batch\n        await searchClient.IndexDocumentsAsync(IndexDocumentsBatch.Upload(batch));\n        Console.WriteLine($\"\u2705 Indexed {batch.Count} claims\");\n    }\n\n    /// &lt;summary&gt;\n    /// Generates embeddings for text content using Azure OpenAI\n    /// &lt;/summary&gt;\n    private async Task&lt;float[]&gt; CreateEmbeddingAsync(string text)\n    {\n        var embeddingClient = _openAIClient.GetEmbeddingClient(_embeddingModel);\n        var response = await embeddingClient.GenerateEmbeddingAsync(text);\n        return response.Value.ToFloats().ToArray();\n    }\n\n    #region Helper Methods\n\n    /// &lt;summary&gt;\n    /// Creates vector search configuration for embeddings-based similarity search\n    /// &lt;/summary&gt;\n    private VectorSearch CreateVectorSearchConfig()\n    {\n        return new VectorSearch\n        {\n            Profiles =\n            {\n                new VectorSearchProfile(\"vector-profile\", \"hnsw-config\")\n            },\n            Algorithms =\n            {\n                new HnswAlgorithmConfiguration(\"hnsw-config\")\n            }\n        };\n    }\n\n    /// &lt;summary&gt;\n    /// Creates semantic search configuration (required by Knowledgebases)\n    /// &lt;/summary&gt;\n    private SemanticSearch CreateSemanticConfig(string configName, string titleField, string contentField, string keywordsField)\n    {\n        return new SemanticSearch\n        {\n            Configurations =\n            {\n                new SemanticConfiguration(configName, new SemanticPrioritizedFields\n                {\n                    TitleField = new SemanticField(titleField),\n                    ContentFields = { new SemanticField(contentField) },\n                    KeywordsFields = { new SemanticField(keywordsField) }\n                })\n            }\n        };\n    }\n\n    #endregion\n}\n</code></pre> <p></p>"},{"location":"pages/custom-engine/agent-framework/02-add-claim-search/#exercise-3-create-the-claimsplugin","title":"Exercise 3: Create the ClaimsPlugin","text":"<p>Now let's create the ClaimsPlugin that uses the KnowledgeBaseService to provide claim search capabilities to your agent.</p>"},{"location":"pages/custom-engine/agent-framework/02-add-claim-search/#step-1-create-complete-claimsplugin","title":"Step 1: Create Complete ClaimsPlugin","text":"What this code does <p>The <code>ClaimsPlugin</code> provides claim search capabilities to your agent:</p> <ul> <li>SearchClaims: Searches for claims by region, type, severity, or status - builds natural language query and uses agentic retrieval with structured output instructions</li> <li>GetClaimDetails: Retrieves comprehensive information for a specific claim ID with detailed formatting instructions for the LLM</li> <li>NotifyUserAsync: Helper method to send real-time status updates to users (\"Searching...\", \"Retrieved data...\") using StreamingResponse</li> </ul> <p>Each method has a <code>[Description]</code> attribute that tells the AI agent when and how to use the tool. The AI automatically decides which tool to call based on user intent.</p> <p>1\ufe0f\u20e3 Create a new file <code>src/Plugins/ClaimsPlugin.cs</code> and add the complete implementation:</p> <pre><code>using Microsoft.Agents.Builder;\nusing Microsoft.Agents.Core;\nusing Microsoft.Agents.Core.Models;\nusing Microsoft.Extensions.Configuration;\nusing System.ComponentModel;\nusing System.Text;\nusing InsuranceAgent.Services;\nusing Azure.Search.Documents.Models;\n\nnamespace ZavaInsurance.Plugins\n{\n    /// &lt;summary&gt;\n    /// Plugin that provides claim search and retrieval capabilities using Azure AI Search\n    /// &lt;/summary&gt;\n    public class ClaimsPlugin\n    {\n        private readonly ITurnContext _turnContext;\n        private readonly KnowledgeBaseService _knowledgeBaseService;\n        private readonly IConfiguration _configuration;\n\n        public ClaimsPlugin(\n            ITurnContext turnContext, \n            KnowledgeBaseService knowledgeBaseService,\n            IConfiguration configuration)\n        {\n            _turnContext = turnContext ?? throw new ArgumentNullException(nameof(turnContext));\n            _knowledgeBaseService = knowledgeBaseService ?? throw new ArgumentNullException(nameof(knowledgeBaseService));\n            _configuration = configuration ?? throw new ArgumentNullException(nameof(configuration));\n        }\n\n        /// &lt;summary&gt;\n        /// Searches for claims based on multiple criteria (region, type, severity, status)\n        /// Returns up to 10 matching claims with structured summaries\n        /// &lt;/summary&gt;\n        [Description(\"Searches for insurance claims based on region, type, severity, and status. Returns a summary of matching claims.\")]\n        public async Task&lt;string&gt; SearchClaims(\n            string region = null,\n            string claimType = null,\n            string severity = null,\n            string status = null)\n        {\n            await NotifyUserAsync($\"Searching claims database using AI Search...\");\n\n            // Build natural language query from parameters\n            var queryParts = new List&lt;string&gt; { \"insurance claims\" };\n\n            if (!string.IsNullOrEmpty(region))\n                queryParts.Add($\"in {region} region\");\n            if (!string.IsNullOrEmpty(claimType))\n                queryParts.Add($\"of type {claimType}\");\n            if (!string.IsNullOrEmpty(severity))\n                queryParts.Add($\"with {severity} severity\");\n            if (!string.IsNullOrEmpty(status))\n                queryParts.Add($\"with status {status}\");\n\n            var query = string.Join(\" \", queryParts);\n\n            // Use agentic retrieval with instructions for structured output\n            var instructions = @\"You are an insurance claims specialist. Provide a clear, structured summary of matching claims.\n                Format your response as follows:\n                - Total number of claims found\n                - For each claim, include: Claim Number, Policyholder, Claim Type, Amount, Status, Date Filed, Severity, Region\n                - Use bullet points for readability\n                - Include relevant details like adjuster notes or special circumstances\n                - Cite sources using [ref_id:X] format\";\n\n            // Retrieve up to 10 matching claims\n            var response = await _knowledgeBaseService.RetrieveAsync(query, instructions, topResults: 10);\n\n            await NotifyUserAsync($\"Retrieved claims information\");\n\n            return response;\n        }\n\n        /// &lt;summary&gt;\n        /// Retrieves comprehensive details for a specific claim by claim number\n        /// Uses direct document access for structured data retrieval\n        /// &lt;/summary&gt;\n        [Description(\"Retrieves detailed information for a specific claim by claim ID, including policyholder info, documentation, and history.\")]\n        public async Task&lt;string&gt; GetClaimDetails(string claimId)\n        {\n            await NotifyUserAsync($\"Retrieving details for claim {claimId}...\");\n\n            // Use direct search to get structured data (more reliable than Knowledge Base answer synthesis)\n            var claimDoc = await _knowledgeBaseService.GetClaimByNumberAsync(claimId);\n\n            if (claimDoc == null)\n            {\n                return $\"\u274c Claim {claimId} not found in the system.\";\n            }\n\n            // Extract fields from the search document\n            var result = new StringBuilder();\n            result.AppendLine(\"**Claim Information:**\");\n            result.AppendLine($\"- Claim Number: {GetFieldValue(claimDoc, \"claimNumber\")}\");\n            result.AppendLine($\"- Status: {GetFieldValue(claimDoc, \"status\")}\");\n            result.AppendLine($\"- Claim Type: {GetFieldValue(claimDoc, \"claimType\")}\");\n            result.AppendLine();\n\n            result.AppendLine(\"**Policyholder &amp; Policy:**\");\n            result.AppendLine($\"- Policyholder Name: {GetFieldValue(claimDoc, \"policyholderName\")}\");\n            result.AppendLine($\"- Policy Number: {GetFieldValue(claimDoc, \"policyNumber\")}\");\n            result.AppendLine();\n\n            result.AppendLine(\"**Financial Details:**\");\n            var estimatedCost = GetFieldValue(claimDoc, \"estimatedCost\");\n            result.AppendLine($\"- Estimated Cost: ${estimatedCost}\");\n            result.AppendLine($\"- Severity: {GetFieldValue(claimDoc, \"severity\")}\");\n            result.AppendLine();\n\n            result.AppendLine(\"**Assignment &amp; Location:**\");\n            result.AppendLine($\"- Assigned Adjuster: {GetFieldValue(claimDoc, \"assignedAdjuster\")}\");\n            result.AppendLine($\"- Region: {GetFieldValue(claimDoc, \"region\")}\");\n            result.AppendLine($\"- Location: {GetFieldValue(claimDoc, \"location\")}\");\n            result.AppendLine();\n\n            result.AppendLine(\"**Incident Details:**\");\n            result.AppendLine($\"- Description: {GetFieldValue(claimDoc, \"description\")}\");\n            result.AppendLine();\n\n            result.AppendLine(\"**Fraud Assessment:**\");\n            var fraudScore = GetFieldValue(claimDoc, \"fraudRiskScore\");\n            result.AppendLine($\"- Fraud Risk Score: {fraudScore}/100\");\n            var fraudIndicators = GetFieldValue(claimDoc, \"fraudIndicators\");\n            result.AppendLine($\"- Fraud Indicators: {(string.IsNullOrWhiteSpace(fraudIndicators) ? \"None identified\" : fraudIndicators)}\");\n            result.AppendLine();\n\n            result.AppendLine(\"**Documentation Status:**\");\n            var isComplete = GetFieldValue(claimDoc, \"isDocumentationComplete\");\n            result.AppendLine($\"- Documentation Complete: {(isComplete == \"True\" || isComplete == \"true\" ? \"Yes\" : \"No\")}\");\n            var missingDocs = GetFieldValue(claimDoc, \"missingDocumentation\");\n            result.AppendLine($\"- Missing Documentation: {(string.IsNullOrWhiteSpace(missingDocs) ? \"None\" : missingDocs)}\");\n\n            await NotifyUserAsync($\"Retrieved details for claim {claimId}\");\n\n            return result.ToString();\n        }\n\n        /// &lt;summary&gt;\n        /// Helper method to safely extract field values from SearchDocument\n        /// &lt;/summary&gt;\n        private string GetFieldValue(SearchDocument doc, string fieldName)\n        {\n            if (doc.ContainsKey(fieldName) &amp;&amp; doc[fieldName] != null)\n            {\n                return doc[fieldName].ToString() ?? \"Not available\";\n            }\n            return \"Not available\";\n        }\n\n        /// &lt;summary&gt;\n        /// Helper method to send real-time status updates to users\n        /// Uses StreamingResponse for immediate feedback during long operations\n        /// &lt;/summary&gt;\n        private async Task NotifyUserAsync(string message)\n        {\n            // Send streaming updates (shows as typing indicators with message)\n            if (!_turnContext.Activity.ChannelId.Channel!.Contains(Channels.Webchat))\n            {\n                await _turnContext.StreamingResponse.QueueInformativeUpdateAsync(message);\n            }\n            else\n            {\n                await _turnContext.StreamingResponse.QueueInformativeUpdateAsync(message).ConfigureAwait(false);\n            }\n        }\n    }\n}\n</code></pre> <p></p>"},{"location":"pages/custom-engine/agent-framework/02-add-claim-search/#exercise-4-register-services-and-configure-agent","title":"Exercise 4: Register Services and Configure Agent","text":"<p>Now let's wire everything together by registering services in Program.cs and adding the ClaimsPlugin to your agent.</p>"},{"location":"pages/custom-engine/agent-framework/02-add-claim-search/#step-1-register-knowledgebaseservice-and-initialize-data","title":"Step 1: Register KnowledgeBaseService and Initialize Data","text":"What this code does <p>The <code>Program.cs</code> takes care of registering the services:</p> <ul> <li>Service Registration: Registers KnowledgeBaseService as a singleton so it's available throughout the app</li> <li>Initialization: Creates index \u2192 knowledge source \u2192 knowledge base \u2192 indexes sample data (must be done in this order)</li> <li>Error Handling: Catches initialization errors without stopping the app (useful for development)</li> </ul> <p>1\ufe0f\u20e3 Open <code>src/Program.cs</code>.</p> <p>2\ufe0f\u20e3 At the top with other using statements, add:</p> <pre><code>using InsuranceAgent.Services;\n</code></pre> <p>3\ufe0f\u20e3 Find <code>builder.Services.AddSingleton&lt;IStorage, MemoryStorage&gt;();</code> and add right after:</p> <pre><code>// Register Knowledge Base Service for Azure AI Search\nbuilder.Services.AddSingleton&lt;KnowledgeBaseService&gt;();\n</code></pre> <p>4\ufe0f\u20e3 Find the line <code>var app = builder.Build();</code> and add this initialization code right after:</p> <pre><code>// Initialize Azure AI Search Knowledge Base\nusing (var scope = app.Services.CreateScope())\n{\n    try\n    {\n        var kbService = scope.ServiceProvider.GetRequiredService&lt;KnowledgeBaseService&gt;();\n\n        Console.WriteLine(\"\ud83d\udd0d Initializing Azure AI Search Knowledge Base...\");\n\n        // IMPORTANT: Must follow this order - indexes \u2192 knowledge sources \u2192 knowledge base \u2192 data\n        await kbService.EnsureClaimsIndexAsync();          // 1. Create claims index\n        await kbService.CreateKnowledgeSourcesAsync();     // 2. Create claims knowledge source\n        await kbService.CreateKnowledgeBaseAsync();        // 3. Create knowledge base\n        await kbService.IndexSampleDataAsync();            // 4. Index sample claims data\n\n        Console.WriteLine(\"\u2705 Knowledge Base initialized successfully\");\n    }\n    catch (Exception ex)\n    {\n        Console.WriteLine($\"\u26a0\ufe0f Knowledge Base initialization warning: {ex.Message}\");\n    }\n}\n</code></pre> <p></p>"},{"location":"pages/custom-engine/agent-framework/02-add-claim-search/#step-2-configure-agent-with-claimsplugin","title":"Step 2: Configure Agent with ClaimsPlugin","text":"What this code does <p>In the <code>ZavaInsuranceAgent.cs</code> file you need to instruct the agent to use the new ClaimsPlugin:</p> <ul> <li>Agent Instructions: Updates the agent's system prompt to include ClaimsPlugin tools (tells AI when to use them)</li> <li>Plugin Creation: Instantiates ClaimsPlugin with required dependencies (context, knowledge base service, configuration)</li> <li>Tool Registration: Registers SearchClaims and GetClaimDetails as callable tools for the AI agent</li> </ul> <p>1\ufe0f\u20e3 Open <code>src/Agent/ZavaInsuranceAgent.cs</code>.</p> <p>2\ufe0f\u20e3 Add the following using statements at the top:</p> <pre><code>using InsuranceAgent.Services;\n</code></pre> <p>3\ufe0f\u20e3 Find the <code>AgentInstructions</code> property and replace it with the following snippet:</p> <pre><code>private readonly string AgentInstructions = \"\"\"\nYou are a professional insurance claims assistant for Zava Insurance.\n\nWhenever the user starts a new conversation or provides a prompt to start a new conversation like \"start over\", \"restart\", \"new conversation\", \"what can you do?\", \"how can you help me?\", etc. use {{StartConversationPlugin.StartConversation}} and provide to the user exactly the message you get back from the plugin.\n\n**Available Tools:**\nUse {{DateTimeFunctionTool.getDate}} to get the current date and time.\nFor claims search, use {{ClaimsPlugin.SearchClaims}} and {{ClaimsPlugin.GetClaimDetails}}.\n\nStick to the scenario above and use only the information from the tools when answering questions.\nBe concise and professional in your responses.\n\"\"\";\n</code></pre> <p>4\ufe0f\u20e3 Find the <code>GetClientAgent</code> method in <code>src/Agent/ZavaInsuranceAgent.cs</code>, locate where <code>StartConversationPlugin</code> is created and add the following snippet right after:</p> <pre><code>var scope = _serviceProvider.CreateScope();\n\n// Get KnowledgeBaseService and IConfiguration from DI\nvar knowledgeBaseService = scope.ServiceProvider.GetRequiredService&lt;KnowledgeBaseService&gt;();\nvar configuration = scope.ServiceProvider.GetRequiredService&lt;IConfiguration&gt;();\n\n// Create ClaimsPlugin with required dependencies\nClaimsPlugin claimsPlugin = new(context, knowledgeBaseService, configuration);\n</code></pre> <p>5\ufe0f\u20e3 Find where tools are registered and add the following snippet to register the ClaimsPlugin, right after <code>toolOptions.Tools.Add(AIFunctionFactory.Create(startConversationPlugin.StartConversation))</code>:</p> <pre><code>// Register ClaimsPlugin tools\ntoolOptions.Tools.Add(AIFunctionFactory.Create(claimsPlugin.SearchClaims));\ntoolOptions.Tools.Add(AIFunctionFactory.Create(claimsPlugin.GetClaimDetails));\n</code></pre> <p></p>"},{"location":"pages/custom-engine/agent-framework/02-add-claim-search/#step-3-update-startconversationplugin-welcome-message","title":"Step 3: Update StartConversationPlugin Welcome Message","text":"<p>Now that we've added claims search capabilities, let's update the welcome message to reflect the new features.</p> <p>1\ufe0f\u20e3 Open <code>src/Plugins/StartConversationPlugin.cs</code>.</p> <p>2\ufe0f\u20e3 Find the <code>welcomeMessage</code> variable in the <code>StartConversation</code> method and replace it with:</p> <pre><code>            var welcomeMessage = \"\ud83d\udc4b Welcome to Zava Insurance Claims Assistant!\\n\\n\" +\n                                \"I'm your AI-powered insurance claims specialist. I help adjusters and investigators streamline the claims process.\\n\\n\" +\n                                \"**What I can do:**\\n\\n\" +\n                                \"- Search and retrieve detailed claim information\\n\" +\n                                \"- Provide current date and time\\n\" +\n                                \"- Answer questions about claims\\n\\n\" +\n                                \"\ud83c\udfaf Try these commands:\\n\" +\n                                \"1. \\\"Search for claims with high severity\\\"\\n\" +\n                                \"2. \\\"Get details for claim CLM-2025-001007\\\"\\n\" +\n                                \"3. \\\"Show me recent claims in the Northeast region\\\"\\n\\n\" +\n                                \"Ready to help with your claims investigation. What would you like to start with?\";\n</code></pre> Progressive feature updates <p>Each lab progressively enhances the welcome message to reflect new capabilities. This ensures users always see an accurate description of what the agent can do at each stage of development.</p> <p></p>"},{"location":"pages/custom-engine/agent-framework/02-add-claim-search/#exercise-5-test-the-document-search","title":"Exercise 5: Test the Document Search","text":"<p>Now let's test the new claims search capabilities!</p>"},{"location":"pages/custom-engine/agent-framework/02-add-claim-search/#step-1-run-the-agent","title":"Step 1: Run the Agent","text":"<p>1\ufe0f\u20e3 Press F5 in VS Code to start debugging.</p> <p>2\ufe0f\u20e3 Select (Preview) Debug in Copilot (Edge) if prompted.</p> <p>3\ufe0f\u20e3 Watch the terminal output - you should see:</p> <pre><code>\ud83d\udd0d Initializing Azure AI Search Knowledge Base...\n\ud83d\udcdd Creating claims index 'claims-index'...\n\u2705 Claims index 'claims-index' created successfully\n\u2705 Knowledge source 'claims-knowledge-source' created\n\u2705 Knowledge base 'zava-insurance-kb' created with model 'gpt-4.1'\n\ud83d\udcdd Indexing sample claims...\n\u2705 Indexed 35 claims\n\u2705 Sample data indexed successfully\n\u2705 Knowledge Base initialized successfully\n</code></pre> <p>About Policies</p> <p>You may see additional output related to policies if your KnowledgeBaseService includes policy functionality from the complete implementation. This is expected - we'll use policies in a future lab. For now, focus on the claims functionality.</p> <p>4\ufe0f\u20e3 A browser window will open with Microsoft 365 Copilot. Your agent should already be installed from the previous lab.</p> <p>5\ufe0f\u20e3 Verify in Azure Portal (optional but recommended):</p> <ul> <li>Go to Azure Portal and search the name of your Azure AI Search service</li> <li>Click Indexes in the left menu and you should see <code>claims-index</code> listed. Click on the index name and select Search to view details and see the 35 indexed documents</li> <li>Go back to your search service and click Agentic retrieval &gt; Knowledge Bases to see <code>zava-insurance-kb</code> listed</li> <li>You can also use the Search Explorer to test queries directly against your index</li> </ul> <p></p>"},{"location":"pages/custom-engine/agent-framework/02-add-claim-search/#step-2-test-claim-search","title":"Step 2: Test Claim Search","text":"<p>1\ufe0f\u20e3 In Microsoft 365 Copilot, try a more specific search: </p> <pre><code>Find claims in the South region\n</code></pre> <p>2\ufe0f\u20e3 Try: </p> <pre><code>Show me auto claims with medium severity\n</code></pre> <p></p>"},{"location":"pages/custom-engine/agent-framework/02-add-claim-search/#step-3-test-claim-details","title":"Step 3: Test Claim Details","text":"<p>1\ufe0f\u20e3 Try: </p> <pre><code>Get details for claim CLM-2025-001007\n</code></pre> <p>The agent should use <code>GetClaimDetails</code> and return detailed information. Note that we'll continue adding more data in future labs that will enhance the responses such as showing policy or claim history in claim details.</p> <p>2\ufe0f\u20e3 Try another claim: </p> <pre><code>Show me information about claim CLM-2025-001003\n</code></pre> <p></p> <p>CONGRATULATIONS!</p> <p>You have completed Lab BAF2 - Add Document Search with Azure AI Search!</p> <p>You've learned how to:</p> <ul> <li>\u2705 Set up Azure AI Search with sample data</li> <li>\u2705 Create a KnowledgeBaseService for AI-powered retrieval</li> <li>\u2705 Build a ClaimsPlugin with multiple search capabilities</li> <li>\u2705 Register services and initialize knowledge base on startup</li> <li>\u2705 Test document search with natural language queries</li> </ul> <p>In the next lab, you'll enhance your agent further by adding vision analysis capabilities to process images related to claims.</p> <p></p> <p></p>"},{"location":"pages/custom-engine/agent-framework/03-add-vision-analysis/","title":"Lab BAF3 - Add Vision Analysis with Mistral AI","text":"<p>In this lab, you'll add AI vision capabilities to analyze damage photos from insurance claims using the Mistral medium-2505 model. Your agent will be able to automatically assess vehicle damage, estimate repair costs, and identify safety concerns from photos.</p> What You'll Learn <ul> <li>How to integrate Mistral AI vision model for multimodal analysis</li> <li>Processing image data from Azure Blob Storage</li> <li>Implementing AI-powered damage assessment</li> <li>Creating approval workflows for AI-generated analysis</li> </ul>"},{"location":"pages/custom-engine/agent-framework/03-add-vision-analysis/#overview","title":"Overview","text":"<p>In Lab BAF2, you added claim search using Azure AI Search Knowledgebases. Now you'll enhance your agent with multimodal AI vision capabilities to analyze damage photos and provide detailed assessment reports.</p> <p>The Vision Service uses the mistral-medium-2505 model deployed in Azure AI Services, which can analyze images and generate structured JSON responses with damage assessments.</p>"},{"location":"pages/custom-engine/agent-framework/03-add-vision-analysis/#exercise-1-update-prerequisites","title":"Exercise 1: Update Prerequisites","text":"<p>Before adding vision analysis, you need to deploy the Mistral vision model.</p>"},{"location":"pages/custom-engine/agent-framework/03-add-vision-analysis/#step-1-deploy-mistral-vision-model-in-microsoft-foundry","title":"Step 1: Deploy Mistral Vision Model in Microsoft Foundry","text":"<p>1\ufe0f\u20e3 Sign in to Microsoft Foundry.</p> <p>2\ufe0f\u20e3 Go to your project or create a new one.</p> <p>3\ufe0f\u20e3 Navigate to Models + endpoints \u2192 Deploy model \u2192 Deploy base model.</p> <p>4\ufe0f\u20e3 Search for mistral-medium-2505 and deploy it:</p> <ul> <li>Model: <code>mistral-medium-2505</code></li> <li>Deployment name: <code>mistral-medium-2505</code> (use exactly this name)</li> <li>Version: Latest available</li> </ul> <p>5\ufe0f\u20e3 Wait for the deployment to complete (~2-3 minutes).</p> <p>6\ufe0f\u20e3 Note your deployment details:</p> <ul> <li>The model uses the same endpoint as your gpt-4.1 deployment</li> <li>The model uses the same API key as your other models</li> <li>Only the model name changes to <code>mistral-medium-2505</code></li> </ul> <p></p>"},{"location":"pages/custom-engine/agent-framework/03-add-vision-analysis/#step-2-create-azure-storage-account-and-container","title":"Step 2: Create Azure Storage Account and Container","text":"<p>Create a storage account and container for damage photos.</p> <p>1\ufe0f\u20e3 Sign in to the Azure Portal.</p> <p>2\ufe0f\u20e3 Create a new Storage Account:</p> <ul> <li>Search for \"Storage accounts\" in the top search bar</li> <li>Click + Create</li> <li> <p>Fill in the details:</p> <ul> <li>Subscription: Select your subscription</li> <li>Resource group: Use the same resource group as your other resources</li> <li>Storage account name: Choose a unique name (e.g., <code>zavadamagestorage</code> + your initials)</li> <li>Region: Same region as your AI services</li> <li>Performance: Standard</li> <li>Redundancy: Locally-redundant storage (LRS)</li> </ul> </li> <li> <p>Click Review + Create, then Create</p> </li> <li>Wait for deployment to complete (~1-2 minutes)</li> </ul> <p>3\ufe0f\u20e3 Navigate to your new storage account and enable anonymous access:</p> <ul> <li>In the left menu, under Settings, select Configuration</li> <li>Find Allow Blob anonymous access and set it to Enabled</li> <li>Click Save at the top</li> </ul> Required for Public Access <p>Anonymous blob access must be enabled at the storage account level before you can configure public access on individual containers. Without this, the container public access settings won't work.</p> <p>4\ufe0f\u20e3 Select Containers from the left menu under Data storage.</p> <p>5\ufe0f\u20e3 Click + Container at the top.</p> <p>5\ufe0f\u20e3 Configure the new container:</p> <ul> <li>Name: <code>claim-photos</code></li> <li>Public access level: <code>Blob (anonymous read access for blobs only)</code></li> <li>Click Create</li> </ul> <p>6\ufe0f\u20e3 Copy your storage account details for configuration:</p> <ul> <li>Go to Access keys in the left menu</li> <li>Copy the Connection string from key1 or key2</li> <li>Copy your Storage account name</li> </ul> Why Blob Public Access? <p>Setting the container to \"Blob\" public access level allows:</p> <ul> <li>Direct URL access to individual images for the AI vision model</li> <li>Images can be displayed in the chat interface</li> <li>No authentication needed for reading specific blob URLs</li> </ul> <p>Only individual blob URLs work - the container itself cannot be listed publicly, maintaining security.</p> <p></p>"},{"location":"pages/custom-engine/agent-framework/03-add-vision-analysis/#step-3-update-configuration","title":"Step 3: Update Configuration","text":"<p>Add the vision model and blob storage configuration to your environment variables.</p> <p>1\ufe0f\u20e3 Open your <code>.env.local</code> file.</p> <p>2\ufe0f\u20e3 Add the vision model and blob storage configuration:</p> <pre><code># Vision &amp; Fraud analysis model (mistral-medium-2505)\nVISION_MODEL_NAME=mistral-medium-2505\n\n# Storage\nAZURE_STORAGE_ACCOUNT_NAME=YOUR-STORAGE-ACCOUNT\n\n# Blob Storage for Damage Photos\nBLOB_STORAGE_CONTAINER_NAME=claim-photos\nBLOB_STORAGE_BASE_URL=https://YOUR-STORAGE-ACCOUNT.blob.core.windows.net\n</code></pre> <p>3\ufe0f\u20e3 Open your <code>.env.local.user</code> file.</p> <p>4\ufe0f\u20e3 Add the blob storage connection string:</p> <pre><code># Storage\nSECRET_AZURE_STORAGE_CONNECTION_STRING=DefaultEndpointsProtocol=https;AccountName=YOUR-STORAGE-ACCOUNT;AccountKey=YOUR-STORAGE-KEY;EndpointSuffix=core.windows.net\n</code></pre> Configuration Notes <ul> <li>SECRET_AZURE_STORAGE_CONNECTION_STRING: Paste the connection string you copied from Azure Portal</li> <li>AZURE_STORAGE_ACCOUNT_NAME: Your storage account name</li> <li>BLOB_STORAGE_CONTAINER_NAME: Must be <code>claim-photos</code> (the container you just created)</li> <li>BLOB_STORAGE_BASE_URL: Replace <code>YOUR-STORAGE-ACCOUNT</code> with your actual storage account name</li> </ul> <p></p>"},{"location":"pages/custom-engine/agent-framework/03-add-vision-analysis/#exercise-2-create-vision-and-storage-services","title":"Exercise 2: Create Vision and Storage Services","text":"<p>Now let's create the services that handle AI vision analysis and blob storage for damage photos.</p>"},{"location":"pages/custom-engine/agent-framework/03-add-vision-analysis/#step-1-create-visionservice-and-blobstorageservice","title":"Step 1: Create VisionService and BlobStorageService","text":"What this code does <p>VisionService: Analyzes damage photos using Mistral AI vision model</p> <ul> <li>Connects to Azure OpenAI with mistral-medium-2505 deployment</li> <li>Takes image bytes and generates structured JSON damage analysis</li> <li>Provides damage type, severity, cost estimates, safety concerns, repair recommendations</li> <li>Includes fallback logic if analysis fails</li> <li>Uses low temperature (0.3) for consistent, factual responses</li> </ul> <p>BlobStorageService: Manages damage photos in Azure Blob Storage</p> <ul> <li>Uploads photos organized by claim number with timestamp naming</li> <li>Downloads photos for AI analysis</li> <li>Deletes photos when needed</li> <li>Automatically detects MIME types (JPEG, PNG, GIF, BMP, WebP)</li> <li>Configures public blob access for direct URL access</li> </ul> <p>This is the complete implementation - no additional methods will be added later.</p> <p>1\ufe0f\u20e3 Create a new file <code>src/Services/VisionService.cs</code> and add the complete implementation:</p> <pre><code>using Azure;\nusing Azure.AI.OpenAI;\nusing Microsoft.Extensions.Configuration;\nusing Microsoft.Extensions.Logging;\nusing System.ClientModel;\nusing System.Text.Json;\nusing OpenAI.Chat;\n\nnamespace InsuranceAgent.Services;\n\n/// &lt;summary&gt;\n/// Service for analyzing images using Mistral AI model capabilities\n/// &lt;/summary&gt;\npublic class VisionService\n{\n    private readonly ChatClient _chatClient;\n    private readonly IConfiguration _configuration;\n    private readonly ILogger&lt;VisionService&gt; _logger;\n\n    public VisionService(\n        IConfiguration configuration,\n        ILogger&lt;VisionService&gt; logger)\n    {\n        _configuration = configuration;\n        _logger = logger;\n\n        // Use shared endpoint and API key, but different model for vision analysis\n        var endpoint = configuration[\"AIModels:Endpoint\"]\n            ?? throw new InvalidOperationException(\"AIModels:Endpoint not configured\");\n        var apiKey = configuration[\"AIModels:ApiKey\"]\n            ?? throw new InvalidOperationException(\"AIModels:ApiKey not configured\");\n        var deployment = configuration[\"AIModels:VisionModel:Name\"] \n            ?? throw new InvalidOperationException(\"AIModels:VisionModel:Name not configured\");\n\n        _logger.LogInformation(\"\ud83d\udd0d VisionService Configuration:\");\n        _logger.LogInformation(\"   Endpoint: {Endpoint}\", endpoint);\n        _logger.LogInformation(\"   Deployment: {DeploymentName}\", deployment);\n\n        var azureClient = new AzureOpenAIClient(new Uri(endpoint), new AzureKeyCredential(apiKey));\n        _chatClient = azureClient.GetChatClient(deployment);\n    }\n\n    /// &lt;summary&gt;\n    /// Analyzes an insurance claim damage photo using Mistral AI model\n    /// &lt;/summary&gt;\n    /// &lt;param name=\"imageBytes\"&gt;The image file bytes&lt;/param&gt;\n    /// &lt;param name=\"fileName\"&gt;The image file name&lt;/param&gt;\n    /// &lt;returns&gt;Detailed damage analysis&lt;/returns&gt;\n    public async Task&lt;DamageAnalysisResult&gt; AnalyzeDamagePhotoAsync(byte[] imageBytes, string fileName)\n    {\n        try\n        {\n            _logger.LogInformation(\"Starting vision analysis for {FileName} ({Size} bytes)\", fileName, imageBytes.Length);\n\n            // Create the vision analysis prompt\n            var prompt = @\"You are an expert insurance claims adjuster analyzing damage photos. \n\nAnalyze this image and provide a detailed assessment in the following JSON format:\n\n{\n  \"\"damageType\"\": \"\"&lt;type of damage: water, fire, storm, hail, flood, etc.&gt;\"\",\n  \"\"severity\"\": \"\"&lt;Low, Medium, High, or Critical&gt;\"\",\n  \"\"detailedDescription\"\": \"\"&lt;detailed description of what you see in the image&gt;\"\",\n  \"\"affectedAreas\"\": [\"\"&lt;list of affected areas/structures as array&gt;\"\"],\n  \"\"estimatedRepairCost\"\": &lt;numeric estimate in dollars&gt;,\n  \"\"safetyConcerns\"\": \"\"&lt;any immediate safety concerns&gt;\"\",\n  \"\"repairRecommendations\"\": \"\"&lt;recommended repair actions&gt;\"\",\n  \"\"urgency\"\": \"\"&lt;Immediate, Within 1 week, Within 1 month, Non-urgent&gt;\"\",\n  \"\"requiresSpecialist\"\": &lt;true/false&gt;,\n  \"\"specialistType\"\": \"\"&lt;type of specialist needed, if any&gt;\"\"\n}\n\nBe specific, professional, and focus on details that would help with claims processing.\";\n\n            // Create chat completion request with image\n            var messages = new List&lt;ChatMessage&gt;\n            {\n                new UserChatMessage(\n                    ChatMessageContentPart.CreateTextPart(prompt),\n                    ChatMessageContentPart.CreateImagePart(BinaryData.FromBytes(imageBytes), GetMimeType(fileName))\n                )\n            };\n\n            var chatOptions = new ChatCompletionOptions\n            {\n                Temperature = 0.3f, // Lower temperature for more consistent analysis\n                ResponseFormat = ChatResponseFormat.CreateJsonObjectFormat()\n            };\n\n            // Call Mistral AI model for vision analysis\n            var response = await _chatClient.CompleteChatAsync(messages, chatOptions);\n\n            var analysisJson = response.Value.Content[0].Text ?? \"{}\";\n            _logger.LogInformation(\"Vision analysis completed for {FileName}\", fileName);\n            _logger.LogDebug(\"Analysis result: {Analysis}\", analysisJson);\n\n            // Parse the JSON response\n            var result = JsonSerializer.Deserialize&lt;DamageAnalysisResult&gt;(analysisJson, new JsonSerializerOptions \n            { \n                PropertyNameCaseInsensitive = true \n            });\n\n            if (result == null)\n            {\n                _logger.LogWarning(\"Failed to parse vision analysis result for {FileName}\", fileName);\n                return CreateFallbackResult(fileName);\n            }\n\n            result.AnalyzedAt = DateTime.UtcNow;\n            result.FileName = fileName;\n\n            return result;\n        }\n        catch (Exception ex)\n        {\n            _logger.LogError(ex, \"Error analyzing image {FileName}\", fileName);\n            return CreateFallbackResult(fileName);\n        }\n    }\n\n    private string GetMimeType(string fileName)\n    {\n        var extension = Path.GetExtension(fileName).ToLowerInvariant();\n        return extension switch\n        {\n            \".jpg\" or \".jpeg\" =&gt; \"image/jpeg\",\n            \".png\" =&gt; \"image/png\",\n            \".gif\" =&gt; \"image/gif\",\n            \".webp\" =&gt; \"image/webp\",\n            _ =&gt; \"image/jpeg\"\n        };\n    }\n\n    private DamageAnalysisResult CreateFallbackResult(string fileName)\n    {\n        return new DamageAnalysisResult\n        {\n            FileName = fileName,\n            DamageType = \"Unknown\",\n            Severity = \"Medium\",\n            DetailedDescription = \"Unable to analyze image automatically. Manual review required.\",\n            AffectedAreas = new[] { \"Unknown\" },\n            EstimatedRepairCost = 0,\n            SafetyConcerns = \"Please review manually\",\n            RepairRecommendations = \"Manual assessment required\",\n            Urgency = \"Within 1 week\",\n            RequiresSpecialist = true,\n            SpecialistType = \"Insurance Adjuster\",\n            AnalyzedAt = DateTime.UtcNow\n        };\n    }\n}\n\n/// &lt;summary&gt;\n/// Result of damage analysis using Mistral AI model\n/// &lt;/summary&gt;\npublic class DamageAnalysisResult\n{\n    public string FileName { get; set; } = \"\";\n    public string DamageType { get; set; } = \"\";\n    public string Severity { get; set; } = \"\";\n    public string DetailedDescription { get; set; } = \"\";\n    public string[] AffectedAreas { get; set; } = Array.Empty&lt;string&gt;();\n    public double EstimatedRepairCost { get; set; }\n    public string SafetyConcerns { get; set; } = \"\";\n    public string RepairRecommendations { get; set; } = \"\";\n    public string Urgency { get; set; } = \"\";\n    public bool RequiresSpecialist { get; set; }\n    public string SpecialistType { get; set; } = \"\";\n    public DateTime AnalyzedAt { get; set; }\n}\n</code></pre> <p>2\ufe0f\u20e3 Create a new file <code>src/Services/BlobStorageService.cs</code> and add the complete implementation:</p> <pre><code>using Azure.Storage.Blobs;\nusing Azure.Storage.Blobs.Models;\nusing Microsoft.Extensions.Configuration;\n\nnamespace InsuranceAgent.Services;\n\n/// &lt;summary&gt;\n/// Service for uploading and managing damage photos in Azure Blob Storage\n/// &lt;/summary&gt;\npublic class BlobStorageService\n{\n    private readonly BlobServiceClient _blobServiceClient;\n    private readonly string _containerName;\n    private readonly string _baseUrl;\n\n    public BlobStorageService(IConfiguration configuration)\n    {\n        var connectionString = configuration[\"SECRET_AZURE_STORAGE_CONNECTION_STRING\"]\n            ?? throw new InvalidOperationException(\"SECRET_AZURE_STORAGE_CONNECTION_STRING not configured\");\n\n        _containerName = configuration[\"BLOB_STORAGE_CONTAINER_NAME\"] ?? \"claim-photos\";\n        _baseUrl = configuration[\"BLOB_STORAGE_BASE_URL\"] ?? \"\";\n\n        _blobServiceClient = new BlobServiceClient(connectionString);\n    }\n\n    /// &lt;summary&gt;\n    /// Uploads a damage photo and returns the public URL\n    /// &lt;/summary&gt;\n    /// &lt;param name=\"claimNumber\"&gt;The claim number for organizing photos&lt;/param&gt;\n    /// &lt;param name=\"imageBytes\"&gt;The image file bytes&lt;/param&gt;\n    /// &lt;param name=\"fileName\"&gt;Original filename&lt;/param&gt;\n    /// &lt;returns&gt;Public URL to the uploaded blob&lt;/returns&gt;\n    public async Task&lt;string&gt; UploadDamagePhotoAsync(string claimNumber, byte[] imageBytes, string fileName)\n    {\n        // Ensure container exists\n        var containerClient = _blobServiceClient.GetBlobContainerClient(_containerName);\n        await containerClient.CreateIfNotExistsAsync(PublicAccessType.Blob);\n\n        // Generate unique blob name: {claimNumber}/{timestamp}_{filename}\n        var timestamp = DateTime.UtcNow.ToString(\"yyyyMMddHHmmss\");\n        var blobName = $\"{claimNumber}/{timestamp}_{fileName}\";\n\n        var blobClient = containerClient.GetBlobClient(blobName);\n\n        // Check if blob already exists\n        if (await blobClient.ExistsAsync())\n        {\n            Console.WriteLine($\"\u23ed\ufe0f  Blob already exists: {blobName}\");\n            return blobClient.Uri.ToString();\n        }\n\n        // Set content type based on file extension\n        var contentType = GetContentType(fileName);\n        var blobHttpHeaders = new BlobHttpHeaders { ContentType = contentType };\n\n        // Upload the image\n        using var stream = new MemoryStream(imageBytes);\n        await blobClient.UploadAsync(stream, new BlobUploadOptions\n        {\n            HttpHeaders = blobHttpHeaders\n        });\n\n        // Return public URL\n        return blobClient.Uri.ToString();\n    }\n\n    /// &lt;summary&gt;\n    /// Downloads a damage photo by URL\n    /// &lt;/summary&gt;\n    public async Task&lt;byte[]&gt; DownloadPhotoAsync(string blobUrl)\n    {\n        var blobClient = new BlobClient(new Uri(blobUrl));\n        var response = await blobClient.DownloadContentAsync();\n        return response.Value.Content.ToArray();\n    }\n\n    /// &lt;summary&gt;\n    /// Deletes a damage photo by URL\n    /// &lt;/summary&gt;\n    public async Task&lt;bool&gt; DeletePhotoAsync(string blobUrl)\n    {\n        try\n        {\n            var blobClient = new BlobClient(new Uri(blobUrl));\n            await blobClient.DeleteIfExistsAsync();\n            return true;\n        }\n        catch\n        {\n            return false;\n        }\n    }\n\n    private string GetContentType(string fileName)\n    {\n        var extension = Path.GetExtension(fileName).ToLowerInvariant();\n        return extension switch\n        {\n            \".jpg\" or \".jpeg\" =&gt; \"image/jpeg\",\n            \".png\" =&gt; \"image/png\",\n            \".gif\" =&gt; \"image/gif\",\n            \".bmp\" =&gt; \"image/bmp\",\n            \".webp\" =&gt; \"image/webp\",\n            _ =&gt; \"application/octet-stream\"\n        };\n    }\n}\n</code></pre> <p></p>"},{"location":"pages/custom-engine/agent-framework/03-add-vision-analysis/#exercise-3-enhance-knowledgebaseservice-with-vision-capabilities","title":"Exercise 3: Enhance KnowledgeBaseService with Vision Capabilities","text":"<p>Before creating the VisionPlugin, we need to add methods to KnowledgeBaseService that the plugin will use. This ensures all dependencies exist when we create the plugin.</p>"},{"location":"pages/custom-engine/agent-framework/03-add-vision-analysis/#step-1-update-knowledgebaseservice-constructor","title":"Step 1: Update KnowledgeBaseService Constructor","text":"What's changing <p>The KnowledgeBaseService constructor now accepts an optional BlobStorageService parameter for uploading damage photos. The constructor was already simplified to only take IConfiguration in Lab BAF2 - now we're just adding the optional blob storage parameter.</p> <p>1\ufe0f\u20e3 Open <code>src/Services/KnowledgeBaseService.cs</code>.</p> <p>2\ufe0f\u20e3 Find <code>KnowledgeBaseService</code> constructor and replace it with the code block below that adds BlobStorageService field and update the constructor parameter:</p> <pre><code>private readonly BlobStorageService? _blobStorageService;\n\npublic KnowledgeBaseService(IConfiguration configuration, BlobStorageService? blobStorageService = null)\n{\n    _configuration = configuration;\n\n    _searchEndpoint = configuration[\"AZURE_AI_SEARCH_ENDPOINT\"]\n        ?? throw new InvalidOperationException(\"AZURE_AI_SEARCH_ENDPOINT not configured\");\n    _searchApiKey = configuration[\"SECRET_AZURE_AI_SEARCH_API_KEY\"]\n        ?? throw new InvalidOperationException(\"SECRET_AZURE_AI_SEARCH_API_KEY not configured\");\n\n    _aiEndpoint = configuration[\"MODELS_ENDPOINT\"]\n        ?? throw new InvalidOperationException(\"MODELS_ENDPOINT not configured\");\n    _aiApiKey = configuration[\"AIModels:ApiKey\"]\n        ?? throw new InvalidOperationException(\"AIModels:ApiKey not configured\");\n    _embeddingModel = configuration[\"EMBEDDING_MODEL_NAME\"]\n        ?? \"text-embedding-ada-002\";\n\n    var credential = new AzureKeyCredential(_searchApiKey);\n    _indexClient = new SearchIndexClient(new Uri(_searchEndpoint), credential);\n    _retrievalClient = new KnowledgeBaseRetrievalClient(new Uri(_searchEndpoint), KnowledgeBaseName, credential);\n\n    _openAIClient = new AzureOpenAIClient(new Uri(_aiEndpoint), new AzureKeyCredential(_aiApiKey));\n\n    _blobStorageService = blobStorageService;\n}\n</code></pre> Constructor changes <p>The constructor now accepts an optional BlobStorageService parameter which will be used to upload damage photos to Azure Blob Storage during data indexing.</p> <p></p>"},{"location":"pages/custom-engine/agent-framework/03-add-vision-analysis/#step-2-add-vision-related-methods","title":"Step 2: Add Vision-Related Methods","text":"What this code does <p>GetClaimImageUrlAsync: Direct query to claims index for imageUrl field - more efficient than RetrieveAsync for simple field lookups. Returns nullable string.</p> <p>UploadSampleDamagePhotosAsync: Complete photo upload workflow:</p> <ul> <li>Reads claims from JSON file</li> <li>Matches images using policyholder name pattern (firstname-lastname-*.jpg)</li> <li>Uploads to blob storage with claim number organization</li> <li>Creates searchable documents in claim-documents-index</li> <li>Updates claims index with imageUrl field</li> <li>Runs automatically during first startup</li> </ul> <p>This ensures all 35 sample damage photos are uploaded and indexed immediately.</p> <p>Add these two new methods to the <code>KnowledgeBaseService</code> class at the end, just before the closing brace:</p> <p>GetClaimImageUrlAsync Method - Retrieves image URLs directly from the claims index:</p> <pre><code>/// &lt;summary&gt;\n/// Gets the damage photo URL for a specific claim\n/// Checks both claims index and claim-documents index\n/// &lt;/summary&gt;\n/// &lt;param name=\"claimNumber\"&gt;The claim number to retrieve the image for&lt;/param&gt;\n/// &lt;returns&gt;The image URL or null if not found&lt;/returns&gt;\npublic async Task&lt;string?&gt; GetClaimImageUrlAsync(string claimNumber)\n{\n    // Check claims index for imageUrl (still stored there for direct access)\n    var claimsClient = _indexClient.GetSearchClient(ClaimsIndex);\n\n    var searchOptions = new SearchOptions\n    {\n        Filter = $\"claimNumber eq '{claimNumber}'\",\n        Size = 1,\n        Select = { \"imageUrl\" }\n    };\n\n    var searchResults = await claimsClient.SearchAsync&lt;SearchDocument&gt;(\"*\", searchOptions);\n\n    await foreach (var searchResult in searchResults.Value.GetResultsAsync())\n    {\n        var doc = searchResult.Document;\n        if (doc.ContainsKey(\"imageUrl\") &amp;&amp; doc[\"imageUrl\"] != null)\n        {\n            return doc[\"imageUrl\"].ToString();\n        }\n    }\n\n    return null;\n}\n</code></pre> Why not use RetrieveAsync? <p>This method directly queries the search index instead of using the Knowledge Base RetrieveAsync API. This is more efficient for simple field lookups where we just need the imageUrl value without LLM synthesis.</p> <p>UploadSampleDamagePhotosAsync Method - Complete implementation for uploading damage photos from <code>infra/img/sample-images</code>:</p> <pre><code>/// &lt;summary&gt;\n/// Uploads sample damage photos to blob storage and indexes them in Azure AI Search\n/// Reads claims from claims.json, matches images from infra/img/sample-images by policyholder name,\n/// uploads to blob storage, creates searchable documents, and updates claims with imageUrl\n/// &lt;/summary&gt;\nprivate async Task UploadSampleDamagePhotosAsync()\n{\n    if (_blobStorageService == null) return;\n\n    Console.WriteLine(\"\ud83d\udcf8 Uploading sample damage photos to blob storage and indexing...\");\n\n    var baseDirectory = AppDomain.CurrentDomain.BaseDirectory;\n    var dataPath = Path.Combine(baseDirectory, \"infra\", \"data\", \"sample-data\");\n    var filePath = Path.Combine(dataPath, \"claims.json\");\n    var imagesPath = Path.Combine(baseDirectory, \"infra\", \"img\", \"sample-images\");\n\n    if (!File.Exists(filePath))\n    {\n        Console.WriteLine($\"\u26a0\ufe0f  Claims data file not found: {filePath}\");\n        return;\n    }\n\n    if (!Directory.Exists(imagesPath))\n    {\n        Console.WriteLine($\"\u26a0\ufe0f  Sample images directory not found: {imagesPath}\");\n        return;\n    }\n\n    var json = await File.ReadAllTextAsync(filePath);\n    var claimsData = System.Text.Json.JsonSerializer.Deserialize&lt;List&lt;System.Text.Json.JsonElement&gt;&gt;(json);\n\n    if (claimsData == null || !claimsData.Any())\n    {\n        Console.WriteLine(\"\u26a0\ufe0f  No claims data to process\");\n        return;\n    }\n\n    var uploadCount = 0;\n    var claimsClient = _indexClient.GetSearchClient(ClaimsIndex);\n    var claimsToUpdate = new List&lt;SearchDocument&gt;();\n\n    Console.WriteLine($\"\ud83d\udccb Processing {claimsData.Count} total claims for damage photos...\");\n    Console.WriteLine($\"\ud83d\udcf8 Uploading to blob storage...\");\n\n    foreach (var claimData in claimsData)\n    {\n        var claimNumber = claimData.GetProperty(\"claimNumber\").GetString() ?? \"\";\n        var policyholderName = claimData.GetProperty(\"policyholderName\").GetString() ?? \"\";\n\n        // Build the expected image filename based on policyholder name\n        // Format: firstname-lastname-description.jpg (e.g., \"ajlal-nueimat-deer-collision.jpg\")\n        var nameKey = policyholderName.ToLower().Replace(\" \", \"-\");\n\n        // Find matching image file in sample-images directory\n        var imageFiles = Directory.GetFiles(imagesPath, $\"{nameKey}*.jpg\");\n\n        if (imageFiles.Length == 0)\n        {\n            Console.WriteLine($\"\u23ed\ufe0f  No image found for {claimNumber} ({policyholderName})\");\n            continue;\n        }\n\n        var imageFile = imageFiles[0];\n        var fileName = Path.GetFileName(imageFile);\n\n        Console.WriteLine($\"\ud83d\udcf8 Processing damage photo for claim {claimNumber}: {fileName}\");\n\n        try\n        {\n            // Read image from local file\n            var imageBytes = await File.ReadAllBytesAsync(imageFile);\n\n            // Upload to blob storage - blob URL will be directly accessible for viewing and AI analysis\n            var blobUrl = await _blobStorageService.UploadDamagePhotoAsync(claimNumber, imageBytes, fileName);\n\n            // Update the claim record with the image URL for direct access\n            claimsToUpdate.Add(new SearchDocument\n            {\n                [\"id\"] = claimNumber,\n                [\"imageUrl\"] = blobUrl\n            });\n\n            uploadCount++;\n            Console.WriteLine($\"\u2705 Uploaded photo for {claimNumber}: {blobUrl}\");\n        }\n        catch (Exception ex)\n        {\n            Console.WriteLine($\"\u26a0\ufe0f  Failed to upload photo for {claimNumber}: {ex.Message}\");\n        }\n    }\n\n    // Update claims with image URLs\n    if (claimsToUpdate.Any())\n    {\n        Console.WriteLine($\"\ud83d\udcdd Updating {claimsToUpdate.Count} claims with image URLs...\");\n        var claimsBatch = IndexDocumentsBatch.MergeOrUpload(claimsToUpdate);\n        await claimsClient.IndexDocumentsAsync(claimsBatch);\n        Console.WriteLine($\"\u2705 Updated {claimsToUpdate.Count} claims with image URLs\");\n    }\n\n    if (uploadCount &gt; 0)\n    {\n        Console.WriteLine($\"\ud83d\udcf8 Total: Uploaded {uploadCount} damage photos to blob storage\");\n    }\n    else\n    {\n        Console.WriteLine(\"\u26a0\ufe0f  No damage photos found to upload\");\n    }\n}\n</code></pre> What this code does <p>The <code>UploadSampleDamagePhotosAsync</code> method provides complete photo upload functionality:</p> <ul> <li>Reads claims data: Loads all claims from <code>infra/data/sample-data/claims.json</code></li> <li>Matches images: Finds corresponding images in <code>infra/img/sample-images</code> using policyholder name pattern (firstname-lastname-description.jpg)</li> <li>Uploads to blob storage: Uses BlobStorageService to upload each image to Azure Blob Storage with claim number organization</li> <li>Updates claims: Merges imageUrl field into existing claim records in <code>claims-index</code> for direct access</li> <li>Automatic execution: Runs during first app startup when IndexSampleDataAsync is called</li> </ul> <p>This simplified approach:</p> <ul> <li>\u2705 Uploads images to Azure Blob Storage for persistent storage</li> <li>\u2705 Updates claims index with imageUrl field pointing to blob URLs</li> <li>\u2705 No separate document index needed - claims contain image URLs directly</li> <li>\u2705 Images are immediately available for AI vision analysis</li> </ul> <p>This ensures all sample damage photos are automatically uploaded and linked to claims, making them immediately available for vision analysis.</p> <p></p>"},{"location":"pages/custom-engine/agent-framework/03-add-vision-analysis/#step-3-update-indexsampledataasync-method","title":"Step 3: Update IndexSampleDataAsync Method","text":"<p>Find the <code>IndexSampleDataAsync</code> method and update the method with the below code for adding the photo upload call:</p> <pre><code>public async Task IndexSampleDataAsync()\n{\n    await IndexClaimsDataAsync();\n\n    // Upload damage photos to blob storage if BlobStorageService is available\n    if (_blobStorageService != null)\n    {\n        await UploadSampleDamagePhotosAsync();\n    }\n\n    Console.WriteLine(\"\u2705 Sample data indexed successfully\");\n}\n</code></pre> <p></p>"},{"location":"pages/custom-engine/agent-framework/03-add-vision-analysis/#exercise-4-create-the-vision-plugin","title":"Exercise 4: Create the Vision Plugin","text":"<p>Now that KnowledgeBaseService has all the necessary methods, let's create the VisionPlugin that uses them.</p>"},{"location":"pages/custom-engine/agent-framework/03-add-vision-analysis/#step-1-create-complete-visionplugin","title":"Step 1: Create Complete VisionPlugin","text":"What this code does <p>The <code>VisionPlugin</code> provides complete AI vision analysis capabilities:</p> <ul> <li>ShowDamagePhoto: Retrieves and displays damage photos from claims without analysis - proxies images through devtunnel for inline display in chat</li> <li>AnalyzeAndShowDamagePhoto: Downloads photo, uses Mistral AI to analyze damage, extracts structured results (damage type, severity, cost, affected areas, safety concerns, recommendations, specialist needs), presents formatted analysis to user</li> <li>ApproveAnalysis/RejectAnalysis: Approval workflow methods that handle user feedback on AI analysis - in production would update claim database and trigger workflows</li> <li>NotifyUserAsync: Helper for real-time streaming updates during long operations</li> </ul> <p>Each method has <code>[Description]</code> attribute so the AI agent knows when to call them based on user intent.</p> <p>1\ufe0f\u20e3 Create a new file <code>src/Plugins/VisionPlugin.cs</code> and add the complete implementation:</p> <pre><code>using Microsoft.Agents.Builder;\nusing Microsoft.Agents.Core;\nusing Microsoft.Agents.Core.Models;\nusing System.ComponentModel;\nusing InsuranceAgent.Services;\nusing Microsoft.Extensions.Configuration;\n\nnamespace ZavaInsurance.Plugins\n{\n    /// &lt;summary&gt;\n    /// Vision Plugin for Zava Insurance\n    /// Uses AI vision models to analyze damage photos from insurance claims\n    /// Provides damage assessment, severity analysis, and repair cost estimates\n    /// &lt;/summary&gt;\n    public class VisionPlugin\n    {\n        private readonly ITurnContext _turnContext;\n        private readonly KnowledgeBaseService _knowledgeBaseService;\n        private readonly VisionService _visionService;\n        private readonly BlobStorageService _blobStorageService;\n        private readonly IConfiguration _configuration;\n\n        public VisionPlugin(\n            ITurnContext turnContext, \n            KnowledgeBaseService knowledgeBaseService, \n            VisionService visionService, \n            BlobStorageService blobStorageService, \n            IConfiguration configuration)\n        {\n            _turnContext = turnContext ?? throw new ArgumentNullException(nameof(turnContext));\n            _knowledgeBaseService = knowledgeBaseService ?? throw new ArgumentNullException(nameof(knowledgeBaseService));\n            _visionService = visionService ?? throw new ArgumentNullException(nameof(visionService));\n            _blobStorageService = blobStorageService ?? throw new ArgumentNullException(nameof(blobStorageService));\n            _configuration = configuration ?? throw new ArgumentNullException(nameof(configuration));\n        }\n\n        /// &lt;summary&gt;\n        /// Finds and shows the first damage photo for a claim (without analyzing)\n        /// Proxies image through devtunnel for inline display in chat\n        /// &lt;/summary&gt;\n        [Description(\"Finds and shows the first damage photo for a claim. Use this when user wants to see/view the damage photo. Does not perform AI analysis.\")]\n        public async Task&lt;string&gt; ShowDamagePhoto(string claimNumber)\n        {\n            await NotifyUserAsync($\"\ud83d\udd0d Searching for damage photos in claim {claimNumber}...\");\n\n            try\n            {\n                // Search for the claim with image URL\n                var imageUrl = await _knowledgeBaseService.GetClaimImageUrlAsync(claimNumber);\n\n                if (string.IsNullOrEmpty(imageUrl))\n                {\n                    return $\"\u274c No damage photo found for claim {claimNumber}.\\n\\n\" +\n                           $\"_The claim may not have an uploaded damage photo yet._\";\n                }\n\n                // Get bot endpoint for devtunnel proxy (required for image display in M365 Copilot)\n                var botEndpoint = _configuration[\"BOT_ENDPOINT\"];\n                if (string.IsNullOrEmpty(botEndpoint))\n                {\n                    var botDomain = _configuration[\"BOT_DOMAIN\"];\n                    botEndpoint = !string.IsNullOrEmpty(botDomain) ? $\"https://{botDomain}\" : \"http://localhost:3978\";\n                }\n                botEndpoint = botEndpoint.TrimEnd('/');\n\n                // Proxy the blob storage URL through devtunnel for inline display\n                var proxyUrl = $\"{botEndpoint}/api/image?url={Uri.EscapeDataString(imageUrl)}\";\n\n                // Return the image with Markdown syntax for inline display\n                return $\"\ud83d\udcf8 **Damage Photo for Claim {claimNumber}**\\n\\n\" +\n                       $\"![Damage Photo]({proxyUrl})\\n\\n\" +\n                       $\"_Image stored in Azure Blob Storage_\";\n            }\n            catch (Exception ex)\n            {\n                return $\"\u274c Error retrieving damage photo: {ex.Message}\";\n            }\n        }\n\n        /// &lt;summary&gt;\n        /// Analyzes a damage photo using Mistral AI vision model and presents results\n        /// Downloads image, calls VisionService, formats structured analysis\n        /// &lt;/summary&gt;\n        [Description(\"Analyzes a damage photo using Mistral AI model and requests user approval before updating the system.\")]\n        public async Task&lt;string&gt; AnalyzeAndShowDamagePhoto(string claimNumber, string documentId)\n        {\n            await NotifyUserAsync($\"\ud83e\udd16 Starting AI Vision Analysis for claim {claimNumber}...\");\n\n            try\n            {\n                // Get the image URL for this claim from knowledge base\n                var imageUrl = await _knowledgeBaseService.GetClaimImageUrlAsync(claimNumber);\n\n                if (string.IsNullOrEmpty(imageUrl))\n                {\n                    return $\"\u274c No damage photo found for claim {claimNumber}.\\n\\n\" +\n                           $\"Please ensure a damage photo has been uploaded first.\";\n                }\n\n                await NotifyUserAsync($\"\ud83d\udcf8 Downloading image from blob storage...\");\n\n                // Download the image bytes from blob storage\n                using var httpClient = new HttpClient();\n                var imageBytes = await httpClient.GetByteArrayAsync(imageUrl);\n                var fileName = Path.GetFileName(new Uri(imageUrl).LocalPath);\n\n                await NotifyUserAsync($\"\ud83e\udd16 Analyzing damage with Mistral AI Vision...\");\n\n                // Analyze the image using Vision AI (Mistral model)\n                var analysisResult = await _visionService.AnalyzeDamagePhotoAsync(imageBytes, fileName);\n\n                await NotifyUserAsync($\"\u2705 Analysis complete!\");\n\n                // Format the structured analysis results for user\n                var response = $\"\ud83d\udd0d **AI Vision Analysis Results**\\n\\n\";\n                response += $\"**Claim:** {claimNumber}\\n\";\n                response += $\"**Image:** {imageUrl}\\n\\n\";\n                response += $\"**Analysis:**\\n\";\n                response += $\"- **Damage Type:** {analysisResult.DamageType}\\n\";\n                response += $\"- **Severity:** {analysisResult.Severity}\\n\";\n                response += $\"- **Estimated Cost:** ${analysisResult.EstimatedRepairCost:N2}\\n\";\n                response += $\"- **Urgency:** {analysisResult.Urgency}\\n\";\n                response += $\"- **Description:** {analysisResult.DetailedDescription}\\n\";\n                if (analysisResult.AffectedAreas.Length &gt; 0)\n                    response += $\"- **Affected Areas:** {string.Join(\", \", analysisResult.AffectedAreas)}\\n\";\n                if (!string.IsNullOrEmpty(analysisResult.SafetyConcerns))\n                    response += $\"- **Safety Concerns:** {analysisResult.SafetyConcerns}\\n\";\n                if (!string.IsNullOrEmpty(analysisResult.RepairRecommendations))\n                    response += $\"- **Recommendations:** {analysisResult.RepairRecommendations}\\n\";\n                if (analysisResult.RequiresSpecialist)\n                    response += $\"- **Specialist Required:** {analysisResult.SpecialistType}\\n\";\n                response += $\"\\n---\\n\\n\";\n                response += $\"Would you like to:\\n\";\n                response += $\"- Approve this analysis and update the claim\\n\";\n                response += $\"- Reject the analysis\\n\";\n                response += $\"- Check for fraud indicators\\n\";\n\n                return response;\n            }\n            catch (Exception ex)\n            {\n                return $\"\u274c Error analyzing damage photo: {ex.Message}\\n\\n\" +\n                       $\"Please try again or contact support if the issue persists.\";\n            }\n        }\n\n        /// &lt;summary&gt;\n        /// Approves a damage photo analysis via text command\n        /// In production: would update database, trigger workflows, assign adjusters\n        /// &lt;/summary&gt;\n        [Description(\"Approves a damage photo analysis by claim number and document ID. Use this when user says 'approve' or 'approve analysis'.\")]\n        public async Task&lt;string&gt; ApproveAnalysis(string claimNumber, string documentId, string userFeedback = \"\")\n        {\n            return await HandleAnalysisApproval(claimNumber, documentId, true, userFeedback);\n        }\n\n        /// &lt;summary&gt;\n        /// Rejects a damage photo analysis via text command\n        /// In production: would flag for manual review, assign human adjuster\n        /// &lt;/summary&gt;\n        [Description(\"Rejects a damage photo analysis by claim number and document ID. Use this when user says 'reject' or 'reject analysis'.\")]\n        public async Task&lt;string&gt; RejectAnalysis(string claimNumber, string documentId, string userFeedback = \"\")\n        {\n            return await HandleAnalysisApproval(claimNumber, documentId, false, userFeedback);\n        }\n\n        /// &lt;summary&gt;\n        /// Common logic for handling analysis approval or rejection\n        /// Provides structured feedback and next steps\n        /// &lt;/summary&gt;\n        private async Task&lt;string&gt; HandleAnalysisApproval(string claimNumber, string documentId, bool approved, string userFeedback = \"\")\n        {\n            await NotifyUserAsync($\"Processing {(approved ? \"approval\" : \"rejection\")}...\");\n\n            try\n            {\n                var action = approved ? \"approved\" : \"rejected\";\n                var emoji = approved ? \"\u2705\" : \"\u274c\";\n\n                // In a real system, you would:\n                // 1. Update the claim status in the database\n                // 2. Store the analysis results\n                // 3. Update estimated costs\n                // 4. Trigger workflow actions (assign adjuster, schedule inspection, etc.)\n\n                var response = $\"{emoji} **Analysis {action.ToUpper()}**\\n\\n\";\n                response += $\"**Claim:** {claimNumber}\\n\";\n\n                if (approved)\n                {\n                    response += $\"**Status:** The AI analysis has been accepted and the claim has been updated.\\n\\n\";\n                    response += $\"**Next Steps:**\\n\";\n                    response += $\"- The estimated repair costs have been added to the claim\\n\";\n                    response += $\"- An adjuster will be notified for final review\\n\";\n                    response += $\"- The claim is ready for processing\\n\";\n                }\n                else\n                {\n                    response += $\"**Status:** The AI analysis has been rejected.\\n\\n\";\n                    response += $\"**Next Steps:**\\n\";\n                    response += $\"- The claim will be flagged for manual review\\n\";\n                    response += $\"- An adjuster will be assigned to inspect the damage\\n\";\n                    response += $\"- Additional documentation may be requested\\n\";\n                }\n\n                if (!string.IsNullOrEmpty(userFeedback))\n                {\n                    response += $\"\\n**Your Feedback:** {userFeedback}\\n\";\n                }\n\n                response += $\"\\n_Note: In a production system, this would update the claim database and trigger automated workflows._\";\n\n                return response;\n            }\n            catch (Exception ex)\n            {\n                return $\"\u274c Error processing {(approved ? \"approval\" : \"rejection\")}: {ex.Message}\";\n            }\n        }\n\n        /// &lt;summary&gt;\n        /// Helper to send real-time streaming updates during long operations\n        /// Shows as typing indicators with messages in chat\n        /// &lt;/summary&gt;\n        private async Task NotifyUserAsync(string message)\n        {\n            // Use StreamingResponse for real-time feedback\n            if (!_turnContext.Activity.ChannelId.Channel!.Contains(Channels.Webchat))\n            {\n                await _turnContext.StreamingResponse.QueueInformativeUpdateAsync(message);\n            }\n            else\n            {\n                await _turnContext.StreamingResponse.QueueInformativeUpdateAsync(message).ConfigureAwait(false);\n            }\n        }\n    }\n}\n</code></pre> <p></p>"},{"location":"pages/custom-engine/agent-framework/03-add-vision-analysis/#exercise-5-update-claimsplugin-to-display-damage-photos","title":"Exercise 5: Update ClaimsPlugin to Display Damage Photos","text":""},{"location":"pages/custom-engine/agent-framework/03-add-vision-analysis/#step-1-update-claimsplugin-to-display-damage-photos","title":"Step 1: Update ClaimsPlugin to Display Damage Photos","text":"What this code does <p>Now that <code>GetClaimImageUrlAsync</code> is available in KnowledgeBaseService, we can update the ClaimsPlugin to display damage photos in claim details. This adds back the image display functionality that was removed in Lab BAF2.</p> <p>1\ufe0f\u20e3 Open <code>src/Plugins/ClaimsPlugin.cs</code>.</p> <p>2\ufe0f\u20e3 Find the <code>GetClaimDetails</code> method and locate this section near the end:</p> <pre><code>            result.AppendLine(\"**Documentation Status:**\");\n            var isComplete = GetFieldValue(claimDoc, \"isDocumentationComplete\");\n            result.AppendLine($\"- Documentation Complete: {(isComplete == \"True\" || isComplete == \"true\" ? \"Yes\" : \"No\")}\");\n            var missingDocs = GetFieldValue(claimDoc, \"missingDocumentation\");\n            result.AppendLine($\"- Missing Documentation: {(string.IsNullOrWhiteSpace(missingDocs) ? \"None\" : missingDocs)}\");\n\n            await NotifyUserAsync($\"Retrieved details for claim {claimId}\");\n\n            return result.ToString();\n</code></pre> <p>3\ufe0f\u20e3 Replace it with this updated version that includes image display:</p> <pre><code>            result.AppendLine(\"**Documentation Status:**\");\n            var isComplete = GetFieldValue(claimDoc, \"isDocumentationComplete\");\n            result.AppendLine($\"- Documentation Complete: {(isComplete == \"True\" || isComplete == \"true\" ? \"Yes\" : \"No\")}\");\n            var missingDocs = GetFieldValue(claimDoc, \"missingDocumentation\");\n            result.AppendLine($\"- Missing Documentation: {(string.IsNullOrWhiteSpace(missingDocs) ? \"None\" : missingDocs)}\");\n\n            // Get damage photo URL if available\n            var imageUrl = await _knowledgeBaseService.GetClaimImageUrlAsync(claimId);\n\n            if (!string.IsNullOrEmpty(imageUrl))\n            {\n                // Get bot endpoint for devtunnel proxy\n                var botEndpoint = _configuration[\"BOT_ENDPOINT\"];\n                if (string.IsNullOrEmpty(botEndpoint))\n                {\n                    var botDomain = _configuration[\"BOT_DOMAIN\"];\n                    botEndpoint = !string.IsNullOrEmpty(botDomain) ? $\"https://{botDomain}\" : \"http://localhost:3978\";\n                }\n                botEndpoint = botEndpoint.TrimEnd('/');\n\n                // Proxy the blob storage URL through devtunnel\n                var proxyUrl = $\"{botEndpoint}/api/image?url={Uri.EscapeDataString(imageUrl)}\";\n\n                result.AppendLine();\n                result.AppendLine(\"**Damage Photo:**\");\n                result.AppendLine($\"![Damage Photo]({proxyUrl})\");\n            }\n\n            await NotifyUserAsync($\"Retrieved details for claim {claimId}\");\n\n            return result.ToString();\n</code></pre> Why this update is needed <p>In Lab BAF2, we omitted the image display code because <code>GetClaimImageUrlAsync</code> didn't exist yet. Now that we've added it to KnowledgeBaseService in Exercise 3, we can add the image display functionality to <code>ClaimsPlugin</code>.</p> <p></p>"},{"location":"pages/custom-engine/agent-framework/03-add-vision-analysis/#exercise-6-register-services-and-configure-agent","title":"Exercise 6: Register Services and Configure Agent","text":"<p>Now let's wire everything together by updating Program.cs and the agent configuration.</p>"},{"location":"pages/custom-engine/agent-framework/03-add-vision-analysis/#step-1-update-service-registration-and-knowledgebaseservice-factory","title":"Step 1: Update Service Registration and KnowledgeBaseService Factory","text":"What this code does <ul> <li>Service Registration: Registers BlobStorageService (singleton) and VisionService (scoped) for dependency injection</li> <li>KnowledgeBaseService Factory: Updates factory to pass BlobStorageService to simplified constructor</li> </ul> <p>The factory pattern ensures proper service resolution and initialization order.</p> <p>1\ufe0f\u20e3 Open <code>src/Program.cs</code>.</p> <p>2\ufe0f\u20e3 Find where <code>builder.Services.AddSingleton&lt;KnowledgeBaseService&gt;();</code> is and replace it with this complete registration block:</p> <pre><code>// Register Blob Storage Service for damage photo uploads\nbuilder.Services.AddSingleton&lt;BlobStorageService&gt;();\n\n// Register VisionService for Mistral AI vision analysis\nbuilder.Services.AddScoped&lt;VisionService&gt;();\n\n// Register Knowledge Base Service with BlobStorageService dependency\nbuilder.Services.AddSingleton&lt;KnowledgeBaseService&gt;(serviceProvider =&gt;\n{\n    var configuration = serviceProvider.GetRequiredService&lt;IConfiguration&gt;();\n    var blobStorageService = serviceProvider.GetRequiredService&lt;BlobStorageService&gt;();\n\n    return new KnowledgeBaseService(configuration, blobStorageService);\n});\n</code></pre> Simplified constructor <p>The updated <code>KnowledgeBaseService</code> constructor now requires:</p> <ul> <li>IConfiguration: For all connection strings and endpoints</li> <li>BlobStorageService: For damage photo uploads (optional parameter)</li> </ul> <p>The service creates its own SearchIndexClient, KnowledgeBaseRetrievalClient, and AzureOpenAIClient internally from the configuration. This simplifies the factory function and reduces coupling.</p> <p></p>"},{"location":"pages/custom-engine/agent-framework/03-add-vision-analysis/#step-2-update-agent-with-visionplugin","title":"Step 2: Update Agent with VisionPlugin","text":"What this code does <p>Agent Instructions: Updates system prompt to include VisionPlugin tools (ShowDamagePhoto, AnalyzeAndShowDamagePhoto, ApproveAnalysis) Plugin Creation: Instantiates VisionPlugin with all required dependencies (context, knowledge base, vision service, blob storage, configuration) Tool Registration: Adds 4 vision tools to agent's capability set for AI-powered damage photo analysis</p> <p>1\ufe0f\u20e3 Open <code>src/Agent/ZavaInsuranceAgent.cs</code>.</p> <p>2\ufe0f\u20e3 Find the <code>AgentInstructions</code> property and replace it with the updated version:</p> <pre><code>private readonly string AgentInstructions = \"\"\"\nYou are a professional insurance claims assistant for Zava Insurance.\n\nWhenever the user starts a new conversation or provides a prompt to start a new conversation like \"start over\", \"restart\", \n\"new conversation\", \"what can you do?\", \"how can you help me?\", etc. use {{StartConversationPlugin.StartConversation}} and \nprovide to the user exactly the message you get back from the plugin.\n\n**Available Tools:**\nUse {{DateTimeFunctionTool.getDate}} to get the current date and time.\nFor claims search, use {{ClaimsPlugin.SearchClaims}} and {{ClaimsPlugin.GetClaimDetails}}.\nFor damage photo viewing, use {{VisionPlugin.ShowDamagePhoto}}.\nFor AI vision damage analysis, use {{VisionPlugin.AnalyzeAndShowDamagePhoto}} and require approval via {{VisionPlugin.ApproveAnalysis}}.\n\nStick to the scenario above and use only the information from the tools when answering questions.\nBe concise and professional in your responses.\n\"\"\";\n</code></pre> <p>3\ufe0f\u20e3 In the <code>GetClientAgent</code> method, find where services are resolved (after <code>var knowledgeBaseService = ...</code>) and add:</p> <pre><code>// Resolve vision and storage services\nvar visionService = scope.ServiceProvider.GetRequiredService&lt;VisionService&gt;();\nvar blobStorageService = scope.ServiceProvider.GetRequiredService&lt;BlobStorageService&gt;();\n</code></pre> <p>4\ufe0f\u20e3 Find where <code>ClaimsPlugin claimsPlugin = new(...)</code> is and add right after:</p> <pre><code>// Create VisionPlugin with all dependencies\nVisionPlugin visionPlugin = new(context, knowledgeBaseService, visionService, blobStorageService, configuration);\n</code></pre> <p>5\ufe0f\u20e3 Find where tools are added to <code>toolOptions.Tools</code> and add the vision tools:</p> <pre><code>// Register Vision tools for AI damage photo analysis\ntoolOptions.Tools.Add(AIFunctionFactory.Create(visionPlugin.AnalyzeAndShowDamagePhoto));\ntoolOptions.Tools.Add(AIFunctionFactory.Create(visionPlugin.ShowDamagePhoto));\ntoolOptions.Tools.Add(AIFunctionFactory.Create(visionPlugin.ApproveAnalysis));\ntoolOptions.Tools.Add(AIFunctionFactory.Create(visionPlugin.RejectAnalysis));\n</code></pre> <p></p>"},{"location":"pages/custom-engine/agent-framework/03-add-vision-analysis/#step-3-add-image-proxy-endpoint","title":"Step 3: Add Image Proxy Endpoint","text":"Why this is needed <p>Microsoft 365 Copilot cannot directly access Azure Blob Storage URLs due to network restrictions. Images must be proxied through the bot's devtunnel endpoint to display inline in the chat interface. The <code>/api/image</code> endpoint fetches images from blob storage and serves them through the bot endpoint.</p> <p>1\ufe0f\u20e3 Open <code>src/Program.cs</code>.</p> <p>2\ufe0f\u20e3 Find where <code>app.MapControllers()</code> is called (near the end of the file, before <code>app.Run()</code>).</p> <p>3\ufe0f\u20e3 Add the image proxy endpoint after <code>app.MapGet(\"/api/citation\"</code> mapping:</p> <pre><code>app.MapGet(\"/api/image\", async (string url) =&gt;\n{\n    try\n    {\n        using var httpClient = new HttpClient();\n        var imageBytes = await httpClient.GetByteArrayAsync(url);\n        var contentType = url.EndsWith(\".png\") ? \"image/png\" : \"image/jpeg\";\n        return Results.File(imageBytes, contentType);\n    }\n    catch (Exception ex)\n    {\n        return Results.Problem($\"Error retrieving image: {ex.Message}\");\n    }\n});\n</code></pre> How the proxy works <ol> <li>VisionPlugin calls ShowDamagePhoto with a claim number</li> <li>Gets blob storage URL from knowledge base (e.g., <code>https://storage.blob.core.windows.net/claim-photos/image.jpg</code>)</li> <li>Constructs proxy URL: <code>https://your-devtunnel.devtunnels.ms/api/image?url=&lt;escaped-blob-url&gt;</code></li> <li>Copilot requests the proxy URL from bot endpoint</li> <li>Bot fetches image from blob storage and returns it</li> <li>Image displays inline in chat</li> </ol> <p></p>"},{"location":"pages/custom-engine/agent-framework/03-add-vision-analysis/#step-4-update-startconversationplugin-welcome-message","title":"Step 4: Update StartConversationPlugin Welcome Message","text":"<p>Now that we've added vision analysis capabilities, let's update the welcome message to reflect the new features.</p> <p>1\ufe0f\u20e3 Open <code>src/Plugins/StartConversationPlugin.cs</code>.</p> <p>2\ufe0f\u20e3 Find the <code>welcomeMessage</code> variable in the <code>StartConversation</code> method and replace it with:</p> <pre><code>var welcomeMessage = \"\ud83d\udc4b Welcome to Zava Insurance Claims Assistant!\\n\\n\" +\n                    \"I'm your AI-powered insurance claims specialist. I help adjusters and investigators streamline the claims process.\\n\\n\" +\n                    \"**What I can do:**\\n\\n\" +\n                    \"- Search and retrieve detailed claim information\\n\" +\n                    \"- Use Mistral AI to analyze damage photos instantly\\n\" +\n                    \"- Provide damage assessments with cost estimates\\n\" +\n                    \"- Identify safety concerns from photos\\n\" +\n                    \"- Provide current date and time\\n\\n\" +\n                    \"\ud83c\udfaf Try this workflow:\\n\" +\n                    \"1. \\\"Get details for claim CLM-2025-001007\\\"\\n\" +\n                    \"2. \\\"Show damage photo for this claim\\\"\\n\" +\n                    \"3. \\\"Analyze this damage photo\\\"\\n\" +\n                    \"4. \\\"Approve the analysis\\\" or \\\"Reject the analysis\\\"\\n\\n\" +\n                    \"Ready to help with your claims investigation. What would you like to start with?\";\n</code></pre> Progressive feature updates <p>The welcome message now includes vision analysis capabilities (damage photo viewing and AI analysis with Mistral). Each lab progressively enhances the message to reflect new features.</p> <p></p>"},{"location":"pages/custom-engine/agent-framework/03-add-vision-analysis/#exercise-7-test-vision-analysis","title":"Exercise 7: Test Vision Analysis","text":"<p>Let's test the vision analysis capabilities!</p>"},{"location":"pages/custom-engine/agent-framework/03-add-vision-analysis/#step-1-run-the-agent","title":"Step 1: Run the Agent","text":"<p>1\ufe0f\u20e3 Press F5 in VS Code to start debugging.</p> <p>2\ufe0f\u20e3 Select (Preview) Debug in Copilot (Edge) if prompted.</p> <p>3\ufe0f\u20e3 Watch the terminal output - you should see:</p> <pre><code>\ud83d\udd0d Initializing Azure AI Search Knowledge Base...\n\ud83d\udcdd Creating claims index 'claims-index'...\n\u2705 Claims index 'claims-index' created successfully\n\u2705 Knowledge source 'claims-knowledge-source' created\n\u2705 Knowledge base 'zava-insurance-kb' created with model 'gpt-4.1'\n\ud83d\udcdd Indexing sample claims...\n\u2705 Indexed 35 claims\n\ud83d\udcf8 Uploading sample damage photos to blob storage and indexing...\n\ud83d\udccb Processing 35 total claims for damage photos...\n\ud83d\udcf8 Uploading to blob storage...\n\ud83d\udcf8 Processing damage photo for claim CLM-2025-001001: ajlal-nueimat-deer-collision.jpg\n\u2705 Uploaded photo for CLM-2025-001001: https://your-storage.blob.core.windows.net/claim-photos/...\n...\n\ud83d\udcf8 Total: Uploaded 35 damage photos to blob storage\n\u2705 Sample data indexed successfully\n</code></pre> <p>4\ufe0f\u20e3 Verify Blob Storage (optional but recommended):</p> <ul> <li>Go to Azure Portal \u2192 Navigate to your Storage Account</li> <li>Click Containers \u2192 Select claim-photos</li> <li>You should see 35 uploaded images organized by claim number</li> <li>Each image has a public blob URL that can be accessed directly</li> </ul> <p>5\ufe0f\u20e3 Verify Azure AI Search Knowledge Sources (optional but recommended):</p> <ul> <li>Go to Azure Portal \u2192 Search for your Azure AI Search service</li> <li>Click Agentic retrieval \u2192 Knowledge Sources in the left menu</li> <li>You should see <code>claims-knowledge-source</code> listed</li> <li>This knowledge source connects your claims index to the knowledge base for AI-powered retrieval</li> </ul> <p>6\ufe0f\u20e3 A browser window will open with Microsoft 365 Copilot. Your agent should already be installed from the previous labs.</p> <p></p>"},{"location":"pages/custom-engine/agent-framework/03-add-vision-analysis/#step-2-test-viewing-damage-photos","title":"Step 2: Test Viewing Damage Photos","text":"<p>1\ufe0f\u20e3 In Microsoft 365 Copilot, try: </p> <pre><code>Show me the damage photo for claim CLM-2025-001007\n</code></pre> <p>The agent should use the <code>ShowDamagePhoto</code> tool and display the damage photo.</p> Image Loading Time <p>Images may take a few seconds to load in the chat as they are being proxied through the bot endpoint from Azure Blob Storage. This is normal behavior.</p> <p>2\ufe0f\u20e3 Try another claim: </p> <pre><code>View the damage photo for claim CLM-2025-001003\n</code></pre> <p></p>"},{"location":"pages/custom-engine/agent-framework/03-add-vision-analysis/#step-2-test-ai-vision-analysis","title":"Step 2: Test AI Vision Analysis","text":"<p>1\ufe0f\u20e3 Try: </p> <pre><code>Analyze the damage photo for claim CLM-2025-001007\n</code></pre> <p>The agent should: - Use the <code>AnalyzeAndShowDamagePhoto</code> tool - Download and analyze the image with Mistral AI - Present detailed analysis including damage type, severity, cost estimates, and recommendations - Ask for approval or rejection</p> <p>2\ufe0f\u20e3 After reviewing the analysis, try: </p> <pre><code>Approve the analysis\n</code></pre> <p>The agent should use <code>ApproveAnalysis</code> and confirm the approval with next steps.</p> <p></p>"},{"location":"pages/custom-engine/agent-framework/03-add-vision-analysis/#step-3-test-combined-workflows","title":"Step 3: Test Combined Workflows","text":"<p>1\ufe0f\u20e3 Try: </p> <pre><code>Show me high severity claims in the Northeast region, then analyze their damage photos\n</code></pre> <p>The agent should search for claims first, then analyze the damage photos for matching claims.</p> <p></p>"},{"location":"pages/custom-engine/agent-framework/03-add-vision-analysis/#congratulations","title":"\ud83c\udf89 Congratulations!","text":"<p>You've successfully added AI vision analysis to your insurance agent! </p> <p>What you accomplished:</p> <p>\u2705 Deployed the Mistral medium-2505 vision model \u2705 Created a VisionService for image analysis \u2705 Built a VisionPlugin with multiple vision capabilities \u2705 Implemented AI-powered damage assessment with structured output \u2705 Added approval workflows for AI-generated analyses  </p> <p>Your agent can now:</p> <ul> <li>View damage photos from claims</li> <li>Analyze photos with multimodal AI</li> <li>Extract damage type, severity, and cost estimates</li> <li>Identify safety concerns and recommend repairs</li> <li>Provide approval workflows for AI analysis</li> </ul> <p>In the next lab, you'll add authentication and email capabilities to secure your agent and enable communication features.</p> <p></p> <p></p>"},{"location":"pages/custom-engine/agent-framework/04-add-policy-search/","title":"Lab BAF4 - Add Policy Search","text":"<p>In this lab, you'll extend your Zava Insurance Agent with policy search capabilities. You'll add the ability to search insurance policies in Azure AI Search using the Knowledgebases.</p> Understanding Policy Search <p>This lab adds policy search capabilities using Azure AI Search:</p> <ul> <li>Search insurance policies (Auto, Homeowners, Commercial) by type, status, or policyholder</li> <li>Retrieve structured policy details including coverage limits, deductibles, and premiums</li> <li>Access vehicle and property information associated with policies</li> <li>Use natural language queries with the Knowledgebases</li> </ul> <p>These features allow adjusters to quickly find policy information and validate coverage for claims.</p>"},{"location":"pages/custom-engine/agent-framework/04-add-policy-search/#exercise-1-add-policies-index-and-knowledge-source","title":"Exercise 1: Add Policies Index and Knowledge Source","text":"<p>Now let's extend the KnowledgeBaseService to support policies alongside claims.</p>"},{"location":"pages/custom-engine/agent-framework/04-add-policy-search/#step-1-add-policy-constants-and-index-creation","title":"Step 1: Add Policy Constants and Index Creation","text":"What this step does <p>You'll add:</p> <ul> <li>Policies Constants: Define the policies index and knowledge source names</li> <li>Policies Index: Search index for policy data (type, status, coverage, vehicle/property info)</li> <li>Policies Knowledge Source: Connects the policies index to the knowledge base</li> <li>Policies Data Indexing: Loads and indexes sample policies from JSON file</li> </ul> <p>These additions work alongside the existing claims functionality without modifying it.</p> <p>1\ufe0f\u20e3 Open <code>src/Services/KnowledgeBaseService.cs</code>.</p> <p>2\ufe0f\u20e3 Find <code>private const string ClaimsKnowledgeSource = \"claims-knowledge-source\";</code> and and add the policies constant and index:</p> <pre><code>// Knowledge source names\nprivate const string PoliciesKnowledgeSource = \"policies-knowledge-source\";\n\n// Index names\nprivate const string PoliciesIndex = \"policies-index\";\n</code></pre> <p>3\ufe0f\u20e3 Find the <code>EnsureClaimsIndexAsync</code> method and add the <code>EnsurePoliciesIndexAsync</code> method right after it:</p> <pre><code>public async Task EnsurePoliciesIndexAsync()\n{\n    try\n    {\n        await _indexClient.GetIndexAsync(PoliciesIndex);\n        Console.WriteLine($\"\u2705 Policies index '{PoliciesIndex}' already exists\");\n    }\n    catch (RequestFailedException ex) when (ex.Status == 404)\n    {\n        Console.WriteLine($\"\ud83d\udcdd Creating policies index '{PoliciesIndex}'...\");\n\n        var index = new SearchIndex(PoliciesIndex)\n        {\n            Fields =\n            {\n                new SimpleField(\"id\", SearchFieldDataType.String) { IsKey = true, IsFilterable = true },\n                new SearchableField(\"policyNumber\") { IsFilterable = true, IsSortable = true },\n                new SearchableField(\"policyholderName\") { IsFilterable = true },\n                new SearchableField(\"policyType\") { IsFilterable = true, IsFacetable = true },\n                new SearchableField(\"status\") { IsFilterable = true, IsFacetable = true },\n                new SimpleField(\"effectiveDate\", SearchFieldDataType.DateTimeOffset) { IsFilterable = true, IsSortable = true },\n                new SimpleField(\"expirationDate\", SearchFieldDataType.DateTimeOffset) { IsFilterable = true, IsSortable = true },\n                new SimpleField(\"coverageLimit\", SearchFieldDataType.Double) { IsFilterable = true, IsSortable = true },\n                new SimpleField(\"deductible\", SearchFieldDataType.Double) { IsFilterable = true, IsSortable = true },\n                new SimpleField(\"annualPremium\", SearchFieldDataType.Double) { IsFilterable = true, IsSortable = true },\n                new SearchableField(\"vehicleMake\") { IsFilterable = true },\n                new SearchableField(\"vehicleModel\") { IsFilterable = true },\n                new SimpleField(\"vehicleYear\", SearchFieldDataType.Int32) { IsFilterable = true },\n                new SearchableField(\"vehicleVin\") { IsFilterable = true },\n                new SearchableField(\"propertyAddress\") { IsFilterable = true },\n                new SearchableField(\"propertyType\") { IsFilterable = true },\n                new SearchableField(\"notes\"),\n                new SearchableField(\"searchableContent\"),\n                new SearchField(\"contentVector\", SearchFieldDataType.Collection(SearchFieldDataType.Single))\n                {\n                    IsSearchable = true,\n                    VectorSearchDimensions = 1536,\n                    VectorSearchProfileName = \"vector-profile\"\n                }\n            },\n            VectorSearch = CreateVectorSearchConfig(),\n            SemanticSearch = CreateSemanticConfig(\"Policies semantic search\", \"policyNumber\", \"policyholderName\", \"notes\")\n        };\n\n        await _indexClient.CreateIndexAsync(index);\n        Console.WriteLine($\"\u2705 Policies index created successfully\");\n    }\n}\n</code></pre> <p></p>"},{"location":"pages/custom-engine/agent-framework/04-add-policy-search/#step-2-update-knowledge-sources-to-include-policies","title":"Step 2: Update Knowledge Sources to Include Policies","text":"<p>Now let's update the <code>CreateKnowledgeSourcesAsync</code> method to create both claims and policies knowledge sources.</p> <p>1\ufe0f\u20e3 Find the <code>CreateKnowledgeSourcesAsync</code> method and replace the entire method with this updated version that includes both policies and claims:</p> <pre><code>public async Task CreateKnowledgeSourcesAsync()\n{\n    // Create claims knowledge source\n    var claimsKnowledgeSource = new SearchIndexKnowledgeSource(\n        name: ClaimsKnowledgeSource,\n        searchIndexParameters: new SearchIndexKnowledgeSourceParameters(searchIndexName: ClaimsIndex)\n        {\n            SourceDataFields = \n            {\n                new SearchIndexFieldReference(name: \"id\"),\n                new SearchIndexFieldReference(name: \"claimNumber\"),\n                new SearchIndexFieldReference(name: \"policyholderName\"),\n                new SearchIndexFieldReference(name: \"policyNumber\"),\n                new SearchIndexFieldReference(name: \"status\"),\n                new SearchIndexFieldReference(name: \"claimType\"),\n                new SearchIndexFieldReference(name: \"region\"),\n                new SearchIndexFieldReference(name: \"assignedAdjuster\"),\n                new SearchIndexFieldReference(name: \"dateFiled\"),\n                new SearchIndexFieldReference(name: \"dateResolved\"),\n                new SearchIndexFieldReference(name: \"description\"),\n                new SearchIndexFieldReference(name: \"location\"),\n                new SearchIndexFieldReference(name: \"severity\"),\n                new SearchIndexFieldReference(name: \"claimAmount\"),\n                new SearchIndexFieldReference(name: \"fraudScore\"),\n                new SearchIndexFieldReference(name: \"fraudIndicators\"),\n                new SearchIndexFieldReference(name: \"adjusterNotes\")\n            }\n        }\n    );\n\n    await _indexClient.CreateOrUpdateKnowledgeSourceAsync(claimsKnowledgeSource);\n    Console.WriteLine($\"\u2705 Knowledge source '{ClaimsKnowledgeSource}' created\");\n\n    // Create policies knowledge source\n    var policiesKnowledgeSource = new SearchIndexKnowledgeSource(\n        name: PoliciesKnowledgeSource,\n        searchIndexParameters: new SearchIndexKnowledgeSourceParameters(searchIndexName: PoliciesIndex)\n        {\n            SourceDataFields = \n            {\n                new SearchIndexFieldReference(name: \"id\"),\n                new SearchIndexFieldReference(name: \"policyNumber\"),\n                new SearchIndexFieldReference(name: \"policyholderName\"),\n                new SearchIndexFieldReference(name: \"policyType\"),\n                new SearchIndexFieldReference(name: \"status\"),\n                new SearchIndexFieldReference(name: \"effectiveDate\"),\n                new SearchIndexFieldReference(name: \"expirationDate\"),\n                new SearchIndexFieldReference(name: \"coverageLimit\"),\n                new SearchIndexFieldReference(name: \"deductible\"),\n                new SearchIndexFieldReference(name: \"annualPremium\")\n            }\n        }\n    );\n\n    await _indexClient.CreateOrUpdateKnowledgeSourceAsync(policiesKnowledgeSource);\n    Console.WriteLine($\"\u2705 Knowledge source '{PoliciesKnowledgeSource}' created\");\n}\n</code></pre> <p></p>"},{"location":"pages/custom-engine/agent-framework/04-add-policy-search/#step-3-update-knowledge-base-to-include-policies","title":"Step 3: Update Knowledge Base to Include Policies","text":"<p>Now update the knowledge base definition to include the policies knowledge source.</p> <p>1\ufe0f\u20e3 Find the <code>new KnowledgeSourceReference(name: ClaimsKnowledgeSource)</code> syntax, add a comma and add the following line right after it, so it includes both claims and policies:</p> <pre><code> new KnowledgeSourceReference(name: PoliciesKnowledgeSource)\n</code></pre> <p>Final version of the knowledge base creation should look like this:</p> <pre><code>var knowledgeBase = new KnowledgeBase(\n    name: KnowledgeBaseName,\n    knowledgeSources: new[]\n    {\n        new KnowledgeSourceReference(name: ClaimsKnowledgeSource),\n        new KnowledgeSourceReference(name: PoliciesKnowledgeSource)\n    }\n)\n{\n    Description = \"Zava Insurance knowledge base for claims\",\n    RetrievalReasoningEffort = new KnowledgeRetrievalLowReasoningEffort(), // Faster for straightforward queries\n    OutputMode = KnowledgeRetrievalOutputMode.AnswerSynthesis, // LLM generates natural answers\n    Models = { new KnowledgeBaseAzureOpenAIModel(azureOpenAIParameters: aoaiParams) }\n};\n</code></pre> <p></p>"},{"location":"pages/custom-engine/agent-framework/04-add-policy-search/#step-4-add-policy-data-indexing","title":"Step 4: Add Policy Data Indexing","text":"<p>Now let's add the method to index sample policies data.</p> <p>1\ufe0f\u20e3 Find the <code>IndexSampleDataAsync</code> method and update it to include policies:</p> <pre><code>public async Task IndexSampleDataAsync()\n{\n    await IndexClaimsDataAsync();\n    await IndexPoliciesDataAsync();\n\n    // Upload damage photos to blob storage if BlobStorageService is available\n    if (_blobStorageService != null)\n    {\n        await UploadSampleDamagePhotosAsync();\n    }\n    Console.WriteLine(\"\u2705 Sample data indexed successfully\");\n}\n</code></pre> <p>2\ufe0f\u20e3 Add the <code>IndexPoliciesDataAsync</code> method right after the <code>IndexClaimsDataAsync</code> method:</p> <pre><code>/// &lt;summary&gt;\n/// Loads and indexes sample policies data from JSON file\n/// &lt;/summary&gt;\nprivate async Task IndexPoliciesDataAsync()\n{\n    Console.WriteLine(\"\ud83d\udcdd Indexing sample policies...\");\n\n    var policiesFile = Path.Combine(AppContext.BaseDirectory, \"infra\", \"data\", \"sample-data\", \"policies.json\");\n\n    if (!File.Exists(policiesFile))\n    {\n        Console.WriteLine($\"\u26a0\ufe0f Policies file not found: {policiesFile}\");\n        return;\n    }\n\n    var policiesJson = await File.ReadAllTextAsync(policiesFile);\n    var policies = System.Text.Json.JsonSerializer.Deserialize&lt;List&lt;System.Text.Json.JsonElement&gt;&gt;(policiesJson);\n\n    if (policies == null || policies.Count == 0)\n    {\n        Console.WriteLine(\"\u26a0\ufe0f No policies data to index\");\n        return;\n    }\n\n    var searchClient = _indexClient.GetSearchClient(PoliciesIndex);\n    var batch = new List&lt;SearchDocument&gt;();\n\n    foreach (var policy in policies)\n    {\n        var policyNumber = policy.GetProperty(\"policyNumber\").GetString();\n        var status = policy.GetProperty(\"status\").GetString() ?? \"\";\n        var random = new Random(policyNumber.GetHashCode());\n\n        // Generate policy dates based on status\n        DateTime effectiveDate;\n        DateTime expirationDate;\n\n        if (status == \"Active\")\n        {\n            effectiveDate = DateTime.UtcNow.Date.AddDays(-random.Next(180, 730));\n            expirationDate = DateTime.UtcNow.Date.AddDays(random.Next(365, 730));\n        }\n        else if (status == \"Expired\")\n        {\n            effectiveDate = DateTime.UtcNow.Date.AddDays(-random.Next(365, 1095));\n            expirationDate = DateTime.UtcNow.Date.AddDays(-random.Next(1, 60));\n        }\n        else\n        {\n            effectiveDate = DateTime.UtcNow.Date.AddDays(-random.Next(30, 365));\n            expirationDate = DateTime.UtcNow.Date.AddDays(random.Next(365, 730));\n        }\n\n        // Build searchable content\n        var searchableContent = $\"Policy {policyNumber} for {policy.GetProperty(\"policyholderName\").GetString()}. \" +\n                              $\"Type: {policy.GetProperty(\"policyType\").GetString()}. Status: {status}. \" +\n                              $\"Coverage: ${policy.GetProperty(\"coverageLimit\").GetDouble():N2}.\";\n\n        // Generate embedding\n        var embedding = await CreateEmbeddingAsync(searchableContent);\n\n        var doc = new SearchDocument\n        {\n            [\"id\"] = policyNumber,\n            [\"policyNumber\"] = policyNumber,\n            [\"policyholderName\"] = policy.GetProperty(\"policyholderName\").GetString(),\n            [\"policyType\"] = policy.GetProperty(\"policyType\").GetString(),\n            [\"status\"] = status,\n            [\"effectiveDate\"] = effectiveDate,\n            [\"expirationDate\"] = expirationDate,\n            [\"coverageLimit\"] = policy.GetProperty(\"coverageLimit\").GetDouble(),\n            [\"deductible\"] = policy.GetProperty(\"deductible\").GetDouble(),\n            [\"annualPremium\"] = policy.GetProperty(\"annualPremium\").GetDouble(),\n            [\"searchableContent\"] = searchableContent,\n            [\"contentVector\"] = embedding\n        };\n\n        // Add vehicle info for Auto policies\n        if (policy.TryGetProperty(\"vehicleInfo\", out var vehicleInfo))\n        {\n            doc[\"vehicleMake\"] = vehicleInfo.GetProperty(\"make\").GetString();\n            doc[\"vehicleModel\"] = vehicleInfo.GetProperty(\"model\").GetString();\n            doc[\"vehicleYear\"] = vehicleInfo.GetProperty(\"year\").GetInt32();\n            doc[\"vehicleVin\"] = vehicleInfo.GetProperty(\"vin\").GetString();\n        }\n\n        // Add property info for Homeowners policies\n        if (policy.TryGetProperty(\"propertyInfo\", out var propertyInfo))\n        {\n            doc[\"propertyAddress\"] = propertyInfo.GetProperty(\"address\").GetString();\n            doc[\"propertyType\"] = propertyInfo.GetProperty(\"propertyType\").GetString();\n        }\n\n        batch.Add(doc);\n    }\n\n    await searchClient.IndexDocumentsAsync(IndexDocumentsBatch.Upload(batch));\n    Console.WriteLine($\"\u2705 Indexed {batch.Count} policies\");\n}\n</code></pre> <p></p>"},{"location":"pages/custom-engine/agent-framework/04-add-policy-search/#step-5-add-getpolicybynumberasync-helper-method","title":"Step 5: Add GetPolicyByNumberAsync Helper Method","text":"<p>Add a helper method to retrieve policy details directly from the index.</p> <p>1\ufe0f\u20e3 In the Retrieval section, add <code>GetPolicyByNumberAsync</code> right after <code>GetClaimByNumberAsync</code>:</p> <pre><code>/// &lt;summary&gt;\n/// Gets policy details directly from the policies index using filter query\n/// This bypasses the Knowledgebases for structured data retrieval\n/// &lt;/summary&gt;\n/// &lt;param name=\"policyNumber\"&gt;The policy number to retrieve&lt;/param&gt;\n/// &lt;returns&gt;SearchDocument with all policy fields or null if not found&lt;/returns&gt;\npublic async Task&lt;SearchDocument?&gt; GetPolicyByNumberAsync(string policyNumber)\n{\n    var policiesClient = _indexClient.GetSearchClient(PoliciesIndex);\n\n    var searchOptions = new SearchOptions\n    {\n        Filter = $\"policyNumber eq '{policyNumber}'\",\n        Size = 1\n    };\n\n    var searchResults = await policiesClient.SearchAsync&lt;SearchDocument&gt;(\"*\", searchOptions);\n\n    await foreach (var searchResult in searchResults.Value.GetResultsAsync())\n    {\n        return searchResult.Document;\n    }\n\n    return null;\n}\n</code></pre> <p></p>"},{"location":"pages/custom-engine/agent-framework/04-add-policy-search/#exercise-2-create-the-policyplugin","title":"Exercise 2: Create the PolicyPlugin","text":"<p>Now let's create the PolicyPlugin with policy search and policy details capabilities.</p>"},{"location":"pages/custom-engine/agent-framework/04-add-policy-search/#step-1-create-complete-policyplugin","title":"Step 1: Create Complete PolicyPlugin","text":"What this plugin does <p>The <code>PolicyPlugin</code> provides two main capabilities:</p> <ul> <li>SearchPolicies: Searches policies using Azure AI Search Knowledge Base with natural language (similar to ClaimsPlugin)</li> <li>GetPolicyDetails: Retrieves structured policy information for a specific policy number</li> </ul> <p>1\ufe0f\u20e3 Create a new file <code>src/Plugins/PolicyPlugin.cs</code> with the complete implementation:</p> <pre><code>using Microsoft.Agents.Builder;\nusing Microsoft.Agents.Core.Models;\nusing System.ComponentModel;\nusing System.Text;\nusing Azure.Search.Documents.Models;\nusing InsuranceAgent.Services;\n\nnamespace ZavaInsurance.Plugins\n{\n    /// &lt;summary&gt;\n    /// Policy Plugin for Zava Insurance\n    /// Provides policy search and retrieval using Azure AI Search Knowledge Base\n    /// Supports filtering by policy type, status, and policyholder name\n    /// &lt;/summary&gt;\n    public class PolicyPlugin\n    {\n        private readonly ITurnContext _turnContext;\n        private readonly KnowledgeBaseService _knowledgeBaseService;\n\n        public PolicyPlugin(ITurnContext turnContext, KnowledgeBaseService knowledgeBaseService)\n        {\n            _turnContext = turnContext ?? throw new ArgumentNullException(nameof(turnContext));\n            _knowledgeBaseService = knowledgeBaseService ?? throw new ArgumentNullException(nameof(knowledgeBaseService));\n        }\n\n        /// &lt;summary&gt;\n        /// Searches for insurance policies using filters\n        /// &lt;/summary&gt;\n        /// &lt;param name=\"policyType\"&gt;Filter by policy type (Auto, Homeowners, Commercial) - optional&lt;/param&gt;\n        /// &lt;param name=\"status\"&gt;Filter by status (Active, Expired, Cancelled) - optional&lt;/param&gt;\n        /// &lt;param name=\"policyholderName\"&gt;Filter by policyholder name - optional&lt;/param&gt;\n        /// &lt;returns&gt;Matching policy information&lt;/returns&gt;\n        [Description(\"Searches insurance policies with optional filters for policy type, status, or policyholder name. Returns relevant policies with details.\")]\n        public async Task&lt;string&gt; SearchPolicies(string policyType = null, string status = null, string policyholderName = null)\n        {\n            await NotifyUserAsync($\"\ud83d\udd0d Searching policies...\");\n\n            try\n            {\n                // Build natural language query for agentic retrieval\n                var queryParts = new List&lt;string&gt; { \"insurance policies\" };\n\n                if (!string.IsNullOrWhiteSpace(policyType))\n                    queryParts.Add($\"type {policyType}\");\n                if (!string.IsNullOrWhiteSpace(status))\n                    queryParts.Add($\"status {status}\");\n                if (!string.IsNullOrWhiteSpace(policyholderName))\n                    queryParts.Add($\"for {policyholderName}\");\n\n                var query = string.Join(\" \", queryParts);\n\n                // Use agentic retrieval with instructions for structured policy listing\n                var instructions = @\"You are an insurance policy specialist. Provide a comprehensive list of matching policies.\n                    For each policy, include:\n                    - Policy Number and Type\n                    - Policyholder Name\n                    - Status and Effective Dates\n                    - Coverage Limit and Deductible\n                    - Premium Amount\n                    - Property/Vehicle details if applicable\n                    Format with clear sections and bullet points. Cite sources with [ref_id:X].\";\n\n                var response = await _knowledgeBaseService.RetrieveAsync(query, instructions, topResults: 10);\n\n                return response;\n            }\n            catch (Exception ex)\n            {\n                Console.WriteLine($\"Error in SearchPolicies: {ex.Message}\");\n                return $\"\u274c Error searching policies: {ex.Message}\";\n            }\n        }\n\n        /// &lt;summary&gt;\n        /// Gets detailed information about a specific insurance policy\n        /// &lt;/summary&gt;\n        /// &lt;param name=\"policyNumber\"&gt;The policy number to retrieve&lt;/param&gt;\n        /// &lt;returns&gt;Detailed policy information&lt;/returns&gt;\n        [Description(\"Retrieves comprehensive details for a specific insurance policy by policy number.\")]\n        public async Task&lt;string&gt; GetPolicyDetails(string policyNumber)\n        {\n            if (string.IsNullOrWhiteSpace(policyNumber))\n                return \"\u274c Error: Policy number cannot be empty.\";\n\n            await NotifyUserAsync($\"Retrieving policy {policyNumber}...\");\n\n            // Use direct search for structured data (more reliable than Knowledge Base answer synthesis)\n            var policyDoc = await _knowledgeBaseService.GetPolicyByNumberAsync(policyNumber);\n\n            if (policyDoc == null)\n            {\n                return $\"\u274c Policy {policyNumber} not found in the system.\";\n            }\n\n            // Extract fields from the search document\n            var result = new StringBuilder();\n            result.AppendLine(\"**Policy Information:**\");\n            result.AppendLine($\"- Policy Number: {GetFieldValue(policyDoc, \"policyNumber\")}\");\n            result.AppendLine($\"- Policy Type: {GetFieldValue(policyDoc, \"policyType\")}\");\n            result.AppendLine($\"- Status: {GetFieldValue(policyDoc, \"status\")}\");\n            result.AppendLine($\"- Policyholder Name: {GetFieldValue(policyDoc, \"policyholderName\")}\");\n            result.AppendLine();\n\n            result.AppendLine(\"**Coverage &amp; Financial:**\");\n            result.AppendLine($\"- Coverage Limit: ${GetFieldValue(policyDoc, \"coverageLimit\")}\");\n            result.AppendLine($\"- Deductible: ${GetFieldValue(policyDoc, \"deductible\")}\");\n            result.AppendLine($\"- Annual Premium: ${GetFieldValue(policyDoc, \"annualPremium\")}\");\n            result.AppendLine();\n\n            // Display vehicle or property info based on policy type\n            var policyType = GetFieldValue(policyDoc, \"policyType\");\n            if (policyType.Contains(\"Auto\", StringComparison.OrdinalIgnoreCase))\n            {\n                var vehicleMake = GetFieldValue(policyDoc, \"vehicleMake\");\n                var vehicleModel = GetFieldValue(policyDoc, \"vehicleModel\");\n                var vehicleYear = GetFieldValue(policyDoc, \"vehicleYear\");\n\n                if (vehicleMake != \"Not available\")\n                {\n                    result.AppendLine(\"**Vehicle Information:**\");\n                    result.AppendLine($\"- Vehicle: {vehicleYear} {vehicleMake} {vehicleModel}\");\n                    result.AppendLine($\"- VIN: {GetFieldValue(policyDoc, \"vehicleVin\")}\");\n                }\n            }\n            else if (policyType.Contains(\"Home\", StringComparison.OrdinalIgnoreCase))\n            {\n                var propertyAddress = GetFieldValue(policyDoc, \"propertyAddress\");\n                if (propertyAddress != \"Not available\")\n                {\n                    result.AppendLine(\"**Property Information:**\");\n                    result.AppendLine($\"- Address: {propertyAddress}\");\n                    result.AppendLine($\"- Property Type: {GetFieldValue(policyDoc, \"propertyType\")}\");\n                }\n            }\n\n            return result.ToString();\n        }\n\n        /// &lt;summary&gt;\n        /// Helper method to safely extract field values from SearchDocument\n        /// &lt;/summary&gt;\n        private string GetFieldValue(SearchDocument doc, string fieldName)\n        {\n            if (doc.ContainsKey(fieldName) &amp;&amp; doc[fieldName] != null)\n            {\n                return doc[fieldName].ToString() ?? \"Not available\";\n            }\n            return \"Not available\";\n        }\n\n        // Helper methods\n        private async Task NotifyUserAsync(string message)\n        {\n            if (!_turnContext.Activity.ChannelId.Channel!.Contains(Channels.Webchat))\n            {\n                await _turnContext.StreamingResponse.QueueInformativeUpdateAsync(message);\n            }\n            else\n            {\n                Console.WriteLine(message);\n            }\n        }\n    }\n}\n</code></pre> <p></p>"},{"location":"pages/custom-engine/agent-framework/04-add-policy-search/#exercise-3-register-policyplugin-in-agent","title":"Exercise 3: Register PolicyPlugin in Agent","text":"<p>Now let's wire up the PolicyPlugin in your ZavaInsuranceAgent.</p>"},{"location":"pages/custom-engine/agent-framework/04-add-policy-search/#step-1-update-programcs-initialization","title":"Step 1: Update Program.cs Initialization","text":"<p>Update the initialization code in Program.cs to create the policies index.</p> <p>1\ufe0f\u20e3 Open <code>src/Program.cs</code>.</p> <p>2\ufe0f\u20e3 Find the Azure AI Search initialization section and update it to include policies:</p> <pre><code>Console.WriteLine(\"\ud83d\udd0d Initializing Azure AI Search Knowledge Base...\");\n\n// IMPORTANT: Must follow this order - indexes \u2192 knowledge sources \u2192 knowledge base \u2192 data\nawait kbService.EnsureClaimsIndexAsync();          // 1. Create claims index\nawait kbService.EnsurePoliciesIndexAsync();        // 2. Create policies index\nawait kbService.CreateKnowledgeSourcesAsync();     // 3. Create knowledge sources (now includes policies)\nawait kbService.CreateKnowledgeBaseAsync();        // 4. Create knowledge base\nawait kbService.IndexSampleDataAsync();            // 5. Index sample data (claims + policies)\n\nConsole.WriteLine(\"\u2705 Knowledge Base initialized successfully\");\n</code></pre> <p></p>"},{"location":"pages/custom-engine/agent-framework/04-add-policy-search/#step-2-update-agent-instructions","title":"Step 2: Update Agent Instructions","text":"<p>Update the agent instructions to include policy tools.</p> <p>1\ufe0f\u20e3 Open <code>src/Agent/ZavaInsuranceAgent.cs</code>.</p> <p>2\ufe0f\u20e3 Find the <code>AgentInstructions</code> property and update it:</p> <pre><code>private readonly string AgentInstructions = \"\"\"\nYou are a professional insurance claims assistant for Zava Insurance.\n\nWhenever the user starts a new conversation or provides a prompt to start a new conversation like \"start over\", \"restart\", \n\"new conversation\", \"what can you do?\", \"how can you help me?\", etc. use {{StartConversationPlugin.StartConversation}} and \nprovide to the user exactly the message you get back from the plugin.\n\n**Available Tools:**\nUse {{DateTimeFunctionTool.getDate}} to get the current date and time.\nFor claims search, use {{ClaimsPlugin.SearchClaims}} and {{ClaimsPlugin.GetClaimDetails}}.\nFor damage photo viewing, use {{VisionPlugin.ShowDamagePhoto}}.\nFor AI vision damage analysis, use {{VisionPlugin.AnalyzeAndShowDamagePhoto}} and require approval via {{VisionPlugin.ApproveAnalysis}}.\nFor policy search, use {{PolicyPlugin.SearchPolicies}} and {{PolicyPlugin.GetPolicyDetails}}.\n\n**IMPORTANT**: When user asks to \"check policy for this claim\", first use GetClaimDetails to get the claim's policy number, then use GetPolicyDetails with that policy number.\n\nStick to the scenario above and use only the information from the tools when answering questions.\nBe concise and professional in your responses.\n\"\"\";\n</code></pre> <p></p>"},{"location":"pages/custom-engine/agent-framework/04-add-policy-search/#step-3-register-policyplugin","title":"Step 3: Register PolicyPlugin","text":"<p>Add the PolicyPlugin to your agent's tools.</p> <p>1\ufe0f\u20e3 In the <code>GetClientAgent</code> method, find where <code>ClaimsPlugin claimsPlugin = new(context, knowledgeBaseService, configuration);</code> is and add PolicyPlugin right after:</p> <pre><code>// Create PolicyPlugin with required dependencies\nPolicyPlugin policyPlugin = new(context, knowledgeBaseService);\n</code></pre> <p>2\ufe0f\u20e3 Find where ClaimsPlugin tools are registered and add PolicyPlugin tools:</p> <pre><code>// Register PolicyPlugin tools\ntoolOptions.Tools.Add(AIFunctionFactory.Create(policyPlugin.SearchPolicies));\ntoolOptions.Tools.Add(AIFunctionFactory.Create(policyPlugin.GetPolicyDetails));\n</code></pre> <p></p>"},{"location":"pages/custom-engine/agent-framework/04-add-policy-search/#step-4-update-startconversationplugin-welcome-message","title":"Step 4: Update StartConversationPlugin Welcome Message","text":"<p>Now that we've added policy search and SharePoint integration, let's update the welcome message to reflect all features.</p> <p>1\ufe0f\u20e3 Open <code>src/Plugins/StartConversationPlugin.cs</code>.</p> <p>2\ufe0f\u20e3 Find the <code>welcomeMessage</code> variable in the <code>StartConversation</code> method and replace it with:</p> <pre><code>            var welcomeMessage = \"\ud83d\udc4b Welcome to Zava Insurance Claims Assistant!\\n\\n\" +\n                                \"I'm your AI-powered insurance claims specialist. I help adjusters and investigators streamline the entire claims process - from initial assessment to final approval.\\n\\n\" +\n                                \"**What I can do:**\\n\\n\" +\n                                \"- Search and retrieve detailed claim information\\n\" +\n                                \"- Validate policy coverage and check expiration dates\\n\" +\n                                \"- Use Mistral AI to analyze damage photos instantly\\n\" +\n                                \"- Provide damage assessments with cost estimates\\n\" +\n                                \"- Track claim timelines and identify processing bottlenecks\\n\\n\" +\n                                \"\ud83c\udfaf Try this complete workflow:\\n\" +\n                                \"1. \\\"Get details for claim CLM-2025-001007\\\"\\n\" +\n                                \"2. \\\"Check policy for this claim\\\"\\n\" +\n                                \"3. \\\"Show damage photo for this claim\\\"\\n\" +\n                                \"4. \\\"Analyze this damage photo\\\"\\n\" +\n                                \"5. \\\"Approve the analysis\\\" or \\\"Reject the analysis\\\"\\n\\n\" +\n                                \"Ready to complete a full claims investigation? What would you like to start with?\";\n</code></pre> Complete feature set <p>The welcome message now includes all capabilities: claims search, policy validation, and vision analysis. This matches the full feature set of the completed agent.</p> <p></p>"},{"location":"pages/custom-engine/agent-framework/04-add-policy-search/#exercise-4-test-policy-search","title":"Exercise 4: Test Policy Search","text":"<p>Now let's test all policy capabilities!</p>"},{"location":"pages/custom-engine/agent-framework/04-add-policy-search/#step-1-run-and-verify-initialization","title":"Step 1: Run and Verify Initialization","text":"<p>1\ufe0f\u20e3 Press F5 in VS Code to start debugging.</p> <p>2\ufe0f\u20e3 Select (Preview) Debug in Copilot (Edge) if prompted.</p> <p>3\ufe0f\u20e3 Watch the terminal output - you should see:</p> <pre><code>\ud83d\udd0d Initializing Azure AI Search Knowledge Base...\n\ud83d\udcdd Creating claims index 'claims-index'...\n\u2705 Claims index created successfully\n\ud83d\udcdd Creating policies index 'policies-index'...\n\u2705 Policies index created successfully\n\u2705 Knowledge source 'claims-knowledge-source' created\n\u2705 Knowledge source 'policies-knowledge-source' created\n\u2705 Knowledge base 'zava-insurance-kb' created with model 'gpt-4.1'\n\ud83d\udcdd Indexing sample claims...\n\u2705 Indexed 35 claims\n\ud83d\udcdd Indexing sample policies...\n\u2705 Indexed 30 policies\n\u2705 Sample data indexed successfully\n\u2705 Knowledge Base initialized successfully\n</code></pre> <p>4\ufe0f\u20e3 A browser window will open with Microsoft 365 Copilot.</p> <p>5\ufe0f\u20e3 Verify in Azure Portal:</p> <ul> <li>Go to Azure Portal</li> <li>Navigate to your Azure AI Search service</li> <li>Click Indexes \u2192 You should see both <code>claims-index</code> and <code>policies-index</code></li> <li>Click Agentic retrieval &gt; Knowledge Bases \u2192 <code>zava-insurance-kb</code> should show 2 knowledge sources</li> </ul> <p></p>"},{"location":"pages/custom-engine/agent-framework/04-add-policy-search/#step-2-test-policy-search","title":"Step 2: Test Policy Search","text":"<p>1\ufe0f\u20e3 In Microsoft 365 Copilot, try: </p> <pre><code>Find all active auto insurance policies\n</code></pre> <p>The agent should use <code>SearchPolicies</code> and return matching policies with details.</p> <p>2\ufe0f\u20e3 Try: </p> <pre><code>Show me policies for Sarah Martinez\n</code></pre> <p>3\ufe0f\u20e3 Try: </p> <pre><code>Find homeowners insurance policies with Active status\n</code></pre> <p></p>"},{"location":"pages/custom-engine/agent-framework/04-add-policy-search/#step-3-test-policy-details","title":"Step 3: Test Policy Details","text":"<p>1\ufe0f\u20e3 Try: </p> <pre><code>Get details for policy POL-AUTO-001\n</code></pre> <p>The agent should use <code>GetPolicyDetails</code> and return structured information including coverage, vehicle info, etc.</p> <p>2\ufe0f\u20e3 Try: </p> <pre><code>Show me policy POL-HOME-001\n</code></pre> <p>3\ufe0f\u20e3 Try the claim-to-policy workflow: </p> <pre><code>Get details for claim CLM-2025-001001, then show me the policy for that claim\n</code></pre> <p>The agent should first get the claim details (which includes policy number), then retrieve the policy details.</p> <p></p> <p>CONGRATULATIONS!</p> <p>You have completed Lab BAF4 - Add Policy Search!</p> <p>You've learned how to:</p> <ul> <li>\u2705 Add policies index and knowledge source to Azure AI Search</li> <li>\u2705 Create a PolicyPlugin with search and policy details capabilities</li> <li>\u2705 Register the PolicyPlugin in your agent</li> <li>\u2705 Test policy search and retrieval</li> </ul> <p>Your Zava Insurance Agent can now search both claims and policies using Azure AI Search!</p> <p></p> <p></p>"},{"location":"pages/custom-engine/agent-framework/05-add-communication/","title":"Lab BAF5 - Add Communication Capabilities","text":"<p>In this lab, you'll enhance the Zava Insurance Agent with professional communication capabilities. You'll add the ability to send detailed claim reports via email using Microsoft Graph and generate comprehensive investigation reports that include vision analysis findings and fraud assessment data.</p> Understanding Communication Plugin <p>The CommunicationPlugin enables your agent to:</p> <ul> <li>Send Professional Emails: Use Microsoft Graph Mail API to send HTML-formatted claim details  </li> <li>Generate Investigation Reports: Create comprehensive reports combining data from ClaimsPlugin, VisionPlugin, and PolicyPlugin  </li> <li>Knowledge Base Aggregation: Pull all available claim data including vision analysis, fraud assessment, and policy details  </li> <li>OAuth Token Management: Use cached On-Behalf-Of (OBO) tokens for secure Graph API calls</li> </ul> <p>This completes the claim processing workflow by adding communication and reporting capabilities.</p>"},{"location":"pages/custom-engine/agent-framework/05-add-communication/#exercise-1-create-the-communicationplugin","title":"Exercise 1: Create the CommunicationPlugin","text":"<p>Now that you have claims search, vision analysis, and policy search capabilities, let's add communication features to send reports and emails.</p>"},{"location":"pages/custom-engine/agent-framework/05-add-communication/#step-1-create-complete-communicationplugin","title":"Step 1: Create Complete CommunicationPlugin","text":"What this plugin does <p>The <code>CommunicationPlugin</code> provides two main capabilities:</p> <p>SendClaimDetailsByEmail:</p> <ul> <li>Retrieves comprehensive claim data from Knowledge Base Service</li> <li>Creates professional HTML-formatted email</li> <li>Sends via Microsoft Graph API</li> <li>Uses cached OAuth token for authentication</li> <li>Defaults to current user's email if no recipient specified</li> </ul> <p>GenerateInvestigationReport:</p> <ul> <li>Gathers all claim data including vision analysis and fraud assessment</li> <li>Formats a comprehensive investigation report with recommendations</li> <li>Returns formatted markdown report with professional structure</li> </ul> <p>Both methods use the KnowledgeBaseService with custom instructions to retrieve and synthesize claim data.</p> <p>1\ufe0f\u20e3 Create a new file <code>src/Plugins/CommunicationPlugin.cs</code> with the complete implementation:</p> <pre><code>using Microsoft.Agents.Builder;\nusing Microsoft.Agents.Core.Models;\nusing System.ComponentModel;\nusing System.Text.Json;\nusing InsuranceAgent.Services;\nusing InsuranceAgent;\nusing Microsoft.Agents.Builder.State;\n\nnamespace ZavaInsurance.Plugins\n{\n    /// &lt;summary&gt;\n    /// Communication Plugin for Zava Insurance\n    /// Provides tools for generating professional policyholder communications\n    /// Ensures consistent, compliant messaging across all customer touchpoints\n    /// &lt;/summary&gt;\n    public class CommunicationPlugin\n    {\n        private readonly ITurnContext _turnContext;\n        private readonly ITurnState _turnState;\n        private readonly KnowledgeBaseService _knowledgeBaseService;\n        private readonly HttpClient _httpClient;\n\n        public CommunicationPlugin(ITurnContext turnContext, ITurnState turnState, KnowledgeBaseService knowledgeBaseService, HttpClient httpClient)\n        {\n            _turnContext = turnContext ?? throw new ArgumentNullException(nameof(turnContext));\n            _turnState = turnState ?? throw new ArgumentNullException(nameof(turnState));\n            _knowledgeBaseService = knowledgeBaseService ?? throw new ArgumentNullException(nameof(knowledgeBaseService));\n            _httpClient = httpClient ?? throw new ArgumentNullException(nameof(httpClient));\n        }\n\n        /// &lt;summary&gt;\n        /// Sends detailed claim information via email using Microsoft Graph\n        /// &lt;/summary&gt;\n        /// &lt;param name=\"claimId\"&gt;The unique claim identifier&lt;/param&gt;\n        /// &lt;param name=\"recipientEmail\"&gt;Email address to send the claim details to (optional, uses policyholder email if not provided)&lt;/param&gt;\n        /// &lt;returns&gt;Success or failure message indicating email delivery status&lt;/returns&gt;\n        [Description(\"Sends a well-formatted email with comprehensive claim details including policyholder info, documentation status, timeline, and recommendations via Microsoft Graph.\")]\n        public async Task&lt;string&gt; SendClaimDetailsByEmail(string claimId, string recipientEmail = null)\n        {\n            await NotifyUserAsync($\"Retrieving details for claim {claimId}...\");\n\n            // Read the user profile\n            var userProfile = _turnState.Conversation.GetCachedUserProfile();\n            var accessToken = _turnState.Conversation.GetCachedOBOAccessToken();\n\n            // Use Knowledge Base with instructions for email-ready claim summary\n            var instructions = @\"You are preparing a professional claim summary for email. Include:\n                - Claim Number, Status, and Date Filed\n                - Policyholder Information\n                - Claim Details (type, amount, location, description)\n                - Current Status and Next Steps\n                - Document Status and Requirements\n                - Key Timeline Events\n                Format clearly for email readability. Cite sources with [ref_id:X].\";\n\n            var query = $\"complete details for claim {claimId}\";\n            var claimData = await _knowledgeBaseService.RetrieveAsync(query, instructions, topResults: 5);\n\n            // Use provided email or default to the current user's email\n            var toEmail = string.IsNullOrEmpty(recipientEmail) ? userProfile.Mail : recipientEmail;\n\n            await NotifyUserAsync($\"Preparing email for {toEmail}...\");\n\n            // Create well-formatted HTML email content using KB data\n            var emailContent = CreateClaimDetailsEmailContentFromKB(claimId, claimData.ToString() ?? \"\");\n\n            try\n            {\n                // Send email via Microsoft Graph\n                var emailPayload = new\n                {\n                    message = new\n                    {\n                        subject = $\"Zava Insurance - Claim Details Report ({claimId})\",\n                        body = new\n                        {\n                            contentType = \"HTML\",\n                            content = emailContent\n                        },\n                        toRecipients = new[]\n                        {\n                            new\n                            {\n                                emailAddress = new\n                                {\n                                    address = toEmail\n                                }\n                            }\n                        },\n                        from = new\n                        {\n                            emailAddress = new\n                            {\n                                address = userProfile.Mail\n                            }\n                        }\n                    },\n                    saveToSentItems = true\n                };\n\n                var jsonContent = JsonSerializer.Serialize(emailPayload);\n                var httpContent = new StringContent(jsonContent, System.Text.Encoding.UTF8, \"application/json\");\n\n                _httpClient.DefaultRequestHeaders.Clear();\n                _httpClient.DefaultRequestHeaders.Add(\"Authorization\", $\"Bearer {accessToken}\");\n                _httpClient.DefaultRequestHeaders.Add(\"Accept\", \"application/json\");\n\n                await NotifyUserAsync($\"Sending email via Microsoft Graph...\");\n\n                var response = await _httpClient.PostAsync(\"https://graph.microsoft.com/v1.0/me/sendMail\", httpContent);\n\n                if (response.IsSuccessStatusCode)\n                {\n                    await NotifyUserAsync($\"\u2705 Email sent successfully!\");\n                    return $\"\u2705 Success: Claim details for {claimId} have been successfully sent to {toEmail}. \" +\n                           $\"The email includes comprehensive claim information, documentation status, timeline, and recommendations.\";\n                }\n                else\n                {\n                    var errorContent = await response.Content.ReadAsStringAsync();\n                    await NotifyUserAsync($\"\u274c Failed to send email: {response.StatusCode}\");\n                    return $\"\u274c Error: Failed to send email for claim {claimId}. \" +\n                           $\"Status: {response.StatusCode}, Details: {errorContent}\";\n                }\n            }\n            catch (Exception ex)\n            {\n                await NotifyUserAsync($\"\u274c Exception occurred while sending email\");\n                return $\"\u274c Error: Exception occurred while sending claim details email: {ex.Message}\";\n            }\n        }\n\n        /// &lt;summary&gt;\n        /// Creates well-formatted HTML email content with claim details\n        /// &lt;/summary&gt;\n        private string CreateClaimDetailsEmailContentFromKB(string claimId, string knowledgeBaseData)\n        {\n            return $@\"\n&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n    &lt;style&gt;\n        body {{ font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; margin: 0; padding: 20px; background-color: #f8f9fa; }}\n        .container {{ max-width: 800px; margin: 0 auto; background-color: white; border-radius: 8px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }}\n        .header {{ background: linear-gradient(135deg, #007bff, #0056b3); color: white; padding: 30px; border-radius: 8px 8px 0 0; }}\n        .content {{ padding: 30px; }}\n        .section {{ margin-bottom: 25px; }}\n        .footer {{ background-color: #f8f9fa; padding: 20px; text-align: center; color: #6c757d; border-radius: 0 0 8px 8px; }}\n    &lt;/style&gt;\n&lt;/head&gt;\n&lt;body&gt;\n    &lt;div class='container'&gt;\n        &lt;div class='header'&gt;\n            &lt;h1&gt;\ud83c\udfe2 Zava Insurance - Claim Details Report&lt;/h1&gt;\n            &lt;h2&gt;Claim #{claimId}&lt;/h2&gt;\n        &lt;/div&gt;\n\n        &lt;div class='content'&gt;\n            &lt;div class='section'&gt;\n                &lt;h3&gt;\ud83d\udccb Claim Information&lt;/h3&gt;\n                &lt;pre style='background-color: #f8f9fa; padding: 15px; border-radius: 5px; white-space: pre-wrap;'&gt;{knowledgeBaseData}&lt;/pre&gt;\n            &lt;/div&gt;\n        &lt;/div&gt;\n\n        &lt;div class='footer'&gt;\n            &lt;p&gt;&lt;strong&gt;Zava Insurance&lt;/strong&gt; | Professional Claims Management&lt;/p&gt;\n            &lt;p&gt;This is an automated report generated from our AI-powered system.&lt;/p&gt;\n        &lt;/div&gt;\n    &lt;/div&gt;\n&lt;/body&gt;\n&lt;/html&gt;\";\n        }\n\n        /// &lt;summary&gt;\n        /// Generates a comprehensive investigation report for a claim including vision analysis and fraud assessment\n        /// &lt;/summary&gt;\n        /// &lt;param name=\"claimNumber\"&gt;The claim number to generate report for&lt;/param&gt;\n        /// &lt;returns&gt;A formatted investigation report with findings and recommendations&lt;/returns&gt;\n        [Description(\"Generates a comprehensive investigation report for a claim that includes damage assessment from vision analysis, fraud risk evaluation, and actionable recommendations for claim resolution.\")]\n        public async Task&lt;string&gt; GenerateInvestigationReport(string claimNumber)\n        {\n            if (string.IsNullOrWhiteSpace(claimNumber))\n                return \"\u274c Error: Claim number cannot be empty.\";\n\n            await NotifyUserAsync($\"\ud83d\udcca Generating investigation report for {claimNumber}...\");\n\n            try\n            {\n                // Use Knowledge Base to gather comprehensive claim data including vision and fraud analysis\n                var instructions = @\"You are an insurance claims investigator preparing a comprehensive investigation report. \n                    Include ALL available information:\n\n                    **Claim Overview:**\n                    - Claim Number, Type, Status\n                    - Policyholder Name and Policy Number\n                    - Date Filed, Estimated Cost\n                    - Location and Description of Incident\n\n                    **Vision Analysis Findings:**\n                    - Damage assessment results from AI vision analysis\n                    - Estimated repair costs from damage photos\n                    - Approval status of vision analysis\n                    - Key damage observations\n\n                    **Fraud Risk Assessment:**\n                    - Fraud risk score and level\n                    - Key fraud indicators identified\n                    - Comparison to normal claim patterns\n                    - Risk assessment explanation\n\n                    **Documentation Review:**\n                    - Completeness of documentation\n                    - Missing items (if any)\n                    - Quality of submitted evidence\n\n                    **Recommendations:**\n                    - Approval/denial recommendation with justification\n                    - Required next steps\n                    - Any additional investigation needed\n                    - Suggested claim resolution path\n\n                    Format professionally with clear sections, bullet points, and evidence-based conclusions.\n                    Cite all sources with [ref_id:X].\";\n\n                var query = $\"Complete investigation details for claim {claimNumber} including vision analysis, fraud assessment, and all supporting evidence\";\n                var reportData = await _knowledgeBaseService.RetrieveAsync(query, instructions, topResults: 10);\n\n                // Format the final report\n                var report = new System.Text.StringBuilder();\n                report.AppendLine($\"# \ud83d\udccb Investigation Report: {claimNumber}\");\n                report.AppendLine($\"**Generated:** {DateTime.UtcNow:yyyy-MM-dd HH:mm:ss} UTC\");\n                report.AppendLine($\"**Status:** Investigation Complete\");\n                report.AppendLine();\n                report.AppendLine(\"---\");\n                report.AppendLine();\n                report.AppendLine(reportData);\n                report.AppendLine();\n                report.AppendLine(\"---\");\n                report.AppendLine();\n                report.AppendLine(\"**Report Prepared By:** Zava Insurance Claims Investigation System\");\n                report.AppendLine(\"**Next Steps:** Review findings and proceed with recommended claim resolution action.\");\n\n                await NotifyUserAsync(\"\u2705 Investigation report generated successfully!\");\n\n                return report.ToString();\n            }\n            catch (Exception ex)\n            {\n                Console.WriteLine($\"Error generating investigation report: {ex.Message}\");\n                return $\"\u274c Error generating investigation report: {ex.Message}\";\n            }\n        }\n\n        // Helper methods\n        private async Task NotifyUserAsync(string message)\n        {\n            if (!_turnContext.Activity.ChannelId.Channel!.Contains(Channels.Webchat))\n            {\n                await _turnContext.StreamingResponse.QueueInformativeUpdateAsync(message);\n            }\n            else\n            {\n                await _turnContext.StreamingResponse.QueueInformativeUpdateAsync(message).ConfigureAwait(false);\n            }\n        }\n    }\n}\n</code></pre> <p></p>"},{"location":"pages/custom-engine/agent-framework/05-add-communication/#exercise-2-register-communicationplugin-in-agent","title":"Exercise 2: Register CommunicationPlugin in Agent","text":"<p>Now let's wire up the CommunicationPlugin in your ZavaInsuranceAgent.</p>"},{"location":"pages/custom-engine/agent-framework/05-add-communication/#step-1-instantiate-communicationplugin","title":"Step 1: Instantiate CommunicationPlugin","text":"<p>1\ufe0f\u20e3 Open <code>src/Agent/ZavaInsuranceAgent.cs</code>.</p> <p>2\ufe0f\u20e3 Find the <code>GetClientAgent</code> method (around line 159).</p> <p>3\ufe0f\u20e3 Locate where plugins are instantiated (after <code>PolicyPlugin policyPlugin = ...</code>).</p> <p>4\ufe0f\u20e3 Add the CommunicationPlugin instantiation:</p> <pre><code>// Create CommunicationPlugin with required dependencies\nCommunicationPlugin communicationPlugin = new(context, turnState, knowledgeBaseService, httpClient);\n</code></pre> <p></p>"},{"location":"pages/custom-engine/agent-framework/05-add-communication/#step-2-register-communication-tools","title":"Step 2: Register Communication Tools","text":"<p>In the same <code>GetClientAgent</code> method, scroll down to where tools are added to <code>toolOptions.Tools</code> (around line 180).</p> <p>Find the Policy tools section and add Communication tools right after:</p> <pre><code>// Register Communication tools\ntoolOptions.Tools.Add(AIFunctionFactory.Create(communicationPlugin.SendClaimDetailsByEmail));\ntoolOptions.Tools.Add(AIFunctionFactory.Create(communicationPlugin.GenerateInvestigationReport));\n</code></pre> Tool Registration Pattern <p>The agent uses AIFunctionFactory to register plugin methods as AI tools. Each <code>[Description]</code> attribute on plugin methods becomes the tool description that helps the LLM decide when to call them.</p> <p></p>"},{"location":"pages/custom-engine/agent-framework/05-add-communication/#exercise-3-update-agent-instructions-and-security","title":"Exercise 3: Update Agent Instructions and security","text":"<p>Update your agent's instructions to include communication capabilities and the agent security to support user's authentication and On-Behalf-Of (OBO) token support.</p>"},{"location":"pages/custom-engine/agent-framework/05-add-communication/#step-1-add-communication-tools-to-instructions","title":"Step 1: Add Communication Tools to Instructions","text":"<p>1\ufe0f\u20e3 In <code>src/Agent/ZavaInsuranceAgent.cs</code>, find the <code>AgentInstructions</code> field (around line 32).</p> <p>2\ufe0f\u20e3 Find the tool list section and update it with the list of all tools including communication:</p> <pre><code>private readonly string AgentInstructions = \"\"\"\nYou are a professional insurance claims assistant for Zava Insurance.\n\nWhenever the user starts a new conversation or provides a prompt to start a new conversation like \"start over\", \"restart\", \n\"new conversation\", \"what can you do?\", \"how can you help me?\", etc. use {{StartConversationPlugin.StartConversation}} and \nprovide to the user exactly the message you get back from the plugin.\n\n**Available Tools:**\nUse {{DateTimeFunctionTool.getDate}} to get the current date and time.\nFor claims search, use {{ClaimsPlugin.SearchClaims}} and {{ClaimsPlugin.GetClaimDetails}}.\nFor damage photo viewing, use {{VisionPlugin.ShowDamagePhoto}}.\nFor AI vision damage analysis, use {{VisionPlugin.AnalyzeAndShowDamagePhoto}} and require approval via {{VisionPlugin.ApproveAnalysis}}.\nFor policy search, use {{PolicyPlugin.SearchPolicies}} and {{PolicyPlugin.GetPolicyDetails}}.\nFor policy coverage questions and terms, use {{PolicyPlugin.SearchPolicyDocuments}}.\nFor sending investigation reports and claim details via email, use {{CommunicationPlugin.GenerateInvestigationReport}} and {{CommunicationPlugin.SendClaimDetailsByEmail}}.\n\n**IMPORTANT**: When user asks to \"check policy for this claim\", first use GetClaimDetails to get the claim's policy number, then use GetPolicyDetails with that policy number.\n\nStick to the scenario above and use only the information from the tools when answering questions.\nBe concise and professional in your responses.\n\"\"\";\n</code></pre> Why Update Instructions <p>The agent instructions guide the LLM on when to use each tool. Adding communication tools ensures the agent knows it can send emails and generate reports when requested.</p> <p></p>"},{"location":"pages/custom-engine/agent-framework/05-add-communication/#step-2-configure-obo-settings","title":"Step 2: Configure OBO settings","text":"<p>1\ufe0f\u20e3 In <code>m365agents.local.yml</code>, find the <code>OnMessageAsyncfile/createOrUpdateJsonFile</code> action (around line 47).</p> <p>2\ufe0f\u20e3 Uncomment the <code>me</code> settings in the <code>UserAuthorization</code> group of settings in order to enable the settings with name <code>OBOConnectionName</code>, <code>OBOScopes</code>, <code>Title</code>, and <code>Text</code>. The code should look like the following:</p> <pre><code>          UserAuthorization:\n            DefaultHandlerName: me\n            AutoSignin: true\n            Handlers:\n              me:\n                Settings:\n                  AzureBotOAuthConnectionName: \"Microsoft Graph\"\n                  OBOConnectionName: \"BotServiceConnection\"\n                  OBOScopes:\n                    - \"https://graph.microsoft.com/.default\"\n                  Title: \"Sign in\"\n                  Text: \"Sign in to Microsoft Graph\"\n</code></pre> What this code does <p>The new code enables settings to support On-Behalf-Of (OBO) flow for the Azure Bot backing the agent.</p> <p></p>"},{"location":"pages/custom-engine/agent-framework/05-add-communication/#step-3-implement-users-authentication-and-obo","title":"Step 3: Implement user's authentication and OBO","text":"<p>1\ufe0f\u20e3 In <code>src/Agent/ZavaInsuranceAgent.cs</code>, find the <code>OnMessageAsync</code> method (around line 87).</p> <p>2\ufe0f\u20e3 Right after the first line of the method <code>await turnContext.StreamingResponse.QueueInformativeUpdateAsync( ...</code> add the following code excerpt:</p> <pre><code>            // Check if user profile is already cached, if not fetch and cache it\n            var userProfile = turnState.Conversation.GetCachedUserProfile();\n            if (userProfile == null)\n            {\n                try\n                {\n                    // Get the access token and store it in the conversation state\n                    var accessToken = await UserAuthorization.ExchangeTurnTokenAsync(turnContext, UserAuthorization.DefaultHandlerName, exchangeScopes: new[] { \"https://graph.microsoft.com/.default\" }, cancellationToken: cancellationToken);\n                    turnState.Conversation.SetCachedOBOAccessToken(accessToken);\n\n                    // Get the user profile and store it in the conversation state\n                    userProfile = await GetUserProfile(accessToken, cancellationToken);\n                    turnState.Conversation.SetCachedUserProfile(userProfile);\n\n                    // Show current user profile information to let clients that support streaming know that we are processing the request for the current user.\n                    await turnContext.StreamingResponse.QueueInformativeUpdateAsync($\"\u2692\ufe0f Working on your request {userProfile.DisplayName} ...\", cancellationToken).ConfigureAwait(false);\n                }\n                catch (InvalidOperationException ex)\n                {\n                    System.Diagnostics.Trace.WriteLine($\"Exception occurred: {ex.Message}\");\n                    // User is not signed in, proceed as anonymous and inform the user\n                    await turnContext.StreamingResponse.QueueInformativeUpdateAsync(\"\u26a0\ufe0f Please sign in if you want to use authenticated features.\", cancellationToken).ConfigureAwait(false);\n                }\n            }\n</code></pre> What this code does <p>The code excerpt you just added takes care of the following activities:</p> <ul> <li>Tries to retrieve the current user profile from the conversation</li> <li>If the user profile does not exist in the cache<ul> <li>Retrieves an OBO token for the current user</li> <li>Caches the OBO token in the current conversation</li> <li>Retrieves the user profile via Microsoft Graph</li> <li>Caches the user profile in the current conversation</li> <li>Informs the user that the agent is working for her/him</li> </ul> </li> </ul> <p>In case of failure while retrieving the user profile, the agent informs via streaming the user to sign in </p> <p></p>"},{"location":"pages/custom-engine/agent-framework/05-add-communication/#exercise-4-update-startconversationplugin","title":"Exercise 4: Update StartConversationPlugin","text":"<p>Update the welcome message to inform users about all capabilities including communication features.</p>"},{"location":"pages/custom-engine/agent-framework/05-add-communication/#step-1-update-welcome-message","title":"Step 1: Update Welcome Message","text":"<p>1\ufe0f\u20e3 Open <code>src/Plugins/StartConversationPlugin.cs</code>.</p> <p>2\ufe0f\u20e3 Find the <code>StartConversation</code> method.</p> <p>3\ufe0f\u20e3 Replace the <code>welcomeMessage</code> with the complete workflow:</p> <pre><code>var welcomeMessage = \"\ud83d\udc4b Welcome to Zava Insurance Claims Assistant!\\n\\n\" +\n                    \"I'm your AI-powered insurance claims specialist. I help adjusters and investigators streamline the entire claims process - from initial assessment to final approval.\\n\\n\" +\n                    \"**What I can do:**\\n\\n\" +\n                    \"- Analyze claims for fraud indicators and risk patterns\\n\" +\n                    \"- Validate policy coverage and check expiration dates\\n\" +\n                    \"- Search policy documentation and claims procedures\\n\" +\n                    \"- Use Mistral AI to analyze damage photos instantly\\n\" +\n                    \"- Generate investigation reports\\n\" +\n                    \"- Send detailed claim information via email\\n\" +\n                    \"- Track claim timelines and identify processing bottlenecks\\n\\n\" +\n                    \"\ud83c\udfaf Try this complete investigation workflow:\\n\" +\n                    \"1. \\\"Get details for claim CLM-2025-001007\\\"\\n\" +\n                    \"2. \\\"Check policy for this claim\\\"\\n\" +\n                    \"3. \\\"What coverage does auto insurance include?\\\"\\n\" +\n                    \"4. \\\"Analyze fraud risk for this claim\\\"\\n\" +\n                    \"5. \\\"Show damage photo for this claim\\\"\\n\" +\n                    \"6. \\\"Analyze this damage photo\\\"\\n\" +\n                    \"7. \\\"What's the claims filing procedure?\\\"\\n\" +\n                    \"8. \\\"Check compliance for this claim\\\"\\n\" +\n                    \"9. \\\"Generate investigation report for claim CLM-2025-001007\\\"\\n\" +\n                    \"10. \\\"Send the report by email\\\"\\n\\n\" +\n                    \"Ready to complete a full claims investigation? What would you like to start with?\";\n</code></pre> Complete Workflow <p>Steps 1-10 demonstrate the complete claims investigation workflow from initial lookup through final report distribution. This mirrors the real-world process adjusters follow.</p> <p></p>"},{"location":"pages/custom-engine/agent-framework/05-add-communication/#exercise-5-test-communication-features","title":"Exercise 5: Test Communication Features","text":"<p>Now let's test the complete communication capabilities!</p>"},{"location":"pages/custom-engine/agent-framework/05-add-communication/#step-1-run-and-verify","title":"Step 1: Run and Verify","text":"<p>1\ufe0f\u20e3 Press F5 in VS Code to start debugging.</p> <p>2\ufe0f\u20e3 Select (Preview) Debug in Copilot (Edge) if prompted.</p> <p>3\ufe0f\u20e3 The terminal should show normal initialization (no new indexes to create).</p> <p>4\ufe0f\u20e3 A browser window will open with Microsoft 365 Copilot.</p> <p></p>"},{"location":"pages/custom-engine/agent-framework/05-add-communication/#step-2-test-investigation-report-generation","title":"Step 2: Test Investigation Report Generation","text":"<p>1\ufe0f\u20e3 In Microsoft 365 Copilot, say: </p> <pre><code>Generate investigation report for CLM-2025-001007\n</code></pre> <p>The agent should:</p> <ul> <li>Use <code>CommunicationPlugin.GenerateInvestigationReport</code></li> <li>Gather comprehensive claim data from Knowledge Base</li> <li>Include vision analysis findings (if photo was analyzed)</li> <li>Include fraud risk assessment</li> <li>Format professional markdown report</li> <li>Return structured report with recommendations</li> </ul> <p>Expected Response:</p> <pre><code>\ud83d\udcca Generating investigation report for CLM-2025-001007...\n\n# \ud83d\udccb Investigation Report: CLM-2025-001007\n**Generated:** 2025-01-15 10:30:00 UTC\n**Status:** Investigation Complete\n\n[Comprehensive claim details including:]\n- Claim overview\n- Vision analysis findings\n- Fraud risk assessment\n- Documentation review\n- Recommendations\n\n**Report Prepared By:** Zava Insurance Claims Investigation System\n**Next Steps:** Review findings and proceed with recommended claim resolution action.\n</code></pre> <p>2\ufe0f\u20e3 Try with different claims: </p> <pre><code>Generate report for CLM-2024-1003\n</code></pre> <p></p>"},{"location":"pages/custom-engine/agent-framework/05-add-communication/#step-3-test-email-functionality","title":"Step 3: Test Email Functionality","text":"<p>1\ufe0f\u20e3 Say: </p> <pre><code>Send claim details for CLM-2025-001007 by email\n</code></pre> <p>The agent should:</p> <ul> <li>Retrieve claim details from Knowledge Base</li> <li>Create HTML-formatted email</li> <li>Send via Microsoft Graph API</li> <li>Use your email as recipient (default)</li> </ul> <p>Expected Response:</p> <pre><code>Retrieving details for claim CLM-2025-001007...\nPreparing email for [your-email]@[domain].com...\nSending email via Microsoft Graph...\n\u2705 Email sent successfully!\n\n\u2705 Success: Claim details for CLM-2025-001007 have been successfully sent to [your-email]@[domain].com. \nThe email includes comprehensive claim information, documentation status, timeline, and recommendations.\n</code></pre> <p>2\ufe0f\u20e3 Check your email inbox - you should receive a professional HTML-formatted claim details email.</p> <p>3\ufe0f\u20e3 Try sending to a specific recipient: </p> <pre><code>Send claim details for CLM-2025-001001 to john.doe@contoso.com\n</code></pre> <p></p>"},{"location":"pages/custom-engine/agent-framework/05-add-communication/#step-4-test-complete-end-to-end-workflow","title":"Step 4: Test Complete End-to-End Workflow","text":"<p>Test the complete 10-step workflow from the welcome message:</p> <pre><code>1. Get details for claim CLM-2025-001007\n2. Check policy for this claim\n3. What coverage does auto insurance include?\n4. Analyze fraud risk for this claim\n5. Show damage photo for this claim\n6. Analyze this damage photo\n7. What's the claims filing procedure?\n8. Check compliance for this claim\n9. Generate investigation report for claim CLM-2025-001007\n10. Send the report by email\n</code></pre> <p>The agent should seamlessly use all plugins (ClaimsPlugin \u2192 PolicyPlugin \u2192 VisionPlugin \u2192 CommunicationPlugin) to complete the full investigation workflow!</p> <p></p> <p>CONGRATULATIONS!</p> <p>You have completed Lab BAF5 - Add Communication Capabilities!</p> <p>You've learned how to:</p> <ul> <li>\u2705 Create a CommunicationPlugin with email and report generation</li> <li>\u2705 Integrate Microsoft Graph Mail API for sending professional emails</li> <li>\u2705 Generate comprehensive investigation reports with aggregated data</li> <li>\u2705 Update agent instructions to include communication workflows</li> <li>\u2705 Test complete end-to-end claims investigation workflow</li> </ul> <p>Your Zava Insurance Agent is now a complete claims processing solution with:</p> <ul> <li>Search: Claims and policies via Azure AI Search</li> <li>Analysis: AI vision with Mistral for damage assessment</li> <li>Validation: SharePoint policy document search</li> <li>Communication: Email reports and investigation summaries</li> </ul> <p>\ud83c\udf89 Congratulations! You've built a production-ready AI agent! \ud83c\udf8a</p> <p></p>"},{"location":"pages/custom-engine/agent-framework/06-add-copilot-api/","title":"Lab BAF6 - Add Microsoft 365 Work IQ API Integration","text":"<p>In this lab, you'll enhance the Zava Insurance Agent with Microsoft 365 Work IQ API. You'll add the ability to analyze claim compliance using policy documents from SharePoint via the Copilot Retrieval API and leverage the power of Microsoft 365 Copilot's enterprise search grounding.</p> Understanding Microsoft 365 Work IQ API <p>The Microsoft 365 Work IQ API enable your agent to:</p> <ul> <li>Copilot Retrieval API: Retrieve relevant text chunks from SharePoint, OneDrive, and Copilot connectors while respecting permissions and compliance settings</li> <li>Secure Data Access: Access Microsoft 365 data within the trust boundary without data egress</li> <li>Enterprise Search Grounding: Ground LLM responses on organization-specific information the same way Microsoft 365 Copilot does</li> <li>Compliance &amp; Security: Maintain strict security standards with built-in permission models</li> </ul> <p>This enables the agent to analyze claim compliance against policy documents stored in SharePoint.</p>"},{"location":"pages/custom-engine/agent-framework/06-add-copilot-api/#overview","title":"Overview","text":"<p>In Lab BAF5, you added communication capabilities with email and report generation. Now you'll enhance your agent with Microsoft 365 Work IQ API to retrieve policy documents from SharePoint and analyze claim compliance using AI-powered analysis.</p> <p>The Copilot Retrieval API offers a streamlined solution for Retrieval Augmented Generation (RAG) without the need to replicate, index, chunk, and secure your data in a separate index. The API understands the user's context and intent and performs query transformations to yield the most relevant results.</p> Licensing Requirements <p>The Copilot Retrieval API is available at no extra cost to users with a Microsoft 365 Copilot add-on license. Support for users without a Microsoft 365 Copilot add-on license isn't currently available.</p>"},{"location":"pages/custom-engine/agent-framework/06-add-copilot-api/#exercise-1-set-up-sharepoint-site-with-policy-documents","title":"Exercise 1: Set Up SharePoint Site with Policy Documents","text":"<p>Before using the Copilot Retrieval API, you need to set up a SharePoint site with policy documents.</p>"},{"location":"pages/custom-engine/agent-framework/06-add-copilot-api/#step-1-create-sharepoint-site","title":"Step 1: Create SharePoint Site","text":"About SharePoint and Copilot Retrieval API <p>The Microsoft Graph Copilot Retrieval API allows your agent to search content in SharePoint using the same powerful semantic search that powers Microsoft 365 Copilot. It provides:</p> <ul> <li>Semantic Search: Natural language queries across SharePoint documents</li> <li>Real-time Access: Always searches the latest document versions</li> <li>Security: Respects SharePoint permissions (requires user authentication)</li> <li>Citations: Returns document snippets with links to sources</li> </ul> <p>This is perfect for searching policy terms, coverage guides, and FAQ documents.</p> <p>1\ufe0f\u20e3 Go to SharePoint and sign in with your Microsoft 365 account.</p> <p>2\ufe0f\u20e3 Click + Create site \u2192 Choose Team site.</p> <p>3\ufe0f\u20e3 Select the Standard team site template and select Use template</p> <p>4\ufe0f\u20e3 Configure your site:</p> <ul> <li>Site name: \"Zava Insurance Policy Documents\"</li> <li>Description: \"Insurance policy terms, coverage guides, and FAQs\"</li> </ul> <p>5\ufe0f\u20e3 Select Next</p> <ul> <li>Privacy settings: Private (only members can access)</li> <li>Select language: English</li> </ul> <p>6\ufe0f\u20e3 Select the Create site command and wait for site creation</p> <p>7\ufe0f\u20e3 When the site is ready, select Finish to browse to the site.</p> <p></p>"},{"location":"pages/custom-engine/agent-framework/06-add-copilot-api/#step-2-upload-policy-documents","title":"Step 2: Upload Policy Documents","text":"<p>Now let's upload the sample policy documents from your project.</p> <p>1\ufe0f\u20e3 In your VS Code workspace, navigate to <code>src/agent-framework/complete/infra/data/sample-documents/</code></p> <p>2\ufe0f\u20e3 You should see these documents:</p> <ul> <li><code>Auto Insurance Claims Policies.docx</code></li> <li><code>Homeowners Insurance Claims Policies.docx</code></li> <li><code>Step-by-Step Guide - Creating an Insurance Quote.docx</code></li> <li><code>Zava Claims Insurance Policies.docx</code></li> </ul> <p>3\ufe0f\u20e3 In SharePoint, go to your new site \u2192 Click Documents in the left menu.</p> <p>4\ufe0f\u20e3 Click Upload \u2192 Files and upload all 4 documents from the sample-documents folder.</p> <p>5\ufe0f\u20e3 Wait 10-15 minutes for SharePoint to index the documents. The Copilot Retrieval API needs time to process and make documents searchable.</p> <p>Verify Indexing</p> <p>You can verify documents are indexed by:</p> <ul> <li>Opening Microsoft 365 Copilot (copilot.microsoft.com)</li> <li>Asking: \"What policy documents are in my SharePoint?\"</li> <li>If documents appear, they're ready to use with your agent</li> </ul> <p>6\ufe0f\u20e3 Copy your SharePoint site URL - you'll need it for testing later.</p> <p></p>"},{"location":"pages/custom-engine/agent-framework/06-add-copilot-api/#exercise-2-create-the-languagemodelservice","title":"Exercise 2: Create the LanguageModelService","text":"<p>Before creating the ClaimsPoliciesPlugin, we need a service to interact with the language model for AI-powered compliance analysis.</p>"},{"location":"pages/custom-engine/agent-framework/06-add-copilot-api/#step-1-create-languagemodelservice","title":"Step 1: Create LanguageModelService","text":"What this service does <p>The <code>LanguageModelService</code> provides centralized access to language model capabilities:</p> <ul> <li>Chat Completions: Send prompts to the language model and receive responses</li> <li>Configurable Model: Uses the language model deployment configured in your settings</li> <li>Shared Endpoint: Uses the same Azure OpenAI endpoint as other AI services</li> </ul> <p>This service will be used by the ClaimsPoliciesPlugin to analyze claim compliance against retrieved policy documents.</p> <p>1\ufe0f\u20e3 Create a new file <code>src/Services/LanguageModelService.cs</code> with the following implementation:</p> <pre><code>using Azure;\nusing Azure.AI.OpenAI;\nusing Microsoft.Extensions.Configuration;\nusing Microsoft.Extensions.Logging;\nusing OpenAI.Chat;\n\nnamespace InsuranceAgent.Services;\n\n/// &lt;summary&gt;\n/// Service for language model operations using gpt-4o-mini\n/// Provides centralized access to language understanding and text generation capabilities\n/// &lt;/summary&gt;\npublic class LanguageModelService\n{\n    private readonly ChatClient _chatClient;\n    private readonly IConfiguration _configuration;\n    private readonly ILogger&lt;LanguageModelService&gt; _logger;\n\n    public LanguageModelService(\n        IConfiguration configuration,\n        ILogger&lt;LanguageModelService&gt; logger)\n    {\n        _configuration = configuration;\n        _logger = logger;\n\n        // Use shared endpoint and API key with language model for general understanding\n        var endpoint = configuration[\"AIModels:Endpoint\"]\n            ?? throw new InvalidOperationException(\"AIModels:Endpoint not configured\");\n        var apiKey = configuration[\"AIModels:ApiKey\"]\n            ?? throw new InvalidOperationException(\"AIModels:ApiKey not configured\");\n        var deployment = configuration[\"LANGUAGE_MODEL_NAME\"] \n            ?? throw new InvalidOperationException(\"LANGUAGE_MODEL_NAME not configured\");\n\n        _logger.LogInformation(\"\ud83d\udd0d LanguageModelService Configuration:\");\n        _logger.LogInformation(\"   Endpoint: {Endpoint}\", endpoint);\n        _logger.LogInformation(\"   Deployment: {DeploymentName}\", deployment);\n\n        var azureClient = new AzureOpenAIClient(new Uri(endpoint), new AzureKeyCredential(apiKey));\n        _chatClient = azureClient.GetChatClient(deployment);\n    }\n\n    /// &lt;summary&gt;\n    /// Completes a chat request with the language model\n    /// &lt;/summary&gt;\n    /// &lt;param name=\"messages\"&gt;The chat messages&lt;/param&gt;\n    /// &lt;param name=\"options\"&gt;Optional chat completion options&lt;/param&gt;\n    /// &lt;returns&gt;Chat completion response&lt;/returns&gt;\n    public async Task&lt;ChatCompletion&gt; CompleteChatAsync(\n        IEnumerable&lt;ChatMessage&gt; messages, \n        ChatCompletionOptions? options = null)\n    {\n        try\n        {\n            _logger.LogDebug(\"Sending chat completion request with {MessageCount} messages\", messages.Count());\n\n            var response = await _chatClient.CompleteChatAsync(messages, options);\n\n            _logger.LogDebug(\"Received chat completion response\");\n\n            return response.Value;\n        }\n        catch (Exception ex)\n        {\n            _logger.LogError(ex, \"Error completing chat request\");\n            throw;\n        }\n    }\n\n    /// &lt;summary&gt;\n    /// Gets the underlying ChatClient for advanced scenarios\n    /// &lt;/summary&gt;\n    public ChatClient ChatClient =&gt; _chatClient;\n}\n</code></pre> <p></p>"},{"location":"pages/custom-engine/agent-framework/06-add-copilot-api/#step-2-register-languagemodelservice-in-dependency-injection","title":"Step 2: Register LanguageModelService in Dependency Injection","text":"<p>Now register the service in your application's dependency injection container.</p> <p>1\ufe0f\u20e3 Open <code>src/Program.cs</code>.</p> <p>2\ufe0f\u20e3 Find where other services are registered (look for <code>builder.Services.AddScoped&lt;VisionService&gt;();</code> or similar) and add the following right after that:</p> <pre><code>// Register LanguageModelService for AI-powered analysis\nbuilder.Services.AddSingleton&lt;LanguageModelService&gt;();\n</code></pre> <p></p>"},{"location":"pages/custom-engine/agent-framework/06-add-copilot-api/#step-3-update-configuration","title":"Step 3: Update Configuration","text":"<p>Ensure your configuration includes the language model settings.</p> <p>1\ufe0f\u20e3 Open your <code>.env.local</code> file.</p> <p>2\ufe0f\u20e3 Verify you have the language model configuration (add if missing):</p> <pre><code># Language Model (for compliance analysis)\nLANGUAGE_MODEL_NAME=gpt-4o\n</code></pre> Configuration Notes <ul> <li>LANGUAGE_MODEL_NAME: The deployment name for your language model in Azure OpenAI</li> <li>The service uses the same endpoint and API key as your other AI models</li> <li>You can use <code>gpt-4o-mini</code> for cost-effective analysis instead of <code>gpt-4o</code>, which you can use for more complex reasoning</li> </ul> <p></p>"},{"location":"pages/custom-engine/agent-framework/06-add-copilot-api/#exercise-3-create-the-claimspoliciesplugin","title":"Exercise 3: Create the ClaimsPoliciesPlugin","text":"<p>Now let's create the ClaimsPoliciesPlugin that uses the Copilot Retrieval API to analyze claim compliance against SharePoint policy documents.</p>"},{"location":"pages/custom-engine/agent-framework/06-add-copilot-api/#step-1-understand-the-copilot-retrieval-api","title":"Step 1: Understand the Copilot Retrieval API","text":"How the Copilot Retrieval API Works <p>The Microsoft 365 Copilot Retrieval API allows you to:</p> <ul> <li>Query SharePoint content: Send natural language queries to retrieve relevant text chunks from SharePoint documents</li> <li>Respect permissions: Results are filtered based on the user's access permissions</li> <li>Get structured responses: Receive text extracts with metadata like titles and authors</li> <li>Use KQL filters: Optionally filter by URLs, date ranges, file types, and more</li> </ul> <p>API Endpoint: <code>POST https://graph.microsoft.com/v1.0/copilot/retrieval</code></p> <p>Request Payload:</p> <p><code>json {     \"queryString\": \"Your natural language query\",     \"dataSource\": \"SharePoint\",     \"resourceMetadata\": [\"title\", \"author\"] }</code></p> <p>Best Practices:</p> <ul> <li>Provide as much context in the query as possible</li> <li>Your <code>queryString</code> should be a single sentence</li> <li>Avoid generic queries that might apply to a wide variety of content</li> <li>Send all extracts returned to your LLM for answer generation</li> </ul> <p></p>"},{"location":"pages/custom-engine/agent-framework/06-add-copilot-api/#step-2-create-the-claimspoliciesplugin","title":"Step 2: Create the ClaimsPoliciesPlugin","text":"What this plugin does <p>The <code>ClaimsPoliciesPlugin</code> provides claim compliance analysis capabilities.</p> <p>AnalyzeClaimCompliance:</p> <ul> <li>Retrieves claim details from KnowledgeBaseService</li> <li>Queries SharePoint policy documents using Copilot Retrieval API</li> <li>Uses AI to analyze claim compliance against retrieved policies</li> <li>Returns structured compliance analysis with citations</li> <li>Adds SharePoint document citations to the streaming response</li> </ul> <p>The plugin uses the On-Behalf-Of (OBO) token to call Microsoft Graph, ensuring user permissions are respected.</p> <p>1\ufe0f\u20e3 Create a new file <code>src/Plugins/ClaimsPoliciesPlugin.cs</code> with the following implementation:</p> <pre><code>using Microsoft.Agents.Builder;\nusing Microsoft.Agents.Core.Models;\nusing System.ComponentModel;\nusing System.Text.Json;\nusing InsuranceAgent;\nusing Microsoft.Agents.Builder.State;\nusing InsuranceAgent.Services;\nusing Azure.Search.Documents.Models;\nusing OpenAI.Chat;\n\nnamespace ZavaInsurance.Plugins\n{\n    /// &lt;summary&gt;\n    /// Claims Policies Plugin for Zava Insurance\n    /// Provides tools for analyzing claim compliance using Copilot Retrieval API\n    /// Retrieves policy documents from SharePoint and uses AI for compliance analysis\n    /// &lt;/summary&gt;\n    public class ClaimsPoliciesPlugin\n    {\n        private readonly ITurnContext _turnContext;\n        private readonly ITurnState _turnState;\n        private readonly HttpClient _httpClient;\n        private readonly KnowledgeBaseService _knowledgeBaseService;\n        private readonly LanguageModelService _languageModelService;\n        private readonly IConfiguration _configuration;\n\n        public ClaimsPoliciesPlugin(ITurnContext turnContext, \n            ITurnState turnState,\n            KnowledgeBaseService knowledgeBaseService,\n            LanguageModelService languageModelService,\n            IConfiguration configuration, \n            HttpClient httpClient)\n        {\n            _turnContext = turnContext ?? throw new ArgumentNullException(nameof(turnContext));\n            _turnState = turnState ?? throw new ArgumentNullException(nameof(turnState));\n            _knowledgeBaseService = knowledgeBaseService ?? throw new ArgumentNullException(nameof(knowledgeBaseService));\n            _languageModelService = languageModelService ?? throw new ArgumentNullException(nameof(languageModelService));\n            _configuration = configuration ?? throw new ArgumentNullException(nameof(configuration));\n            _httpClient = httpClient ?? throw new ArgumentNullException(nameof(httpClient));\n        }\n\n        /// &lt;summary&gt;\n        /// Retrieves claims policies from SharePoint Online using Copilot Retrieval APIs and analyzes claim compliance\n        /// &lt;/summary&gt;\n        /// &lt;param name=\"claimId\"&gt;The unique claim identifier&lt;/param&gt;\n        /// &lt;returns&gt;The claim compliance with policies&lt;/returns&gt;\n        [Description(\"Retrieves claims policies from SharePoint Online using Copilot Retrieval APIs and analyzes claim compliance\")]\n        public async Task&lt;string&gt; AnalyzeClaimCompliance(string claimId)\n        {\n            await NotifyUserAsync($\"Retrieving policies for claim {claimId}...\");\n\n            // Read the user profile and OBO token from conversation state\n            var userProfile = _turnState.Conversation.GetCachedUserProfile();\n            var accessToken = _turnState.Conversation.GetCachedOBOAccessToken();\n\n            // Use direct search to get structured data (more reliable than Knowledge Base answer synthesis)\n            var claimDoc = await _knowledgeBaseService.GetClaimByNumberAsync(claimId);\n\n            if (claimDoc == null)\n            {\n                return $\"\u274c Claim {claimId} not found in the system.\";\n            }\n\n            try\n            {\n                // Build the Copilot Retrieval API request payload\n                var retrievalPayload = new\n                {\n                    queryString = $\"Retrieve the claims policies for claims of type '{GetFieldValue(claimDoc, \"claimType\")}' in region '{GetFieldValue(claimDoc, \"region\")}'\",\n                    dataSource = \"SharePoint\",\n                    resourceMetadata = new[] { \"title\", \"author\" }\n                };\n\n                var jsonContent = JsonSerializer.Serialize(retrievalPayload);\n                var httpContent = new StringContent(jsonContent, System.Text.Encoding.UTF8, \"application/json\");\n\n                // Configure HTTP client with OBO token\n                _httpClient.DefaultRequestHeaders.Clear();\n                _httpClient.DefaultRequestHeaders.Add(\"Authorization\", $\"Bearer {accessToken}\");\n                _httpClient.DefaultRequestHeaders.Add(\"Accept\", \"application/json\");\n\n                await NotifyUserAsync($\"Using Copilot Retrieval APIs to fetch policies from SharePoint...\");\n\n                // Call the Microsoft 365 Copilot Retrieval API\n                var response = await _httpClient.PostAsync(\"https://graph.microsoft.com/v1.0/copilot/retrieval\", httpContent);\n\n                if (response.IsSuccessStatusCode)\n                {\n                    await NotifyUserAsync($\"\u2705 Policies successfully retrieved from SharePoint!\");\n                }\n                else\n                {\n                    var errorContent = await response.Content.ReadAsStringAsync();\n                    await NotifyUserAsync($\"\u274c Failed to retrieve policies: {response.StatusCode}\");\n                    return $\"\u274c Error retrieving policies from SharePoint: {response.StatusCode} - {errorContent}\";\n                }\n\n                var policiesContent = await response.Content.ReadAsStringAsync();\n                var estimatedCost = GetFieldValue(claimDoc, \"estimatedCost\");\n                var isComplete = GetFieldValue(claimDoc, \"isDocumentationComplete\");\n                var missingDocs = GetFieldValue(claimDoc, \"missingDocumentation\");\n\n                // Build AI prompt for compliance analysis\n                var prompt = $@\"You are an insurance claims expert and you need to analyze the claim policies for a specific claim.\n\n                    **CLAIM DETAILS:**\n                    - Claim Number: {GetFieldValue(claimDoc, \"claimNumber\")}\n                    - Claim Type: {GetFieldValue(claimDoc, \"claimType\")}\n                    - Region: {GetFieldValue(claimDoc, \"region\")}\n                    - Amount: ${estimatedCost:N2}\n                    - Status: {GetFieldValue(claimDoc, \"status\")}\n                    - Severity: {GetFieldValue(claimDoc, \"severity\")}\n                    - Description: {GetFieldValue(claimDoc, \"description\")}\n                    - Policy Number: {GetFieldValue(claimDoc, \"policyNumber\")}\n                    - Policyholder: {GetFieldValue(claimDoc, \"policyholderName\")}\n                    - Assigned Adjuster: {GetFieldValue(claimDoc, \"assignedAdjuster\")}\n                    - Documentation Complete: {(isComplete == \"True\" || isComplete == \"true\" ? \"Yes\" : \"No\")}\n                    - Missing Documentation: {(string.IsNullOrWhiteSpace(missingDocs) ? \"None\" : missingDocs)}\n\n                    Here are the claim policies retrieved from SharePoint in JSON format:\n                    {policiesContent}\n\n                    Provide analysis in this JSON format:\n                    {{\n                    \"\"complianceScore\"\": &lt;0-100&gt;,\n                    \"\"complianceLevel\"\": \"\"&lt;Low/Medium/High/Critical&gt;\"\",\n                    \"\"analysis\"\": \"\"&lt;detailed explanation of claim compliance with policies&gt;\"\",\n                    \"\"keyIndicators\"\": [\"\"&lt;list of specific compliance indicators with references citations to policies using the [1], [2], ... [n] format&gt;\"\"],\n                    \"\"recommendations\"\": [\"\"&lt;recommended actions&gt;\"\"],\n                    \"\"citationsTitles\"\": [\"\"&lt;list of titles corresponding to the citations&gt;\"\"],\n                    \"\"citationsLinks\"\": [\"\"&lt;list of URLs corresponding to the citations&gt;\"\"]\n                    }}\n\n                    \";\n\n                await NotifyUserAsync($\"\ud83e\udd16 Running AI compliance analysis...\");\n\n                Console.WriteLine($\"\ud83d\udd0d ClaimsPoliciesPlugin.AnalyzeClaimCompliance calling LanguageModelService with Temperature=0.2\");\n\n                // Use AI to analyze compliance\n                var messages = new List&lt;ChatMessage&gt;\n                {\n                    new UserChatMessage(prompt)\n                };\n\n                var chatOptions = new ChatCompletionOptions\n                {\n                    Temperature = 0.2f,\n                    ResponseFormat = ChatResponseFormat.CreateJsonObjectFormat()\n                };\n\n                var chatResponse = await _languageModelService.CompleteChatAsync(messages, chatOptions);\n                var analysisJson = chatResponse.Content[0].Text ?? \"{}\";\n\n                var complianceResult = JsonSerializer.Deserialize&lt;ComplianceAnalysisResult&gt;(analysisJson, new JsonSerializerOptions\n                {\n                    PropertyNameCaseInsensitive = true\n                });\n\n                if (complianceResult == null)\n                {\n                    return $\"\u274c Error: Unable to parse compliance analysis for claim {claimId}.\";\n                }\n\n                await NotifyUserAsync($\"\u2705 Compliance analysis complete. Compliance Score: {complianceResult.ComplianceScore}/100\");\n\n                // Add citations to streaming response\n                for (int i = 0; i &lt; complianceResult.CitationsTitles.Count; i++)\n                {\n                    var citationTitle = complianceResult.CitationsTitles.Count &gt; i ? complianceResult.CitationsTitles[i] : $\"Policy Document {i + 1}\";\n                    var citationLink = complianceResult.CitationsLinks.Count &gt; i ? complianceResult.CitationsLinks[i] : null;\n                    citationLink = citationLink != null ? GetCitationUrl(citationLink) : citationLink;\n\n                    _turnContext.StreamingResponse.AddCitation(\n                        new ClientCitation(\n                            position: i + 1,\n                            title: citationTitle,\n                            abstractText: \"Claims Policy\",\n                            text: \"Claims Policy\",\n                            keywords: null,\n                            citationLink: citationLink,\n                            imageName: ClientCitationsIconNameEnum.MicrosoftWord,\n                            useDefaultAdaptiveCard: true));\n\n                    Console.WriteLine($\"\ud83d\udd17 Added citation for \\\"{citationTitle}\\\" with link {citationLink ?? \"[no link]\"}\");\n                }\n\n                // Format the response\n                return $\"\ud83d\udea8 **Compliance Analysis for {claimId}**\\n\\n\" +\n                       $\"**Compliance Score:** {complianceResult.ComplianceScore}/100\\n\" +\n                       $\"**Compliance Level:** {complianceResult.ComplianceLevel}\\n\\n\" +\n                       $\"**Analysis:**\\n{complianceResult.Analysis}\\n\\n\" +\n                       (complianceResult.KeyIndicators != null &amp;&amp; complianceResult.KeyIndicators.Count &gt; 0\n                           ? $\"**Key Compliance Indicators:**\\n{string.Join(\"\\n\", complianceResult.KeyIndicators.Select(i =&gt; $\"\u2022 {i}\"))}\\n\\n\"\n                           : \"\") +\n                       (complianceResult.Recommendations != null &amp;&amp; complianceResult.Recommendations.Count &gt; 0\n                           ? $\"**Recommendations:**\\n{string.Join(\"\\n\", complianceResult.Recommendations.Select(r =&gt; $\"\u2022 {r}\"))}\\n\\n\"\n                           : \"\");\n            }\n            catch (Exception ex)\n            {\n                Console.WriteLine($\"\u274c Error analyzing claim compliance: {ex.Message}\");\n                return $\"\u274c Error analyzing claim compliance: {ex.Message}\";\n            }\n        }\n\n        /// &lt;summary&gt;\n        /// Helper method to safely extract field values from SearchDocument\n        /// &lt;/summary&gt;\n        private string GetFieldValue(SearchDocument doc, string fieldName)\n        {\n            if (doc.ContainsKey(fieldName) &amp;&amp; doc[fieldName] != null)\n            {\n                return doc[fieldName].ToString() ?? \"Not available\";\n            }\n            return \"Not available\";\n        }\n\n        // Helper method to construct citation URL through the bot's proxy endpoint\n        private string GetCitationUrl(string targetUrl)\n        {\n            var botEndpoint = _configuration[\"BOT_ENDPOINT\"];\n\n            Console.WriteLine($\"\ud83d\udd0d BOT_ENDPOINT from config: {botEndpoint ?? \"NULL\"}\");\n\n            if (string.IsNullOrEmpty(botEndpoint))\n            {\n                var botDomain = _configuration[\"BOT_DOMAIN\"];\n                if (!string.IsNullOrEmpty(botDomain))\n                {\n                    botEndpoint = $\"https://{botDomain}\";\n                    Console.WriteLine($\"\ud83d\udd0d Using BOT_DOMAIN: {botEndpoint}\");\n                }\n                else\n                {\n                    botEndpoint = \"http://localhost:3978\";\n                    Console.WriteLine($\"\u26a0\ufe0f Falling back to localhost\");\n                }\n            }\n\n            botEndpoint = botEndpoint.TrimEnd('/');\n            var citationUrl = $\"{botEndpoint}/api/citation?targetUrl={Uri.EscapeDataString(targetUrl)}\";\n            Console.WriteLine($\"\u2699\ufe0f Generated citation URL: {citationUrl}\");\n\n            return citationUrl;\n        }\n\n        // Helper method to notify user via streaming\n        private async Task NotifyUserAsync(string message)\n        {\n            if (!_turnContext.Activity.ChannelId.Channel!.Contains(Channels.Webchat))\n            {\n                await _turnContext.StreamingResponse.QueueInformativeUpdateAsync(message);\n            }\n            else\n            {\n                await _turnContext.StreamingResponse.QueueInformativeUpdateAsync(message).ConfigureAwait(false);\n            }\n        }\n    }\n\n    /// &lt;summary&gt;\n    /// Result of AI-powered compliance analysis\n    /// &lt;/summary&gt;\n    public class ComplianceAnalysisResult\n    {\n        public int ComplianceScore { get; set; }\n        public string ComplianceLevel { get; set; } = \"\";\n        public string Analysis { get; set; } = \"\";\n        public List&lt;string&gt; KeyIndicators { get; set; } = new();\n        public List&lt;string&gt; Recommendations { get; set; } = new();\n        public List&lt;string&gt; CitationsTitles { get; set; } = new();\n        public List&lt;string&gt; CitationsLinks { get; set; } = new();\n    }\n}\n</code></pre> How Citations Work with StreamingResponse <p>The <code>ClaimsPoliciesPlugin</code> adds citations to the response using the <code>StreamingResponse.AddCitation()</code> method on the <code>ITurnContext</code>. Here's how it works:</p> <ol> <li> <p>AI generates citation references: The language model returns references like <code>[1]</code>, <code>[2]</code> in its analysis text, along with <code>CitationsTitles</code> and <code>CitationsLinks</code> arrays.</p> </li> <li> <p>Create ClientCitation objects: For each citation, create a <code>ClientCitation</code> with:</p> <ul> <li><code>position</code>: The citation number (1-based, matching <code>[1]</code>, <code>[2]</code> in text)</li> <li><code>title</code>: Display title for the citation</li> <li><code>citationLink</code>: URL to the source document (routed through the bot's proxy endpoint)</li> <li><code>imageName</code>: Icon to display (e.g., <code>ClientCitationsIconNameEnum.MicrosoftWord</code>)</li> </ul> </li> <li> <p>Add to StreamingResponse: Call <code>_turnContext.StreamingResponse.AddCitation(citation)</code> to queue the citation.</p> </li> <li> <p>M365 Copilot renders citations: Microsoft 365 Copilot automatically renders clickable citation links that users can follow to view the source documents.</p> </li> </ol> <p>Why use a proxy endpoint? SharePoint URLs require authentication. The <code>GetCitationUrl()</code> method routes links through your bot's <code>/api/citation</code> endpoint, which handles authentication and redirects users to the actual document.</p> <p></p>"},{"location":"pages/custom-engine/agent-framework/06-add-copilot-api/#exercise-4-register-claimspoliciesplugin-in-agent","title":"Exercise 4: Register ClaimsPoliciesPlugin in Agent","text":"<p>Now let's wire up the ClaimsPoliciesPlugin in your ZavaInsuranceAgent.</p>"},{"location":"pages/custom-engine/agent-framework/06-add-copilot-api/#step-1-instantiate-claimspoliciesplugin","title":"Step 1: Instantiate ClaimsPoliciesPlugin","text":"<p>1\ufe0f\u20e3 Open <code>src/Agent/ZavaInsuranceAgent.cs</code>.</p> <p>2\ufe0f\u20e3 Find the <code>GetClientAgent</code> method (around line 169).</p> <p>3\ufe0f\u20e3 Locate where the service instances are retrieved and right after the <code>var visionService = scope.ServiceProvider.GetRequiredService&lt;VisionService&gt;();</code> line add the following:</p> <pre><code>var languageModelService = scope.ServiceProvider.GetRequiredService&lt;LanguageModelService&gt;();\n</code></pre> <p>4\ufe0f\u20e3 Locate where plugins are instantiated (after <code>CommunicationPlugin communicationPlugin = ...</code>).</p> <p>5\ufe0f\u20e3 Add the ClaimsPoliciesPlugin instantiation:</p> <pre><code>// Create ClaimsPoliciesPlugin with required dependencies\nClaimsPoliciesPlugin claimsPoliciesPlugin = new(context, turnState, knowledgeBaseService, languageModelService, configuration, httpClient);\n</code></pre> <p></p>"},{"location":"pages/custom-engine/agent-framework/06-add-copilot-api/#step-2-register-claimspoliciesplugin-tools","title":"Step 2: Register ClaimsPoliciesPlugin Tools","text":"<p>In the same <code>GetClientAgent</code> method, scroll down to where tools are added to <code>toolOptions.Tools</code>.</p> <p>Find the Communication tools section and add ClaimsPoliciesPlugin tools right after:</p> <pre><code>// Register ClaimsPolicies tools (Copilot Retrieval API)\ntoolOptions.Tools.Add(AIFunctionFactory.Create(claimsPoliciesPlugin.AnalyzeClaimCompliance));\n</code></pre> Tool Registration Pattern <p>The agent uses AIFunctionFactory to register plugin methods as AI tools. The <code>[Description]</code> attribute on the plugin method becomes the tool description that helps the LLM decide when to call it.</p> <p></p>"},{"location":"pages/custom-engine/agent-framework/06-add-copilot-api/#step-3-update-agent-instructions","title":"Step 3: Update Agent Instructions","text":"<p>Update the agent instructions to include the claims compliance analysis tool.</p> <p>1\ufe0f\u20e3 In <code>src/Agent/ZavaInsuranceAgent.cs</code>, find the <code>AgentInstructions</code> field.</p> <p>2\ufe0f\u20e3 Add the claims compliance tool to the instructions. Find the existing tool list and add:</p> <pre><code>For claims compliance analysis, use {{ClaimsPoliciesPlugin.AnalyzeClaimCompliance}}.\n</code></pre> <p>Your complete <code>AgentInstructions</code> should now include all tools:</p> <pre><code>private readonly string AgentInstructions = \"\"\"\nYou are a professional insurance claims assistant for Zava Insurance.\n\nWhenever the user starts a new conversation or provides a prompt to start a new conversation like \"start over\", \"restart\", \n\"new conversation\", \"what can you do?\", \"how can you help me?\", etc. use {{StartConversationPlugin.StartConversation}} and \nprovide to the user exactly the message you get back from the plugin.\n\n**Available Tools:**\nUse {{DateTimeFunctionTool.getDate}} to get the current date and time.\nFor claims search, use {{ClaimsPlugin.SearchClaims}} and {{ClaimsPlugin.GetClaimDetails}}.\nFor damage photo viewing, use {{VisionPlugin.ShowDamagePhoto}}.\nFor AI vision damage analysis, use {{VisionPlugin.AnalyzeAndShowDamagePhoto}} and require approval via {{VisionPlugin.ApproveAnalysis}}.\nFor policy search, use {{PolicyPlugin.SearchPolicies}} and {{PolicyPlugin.GetPolicyDetails}}.\nFor sending investigation reports and claim details via email, use {{CommunicationPlugin.GenerateInvestigationReport}} and {{CommunicationPlugin.SendClaimDetailsByEmail}}.\nFor claims compliance analysis, use {{ClaimsPoliciesPlugin.AnalyzeClaimCompliance}}.\n\n**IMPORTANT**: When user asks to \"check policy for this claim\", first use GetClaimDetails to get the claim's policy number, then use GetPolicyDetails with that policy number.\n\n**IMPORTANT**: If in the response there are references to citations like [1], [2], etc., make sure to include those citations in the response so that M365 Copilot can render them properly.\n\nStick to the scenario above and use only the information from the tools when answering questions.\nBe concise and professional in your responses.\n\"\"\";\n</code></pre> <p></p>"},{"location":"pages/custom-engine/agent-framework/06-add-copilot-api/#step-4-update-welcome-message","title":"Step 4: Update Welcome Message","text":"<p>Update the StartConversationPlugin to include the compliance analysis in the suggested workflow.</p> <p>1\ufe0f\u20e3 Open <code>src/Plugins/StartConversationPlugin.cs</code>.</p> <p>2\ufe0f\u20e3 Find the <code>welcomeMessage</code> variable in the <code>StartConversation</code> method.</p> <p>3\ufe0f\u20e3 Add the compliance check prompt to the workflow list. After the \"Analyze this damage photo\" step, add:</p> <pre><code>\"8. \\\"Check compliance for this claim\\\"\\n\" +\n</code></pre> <p>4\ufe0f\u20e3 Update the numbering for the remaining steps (Generate investigation report becomes 9, Update claim status becomes 10).</p> <p>Your updated workflow section should look like:</p> <pre><code>\"\ud83c\udfaf Try this complete investigation workflow:\\n\" +\n\"1. \\\"Get details for claim CLM-2025-001007\\\"\\n\" +\n\"2. \\\"Check policy for this claim\\\"\\n\" +\n\"3. \\\"What coverage does auto insurance include?\\\"\\n\" +\n\"4. \\\"Analyze fraud risk for this claim\\\"\\n\" +\n\"5. \\\"Show damage photo for this claim\\\"\\n\" +\n\"6. \\\"Analyze this damage photo\\\"\\n\" +\n\"7. \\\"What's the claims filing procedure?\\\"\\n\" +\n\"8. \\\"Check compliance for this claim\\\"\\n\" +\n\"9. \\\"Generate investigation report for claim CLM-2025-001007\\\"\\n\" +\n\"10. \\\"Update claim status to 'Approved for Payment'\\\"\\n\\n\" +\n</code></pre> <p></p>"},{"location":"pages/custom-engine/agent-framework/06-add-copilot-api/#exercise-5-test-copilot-api-integration","title":"Exercise 5: Test Copilot API Integration","text":"<p>Now let's test the complete Copilot API integration!</p>"},{"location":"pages/custom-engine/agent-framework/06-add-copilot-api/#step-1-run-and-verify","title":"Step 1: Run and Verify","text":"<p>1\ufe0f\u20e3 Press F5 in VS Code to start debugging.</p> <p>2\ufe0f\u20e3 Select (Preview) Debug in Copilot (Edge) if prompted.</p> <p>3\ufe0f\u20e3 The terminal should show normal initialization.</p> <p>4\ufe0f\u20e3 A browser window will open with Microsoft 365 Copilot.</p> <p></p>"},{"location":"pages/custom-engine/agent-framework/06-add-copilot-api/#step-2-test-claim-compliance-analysis","title":"Step 2: Test Claim Compliance Analysis","text":"<p>1\ufe0f\u20e3 In Microsoft 365 Copilot, say:</p> <pre><code>Check compliance for claim CLM-2025-001007\n</code></pre> <p>The agent should:</p> <ul> <li>Use <code>ClaimsPoliciesPlugin.AnalyzeClaimCompliance</code></li> <li>Retrieve the claim details from Table Storage</li> <li>Call the Copilot Retrieval API to fetch policies from SharePoint</li> <li>Use AI to analyze compliance</li> <li>Return a structured compliance report with citations</li> </ul> <p>Expected Response:</p> <pre><code>Retrieving policies for claim CLM-2025-001007...\nUsing Copilot Retrieval APIs to fetch policies from SharePoint...\n\u2705 Policies successfully retrieved from SharePoint!\n\ud83e\udd16 Running AI compliance analysis...\n\u2705 Compliance analysis complete. Compliance Score: 85/100\n\n## \ud83d\udccb Compliance Analysis for Claim CLM-2025-001007\n\n**Compliance Score**: 40/100 (High)\n**Compliance Level**: Low\n\n### Analysis\nThe claim is currently open and has a high severity rating due to a multi-vehicle...\n\n### Key Compliance Indicators\n- Incomplete documentation [1]\n- High severity claim requires thorough investigation [2]\n- ...\n\n### Recommendations\n- Contact the policyholder, Arnel Cruz, to gather missing documentation related to the accident.\n- ...\n</code></pre> <p>2\ufe0f\u20e3 Notice the citations in the response (like <code>[1]</code>, <code>[2]</code>). These link back to the SharePoint policy documents that were used for the analysis.</p> <p></p>"},{"location":"pages/custom-engine/agent-framework/06-add-copilot-api/#step-3-test-with-different-claims","title":"Step 3: Test with Different Claims","text":"<p>1\ufe0f\u20e3 Try a different prompt with another claim:</p> <pre><code>Check if claim CLM-2025-001001 follows our policies\n</code></pre> <p>2\ufe0f\u20e3 The agent should use the Copilot Retrieval API to fetch the appropriate policies based on the claim type (Auto, Homeowners, etc.) and region.</p> <p></p>"},{"location":"pages/custom-engine/agent-framework/06-add-copilot-api/#step-4-test-complete-workflow-with-compliance","title":"Step 4: Test Complete Workflow with Compliance","text":"<p>Test the complete workflow including compliance analysis:</p> <pre><code>1. Get details for claim CLM-2025-001007\n2. Check policy for this claim\n3. Analyze fraud risk for this claim\n4. Check compliance for this claim\n5. Generate investigation report for this claim\n6. Send the report by email\n</code></pre> <p>The agent should seamlessly integrate the Copilot Retrieval API alongside all other capabilities!</p> <p></p> <p>CONGRATULATIONS!</p> <p>You have completed Lab BAF6 - Add Microsoft 365 Work IQ API Integration!</p> <p>You've learned how to:</p> <ul> <li>\u2705 Set up SharePoint site with policy documents for the Copilot Retrieval API</li> <li>\u2705 Create a centralized LanguageModelService for AI operations</li> <li>\u2705 Understand the Microsoft 365 Copilot Retrieval API and its capabilities</li> <li>\u2705 Create a ClaimsPoliciesPlugin that uses Copilot Retrieval API</li> <li>\u2705 Integrate SharePoint policy document search via Microsoft Graph</li> <li>\u2705 Combine AI analysis with retrieved policy documents</li> <li>\u2705 Add citations from SharePoint documents to agent responses</li> </ul> <p>Your Zava Insurance Agent now includes:</p> <ul> <li>Search: Claims and policies via Azure AI Search</li> <li>Analysis: AI vision with Mistral for damage assessment</li> <li>Compliance: Copilot Retrieval API for policy compliance analysis from SharePoint</li> <li>Communication: Email reports and investigation summaries</li> </ul> About Microsoft 365 Work IQ API <p>The Microsoft 365 Work IQ API provide access to components that power Copilot experiences:</p> <ul> <li>Retrieval API: Ground your AI solutions with Microsoft 365 data without data egress</li> <li>Chat API (preview): Engage in multi-turn conversations with enterprise search grounding</li> </ul> <p>These APIs maintain strict security and compliance by keeping data in place and respecting permissions.</p> <p>\ud83c\udf89 Congratulations! You've built a production-ready AI agent with Microsoft 365 Copilot API integration! \ud83c\udf8a</p> <p></p>"},{"location":"pages/custom-engine/agent-framework/07-add-mcp-tools/","title":"Lab BAF7 - Add MCP Tools Integration","text":"<p>In this lab, you'll extend your Zava Insurance Agent with Model Context Protocol (MCP) tools. You'll create an MCP server using Azure Functions that provides claims adjuster management capabilities, then consume those tools from a custom plugin in your Custom Engine Agent.</p> Understanding MCP Integration <p>The Model Context Protocol (MCP) enables your agent to:</p> <ul> <li>Connect to External Tools: Use standardized protocol to access tools from MCP servers</li> <li>Manage Claims Adjusters: List adjusters by area of expertise and country</li> <li>Assign Adjusters to Claims: Automatically assign the right adjuster based on claim type</li> <li>Leverage Azure Functions: Host MCP tools as serverless functions for scalability</li> </ul> <p>This integration demonstrates how to extend your agent's capabilities using the MCP ecosystem.</p>"},{"location":"pages/custom-engine/agent-framework/07-add-mcp-tools/#overview","title":"Overview","text":"<p>In previous labs, you added claims search, vision analysis, policy search, and communication capabilities. Now you'll extend your agent with MCP tools to manage claims adjusters - a common requirement in insurance workflows where claims need to be routed to specialized adjusters based on claim type and location.</p> <p>The Model Context Protocol (MCP) is an open standard that enables AI applications to connect to external data sources and tools. By creating an MCP server with Azure Functions, you can expose business logic as tools that any MCP-compatible agent can consume.</p> What You'll Build <ul> <li>MCP Server: An Azure Function app that exposes claims adjuster tools via MCP</li> <li>ClaimsAdjustersPlugin: A plugin that consumes MCP tools to list and assign adjusters</li> <li>Agent Integration: Wire up the plugin to enable adjuster management in conversations</li> </ul>"},{"location":"pages/custom-engine/agent-framework/07-add-mcp-tools/#exercise-1-create-the-mcp-server-with-azure-functions","title":"Exercise 1: Create the MCP Server with Azure Functions","text":"Pre-defined MCP server <p>If you don't want to create the MCP server from scratch, you can skip Exercise 1, download a pre-defined one from folder /<code>src/agent-framework/insurance-mcp</code>, configure the <code>env/.env.local</code> and the <code>env/.env.local.user</code> files, and run it pressing F5 in Visual Studio Code. If that is the case, you can move straight to Exercise 2.</p> <p>First, let's create an Azure Function app that serves as your MCP server, exposing claims adjuster management tools.</p>"},{"location":"pages/custom-engine/agent-framework/07-add-mcp-tools/#step-1-understand-the-mcp-server-architecture","title":"Step 1: Understand the MCP Server Architecture","text":"How MCP Server Works <p>The MCP server exposes tools that can be called by MCP clients. Each tool has:</p> <ul> <li>Tool Name: Unique identifier (e.g., <code>get_claims_adjusters</code>)</li> <li>Description: Helps the LLM understand when to use the tool</li> <li>Properties: Input parameters with types and descriptions</li> <li>Handler: Function that executes when the tool is called</li> </ul> <p>Azure Functions provides a convenient hosting model for MCP servers, with built-in support for the MCP protocol via the native MCP protocol binding.</p> <p>The MCP server architecture consists of:</p> <ol> <li>Data Storage: Azure Table Storage for claims adjuster records</li> <li>HTTP Handlers: REST endpoints for direct API access</li> <li>MCP Tool Handlers: Functions registered as MCP tools for agent consumption</li> </ol> <p></p>"},{"location":"pages/custom-engine/agent-framework/07-add-mcp-tools/#step-2-create-the-azure-function-project","title":"Step 2: Create the Azure Function Project","text":"<p>1\ufe0f\u20e3 Create a new folder for your MCP server project:</p> <pre><code>mkdir InsuranceMCPServer\ncd InsuranceMCPServer\n</code></pre> <p>2\ufe0f\u20e3 Initialize a new Azure Functions project with TypeScript:</p> <pre><code>func init --typescript\n</code></pre> <p>3\ufe0f\u20e3 Install the required dependencies:</p> <pre><code>npm install @azure/data-tables dotenv\nnpm install --save-dev @types/node\n</code></pre> <p>4\ufe0f\u20e3 Create the environment configuration file <code>env/.env.local</code>:</p> <pre><code>AZURE_STORAGE_ACCOUNT=your_storage_account\nAZURE_TABLE_ENDPOINT=https://your_storage_account.table.core.windows.net\nTABLE_NAME=ClaimsAdjusters\nALLOW_INSECURE_CONNECTION=false\n</code></pre> <p>5\ufe0f\u20e3 Create the environment configuration file <code>env/.env.local.user</code>:</p> <pre><code>SECRET_AZURE_STORAGE_KEY=your_storage_key\n</code></pre> <p></p>"},{"location":"pages/custom-engine/agent-framework/07-add-mcp-tools/#step-3-create-the-claims-adjusters-function","title":"Step 3: Create the Claims Adjusters Function","text":"<p>Create a new file <code>src/functions/ClaimsAdjusters.ts</code> with the MCP tool implementations:</p> <pre><code>import { app, HttpRequest, HttpResponseInit, InvocationContext } from \"@azure/functions\";\nimport { TableClient, AzureNamedKeyCredential } from \"@azure/data-tables\";\nimport * as dotenv from \"dotenv\";\nimport * as path from \"path\";\nimport * as fs from \"fs\";\n\n// Load environment variables (.env.local.user takes precedence over .env.local)\nconst envLocalFile = path.join(__dirname, \"../../../env/.env.local\");\nconst envLocalUserFile = path.join(__dirname, \"../../../env/.env.local.user\");\n\n// Load .env.local first, then .env.local.user (later values override earlier ones)\ndotenv.config({ path: envLocalFile });\nif (fs.existsSync(envLocalUserFile)) {\n    dotenv.config({ path: envLocalUserFile, override: true });\n}\n\ninterface ClaimAdjuster {\n    id: string;\n    firstName: string;\n    lastName: string;\n    email: string;\n    phone: string;\n    country: string;\n    area: string;\n}\n\n// Initialize Table Storage client\nfunction getTableClient(): TableClient {\n    const account = process.env.AZURE_STORAGE_ACCOUNT;\n    const accountKey = process.env.SECRET_AZURE_STORAGE_KEY;\n    const tableEndpoint = process.env.AZURE_TABLE_ENDPOINT;\n    const tableName = process.env.TABLE_NAME;\n    const allowInsecure = process.env.ALLOW_INSECURE_CONNECTION === \"true\";\n\n    if (!account || !accountKey || !tableEndpoint || !tableName) {\n        throw new Error(\"Missing required environment variables. Please check your env/.env file.\");\n    }\n\n    const credential = new AzureNamedKeyCredential(account, accountKey);\n    return new TableClient(tableEndpoint, tableName, credential, {\n        allowInsecureConnection: allowInsecure\n    });\n}\n\n// Load claims adjusters data from Table Storage\nasync function loadClaimsAdjusters(): Promise&lt;ClaimAdjuster[]&gt; {\n    const tableClient = getTableClient();\n    const adjusters: ClaimAdjuster[] = [];\n\n    const entities = tableClient.listEntities({\n        queryOptions: { filter: `PartitionKey eq 'ClaimsAdjusters'` }\n    });\n\n    for await (const entity of entities) {\n        adjusters.push({\n            id: entity.rowKey as string,\n            firstName: entity.firstName as string,\n            lastName: entity.lastName as string,\n            email: entity.email as string,\n            phone: entity.phone as string,\n            country: entity.country as string,\n            area: entity.area as string\n        });\n    }\n\n    return adjusters;\n}\n\n// Internal implementation: List claims adjusters with optional filters\nasync function listClaimsAdjustersImpl(country?: string, area?: string): Promise&lt;ClaimAdjuster[]&gt; {\n    let adjusters = await loadClaimsAdjusters();\n\n    // Apply filters\n    if (country) {\n        adjusters = adjusters.filter(adj =&gt; adj.country.toLowerCase() === country.toLowerCase());\n    }\n\n    if (area) {\n        adjusters = adjusters.filter(adj =&gt; adj.area.toLowerCase() === area.toLowerCase());\n    }\n\n    return adjusters;\n}\n\n// Internal implementation: Get claim adjuster by ID\nasync function getClaimAdjusterByIdImpl(id: string): Promise&lt;ClaimAdjuster | null&gt; {\n    const tableClient = getTableClient();\n\n    try {\n        const entity = await tableClient.getEntity(\"ClaimsAdjusters\", id);\n        const adjuster: ClaimAdjuster = {\n            id: entity.rowKey as string,\n            firstName: entity.firstName as string,\n            lastName: entity.lastName as string,\n            email: entity.email as string,\n            phone: entity.phone as string,\n            country: entity.country as string,\n            area: entity.area as string\n        };\n        return adjuster;\n    } catch (entityError: any) {\n        if (entityError.statusCode === 404) {\n            return null;\n        }\n        throw entityError;\n    }\n}\n\n// Internal implementation: Assign a claim adjuster to a claim\nasync function assignClaimAdjusterImpl(claimId: string, adjusterId: string): Promise&lt;{\n    success: boolean;\n    assignmentId?: string;\n    adjusterName?: string;\n    error?: string;\n}&gt; {\n    if (!claimId || !adjusterId) {\n        return {\n            success: false,\n            error: \"Both claimId and adjusterId are required\"\n        };\n    }\n\n    // Verify adjuster exists\n    const adjuster = await getClaimAdjusterByIdImpl(adjusterId);\n\n    if (!adjuster) {\n        return {\n            success: false,\n            error: `Claim adjuster with ID ${adjusterId} not found`\n        };\n    }\n\n    // Generate fake assignment ID\n    const currentYear = new Date().getFullYear();\n    const randomNumber = Math.floor(Math.random() * 1000000).toString().padStart(6, '0');\n    const assignmentId = `ASS-${currentYear}-${randomNumber}`;\n\n    return {\n        success: true,\n        assignmentId: assignmentId,\n        adjusterName: `${adjuster.firstName} ${adjuster.lastName}`\n    };\n}\n</code></pre> <p></p>"},{"location":"pages/custom-engine/agent-framework/07-add-mcp-tools/#step-4-register-mcp-tools","title":"Step 4: Register MCP Tools","text":"<p>Add the MCP tool registrations at the end of <code>src/functions/ClaimsAdjusters.ts</code>:</p> <pre><code>// MCP Tool Handler: List claims adjusters with optional filters\nasync function handleListClaimsAdjusters(input: any, context: InvocationContext): Promise&lt;ClaimAdjuster[] | { error: string }&gt; {\n    context.log(`MCP: Listing claims adjusters with filters`);\n\n    try {\n        const country = input.arguments[\"country\"] || undefined;\n        const area = input.arguments[\"area\"] || undefined;\n\n        const adjusters = await listClaimsAdjustersImpl(country, area);\n        return adjusters;\n    } catch (error) {\n        context.log('Error fetching claim adjusters:', error);\n        return { error: (error as Error).message };\n    }\n}\n\n// MCP Tool Handler: Get claim adjuster by ID\nasync function handleGetClaimsAdjusterById(input: any, context: InvocationContext): Promise&lt;ClaimAdjuster | { error: string }&gt; {\n    context.log(`MCP: Getting claim adjuster by ID`);\n\n    try {\n        const id = input.arguments[\"id\"];\n\n        if (!id) {\n            return { error: \"Claim adjuster ID is required\" };\n        }\n\n        const adjuster = await getClaimAdjusterByIdImpl(id);\n\n        if (!adjuster) {\n            return { error: `Claim adjuster with ID ${id} not found` };\n        }\n\n        return adjuster;\n    } catch (error) {\n        context.log('Error fetching claim adjuster:', error);\n        return { error: (error as Error).message };\n    }\n}\n\n// MCP Tool Handler: Assign a claim adjuster to a claim\nasync function handleAssignClaimAdjuster(input: any, context: InvocationContext): Promise&lt;{ success: boolean; assignmentId?: string; adjusterName?: string; error?: string }&gt; {\n    context.log(`MCP: Assigning claim adjuster to claim`);\n\n    try {\n        const claimId = input.arguments[\"claimId\"];\n        const adjusterId = input.arguments[\"adjusterId\"];\n\n        const result = await assignClaimAdjusterImpl(claimId, adjusterId);\n        return result;\n    } catch (error) {\n        context.log('Error assigning claim adjuster:', error);\n        return { success: false, error: (error as Error).message };\n    }\n}\n\n// Register MCP tools\napp.mcpTool(\"get_claims_adjusters\", {\n    toolName: \"get_claims_adjusters\",\n    description: \"Retrieve a list of all insurance claims adjusters\",\n    toolProperties: [\n        {\n            \"propertyName\": \"country\",\n            \"propertyType\": \"string\",\n            \"description\": \"The country of the claim adjuster\",\n            \"isRequired\": false\n        },\n        {\n            \"propertyName\": \"area\",\n            \"propertyType\": \"string\",\n            \"description\": \"The area of expertise of the claim adjuster\",\n            \"isRequired\": false\n        }\n    ],\n    handler: handleListClaimsAdjusters\n});\n\napp.mcpTool(\"get_claims_adjuster\", {\n    toolName: \"get_claims_adjuster\",\n    description: \"Retrieve a specific insurance claims adjuster by ID\",\n    toolProperties: [\n        {\n            \"propertyName\": \"id\",\n            \"propertyType\": \"string\",\n            \"description\": \"The unique identifier of the claim adjuster\",\n            \"isRequired\": true\n        }\n    ],\n    handler: handleGetClaimsAdjusterById\n});\n\napp.mcpTool(\"assign_claim_adjuster\", {\n    toolName: \"assign_claim_adjuster\",\n    description: \"Assign a claim adjuster to an insurance claim\",\n    toolProperties: [\n        {\n            \"propertyName\": \"claimId\",\n            \"propertyType\": \"string\",\n            \"description\": \"The unique identifier of the claim\",\n            \"isRequired\": true\n        },\n        {\n            \"propertyName\": \"adjusterId\",\n            \"propertyType\": \"string\",\n            \"description\": \"The unique identifier of the claim adjuster to assign\",\n            \"isRequired\": true\n        }\n    ],\n    handler: handleAssignClaimAdjuster\n});\n</code></pre> MCP Tool Registration Pattern <p>Each MCP tool is registered using <code>app.mcpTool()</code> with:</p> <ul> <li>toolName: The identifier used when calling the tool</li> <li>description: Helps the LLM understand when to use this tool</li> <li>toolProperties: Array of input parameters with name, type, description, and required flag</li> <li>handler: The async function that executes the tool logic</li> </ul> <p></p>"},{"location":"pages/custom-engine/agent-framework/07-add-mcp-tools/#step-5-deploy-the-mcp-server","title":"Step 5: Deploy the MCP Server","text":"<p>1\ufe0f\u20e3 Create the Azure Function App in Azure:</p> <pre><code>az functionapp create --name your-mcp-server --resource-group your-rg --consumption-plan-location eastus --runtime node --runtime-version 20 --functions-version 4 --storage-account your-storage\n</code></pre> <p>2\ufe0f\u20e3 Deploy the function:</p> <pre><code>func azure functionapp publish your-mcp-server\n</code></pre> <p>3\ufe0f\u20e3 Note your MCP server endpoint URL (e.g., <code>https://your-mcp-server.azurewebsites.net/runtime/webhooks/mcp</code>)</p> MCP server local with devtunnel <p>Instead of publishing the MCP server to Azure, you can keep it running locally and use Dev Tunnels to create a public URL:</p> <p>1\ufe0f\u20e3 Start your Azure Function locally: <code>bash func start</code></p> <p>2\ufe0f\u20e3 In a new terminal, create and host a dev tunnel: <code>bash devtunnel create --allow-anonymous devtunnel port create -p 7071 devtunnel host</code></p> <p>3\ufe0f\u20e3 Copy the tunnel URL (e.g., <code>https://abc123.devtunnels.ms</code>) and use it to compose your MCP server endpoint:</p> <p><code>text https://abc123.devtunnels.ms/runtime/webhooks/mcp</code></p> <p>This is useful for development and testing without deploying to Azure. The tunnel remains active as long as the <code>devtunnel host</code> command is running.</p> <p></p>"},{"location":"pages/custom-engine/agent-framework/07-add-mcp-tools/#exercise-2-configure-mcp-client-in-the-agent","title":"Exercise 2: Configure MCP Client in the Agent","text":"<p>Now let's configure the Custom Engine Agent to connect to your MCP server.</p>"},{"location":"pages/custom-engine/agent-framework/07-add-mcp-tools/#step-1-add-mcp-client-configuration","title":"Step 1: Add MCP Client Configuration","text":"<p>1\ufe0f\u20e3 Open your <code>.env.local</code> file in the agent project.</p> <p>2\ufe0f\u20e3 Add the MCP server configuration:</p> <pre><code># MCP Server Configuration\nMCP_SERVER_URL=https://your-mcp-server-url/runtime/webhooks/mcp\n</code></pre> <p></p>"},{"location":"pages/custom-engine/agent-framework/07-add-mcp-tools/#step-2-register-mcp-client-in-dependency-injection","title":"Step 2: Register MCP Client in Dependency Injection","text":"<p>1\ufe0f\u20e3 Install the ModelContextProtocol NuGet package. Open a terminal in your agent project folder and run:</p> <pre><code>dotnet add package ModelContextProtocol --version 0.4.1-preview.1\n</code></pre> <p>2\ufe0f\u20e3 Open <code>src/Program.cs</code>.</p> <p>3\ufe0f\u20e3 Add the required using statements at the top of the file:</p> <pre><code>using ModelContextProtocol.Client;\nusing ModelContextProtocol.Protocol;\n</code></pre> <p>4\ufe0f\u20e3 Find where services are registered and add the MCP client registration:</p> <pre><code>// Register MCP Client for claims adjusters\nbuilder.Services.AddSingleton&lt;McpClient&gt;(sp =&gt;\n{\n    var configuration = sp.GetRequiredService&lt;IConfiguration&gt;();\n    var mcpServerUrl = configuration[\"MCP_SERVER_URL\"] \n        ?? throw new InvalidOperationException(\"MCP_SERVER_URL is not configured\");\n\n    var clientTransport = new HttpClientTransport(new HttpClientTransportOptions {\n        Endpoint = new Uri(mcpServerUrl)});\n\n    return McpClient.CreateAsync(clientTransport).GetAwaiter().GetResult();\n});\n</code></pre> <p></p>"},{"location":"pages/custom-engine/agent-framework/07-add-mcp-tools/#exercise-3-create-the-claimsadjustersplugin","title":"Exercise 3: Create the ClaimsAdjustersPlugin","text":"<p>Now let's create the plugin that consumes MCP tools to manage claims adjusters.</p>"},{"location":"pages/custom-engine/agent-framework/07-add-mcp-tools/#step-1-create-claimsadjustersplugin","title":"Step 1: Create ClaimsAdjustersPlugin","text":"What this plugin does <p>The <code>ClaimsAdjustersPlugin</code> provides two main capabilities:</p> <p>ListClaimsAdjustersAsync:</p> <ul> <li>Retrieves claims adjusters filtered by claim type and country</li> <li>Validates claim types (only \"Auto\" and \"Homeowners\" supported)</li> <li>Calls the MCP server's <code>get_claims_adjusters</code> tool</li> </ul> <p>AssignClaimAdjusterAsync:</p> <ul> <li>Assigns a specific adjuster to a claim</li> <li>Returns assignment confirmation with assignment ID</li> <li>Calls the MCP server's <code>assign_claim_adjuster</code> tool</li> </ul> <p>1\ufe0f\u20e3 Create a new file <code>src/Plugins/ClaimsAdjustersPlugin.cs</code> with the following implementation:</p> <pre><code>using Microsoft.Agents.Builder;\nusing Microsoft.Agents.Core.Models;\nusing System.ComponentModel;\nusing System.Text.Json;\nusing InsuranceAgent;\nusing Microsoft.Agents.Builder.State;\nusing ModelContextProtocol.Client;\n\nnamespace ZavaInsurance.Plugins\n{\n    /// &lt;summary&gt;\n    /// Claims Adjusters Plugin for Zava Insurance\n    /// Provides tools for managing and retrieving claims adjuster information via MCP.\n    /// &lt;/summary&gt;\n    public class ClaimsAdjustersPlugin\n    {\n        private readonly ITurnContext _turnContext;\n        private readonly McpClient _mcpClient;\n        private readonly IConfiguration _configuration;\n\n        public ClaimsAdjustersPlugin(ITurnContext turnContext,\n            McpClient mcpClient, \n            IConfiguration configuration)\n        {\n            _turnContext = turnContext ?? throw new ArgumentNullException(nameof(turnContext));\n            _mcpClient = mcpClient ?? throw new ArgumentNullException(nameof(mcpClient));\n            _configuration = configuration ?? throw new ArgumentNullException(nameof(configuration));\n        }\n\n        /// &lt;summary&gt;\n        /// Retrieves claims adjusters based on claim type and country.\n        /// &lt;/summary&gt;\n        /// &lt;param name=\"claimType\"&gt;The claim type to filter claims adjusters (Auto or Homeowners)&lt;/param&gt;\n        /// &lt;param name=\"country\"&gt;The country to filter claims adjusters&lt;/param&gt;\n        /// &lt;returns&gt;A list of claims adjusters matching the criteria&lt;/returns&gt;\n        [Description(\"Retrieves claims adjusters based on area and country\")]\n        public async Task&lt;string&gt; ListClaimsAdjustersAsync(string claimType, string country)\n        {\n            await NotifyUserAsync($\"Retrieving claims adjusters for area {claimType} and country {country}...\");\n\n            // Validate claim type - only \"Auto\" and \"Homeowners\" are supported\n            if (claimType != \"Auto\" &amp;&amp; claimType != \"Homeowners\")\n            {\n                claimType = null;\n            }\n\n            // Validate country\n            if (country == \"All\")\n            {\n                country = null;\n            }\n\n            var result = await _mcpClient.CallToolAsync(\"get_claims_adjusters\", \n                new Dictionary&lt;string, object?&gt; {                 \n                    [\"area\"] = claimType, \n                    [\"country\"] = country\n                }\n            );\n\n            if (!result.IsError.HasValue || result.IsError.HasValue &amp;&amp; !result.IsError.Value)\n            {\n                var adjusters = result.Content;\n                return JsonSerializer.Serialize(adjusters, new JsonSerializerOptions { WriteIndented = true });\n            }\n            else\n            {\n                return $\"Error retrieving claims adjusters!\";\n            }\n        }\n\n        /// &lt;summary&gt;\n        /// Assigns a claims adjuster to a specific claim.\n        /// &lt;/summary&gt;\n        /// &lt;param name=\"claimId\"&gt;The ID of the claim&lt;/param&gt;\n        /// &lt;param name=\"adjusterId\"&gt;The ID of the claims adjuster&lt;/param&gt;\n        /// &lt;returns&gt;Confirmation message of assignment&lt;/returns&gt;\n        [Description(\"Assigns a claims adjuster to a specific claim\")]\n        public async Task&lt;string&gt; AssignClaimAdjusterAsync(string claimId, string adjusterId)\n        {\n            await NotifyUserAsync($\"Assigning claims adjuster {adjusterId} to claim {claimId}...\");\n\n            var result = await _mcpClient.CallToolAsync(\"assign_claim_adjuster\", \n                new Dictionary&lt;string, object?&gt; {                 \n                    [\"claimId\"] = claimId, \n                    [\"adjusterId\"] = adjusterId\n                }\n            );\n\n            if (!result.IsError.HasValue || result.IsError.HasValue &amp;&amp; !result.IsError.Value)\n            {\n                var adjusters = result.Content;\n                return JsonSerializer.Serialize(adjusters, new JsonSerializerOptions { WriteIndented = true });\n            }\n            else\n            {\n                return $\"Error assigning claims adjuster!\";\n            }\n        }\n\n        private async Task NotifyUserAsync(string message)\n        {\n            if (!_turnContext.Activity.ChannelId.Channel!.Contains(Channels.Webchat))\n            {\n                await _turnContext.StreamingResponse.QueueInformativeUpdateAsync(message);\n            }\n            else\n            {\n                await _turnContext.StreamingResponse.QueueInformativeUpdateAsync(message).ConfigureAwait(false);\n            }\n        }\n    }\n}\n</code></pre> <p></p>"},{"location":"pages/custom-engine/agent-framework/07-add-mcp-tools/#exercise-4-register-claimsadjustersplugin-in-agent","title":"Exercise 4: Register ClaimsAdjustersPlugin in Agent","text":"<p>Now let's wire up the ClaimsAdjustersPlugin in your ZavaInsuranceAgent.</p>"},{"location":"pages/custom-engine/agent-framework/07-add-mcp-tools/#step-1-update-agent-constructor","title":"Step 1: Update Agent Constructor","text":"<p>1\ufe0f\u20e3 Open <code>src/Agent/ZavaInsuranceAgent.cs</code>.</p> <p>2\ufe0f\u20e3 Add the required using statement at the top of the file:</p> <pre><code>using ModelContextProtocol.Client;\n</code></pre> <p>3\ufe0f\u20e3 Find the class fields section and add the MCP client field:</p> <pre><code>private readonly McpClient _mcpClient = null;\n</code></pre> <p>4\ufe0f\u20e3 Update the constructor to accept and store the MCP client:</p> <pre><code>public ZavaInsuranceAgent(AgentApplicationOptions options, IChatClient chatClient, IConfiguration configuration, IServiceProvider serviceProvider, IHttpClientFactory httpClientFactory, McpClient mcpClient) : base(options)\n{\n    _chatClient = chatClient;\n    _configuration = configuration;\n    _serviceProvider = serviceProvider;\n    _httpClient = httpClientFactory.CreateClient() ?? throw new ArgumentNullException(nameof(httpClientFactory));\n    _mcpClient = mcpClient;\n\n    // Greet when members are added to the conversation\n    OnConversationUpdate(ConversationUpdateEvents.MembersAdded, WelcomeMessageAsync);\n\n    // Listen for ANY message to be received\n    OnActivity(ActivityTypes.Message, OnMessageAsync, autoSignInHandlers: [UserAuthorization.DefaultHandlerName]);\n}\n</code></pre> <p></p>"},{"location":"pages/custom-engine/agent-framework/07-add-mcp-tools/#step-2-instantiate-claimsadjustersplugin","title":"Step 2: Instantiate ClaimsAdjustersPlugin","text":"<p>1\ufe0f\u20e3 Find the <code>GetClientAgent</code> method (where other plugins are instantiated).</p> <p>2\ufe0f\u20e3 Add the ClaimsAdjustersPlugin instantiation after other plugins:</p> <pre><code>// Create ClaimsAdjustersPlugin with MCP client\nClaimsAdjustersPlugin claimsAdjustersPlugin = new(context, _mcpClient, _configuration);\n</code></pre> <p></p>"},{"location":"pages/custom-engine/agent-framework/07-add-mcp-tools/#step-3-register-claimsadjusters-tools","title":"Step 3: Register ClaimsAdjusters Tools","text":"<p>In the same <code>GetClientAgent</code> method, find where tools are added to <code>toolOptions.Tools</code> and add the claims adjusters tools:</p> <pre><code>// Register Claims Adjusters MCP tools\ntoolOptions.Tools.Add(AIFunctionFactory.Create(claimsAdjustersPlugin.ListClaimsAdjustersAsync));\ntoolOptions.Tools.Add(AIFunctionFactory.Create(claimsAdjustersPlugin.AssignClaimAdjusterAsync));\n</code></pre> <p></p>"},{"location":"pages/custom-engine/agent-framework/07-add-mcp-tools/#step-4-update-agent-instructions","title":"Step 4: Update Agent Instructions","text":"<p>Update the agent instructions to include claims adjuster capabilities.</p> <p>1\ufe0f\u20e3 Find the <code>AgentInstructions</code> field in <code>ZavaInsuranceAgent.cs</code>.</p> <p>2\ufe0f\u20e3 Add the claims adjuster tools to the instructions:</p> <pre><code>private readonly string AgentInstructions = \"\"\"\n        You are a professional insurance claims assistant for Zava Insurance.\n\n        Whenever the user starts a new conversation or provides a prompt to start a new conversation like \"start over\", \"restart\", \n        \"new conversation\", \"what can you do?\", \"how can you help me?\", etc. use {{StartConversationPlugin.StartConversation}} and \n        provide to the user exactly the message you get back from the plugin.\n\n        **Available Tools:**\n        Use {{DateTimeFunctionTool.getDate}} to get the current date and time.\n        For claims search, use {{ClaimsPlugin.SearchClaims}} and {{ClaimsPlugin.GetClaimDetails}}.\n        For damage photo viewing, use {{VisionPlugin.ShowDamagePhoto}}.\n        For AI vision damage analysis, use {{VisionPlugin.AnalyzeAndShowDamagePhoto}} and require approval via {{VisionPlugin.ApproveAnalysis}}.\n        For policy search, use {{PolicyPlugin.SearchPolicies}} and {{PolicyPlugin.GetPolicyDetails}}.\n        For sending investigation reports and claim details via email, use {{CommunicationPlugin.GenerateInvestigationReport}} and {{CommunicationPlugin.SendClaimDetailsByEmail}}.\n        For claims compliance analysis, use {{ClaimsPoliciesPlugin.AnalyzeClaimCompliance}}.\n\n        To list claim adjusters use {{ClaimsAdjustersPlugin.ListClaimsAdjusters}}. When listing claim adjusters:\n        - Always try to use the country of the current claim, if any. Otherwise, if no country is specified by the user, set country value to 'All'.\n        - Always try to use the claim type of the current claim, if any.\n        - Always retrieve id, firstName, lastName, email, country, phone, and area for each claim adjuster.\n        - Only \"Auto\" and \"Homeowners\" are valid claim types. If the user provides any other claim type, set area value to null.\n\n        To assign a claim adjuster to a claim use {{ClaimsAdjustersPlugin.AssignClaimAdjuster}}.\n\n        **IMPORTANT**: When user asks to \"check policy for this claim\", first use GetClaimDetails to get the claim's policy number, then use GetPolicyDetails with that policy number.\n\n        **IMPORTANT**: If in the response there are references to citations like [1], [2], etc., make sure to include those citations in the response so that M365 Copilot can render them properly.\n\n        Stick to the scenario above and use only the information from the tools when answering questions.\n        Be concise and professional in your responses.\n        \"\"\";\n</code></pre> Why These Instructions Matter <p>The instructions guide the LLM on how to use the claims adjuster tools effectively:</p> <ul> <li>Country inference: Uses the claim's country when available</li> <li>Claim type validation: Only \"Auto\" and \"Homeowners\" are valid areas of expertise</li> <li>Contextual awareness: Leverages existing claim context to provide relevant adjusters</li> </ul> <p></p>"},{"location":"pages/custom-engine/agent-framework/07-add-mcp-tools/#exercise-5-test-mcp-tools-integration","title":"Exercise 5: Test MCP Tools Integration","text":"<p>Now let's test the complete MCP tools integration!</p>"},{"location":"pages/custom-engine/agent-framework/07-add-mcp-tools/#step-1-run-and-verify","title":"Step 1: Run and Verify","text":"<p>1\ufe0f\u20e3 Make sure your MCP server is running (locally or deployed to Azure).</p> <p>2\ufe0f\u20e3 Press F5 in VS Code to start debugging your agent.</p> <p>3\ufe0f\u20e3 Select (Preview) Debug in Copilot (Edge) if prompted.</p> <p>4\ufe0f\u20e3 The terminal should show normal initialization.</p> <p>5\ufe0f\u20e3 A browser window will open with Microsoft 365 Copilot.</p> <p></p>"},{"location":"pages/custom-engine/agent-framework/07-add-mcp-tools/#step-2-test-listing-claims-adjusters","title":"Step 2: Test Listing Claims Adjusters","text":"<p>1\ufe0f\u20e3 In Microsoft 365 Copilot, first get a claim to establish context:</p> <pre><code>Get details for claim CLM-2025-001007\n</code></pre> <p>2\ufe0f\u20e3 Then ask for adjusters:</p> <pre><code>List available claims adjusters for this claim\n</code></pre> <p>The agent should:</p> <ul> <li>Use the claim's type (Auto) and country from the claim details</li> <li>Call the <code>get_claims_adjusters</code> MCP tool</li> <li>Return a list of adjusters matching the criteria</li> </ul> <p></p>"},{"location":"pages/custom-engine/agent-framework/07-add-mcp-tools/#step-3-test-assigning-an-adjuster","title":"Step 3: Test Assigning an Adjuster","text":"<p>1\ufe0f\u20e3 After getting the list of adjusters, assign one:</p> <pre><code>Assign adjuster ADJ-EE-0001 to this claim\n</code></pre> <p>The agent should:</p> <ul> <li>Call the <code>assign_claim_adjuster</code> MCP tool</li> <li>Return confirmation with an assignment ID</li> <li>Confirm the adjuster's name</li> </ul> <p></p>"},{"location":"pages/custom-engine/agent-framework/07-add-mcp-tools/#step-4-test-with-filters","title":"Step 4: Test with Filters","text":"<p>1\ufe0f\u20e3 Test direct filtering:</p> <pre><code>Show me all Auto adjusters in the United States\n</code></pre> <p>The agent should filter adjusters by both area and country.</p> <p>2\ufe0f\u20e3 Test with \"All\" countries:</p> <pre><code>List all Homeowners adjusters\n</code></pre> <p>The agent should return all Homeowners adjusters regardless of country.</p> <p></p> <p>Congratulations!</p> <p>You've successfully integrated MCP tools into your Custom Engine Agent! Your agent can now:</p> <p>\u2705 Connect to external MCP servers \u2705 List claims adjusters with filtering by area and country \u2705 Assign adjusters to claims with confirmation \u2705 Use claim context to provide relevant adjuster suggestions</p> <p>This pattern can be extended to integrate with any MCP-compatible service, enabling your agent to leverage a rich ecosystem of tools and capabilities.</p>"},{"location":"pages/custom-engine/agents-sdk/","title":"Intro - Build your own agent with the M365 Agents SDK and Semantic Kernel","text":"<p>During the Build Path of the Copilot Developer Camp, you will develop a custom engine agent that runs across Microsoft Teams, Microsoft 365 Copilot Chat, and even external channels using the Microsoft 365 Agents SDK and Semantic Kernel.</p> What is a custom engine agent? <p>Custom engine agents are chatbots powered by Generative AI and enhanced through an orchestration layer. When built using the M365 Agents SDK, these agents are structured around capabilities like intent handling, planner integration, and system message configuration. The Semantic Kernel framework powers multi-step reasoning and external tool usage, enabling your agent to act autonomously while delivering consistent and secure experiences across Microsoft 365 and beyond.</p> <p>This journey begins in Microsoft Foundry, where you\u2019ll define your agent\u2019s core instructions, tools, and personality. From there, you\u2019ll use the Microsoft 365 Agents SDK and Visual Studio to bring your agent to life, customizing its behaviors and integrating it with Semantic Kernel for orchestration. You\u2019ll then test your agent in Microsoft Teams, bring it into Copilot Chat, and see it come to life across Microsoft 365 applications.</p> <p>The lab includes multiple exercises. Complete them in order, as each one builds on the previous:</p> <ul> <li>Prepare your agent in Microsoft Foundry</li> <li>Build your first agent using the M365 Agents SDK</li> <li>Configure your agent\u2019s properties using the SDK</li> <li>Integrate your agent with Teams using Microsoft Foundry</li> <li>Bring your agent into Microsoft 365 Copilot Chat</li> </ul>"},{"location":"pages/custom-engine/agents-sdk/#start-here-with-lab-bma0-where-youll-set-up-your-development-environment","title":"Start here with Lab BMA0, where you'll set up your development environment.","text":""},{"location":"pages/custom-engine/agents-sdk/00-prerequisites/","title":"Lab BMA0 - Prerequisites","text":"<p>In this lab you will set up your development environment to build, test, and deploy the custom engine agent you will develop throughout the path.</p> <p>In this lab you will learn how to:</p> <ul> <li>Setup your Microsoft 365 environment</li> <li>Install and configure Visual Studio 2022 with Microsoft 365 Agents Toolkit</li> <li>Prepare your Azure environment to create required resources</li> </ul> <p>Disclaimer</p> <p>These samples and labs are intended for instructive and demonstration purposes and are not intended for use in production. Do not put them into production without upgrading them to production quality.</p> <p>Note</p> <p>To install and run your own custom engine agent, you'll need a Microsoft 365 tenant where you have administrator permission. You won't need Microsoft 365 Copilot License to test your custom engine agent.</p>"},{"location":"pages/custom-engine/agents-sdk/00-prerequisites/#exercise-1-setup-microsoft-teams","title":"Exercise 1 : Setup Microsoft Teams","text":""},{"location":"pages/custom-engine/agents-sdk/00-prerequisites/#step-1-enable-teams-custom-application-uploads","title":"Step 1: Enable Teams custom application uploads","text":"<p>By default, end users can't upload applications directly; instead a Teams administrator needs to upload them into the enterprise app catalog. In this step you will ensure your tenant is set up for direct uploads by M365 Agents Toolkit.</p> <p>1\ufe0f\u20e3 Navigate to https://admin.microsoft.com/, which is the Microsoft 365 Admin Center.</p> <p>2\ufe0f\u20e3 In the left panel of the admin center, select Show all to open up the entire navigation. When the panel opens, select Teams to open the Microsoft Teams admin center.</p> <p>3\ufe0f\u20e3 In the left of the Microsoft Teams admin center, open the Teams apps accordion. Select Setup Policies, you will see a list of App setup policies. Then, select the Global (Org-wide default) policy.</p> <p>4\ufe0f\u20e3 Ensure the first switch, Upload custom apps is turned On.</p> <p>5\ufe0f\u20e3 Be sure to scroll down and select the Save button to persist your change.</p> <p>The change can take up to 24 hours to take effect, but usually it's much faster.</p> <p></p>"},{"location":"pages/custom-engine/agents-sdk/00-prerequisites/#exercise-2-setup-m365-agents-toolkit","title":"Exercise 2: Setup M365 Agents Toolkit","text":"<p>You can complete these labs on a Windows machine and you do need the ability to install the prerequisites. If you are not permitted to install applications on your computer, you'll need to find another machine (or virtual machine) to use throughout the workshop.</p>"},{"location":"pages/custom-engine/agents-sdk/00-prerequisites/#step-1-install-agents-toolkit-for-visual-studio","title":"Step 1: Install Agents Toolkit for Visual Studio","text":"<ol> <li>You can download Visual Studio 2022 here: Visual Studio 2022.</li> <li>Select Install. If you've already installed Visual Studio, select Modify.</li> <li>Visual Studio installer shows all workloads.     </li> <li>From the installation screen, perform the following steps:<ol> <li>Select Workloads &gt; ASP.NET and web development.</li> <li>On the right pane, go to Installation details &gt; Optional and then select Microsoft 365 Agents toolkit.</li> <li>Select Install. Visual Studio is installed and a pop-up appears.</li> </ol> </li> <li>Select Launch.</li> </ol>"},{"location":"pages/custom-engine/agents-sdk/00-prerequisites/#exercise-3-get-an-azure-subscription","title":"Exercise 3: Get an Azure subscription","text":"<p>To complete the exercises in Path B, you'll need an Azure subscription to create resources on Azure. If you don't have an Azure subscription yet, you can activate an Azure free account that offers $200 in credits which can be used within the first 30 days on most Azure services.</p>"},{"location":"pages/custom-engine/agents-sdk/00-prerequisites/#step-1-create-an-azure-free-account","title":"Step 1: Create an Azure free account","text":"<p>Follow the steps to activate an Azure free account:</p> <p>1\ufe0f\u20e3 Navigate to Azure free account page and select Activate.</p> <p>2\ufe0f\u20e3 Login with an account of your choice, it's recommended to use the Microsoft 365 tenant account you would like to use in the exercises.</p> <p>3\ufe0f\u20e3 Check the boxes for Privacy Statement, then select Next.</p> <p>4\ufe0f\u20e3 Provide a mobile phone number for identity verification step.</p> <p>5\ufe0f\u20e3 Provide payment details for a temporary authorization. You won\u2019t be charged unless you move to pay-as-you-go pricing. Then, select Sign up.</p> <p>Tip: Managing Azure resources after 30 days</p> <p>Azure free account will be available only for 30 days. Make sure you don't have any services running in your free subscription at the end of 30 days. If you want to continue using Azure services at the end of 30 days, you must upgrade to a pay-as-you-go subscription by removing the spending limit. This allows continued use of the Azure free account and select free services for the term.</p> <p></p> <p>CONGRATULATIONS!</p> <p>You have completed Lab BMA0 - Setup! You are now ready to proceed to lab BMA1 - Prepare your agent in Microsoft Foundry. Select Next.</p> <p></p> <p></p>"},{"location":"pages/custom-engine/agents-sdk/01-agent-in-foundry/","title":"Lab BMA1 - Prepare your agent in Microsoft Foundry","text":"<p>In this lab, you\u2019ll begin your journey by preparing a custom engine agent using Microsoft Foundry, Microsoft\u2019s platform for creating, configuring, and scaling AI agents. You'll explore the Agents Playground, define your agent's role, personalize its instructions, and connect it to relevant internal documents to support Retrieval-Augmented Generation (RAG).</p> <p>This exercise sets the foundation for the rest of the Build Path using the Microsoft 365 Agents SDK and Semantic Kernel. You\u2019ll simulate a real-world Human Resources agent for Contoso Electronics that can answer questions based on uploaded documents like the Employee Handbook, Role Library, and Benefit Plans.</p> What is Microsoft Foundry? <p>Microsoft Foundry is a development platform that helps you build, manage, and test intelligent agents powered by large language models. It provides a centralized workspace where you can define agent instructions, configure tool usage, upload knowledge sources, and interactively test agent behavior. It supports integration with custom orchestrators like Semantic Kernel and downstream endpoints like Teams and Copilot Chat.</p>"},{"location":"pages/custom-engine/agents-sdk/01-agent-in-foundry/#exercise-1-prepare-your-agent-in-microsoft-foundry","title":"Exercise 1: Prepare your agent in Microsoft Foundry","text":"<p>In this exercise, you'll explore Microsoft Foundry, a platform that enables developers to build, deploy, and scale AI agents with ease. You'll learn how to configure an agent, and test its functionality using the Agents Playground. This hands-on experience will provide insight into the capabilities of Azure AI Agent Service and how it integrates with various AI models and tools.</p>"},{"location":"pages/custom-engine/agents-sdk/01-agent-in-foundry/#step-1-get-started-with-microsoft-foundry","title":"Step 1: Get started with Microsoft Foundry","text":"<p>Microsoft Foundry is your launchpad for building AI agents. In this step, you\u2019ll log in to Microsoft Foundry with the account that has Azure subscription enabled.</p> <ol> <li>Open the browser and navigate to https://ai.azure.com and sign to your Azure account.</li> <li>From the Microsoft Foundry homepage, select + Create new, Microsoft Foundry resource and then Next.</li> <li>Leave the project name as recommended and select Create.</li> <li>This will scaffold a new project for you in Microsoft Foundry, it usually takes 3-5 minutes.</li> <li>When your project is created, you'll be redirected to your project, extend the left side bar and select Agents. This will open the Agents Playground.</li> <li>In the Agent Playground, the first time you'll see the Deploy a model window. Search for gpt-4o and select Confirm, then select Deploy in the following window.</li> <li>Once you are in the Agents Playground, you'll recognize there is a pre-populated agent for you in the list. Select the agent and select Try in playground.     </li> </ol> <p>If you don't see the agent side bar with Try in playground option when you click on the agent, extend the browser size on your screen until it shows up on the right side.</p> <p></p>"},{"location":"pages/custom-engine/agents-sdk/01-agent-in-foundry/#step-2-customize-your-agent-in-agent-playground","title":"Step 2: Customize your agent in Agent Playground","text":"<p>Now that you're inside the Agents Playground, you'll customize your agent's identity and behavior to match a real-world scenario: an internal HR Agent at Contoso.</p> <ol> <li>In your agent's Setup panel, Name your agent as Contoso HR Agent and update the Instructions as the following:</li> </ol> <pre><code>You are Contoso HR Agent, an internal assistant for Contoso Electronics. Your role is to help employees find accurate, policy-aligned answers to questions related to:\n- Job role descriptions and responsibilities\n- Performance review process\n- Health and wellness benefits (PerksPlus, Northwind Standard, Northwind Plus)\n- Employee rights and workplace safety\n- Company values and conduct\n\nAlways base your responses on the content provided in the official documents such as the Employee Handbook, Role Library, and Benefit Plans. If you are unsure or the information is not covered, suggest the employee contact HR.\n\nRespond in a professional but approachable tone. Keep answers factual and to the point.\n\nExample scenarios you should support:\n- What is the deductible for Northwind Standard?\n- Can I use PerksPlus for spa treatments?\n- What does the CTO at Contoso do?\n- What happens during a performance review?\n</code></pre> <ol> <li>Finally in the Knowledge section, Select + Add and select Files, then Select local files. Download this zip file consisting of few files from the following link, extract the files, browse for them and hit Upload and save to upload them. This will create a vector store for our agent.</li> </ol> <p>When you upload documents, Foundry automatically converts them into vectors, a format that allows the agent to search and retrieve relevant information efficiently.</p> <p></p> <p>By customizing the instructions and uploading relevant documents, you're teaching the agent how to behave and what knowledge to rely on. This is a simplified form of Retrieval-Augmented Generation (RAG).</p> <p></p>"},{"location":"pages/custom-engine/agents-sdk/01-agent-in-foundry/#step-3-test-your-agent-in-the-playground","title":"Step 3: Test your agent in the playground","text":"<p>It's time to test your agent. You\u2019ll simulate realistic employee questions to see how well the agent understands and responds based on the documents you uploaded.</p> <p>In the Agent Playground, interact with your agent by entering prompts and observe the agent's responses, adjust instructions or tools as needed to refine performance. You may use the examples listed below to test the agent\u2019s response:</p> <ul> <li>What\u2019s the difference between Northwind Standard and Health Plus when it comes to emergency and mental health coverage?</li> <li>Can I use PerksPlus to pay for both a rock climbing class and a virtual fitness program?</li> <li>If I hit my out-of-pocket max on Northwind Standard, do I still pay for prescriptions?</li> <li>What exactly happens during a Contoso performance review, and how should I prepare?</li> <li>Is a wellness spa weekend eligible under the PerksPlus reimbursement program?</li> <li>What are the key differences between the roles of COO and CFO at Contoso?</li> <li>How does the split copay work under Northwind Health Plus for office visits?</li> <li>Can I combine yoga class reimbursements from PerksPlus with services covered under my health plan?</li> <li>What values guide behavior and decision-making at Contoso Electronics?</li> <li>I\u2019m seeing a non-participating provider \u2014 what costs should I expect under my current plan?</li> </ul> <p>Save Agents id for the next exercises</p> <p>Save the Agent id that'll be required in the next exercises. You can find your Agent id in the agent\u2019s details panel. </p> <p></p> <p>CONGRATULATIONS!</p> <p>You have completed Lab BMA1 - Prepare your agent in Microsoft Foundry! If you want explore further.</p> <p>You are now ready to proceed to Lab BMA2 - Build your first agent using M365 Agents SDK. Select Next.</p> <p></p> <p></p>"},{"location":"pages/custom-engine/agents-sdk/02-agent-with-agents-sdk/","title":"Lab BMA2 - Build your first agent using M365 Agents SDK","text":"<p>This lab introduces you to the Microsoft 365 Agents SDK and Microsoft 365 Agents Toolkit for building enterprise-grade, scalable, multi-channel agents. You'll learn how to create a new agent project with Visual Studio and test it within Test Tool. This experience will demonstrate how to integrate agent capabilities into Microsoft 365 apps and Copilot Chat effectively.</p>"},{"location":"pages/custom-engine/agents-sdk/02-agent-with-agents-sdk/#exercise-1-build-your-first-agent-using-m365-agents-sdk","title":"Exercise 1: Build your first agent using M365 Agents SDK","text":""},{"location":"pages/custom-engine/agents-sdk/02-agent-with-agents-sdk/#step-1-create-an-echo-bot-using-visual-studio","title":"Step 1: Create an echo bot using Visual Studio","text":"<p>Now that you\u2019ve seen how to build an agent using Microsoft Foundry, let\u2019s switch gears and explore how to build your own agent locally using the Microsoft 365 Agents SDK. This SDK lets you build multi-channel, production-ready agents that can run in Microsoft Teams, Microsoft 365 Copilot, and other preferred channels.</p> <ol> <li>Open Visual Studio 2022 and select Create a new project.</li> <li>Search and select Microsoft 365 Agents template.</li> <li>Provide a name for your agent as <code>ContosoHRAgent</code> and select Create.  </li> <li>From the list of templates, select Echo Bot and select Create.</li> <li>When the project template is scaffolded, go to Solution Explorer on the right-side panel and explore the agent template. Expand the ContosoHRAgent project.<ul> <li>Open Program.cs, this code configures and runs the web server that hosts your agent. It sets up required services like authentication, routing, storage and registers the EchoBot and injects memory-based state handling.</li> <li>Open Bot &gt; EchoBot.cs and observe that this sample sets up a basic AI agent using the Microsoft.Agents.Builder. It sends a welcome message when a user joins the chat and listens for any message and echoes it back with a running message count.</li> </ul> </li> </ol> <p>You've started with an Echo Bot, a simple bot that repeats back any message a user sends. It\u2019s a useful way to verify your setup and understand how conversations are handled behind the scenes.</p> <p></p>"},{"location":"pages/custom-engine/agents-sdk/02-agent-with-agents-sdk/#step-2-test-your-agent-in-test-tool","title":"Step 2: Test your agent in Test Tool","text":"<p>To test your echo agent, hit Start or F5. This will launch Test Tool automatically in localhost where you can interact with your agent. In case Visual Studio will ask you to confirm the creation of a self-issued SSL certificate to test the application locally, confirm and proceed.</p> <p>Wait until the agent's message \"Hello and Welcome!\", then type anything such as \u201cHi\u201d, \u201cHello\u201d. Observe that the agent echoes everything back.</p> <p></p> <p>Stop the debugging session on Visual Studio before moving to the next exercise.</p> <p></p> <p>CONGRATULATIONS!</p> <p>You have completed Lab BMA2 - Build your first agent using M365 Agents SDK! This simple agent forms the base for more powerful experiences. In the next step, you'll combine this with your Microsoft Foundry agent to enable richer, context-aware answers.</p> <p>You are now ready to proceed to Lab BMA3 - Integrate Microsoft Foundry Agent with M365 Agents SDK. Select Next.</p> <p></p> <p></p>"},{"location":"pages/custom-engine/agents-sdk/03-agent-configuration/","title":"Lab BMA3 - Integrate Microsoft Foundry Agent with M365 Agents SDK","text":"<p>In this lab, you\u2019ll bring together the best of both worlds\u2014combining the generative AI power of your Microsoft Foundry agent with the multi-channel flexibility of the Microsoft 365 Agents SDK. You\u2019ll configure Semantic Kernel, set up agent properties, and securely connect to your Foundry-hosted agent to deliver rich, enterprise-aware answers directly in Microsoft Teams.</p>"},{"location":"pages/custom-engine/agents-sdk/03-agent-configuration/#exercise-1-configure-agent-properties-and-test-on-teams","title":"Exercise 1: Configure agent properties and test on Teams","text":"<p>Now that you\u2019ve created a basic bot, it\u2019s time to enhance it with generative AI capabilities and upgrade it to an AI agent. In this exercise, you\u2019ll install key libraries such as Semantic Kernel and prepare your agent to reason and respond more intelligently, ready for Teams or Copilot Chat.</p>"},{"location":"pages/custom-engine/agents-sdk/03-agent-configuration/#step-1-add-semantic-kernel-nuget-package","title":"Step 1: Add Semantic Kernel Nuget Package","text":"<p>The package you'll add in this step will provide support for Azure AI integration. Right-click to ContosoHRAgent project and select Manage Nuget Packages..., select Browse tab and search for <code>Microsoft.SemanticKernel.Agents.AzureAI</code>. Make sure to check Include prerelease checkbox. Select the package and select Install.</p> <p></p> <p></p>"},{"location":"pages/custom-engine/agents-sdk/03-agent-configuration/#step-2-add-semantic-kernel-in-programcs","title":"Step 2: Add Semantic Kernel in Program.cs","text":"<p>Open Program.cs and add the following code snippet right before var app = builder.Build():</p> <pre><code>builder.Services.AddKernel();\n</code></pre> <p>This registers the Semantic Kernel, a core component that allows your agent to interact with generative AI models.</p> <p></p>"},{"location":"pages/custom-engine/agents-sdk/03-agent-configuration/#step-3-add-custom-classes-for-document-citations-and-message-tracking","title":"Step 3: Add custom classes for document citations and message tracking","text":"<p>Right-click to ContosoHRAgent project and select Add &gt; Class and define your class name as <code>FileReference.cs</code>. Replace the existing code with the following:</p> <p>This class defines the structure used when referencing specific documents in responses\u2014useful when your agent cites content from uploaded files.</p> <pre><code>using Microsoft.Agents.Core.Models;\n\nnamespace ContosoHRAgent\n{\n    public class FileReference(string fileId, string fileName, string quote, Citation citation)\n    {\n        public string FileId { get; set; } = fileId;\n        public string FileName { get; set; } = fileName;\n        public string Quote { get; set; } = quote;\n        public Citation Citation { get; set; } = citation;\n    }\n}\n</code></pre> <p>Right-click to ContosoHRAgent project and select Add &gt; Class and define your class name as <code>ConversationStateExtensions.cs</code>. Replace existing the code with following:</p> <p>This class adds helper methods to manage and track the number of user messages\u2014demonstrating how state is stored and modified during an ongoing conversation.</p> <pre><code>using Microsoft.Agents.Builder.State;\n\nnamespace ContosoHRAgent\n{\n public static class ConversationStateExtensions\n {\n     public static int MessageCount(this ConversationState state) =&gt; state.GetValue&lt;int&gt;(\"countKey\");\n\n     public static void MessageCount(this ConversationState state, int value) =&gt; state.SetValue(\"countKey\", value);\n\n     public static int IncrementMessageCount(this ConversationState state)\n     {\n         int count = state.GetValue&lt;int&gt;(\"countKey\");\n         state.SetValue(\"countKey\", ++count);\n         return count;\n     }\n\n     public static string ThreadId(this ConversationState state) =&gt; state.GetValue&lt;string&gt;(\"threadId\");\n\n     public static void ThreadId(this ConversationState state, string value) =&gt; state.SetValue(\"threadId\", value);\n }\n}\n</code></pre> <p></p>"},{"location":"pages/custom-engine/agents-sdk/03-agent-configuration/#exercise-2-integrate-microsoft-foundry-agent-with-m365-agents-sdk","title":"Exercise 2: Integrate Microsoft Foundry Agent with M365 Agents SDK","text":"<p>You\u2019ve built an agent using the M365 Agents SDK and configured it with generative AI capabilities. Now, you\u2019ll connect this local agent to the Microsoft Foundry agent you created earlier. This enables your agent to respond using enterprise data and instructions stored in the Foundry project, bringing everything full circle.</p>"},{"location":"pages/custom-engine/agents-sdk/03-agent-configuration/#step-1-configure-echobotcs-to-connect-with-microsoft-foundry-agent","title":"Step 1: Configure EchoBot.cs to Connect with Microsoft Foundry Agent","text":"<p>In this step, you\u2019ll connect to the Microsoft Foundry agent by adding a client to fetch and invoke your Foundry-hosted model inside the EchoBot.cs.</p> <p>In ContosoHRAgent project, open Bot/EchoBot.cs and add the following lines inside the EchoBot public class:</p> <pre><code>private readonly PersistentAgentsClient _projectClient;\nprivate readonly string _agentId;\n</code></pre> <p>Replace the existing EchoBot constructor with the following: </p> <pre><code>public EchoBot(AgentApplicationOptions options, IConfiguration configuration) : base(options)\n{\n\n    OnConversationUpdate(ConversationUpdateEvents.MembersAdded, WelcomeMessageAsync);\n\n    // Listen for ANY message to be received. MUST BE AFTER ANY OTHER MESSAGE HANDLERS \n    OnActivity(ActivityTypes.Message, OnMessageAsync);\n\n    // Microsoft Foundry Project ConnectionString\n    string projectEndpoint = configuration[\"AIServices:ProjectEndpoint\"];\n    if (string.IsNullOrEmpty(projectEndpoint))\n    {\n        throw new InvalidOperationException(\"ProjectEndpoint is not configured.\");\n    }\n    _projectClient = new PersistentAgentsClient(projectEndpoint, new AzureCliCredential());\n\n    // Microsoft Foundry Agent Id\n    _agentId = configuration[\"AIServices:AgentID\"];\n    if (string.IsNullOrEmpty(_agentId))\n    {\n        throw new InvalidOperationException(\"AgentID is not configured.\");\n    }\n\n}\n</code></pre> <p>Replace OnMessageAsync method with the following:</p> <pre><code>protected async Task OnMessageAsync(ITurnContext turnContext, ITurnState turnState, CancellationToken cancellationToken)\n{\n    // send the initial message to the user\n    await turnContext.StreamingResponse.QueueInformativeUpdateAsync(\"Working on it...\", cancellationToken);\n\n    // get the agent definition from the project\n    var agentDefinition = await _projectClient.Administration.GetAgentAsync(_agentId, cancellationToken);\n\n    // initialize a new agent instance from the agent definition\n    var agent = new AzureAIAgent(agentDefinition, _projectClient);\n\n    // retrieve the threadId from the conversation state\n    // this is set if the agent has been invoked before in the same conversation\n    var threadId = turnState.Conversation.ThreadId();\n\n    // if the threadId is not set, we create a new thread\n    // otherwise, we use the existing thread\n    var thread = string.IsNullOrEmpty(threadId)\n        ? new AzureAIAgentThread(_projectClient)\n        : new AzureAIAgentThread(_projectClient, threadId);\n\n    try\n    {\n        // increment the message count in state and queue the count to the user\n        int count = turnState.Conversation.IncrementMessageCount();\n        turnContext.StreamingResponse.QueueTextChunk($\"({count}) \");\n\n        // create the user message to send to the agent\n        var message = new ChatMessageContent(AuthorRole.User, turnContext.Activity.Text);\n\n        // invoke the agent and stream the responses to the user\n        await foreach (AgentResponseItem&lt;StreamingChatMessageContent&gt; agentResponse in agent.InvokeStreamingAsync(message, thread, cancellationToken: cancellationToken))\n        {\n            // if the threadId is not set, we set it from the agent response\n            // and store it in the conversation state for future use\n            if (string.IsNullOrEmpty(threadId))\n            {\n                threadId = agentResponse.Thread.Id;\n                turnState.Conversation.ThreadId(threadId);\n            }\n\n            turnContext.StreamingResponse.QueueTextChunk(agentResponse.Message.Content);\n        }\n    }\n    finally\n    {\n        // ensure we end the streaming response\n        await turnContext.StreamingResponse.EndStreamAsync(cancellationToken);\n    }\n}\n\n</code></pre> <p>\u26a0\ufe0f Note: When pasting the following code excerpt, you might see a warning (SKEXP0110) because this feature is still in preview. You can safely suppress this warning for now by right-clicking on AzureAIAgent, selecting Quick Actions and Refactorings &gt; Suppress or configure issues &gt; Configure SKEXP0110 Severity &gt; Silent.</p> <p></p> What happens in OnMessageAsync? <p>The OnMessageAsync method is the heart of your agent\u2019s response logic. By replacing the default echo behavior, you\u2019ve enabled your agent to send the user\u2019s message to your Microsoft Foundry agent, stream the response back to the user in real time, track and attach citations and file references for transparency and add sensitivity and AI-generated labels for security and traceability.</p> <p></p>"},{"location":"pages/custom-engine/agents-sdk/03-agent-configuration/#step-2-configure-azure-ai-agent-service-keys","title":"Step 2: Configure Azure AI Agent Service Keys","text":"<p>Add your Foundry connection details to appsettings.json, these values connect your M365 agent to the correct Foundry project and agent. In ContosoHRAgent project, open appsettings.json and add the following lines at the bottom of the appsettings list:</p> <pre><code>,\n  \"AIServices\": {\n   \"AgentID\": \"&lt;AzureAIFoundryAgentId&gt;\",\n   \"ProjectEndpoint\": \"&lt;ProjectEndpoint&gt;\"\n  }\n</code></pre> <p>You can find these values in the Overview and Agents Playground sections of Microsoft Foundry.</p> <p>Replace the  with your Agent id which can be found in Agents Playground. <p></p> <p>Replace  with your AI Foundry project endpoing which can be found in the Overview page of the AI Foundry, under Endpoints and keys. <p>Final version of the appsettings.json will look like below:</p> <pre><code>{\n  \"AgentApplicationOptions\": {\n    \"StartTypingTimer\": false,\n    \"RemoveRecipientMention\": false,\n    \"NormalizeMentions\": false\n  },\n\n  \"TokenValidation\": {\n    \"Audiences\": [\n      \"{{ClientId}}\" // this is the Client ID used for the Azure Bot\n    ]\n  },\n\n  \"Logging\": {\n    \"LogLevel\": {\n      \"Default\": \"Information\",\n      \"Microsoft.AspNetCore\": \"Warning\",\n      \"Microsoft.Agents\": \"Warning\",\n      \"Microsoft.Hosting.Lifetime\": \"Information\"\n    }\n  },\n  \"AllowedHosts\": \"*\",\n  \"Connections\": {\n    \"BotServiceConnection\": {\n      \"Settings\": {\n        \"AuthType\": \"UserManagedIdentity\", // this is the AuthType for the connection, valid values can be found in Microsoft.Agents.Authentication.Msal.Model.AuthTypes.\n        \"ClientId\": \"{{BOT_ID}}\", // this is the Client ID used for the connection.\n        \"TenantId\": \"{{BOT_TENANT_ID}}\",\n        \"Scopes\": [\n          \"https://api.botframework.com/.default\"\n        ]\n      }\n    }\n  },\n  \"ConnectionsMap\": [\n    {\n      \"ServiceUrl\": \"*\",\n      \"Connection\": \"BotServiceConnection\"\n    }\n  ],\n  \"AIServices\": {\n   \"AgentID\": \"&lt;AzureAIFoundryAgentId&gt;\",\n   \"ProjectEndpoint\": \"&lt;ProjectEndpoint&gt;\"\n  }\n}\n</code></pre> <p></p>"},{"location":"pages/custom-engine/agents-sdk/03-agent-configuration/#step-3-test-your-agent-on-teams","title":"Step 3: Test your agent on Teams","text":"<p>Open Tools &gt; Command Line &gt; Developer Command Prompt and run:</p> <pre><code>az login\n</code></pre> <p>A window will pop up on your browser and you'll need to sign into your Microsoft account to successfully complete az login.</p> <p>Expand Start and select Dev Tunnels &gt; Create a Tunnel:</p> <ul> <li>Select Sign in and Work or school account. Login with the same credentials mentioned above.</li> <li>Provide a name for your tunnel such as <code>DevTunnel</code>.</li> <li>Keep the Tunnel Type Temporary.</li> <li>Select Access as Public and then Create.</li> </ul> <p></p> <p>Right click to M365Agent project, select Microsoft 365 Agents Toolkit &gt; Select Microsoft 365 Account.</p> <p></p> <p>Select the same account as before and select Continue to use it. If your account doesn't show up automatically, select Sign in and Work or school account.</p> <p>Expand the startup item on top of Visual Studio, where there is by default , and Select Microsoft Teams (browser). <p></p> <p>You're now ready to run your integrated agent and test it live in Microsoft Teams. Make sure your dev tunnel is created and your account is authenticated.</p> <p>Once Dev Tunnel is created, hit Start or F5 to start debugging. Microsoft Teams will launch automatically, and your agent app will pop up on the window. Select Add and Open to start chatting with your agent.  </p> <p>You can ask one of the following questions to interact with the agent:</p> <ul> <li>What\u2019s the difference between Northwind Standard and Health Plus when it comes to emergency and mental health coverage?</li> <li>Can I use PerksPlus to pay for both a rock climbing class and a virtual fitness program?</li> <li>What values guide behavior and decision-making at Contoso Electronics?</li> </ul> <p>You should observe that you are getting similar responses with the agent you've created on Microsoft Foundry.</p> <p></p> <p></p> <p>CONGRATULATIONS!</p> <p>You have completed Lab BMA3 - Integrate Microsoft Foundry Agent with M365 Agents SDK!</p> <p>You are now ready to proceed to Lab BMA4 - Bring your agent to Copilot Chat. Select Next.</p> <p></p> <p></p>"},{"location":"pages/custom-engine/agents-sdk/04-bring-agent-to-copilot/","title":"Lab MBA4 - Bring your agent to Copilot Chat","text":"<p>In this final lab, you\u2019ll bring your custom engine agent into Copilot Chat by updating the agent's manifest. By enabling copilotAgents in the app manifest, you\u2019ll make your AI-powered assistant available directly inside the Copilot experience.</p>"},{"location":"pages/custom-engine/agents-sdk/04-bring-agent-to-copilot/#exercise-1-bring-your-agent-to-copilot-chat","title":"Exercise 1: Bring your agent to Copilot Chat","text":""},{"location":"pages/custom-engine/agents-sdk/04-bring-agent-to-copilot/#step-1-update-the-manifest","title":"Step 1: Update the manifest","text":"<p>Stop debugging</p> <p>Close the previous debugging session before proceeding with this exercise.</p> <p>Go to M365Agent/AppPackage/manifest.json, update the manifest schema and version as following: </p> <pre><code>\"$schema\": \"https://developer.microsoft.com/en-us/json-schemas/teams/v1.22/MicrosoftTeams.schema.json\",\n\"manifestVersion\": \"1.22\",\n</code></pre> <p>Replace bots section with the following that will also add copilotAgents in the manifest:</p> <p>This block declares your agent as a custom engine agent for M365 Copilot. It tells Microsoft 365 to expose this agent in Copilot Chat and surface its command list in the conversation UI along with the conversation starters to help users get started quickly.</p> <pre><code>\"bots\": [ \n  { \n    \"botId\": \"${{BOT_ID}}\", \n    \"scopes\": [ \n      \"personal\", \n      \"team\", \n      \"groupChat\" \n    ], \n    \"supportsFiles\": false, \n    \"isNotificationOnly\": false, \n    \"commandLists\": [ \n      { \n        \"scopes\": [ \"personal\", \"team\", \"groupChat\" ], \n        \"commands\": [ \n          { \n            \"title\": \"Emergency and Mental Health\",\n            \"description\": \"What\u2019s the difference between Northwind Standard and Health Plus when it comes to emergency and mental health coverage?\" \n          }, \n          { \n            \"title\": \"PerksPlus Details\", \n            \"description\": \"Can I use PerksPlus to pay for both a rock climbing class and a virtual fitness program?\" \n          }, \n          { \n            \"title\": \"Contoso Electronics Values\", \n            \"description\": \"What values guide behavior and decision making at Contoso Electronics?\" \n          } \n        ] \n      } \n    ] \n  } \n], \n\"copilotAgents\": { \n  \"customEngineAgents\": [ \n    { \n      \"id\": \"${{BOT_ID}}\", \n      \"type\": \"bot\" \n    } \n  ] \n}, \n</code></pre> <p>Hit Start or F5 to start debugging. Microsoft Teams will launch automatically. When Microsoft Teams open in your browser, ignore the app pop-up and select Apps &gt; Manage your apps &gt; Upload an app and then select Upload a custom app. In the File Explorer go to your project folder <code>...\\ContosoHRAgent\\M365Agent\\appPackage\\build</code> select appPackage.local.zip.</p> <p></p> <p>Your app will pop-up on Teams again, select Add. This time there will be an option to Open with Copilot, select Open with Copilot to test your agent on Copilot.</p> <p></p> <p>Select your ContosoHRAgentlocal from the list of agents in Copilot Chat. You can select one of the conversation starters to chat with your agent.</p> <p></p> <p>Observe that your agent responds back with a similar behavior on Copilot Chat.</p> <p></p> <p>CONGRATULATIONS!</p> <p>\ud83c\udf89 Congratulations! You've just built your first Custom Engine Agent using the Microsoft 365 Agents SDK and Microsoft Foundry!</p> <p>In this lab, you learned how to:</p> <ul> <li>Configure an AI agent in Microsoft Foundry using the Agent Playground</li> <li>Upload enterprise documents to ground your agent\u2019s responses</li> <li>Scaffold a bot using the M365 Agents SDK in Visual Studio</li> <li>Add Semantic Kernel and connect to Azure AI Agent Service</li> <li>Integrate your bot with the Microsoft Foundry agent for real-time, grounded reasoning</li> <li>Deploy and test your agent in Microsoft Teams and Copilot Chat</li> </ul>"},{"location":"pages/custom-engine/agents-sdk/04-bring-agent-to-copilot/#resources","title":"Resources","text":"<ul> <li>Copilot Developer Camp</li> <li>M365 Agents SDK docs</li> <li>Microsoft Foundry</li> <li>Learn more about Copilot extensibility</li> </ul>"},{"location":"pages/custom-engine/teams-ai/","title":"Intro - Build your own agent with Teams AI library","text":"<p>During Build Path of the Copilot Developer Camp, you will develop a custom engine agent that runs across Microsoft Teams using the Teams AI Library. The agent will be specifically designed to help Human Resources departments manage resumes, create new job posts, and more.</p> What is a custom engine agent? <p>Custom engine agents are chatbots powered by Generative AI, designed to provide sophisticated conversational experiences. Custom engine agents are built using the Teams AI library, which provides comprehensive AI functionalities, including managing prompts, actions, and model integration as well as extensive options for UI customization. This ensures that your chatbots leverage the full range of AI capabilities while delivering a seamless and engaging experience aligned with Microsoft platforms.</p> <p>The journey starts with building a basic custom engine agent using M365 Agents Toolkit, Teams AI library and Azure OpenAI. Then, you will implement Retrieval Augmented Generation (RAG) that provides ability to search across diverse resumes, apply UI enhancements to make the chatbot look and feel like a Copilot experience, finally you will enable authentication to secure your custom engine agent and use Microsoft Graph to incorporate Microsoft 365 data. This sophisticated custom engine agent will utilize custom AI models and an orchestrator to meet the unique needs of the Human Resources department.</p> <p>Do these labs if you want to build a Custom engine agent with custom AI model and orchestration using Azure OpenAI and Teams AI library</p> <ul> <li>BTA0 - Setup</li> <li>BTA1 - First custom engine agent</li> <li>BTA2 - Index your data in Azure AI Search</li> <li>BTA3 - Enhance the user experience</li> <li>BTA4 - Add single sign on authentication</li> <li>BTA5 - Add actions to handle complex tasks</li> </ul>"},{"location":"pages/custom-engine/teams-ai/#start-here-with-lab-bta0-where-youll-set-up-development-your-environment","title":"Start here with Lab BTA0, where you'll set up development your environment.","text":""},{"location":"pages/custom-engine/teams-ai/00-prerequisites/","title":"Lab BTA0 - Prerequisites","text":"<p>In this lab you will set up your development environment to build, test, and deploy the custom engine agent you will develop throughout the path.</p> <p>In this lab you will learn how to:</p> <ul> <li>Install and configure M365 Agents Toolkit for Visual Studio Code</li> <li>Prepare your Azure environment to create required resources</li> </ul> Get a quick overview of the lab in this video. <p>Do these labs if you want to build a Custom engine agent with custom AI model and orchestration using Azure OpenAI and Teams AI library</p> <ul> <li>BTA0 - Setup</li> <li>BTA1 - First custom engine agent</li> <li>BTA2 - Index your data in Azure AI Search</li> <li>BTA3 - Enhance the user experience</li> <li>BTA4 - Add single sign on authentication</li> <li>BTA5 - Add actions to handle complex tasks</li> </ul> <p>Disclaimer</p> <p>These samples and labs are intended for instructive and demonstration purposes and are not intended for use in production. Do not put them into production without upgrading them to production quality.</p> <p>Note</p> <p>To install and run your own custom engine agent, you'll need a Microsoft 365 tenant where you have administrator permission. You won't need Microsoft 365 Copilot License to test your custom engine agent.</p>"},{"location":"pages/custom-engine/teams-ai/00-prerequisites/#exercise-1-setup-microsoft-teams","title":"Exercise 1 : Setup Microsoft Teams","text":""},{"location":"pages/custom-engine/teams-ai/00-prerequisites/#step-1-enable-teams-custom-application-uploads","title":"Step 1: Enable Teams custom application uploads","text":"<p>By default, end users can't upload applications directly; instead a Teams administrator needs to upload them into the enterprise app catalog. In this step you will ensure your tenant is set up for direct uploads by M365 Agents Toolkit.</p> <p>1\ufe0f\u20e3 Navigate to https://admin.microsoft.com/, which is the Microsoft 365 Admin Center.</p> <p>2\ufe0f\u20e3 In the left panel of the admin center, select Show all to open up the entire navigation. When the panel opens, select Teams to open the Microsoft Teams admin center.</p> <p>3\ufe0f\u20e3 In the left of the Microsoft Teams admin center, open the Teams apps accordion. Select Setup Policies, you will see a list of App setup policies. Then, select the Global (Org-wide default) policy.</p> <p>4\ufe0f\u20e3 Ensure the first switch, Upload custom apps is turned On.</p> <p>5\ufe0f\u20e3 Be sure to scroll down and select the Save button to persist your change.</p> <p>The change can take up to 24 hours to take effect, but usually it's much faster.</p> <p></p>"},{"location":"pages/custom-engine/teams-ai/00-prerequisites/#exercise-2-install-m365-agents-toolkit-and-prerequisites","title":"Exercise 2: Install M365 Agents Toolkit and prerequisites","text":"<p>You can complete these labs on a Windows, Mac, or Linux machine, but you do need the ability to install the prerequisites. If you are not permitted to install applications on your computer, you'll need to find another machine (or virtual machine) to use throughout the workshop.</p>"},{"location":"pages/custom-engine/teams-ai/00-prerequisites/#step-1-install-visual-studio-code","title":"Step 1: Install Visual Studio Code","text":"<p>It should be no surprise that M365 Agents Toolkit for Visual Studio Code requires Visual Studio Code! You can download it here: Visual Studio Code.</p> <p></p>"},{"location":"pages/custom-engine/teams-ai/00-prerequisites/#step-2-install-nodejs","title":"Step 2: Install NodeJS","text":"<p>NodeJS is a program that allows you to run JavaScript on your computer; it uses the open source \"V8\" engine, which is used in popular web browsers such as Microsoft Edge and Google Chrome. You will need NodeJS to run the web server code used throughout this workshop.</p> <p>Browse to https://nodejs.org/en/download/ and install version 18 or 16 for your operating system. This lab has been tested using NodeJS version 18.16.0. If you already have another version of NodeJS installed, you may want to set up the Node Version Manager (or this variation for Microsoft Windows), which allows you to easily switch Node versions on the same computer.</p> <p></p>"},{"location":"pages/custom-engine/teams-ai/00-prerequisites/#step-3-install-m365-agents-toolkit","title":"Step 3: Install M365 Agents Toolkit","text":"<p>These labs are based on M365 Agents Toolkit version 5.0. Follow the steps as shown in the screen shot below.</p> <p>1\ufe0f\u20e3 Open Visual Studio Code and click on the Extensions toolbar button</p> <p>2\ufe0f\u20e3 Search for \"Teams\" and locate M365 Agents Toolkit</p> <p>3\ufe0f\u20e3 Click Install</p> <p>If you have M365 Agents Toolkit installed but hidden</p> <p>If you previously installed M365 Agents Toolkit, and then hid it on the Visual Studio sidebar, you might wonder why you can't see it. Right-click on the left sidebar and check off M365 Agents Toolkit to bring it back into view.</p> <p></p>"},{"location":"pages/custom-engine/teams-ai/00-prerequisites/#exercise-3-get-an-azure-subscription","title":"Exercise 3: Get an Azure subscription","text":"<p>To complete the exercises in Path B, you'll need an Azure subscription to create resources on Azure. If you don't have an Azure subscription yet, you can activate an Azure free account that offers $200 in credits which can be used within the first 30 days on most Azure services.</p>"},{"location":"pages/custom-engine/teams-ai/00-prerequisites/#step-1-create-an-azure-free-account","title":"Step 1: Create an Azure free account","text":"<p>Follow the steps to activate an Azure free account:</p> <p>1\ufe0f\u20e3 Navigate to Azure free account page and select Activate.</p> <p>2\ufe0f\u20e3 Login with an account of your choice, it's recommended to use the Microsoft 365 tenant account you would like to use in the exercises.</p> <p>3\ufe0f\u20e3 Check the boxes for Privacy Statement, then select Next.</p> <p>4\ufe0f\u20e3 Provide a mobile phone number for identity verification step.</p> <p>5\ufe0f\u20e3 Provide payment details for a temporary authorization. You won\u2019t be charged unless you move to pay-as-you-go pricing. Then, select Sign up.</p> <p>Tip: Managing Azure resources after 30 days</p> <p>Azure free account will be available only for 30 days. Make sure you don't have any services running in your free subscription at the end of 30 days. If you want to continue using Azure services at the end of 30 days, you must upgrade to a pay-as-you-go subscription by removing the spending limit. This allows continued use of the Azure free account and select free services for the term.</p> <p></p> <p>CONGRATULATIONS!</p> <p>You have completed Lab BTA0 - Setup! You are now ready to proceed to lab BTA1 - First custom engine agent. Select Next.</p> <p></p> <p></p>"},{"location":"pages/custom-engine/teams-ai/01-custom-engine-agent/","title":"Lab BTA1 - First custom engine agent with Teams AI library","text":"<p>In this lab you will build a custom engine agent using M365 Agents Toolkit for Visual Studio Code. You will also utilize Azure OpenAI models in your custom engine agent and define your first prompt.</p> <p>In this lab you will:</p> <ul> <li>Learn what is a custom engine agent</li> <li>Create Azure OpenAI service and a deployment model</li> <li>Create a custom engine agent using M365 Agents Toolkit</li> <li>Define a prompt in your custom engine agent</li> <li>Learn how to run and test your app</li> </ul> Get a quick overview of the lab in this video. <p>Do these labs if you want to build a Custom engine agent with custom AI model and orchestration using Azure OpenAI and Teams AI library</p> <ul> <li>BTA0 - Setup</li> <li>BTA1 - First custom engine agent</li> <li>BTA2 - Index your data in Azure AI Search</li> <li>BTA3 - Enhance the user experience</li> <li>BTA4 - Add single sign on authentication</li> <li>BTA5 - Add actions to handle complex tasks</li> </ul>"},{"location":"pages/custom-engine/teams-ai/01-custom-engine-agent/#introduction","title":"Introduction","text":"<p>Welcome aboard to the exciting journey of building your own custom engine agent! In this path, you'll create a custom engine agent for Microsoft Teams using cutting-edge Azure OpenAI models. You'll be able to define specific prompts, integrate complex data, and add advanced skills to make your agent truly unique. By using custom models and orchestration, your agent will tackle advanced tasks, complex conversations, and workflows, delivering an exceptional, personalized experience. Let's dive in and start building your first custom engine agent!</p> Before everything else, lets remember... What is a custom engine agent? <p>Custom engine agents are chatbots powered by Generative AI, designed to provide sophisticated conversational experiences. Custom engine agents are built using the Teams AI library, which provides comprehensive AI functionalities, including managing prompts, actions, and model integration as well as extensive options for UI customization. This ensures that your chatbots leverage the full range of AI capabilities while delivering a seamless and engaging experience aligned with Microsoft platforms.</p>"},{"location":"pages/custom-engine/teams-ai/01-custom-engine-agent/#exercise-1-create-azure-openai-service-and-models","title":"Exercise 1: Create Azure OpenAI service and models","text":"<p>This exercise particularly demonstrates how to create and utilize Azure OpenAI's GPT models in custom engine agents. However, Custom engine agents are not limited to using GPT models only. You can also test the lab with any other model you prefer use.</p> Choosing Between Small and Large Language Models <p>When choosing between Small Language Models (SLMs) and Large Language Models (LLMs), as well as among various GPT models, it's important to consider the specific needs of your project in terms of complexity, computational resources, and efficiency.</p> <ul> <li> <p>LLMs: Best for complex and nuanced tasks requiring deep capabilities. They have billions of parameters and excel in understanding and generating human language. GPT-4, LLaMA 2, BERT or PaLM can be examples for LLMs.  Example scenarios: Handling intricate customer inquiries, offering detailed and context-aware responses, generating high-quality articles from brief prompts, summarizing large volumes of academic papers, extracting key insights, and answering detailed questions.</p> </li> <li> <p>SLMs: Better for quick tasks with limited resources where speed and efficiency are key. They have fewer parameters and are optimized for specific tasks with lower computational needs. Phi-3 by Microsoft, ALBERT by Google or DistilBERT by HuggingFace can be examples for SLMs.  Example scenarios: Providing efficient text analysis without needing cloud resources, enabling accurate and responsive voice commands with minimal latency, smart home automation and control with natural speech.</p> </li> </ul> <p>OpenAI's GPT models are popular examples for LLMs. When choosing between OpenAI's models you may consider the following benefits:</p> <ul> <li> <p>gpt-4: The most advanced model, suitable for highly complex tasks that require extensive understanding and generation capabilities.</p> </li> <li> <p>gpt-4o: An optimized version for specific tasks, offering faster and more efficient performance in those areas.</p> </li> <li> <p>gpt-35-turbo: A balanced model that provides good performance at a lower cost, ideal for a wide range of applications.</p> </li> </ul> <p>You'll need to complete the Azure subscription prerequisite before starting with this exercise.</p>"},{"location":"pages/custom-engine/teams-ai/01-custom-engine-agent/#step-1-create-azure-openai-service-resource","title":"Step 1: Create Azure OpenAI service resource","text":"Make sure the model you want to create in further steps is available in your Azure OpenAI service region <p>Please check Model summary table and region availability before creating your Azure OpenAI service in any particular region. Make sure that the model you want to use such as <code>gpt-4</code> is available in Standard or Global Standard types in the region you prefer to create your Azure OpenAI Service.</p> <ol> <li>Open the browser of your choice and navigate to Azure Portal.</li> <li>Select Create a resource, then search for <code>Azure OpenAI</code>. Select the Azure OpenAI service and then Create.</li> <li>Fill out the following details and select Next:<ul> <li>Subscription: The Azure subscription for your Azure OpenAI Service</li> <li>Resource group: The Azure resource group to contain your Azure OpenAI resource. You can create a new group or use a pre-existing group.</li> <li>Region: The location of your instance. (Make sure that the deployment model is available in your region).</li> <li>Name: A descriptive name for your Azure OpenAI Service resource, such as <code>MyOpenAIResource</code>.</li> <li>Pricing Tier: The pricing tier for the resource. Currently, only the <code>Standard</code> tier is available for the Azure OpenAI Service.</li> </ul> </li> <li>Select the network configuration of your choice and select Next.</li> <li>Leave the Tags section as default and select Next.</li> <li>Finally, review your Azure OpenAI service details and select Create.</li> </ol> <p>Once your Azure OpenAI service is created successfully, navigate to your resource, select Keys and Endpoint from the left side panel. Copy and save <code>KEY 1</code> and <code>Endpoint</code>that will be required later in Exercise 2.</p> <p></p>"},{"location":"pages/custom-engine/teams-ai/01-custom-engine-agent/#step-2-create-a-deployment-model","title":"Step 2: Create a deployment model","text":"<p>In your Azure OpenAI service, navigate to <code>Microsoft Foundry</code> where you can create your deployment model.</p> What is Microsoft Foundry? <p>Microsoft Foundry is a playground to explore OpenAI models like <code>gpt-35-turbo</code>, <code>gpt-4</code> or <code>Dall-e</code> that helps you craft unique prompts for your use cases, and fine-tune your models. It's also a playground to models other than OpenAI such as <code>Phi-3</code>, <code>Llama 3.1</code> and a starting point to other Azure AI services such as Speech, Vision and more.</p> <p>Learn more about the Generative AI, prompting by watching this Doodle to Code video!</p> <p></p> <p>In Microsoft Foundry, select Deployments tab, Deploy model and then Deploy base model. Search the model you prefer to use such as <code>gpt-4</code> and Confirm. Fill out the following details and select Deploy:</p> <ul> <li>Deployment name: Recommended to use the same name with the selected deployment model, such as <code>gpt-4</code>.</li> <li>Select a model: Select a model, <code>gpt-4</code> is recommended.</li> <li>Deployment type: Global Standard.</li> </ul> <p>Tip: Handling no quota available message</p> <p>When you select a model, you may see No quota available message pop-up on top of the configuration page. To handle this, you have two options: 1. Select a different version or deployment type 2. Free up the resources on other deployments by requesting for more quota or adjust the existing quota</p> <p>Once your model is successfully created, select Open in playground, and test your model by selecting Prompt samples from the top and choose one of the prompts available.</p> <p>For example, choose \"Shakespearean Writing Assistant\" and select Use prompt. and ask questions such as \"tell me about Istanbul\". You'll be amazed by the descriptive and poetic style of the response \u270d\ufe0f.</p> <p></p> <p></p>"},{"location":"pages/custom-engine/teams-ai/01-custom-engine-agent/#exercise-2-scaffold-a-custom-engine-agent-from-a-template","title":"Exercise 2: Scaffold a custom engine agent from a template","text":"<p>You'll need to complete all the required prerequisites before starting with this exercise.</p>"},{"location":"pages/custom-engine/teams-ai/01-custom-engine-agent/#step-1-use-m365-agents-toolkit-to-create-a-new-custom-engine-agent","title":"Step 1: Use M365 Agents Toolkit to create a new custom engine agent","text":"<ol> <li>Open M365 Agents Toolkit on Visual Studio Code and select Create a New App &gt; Custom Engine Agent &gt; Basic AI Chatbot.</li> <li>Select TypeScript as a programming language choice and Azure OpenAI as Large Language model of your choice.<ol> <li>Paste the Azure OpenAI key and press enter.</li> <li>Paste the Azure OpenAI endpoint and press enter. (Endpoint shouldn't include forward slash at the end of its URL.)</li> <li>Type Azure OpenAI deployment model name and press enter.</li> </ol> </li> <li>Select a folder for your project root.</li> <li>Provide a name for your project such as <code>CareerGenie</code> and press enter.</li> </ol> <p>After providing all the details mentioned above, your project will be scaffolded successfully in seconds.</p> <p></p>"},{"location":"pages/custom-engine/teams-ai/01-custom-engine-agent/#step-2-customize-prompt-and-test-the-app","title":"Step 2: Customize prompt and test the app","text":"<p>Prompts are essential for interacting with AI language models and directing their behavior. They serve as the inputs or questions we provide to the model to obtain specific responses. By crafting prompts carefully, we can guide the AI to generate desired outputs. Let's customize the prompt of our custom engine agent and define the behavior of Career Genie!</p> <p>In your project folder, navigate to <code>src/prompts/chat/skprompt.txt</code> and replace the existing text with the following prompt:</p> <pre><code>You are a career specialist named \"Career Genie\" that helps Human Resources team for writing job posts.\nYou are friendly and professional.\nYou always greet users with excitement and introduce yourself first.\nYou like using emojis where appropriate.\n</code></pre> <p>To test the behavior of your app quickly, you can use Teams App Test Tool. Later in the exercise, you'll run and debug your custom engine agent on Microsoft Teams.</p> More information about the Teams App Test Tool <p>The Teams App Test Tool, or simply Test Tool, is a feature within M365 Agents Toolkit that enables developers to debug, test, and refine their Teams bot applications in a web-based chat environment that mimics the behavior, look, and feel of Microsoft Teams. This tool eliminates the need for a Microsoft 365 tenant or a dev tunnel, streamlining the development process.</p> <p>Start debugging your app by selecting Run and Debug tab on Visual Studio Code and Debug in Test Tool. Teams App Test Tool will pop up on your browser and you can start chatting with your custom engine agent right away! Some of the recommended questions you can ask to test the behavior:</p> <ul> <li>\"Can you help me write a job post for a Senior Developer role?\"</li> <li>\"What would be the list of required skills for a Project Manager role?\"</li> <li>\"Can you share a job template?\"</li> </ul> <p></p> What does M365 Agents Toolkit do behind the scene? <p>When you start debugging your app, M365 Agents Toolkit completes some required tasks for you behind the scene, such as:</p> <ul> <li>Checking the required prerequisites such as Node.js, Microsoft 365 Account (If debugging in local or dev), ports occupancy.</li> <li>Starting local tunneling service (If debugging in local) to forward public URL to local port.</li> <li>Executing the lifecycle stage provision, available in <code>teamsapp.yml</code>, <code>teamsapp.local.user</code> or <code>teamsapp.testtool.user</code> files for creating Teams App ID, completing bot registration, executing the app manifest and creating the app package, available in <code>appPackage/</code> folder.</li> <li>Create or update variables to env file, available in <code>env/</code> folder.</li> </ul> <p>After successfully completing your testing, end your debugging session and close the terminals in Visual Studio Code.</p> <p></p> <p>CONGRATULATIONS!</p> <p>You have completed Lab BTA1 - First custom engine agent to build a custom engine agent using Azure OpenAI and M365 Agents Toolkit! If you want explore further, the source code of this lab is available in the Copilot Developer Camp repo.</p> <p>You are now ready to proceed to Lab BTA2 - Index your data in Azure AI Search to bring your data into your custom engine agent. Select Next.</p> <p></p> <p></p>"},{"location":"pages/custom-engine/teams-ai/02-rag/","title":"Lab BTA2 - Index your data in Azure AI Search","text":"<p>In this lab you will enable Retrieval-Augmented Generation for your custom engine agent and integrate with Azure AI Search to chat with your data.</p> <p>In this lab you will:</p> <ul> <li>Learn what is Retrieval-Augmented Generation (RAG)</li> <li>Setup Azure resources</li> <li>Upload your documents to Azure AI Search</li> <li>Prepare your custom engine agent for Vector Search</li> <li>Learn how to run and test your app</li> </ul> Get a quick overview of the lab in this video. <p>Do these labs if you want to build a Custom engine agent with custom AI model and orchestration using Azure OpenAI and Teams AI library</p> <ul> <li>BTA0 - Setup</li> <li>BTA1 - First custom engine agent</li> <li>BTA2 - Index your data in Azure AI Search</li> <li>BTA3 - Enhance the user experience</li> <li>BTA4 - Add single sign on authentication</li> <li>BTA5 - Add actions to handle complex tasks</li> </ul>"},{"location":"pages/custom-engine/teams-ai/02-rag/#introduction","title":"Introduction","text":"<p>In the previous exercise, you learned how to create a custom engine agent and customize the prompt for defining the behavior of the AI chatbot, Career Genie. In this exercise, you'll apply vector search to a collection of resumes to find the best candidate for the job requirements. To enable vector search in Career Genie, you'll use the \"Microsoft Foundry on your data\" feature to:</p> <ul> <li>Create an index on Azure AI Search.</li> <li>Generate vector embeddings for the resumes (PDF documents).</li> <li>Upload the data in chunks to Azure AI Search.</li> </ul> <p>Finally, you'll integrate your custom engine agent with Azure AI Search to chat with your data and obtain the best results.</p> What is Retrieval-Augmented Generation (RAG)? <p>Retrieval-Augmented Generation (RAG) is a technique used in artificial intelligence to improve the quality of responses generated by language models. Here's a simple example to understand it better:</p> <p>Imagine you have a smart assistant that can write answers to your questions. Sometimes, this assistant might not know everything it needs to give a great answer. To help with this, RAG lets the assistant look up information from a large collection of documents, videos, images similar to how you might search the internet for answers. After finding the relevant information, the assistant then uses this data to write a better, more accurate response.</p> <p>So, RAG combines two steps:</p> <ul> <li>Retrieval: Finding relevant information from a big pool of data.</li> <li>Generation: Using that information to create a detailed and accurate response.</li> </ul> <p>This way, RAG helps in providing more informed and useful answers, making it very effective for tasks like answering questions, writing articles, and assisting with research.</p> <p>Learn more about the RAG by watching this Doodle to Code video!</p> <p></p> Benefits of using Vector Search <p>Vector search is an advanced technique used to find information quickly and accurately based on its meaning rather than just matching exact words. Unlike traditional text-based search, which relies on exact keyword matches, vector search uses numeric vectors to find content that is similar to your query. This enables Vector search to handle:</p> <ul> <li>Semantic or conceptual similarity: Matching concepts that are similar in meaning even if they use different words (e.g., \"pastry\" and \"croissant\").</li> <li>Multilingual content: Finding equivalent content across different languages (e.g., \"pastry\" in English and \"geb\u00e4ck\" in German).</li> <li>Multiple content types: Searching across different formats (e.g., \"pastry\" in text and an image of a pastry).</li> </ul> <p>Here is how vector search works:</p> <ol> <li>Converting text to vectors: Imagine turning words or sentences into a series of numbers (a vector) that captures the essence or meaning of that text. This is done using techniques like word embeddings or deep learning models.</li> <li>Storing vectors: These vectors are stored in a special database designed to handle them efficiently.</li> <li>Searching with vectors: When you search for something, your query is also converted into a vector. The search system then looks for vectors in the database that are close to your query vector in terms of meaning, not just exact word matches.</li> </ol> <p>For example, if you search for \"how to bake a cake\" the system can find documents about \"cake recipes\" or \"baking tips\" even if they don't have the exact words \"how to bake a cake\" or even if the recipes are written in another language. This makes vector search powerful for finding relevant information based on context and meaning, especially in large datasets.</p> <p>In summary, vector search improves the search process by focusing on the meaning behind the words, enabling more accurate and relevant results.</p>"},{"location":"pages/custom-engine/teams-ai/02-rag/#exercise-1-setup-azure-resources","title":"Exercise 1: Setup Azure Resources","text":"<p>You'll need to complete the Azure subscription prerequisite before starting with this exercise.</p>"},{"location":"pages/custom-engine/teams-ai/02-rag/#step-1-create-azure-ai-search-service-resource","title":"Step 1: Create Azure AI Search service resource","text":"What is Azure AI Search? <p>Azure AI Search (formerly known as \"Azure Cognitive Search\") provides secure information retrieval at scale over user-owned content in traditional and generative AI search applications.When you create a search service, you work with the following capabilities:</p> <ul> <li>A search engine for vector search, full text and hybrid search over a search index</li> <li>Rich indexing with integrated data chunking and vectorization</li> <li>Rich query syntax for vector queries, text search, hybrid queries</li> <li>Integration with Azure AI services and Azure OpenAI</li> </ul> <ol> <li>Open the browser of your choice and navigate to Azure Portal.</li> <li>Select Create a resource, then search for <code>Azure AI Search</code>. Select the Azure AI Search service and then Create.</li> <li>Fill out the following details and select Review + Create:<ul> <li>Subscription: The Azure subscription for your Azure AI Search service</li> <li>Resource group: Select the pre-existing resource group you created earlier for Azure OpenAI service.</li> <li>Name: A descriptive name for your Azure AI Search service resource, such as <code>copilotcamp-ai-search</code>.</li> <li>Location: The location of your instance.</li> <li>Pricing Tier: Basic</li> </ul> </li> </ol> <p>Once your Azure AI Search service resource is created successfully, navigate to your resource, In Overview, copy and save <code>Url</code>. Then, navigate to Keys tab under the Settings, copy and save <code>Primary admin key</code>. Both of them will be required later in the following exercises.</p> <p></p>"},{"location":"pages/custom-engine/teams-ai/02-rag/#step-2-create-a-storage-account-service-resource","title":"Step 2: Create a storage account service resource","text":"<ol> <li>Open the browser of your choice and navigate to Azure Portal.</li> <li>Select Create a resource, then search for <code>Storage Account</code>. Select the Storage Account service and then Create.</li> <li>Fill out the following details and select Review, then Create:<ul> <li>Subscription: The Azure subscription for your Azure Storage Account service</li> <li>Resource group: Select the pre-existing resource group you created earlier for Azure OpenAI service.</li> <li>Name: A descriptive name for your Azure Storage Account service resource, such as <code>copilotcampstorage</code>.</li> <li>Region: The location of your instance.</li> <li>Performance: Standard</li> <li>Redundancy: Geo-redundant storage (GRS)</li> </ul> </li> </ol>"},{"location":"pages/custom-engine/teams-ai/02-rag/#step-3-create-a-text-embedding-ada-002-model","title":"Step 3: Create a <code>text-embedding-ada-002</code> model","text":"What does <code>text-embedding-ada-002</code> do? <p>The <code>text-embedding-ada-002</code> model on Azure OpenAI converts text into numeric vectors that represent the meaning of the text. This allows for vector search, where instead of matching exact words, the search finds text with similar meanings. It works with multiple languages and different content types, making it useful for comparing text across languages and formats. When used with Azure AI Search, it improves search results by finding the most relevant and contextually accurate information. This model is perfect for creating advanced search solutions and applications that need to understand natural language.</p> <p>Open Microsoft Foundry in your browser, then select Deployments. Select Create a new deployment. Fill out the following details and select Create:</p> <ul> <li>Select a model: <code>text-embedding-ada-002</code>.</li> <li>Model version: Default.</li> <li>Deployment type: Standard.</li> <li>Deployment name: Choose a memorable name, such as <code>text-embeddings</code></li> <li>Content Filter: Default.</li> </ul> <p>Tip: Handling no quota available message</p> <p>When you select a model, you may see No quota available message pop-up on top of the configuration page. To handle this, you have two options: 1. Select a different version or deployment type 2. Free up the resources on other deployments by requesting for more quota or adjust the existing quota</p> <p></p>"},{"location":"pages/custom-engine/teams-ai/02-rag/#exercise-2-upload-your-documents-to-azure-ai-search-using-microsoft-foundry-chat-playground","title":"Exercise 2: Upload your documents to Azure AI Search using Microsoft Foundry Chat Playground","text":"<p>For this exercise, download fictitious_resumes.zip and unzip the folder.</p>"},{"location":"pages/custom-engine/teams-ai/02-rag/#step-1-upload-your-documents-to-azure-ai-search","title":"Step 1: Upload your documents to Azure AI Search","text":"<ol> <li> <p>Open Microsoft Foundry in your browser, then select Chat playground. In the Setup section, first make sure you reset the model instructions by selecting Reset and delete examples related to Shakespearean writing to start from scratch. If you already have the Chat playground in empty and default setup, you can proceed to the next step.</p> <p></p> </li> <li> <p>Select Add your data and then Add a data source.</p> <p></p> </li> <li> <p>Select Upload files (preview), then fill the details as the following and select Next:</p> <ul> <li>Subscription: Select the subscription you created your Azure resources.</li> <li>Select Azure Blob storage resource: Select your storage resource, <code>copilotcampstorage</code>. (You'll see a message Azure OpenAI needs your permission to access this resource, select Turn on CORS.)</li> <li>Select Azure AI Search resource: Select your Azure AI Search resournce, <code>copilotcamp-ai-search</code>.</li> <li>Enter the index name: Index name, such as <code>resumes</code>; make note of this</li> <li>Select the box for Add vector search to this search resource.</li> <li>Select an embedding model: Select your text-embedding-ada-002 model, <code>text-embeddings</code>.</li> </ul> </li> </ol> <p>Take note of the index name as you will use this in the <code>INDEX_NAME</code> environment variable.</p> <p></p> <ol> <li>Select Browse for a file and select the pdf documents from the <code>resumes</code> folder. Then, select Upload files and Next.</li> <li>Select Search type as <code>Vector</code> and chunk size as <code>1024(Default)</code>, then Next.</li> <li>Select <code>API Key</code> as Azure resource authentication type, then Next.</li> </ol> <p>It takes couple of minutes to complete the data ingestion. Once the data is ready, you can proceed with testing.</p> <p></p> <p>Note</p> <p>Once you index your data, your index remains on Azure AI Search even if you close or refresh the Chat Playground. If the Chat Playground resets itself and you have to add your data again, you don't have to index your data for the second time using Upload files, instead you can select Azure AI Search from Add Your Data section and select your existing index to test out your data.</p>"},{"location":"pages/custom-engine/teams-ai/02-rag/#step-2-test-your-data-on-microsoft-foundry","title":"Step 2: Test your data on Microsoft Foundry","text":"<p>Once your data  ingestion is completed, use Chat playground to ask questions about your data. </p> <p>You can ask questions such as \"Can you suggest me a candidate who is suitable for Spanish speaking role that requires at least 2 years of .NET experience?\".</p> <p>Tip: Making the most out of your data</p> <p>Review your dataset before asking questions testing the vector search. Go through the <code>resumes</code> folder and recognize the resumes provided in different languages with diverse professions, years of experience, skills and more. Start chatting with your data by asking questions to find out the right candidate for a skill, language, profession, years of experience and other categories. Try to test out the combination of requirements to challenge the search experience!</p> <p></p> <p></p>"},{"location":"pages/custom-engine/teams-ai/02-rag/#step-3-sneak-peek-to-your-index-on-azure-ai-search","title":"Step 3: Sneak peek to your index on Azure AI Search","text":"<p>To understand more about your dataset and explore more, select resumes from the Add your data section of the Chat playground. This will redirect you to your resumes index on Azure AI Search.</p> <p></p> <p>First, let's include the vector content in our data. Select Fields tab in your Resumes index page, then check the box for contentVector, finally select Save.</p> <p></p> <p>Go back to Search explorer tab, select Query options in your Resumes index page and then change the API version as <code>2024-11-01-preview</code>, then select Close. To view your data, press Search.</p> <p>Tip: Recognize <code>contentVector</code> parameter</p> <p>When scrolling through your data, recognize that each document has <code>contentVector</code> parameter that contains the numeric vectors of the pdf document. These numeric vectors will be used for Vector Search to identify the best matching results.</p> <p></p> <p></p>"},{"location":"pages/custom-engine/teams-ai/02-rag/#exercise-3-integrate-your-app-with-azure-ai-search","title":"Exercise 3: Integrate your app with Azure AI Search","text":"<p>For this exercise, ensure that you obtain Azure OpenAI text embedding deployment name and Azure AI Search key and endpoint.</p>"},{"location":"pages/custom-engine/teams-ai/02-rag/#step-1-configure-environment-variables","title":"Step 1: Configure environment variables","text":"<p>In your Career Genie project, navigate to <code>env/.env.local.user</code> and paste the following environment variables:</p> <pre><code>AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME='&lt;Your-Text-Embedding-Model-Name&gt;'\nSECRET_AZURE_SEARCH_KEY='&lt;Your-Azure-AI-Search-Key&gt;'\nAZURE_SEARCH_ENDPOINT='&lt;Your-Azure-AI-Search-Endpoint&gt;'\nINDEX_NAME='&lt;Your-index-name&gt;'\n</code></pre> <p>Open <code>teamsapp.local.yml</code> and add the following snippet at the bottom of the file, under <code>uses: file/createOrUpdateEnvironmentFile</code>:</p> <pre><code>AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME: ${{AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME}}\nAZURE_SEARCH_KEY: ${{SECRET_AZURE_SEARCH_KEY}}\nAZURE_SEARCH_ENDPOINT: ${{AZURE_SEARCH_ENDPOINT}}\nINDEX_NAME: ${{INDEX_NAME}}\n</code></pre> <p>Navigate to <code>src/config.ts</code> and add the following snippet inside <code>config</code>:</p> <pre><code>azureOpenAIEmbeddingDeploymentName: process.env.AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME,\nazureSearchKey: process.env.AZURE_SEARCH_KEY,\nazureSearchEndpoint: process.env.AZURE_SEARCH_ENDPOINT,\nindexName: process.env.INDEX_NAME,\n</code></pre> <p></p>"},{"location":"pages/custom-engine/teams-ai/02-rag/#step-2-configure-azure-ai-search-as-a-data-source","title":"Step 2: Configure Azure AI Search as a data source","text":"<p>Open <code>src/prompts/chat/config.json</code> in your project, then add <code>data_sources</code> inside the <code>completion</code> brackets:</p> <pre><code>\"data_sources\": [\n    {\n        \"type\": \"azure_search\",\n        \"parameters\": {\n            \"endpoint\": \"$searchEndpoint\",\n            \"index_name\": \"$indexName\",\n            \"authentication\": {\n                \"type\": \"api_key\",\n                \"key\": \"$searchApiKey\"\n            },\n            \"query_type\":\"vector\",\n            \"in_scope\": true,\n            \"strictness\": 3,\n            \"top_n_documents\": 3,\n            \"embedding_dependency\": {\n            \"type\": \"deployment_name\",\n            \"deployment_name\": \"$azureOpenAIEmbeddingDeploymentName\"\n            }\n        }\n    }\n]\n</code></pre> <p>Open <code>src/prompts/chat/skprompt.txt</code> and update the prompt as the following:</p> <pre><code>You are a career specialist named \"Career Genie\" that helps Human Resources team for finding the right candidate for the jobs. \nYou are friendly and professional.\nYou always greet users with excitement and introduce yourself first.\nYou like using emojis where appropriate.\nAlways mention all citations in your content.\n</code></pre> <p>Open the terminal in Visual Studio Code, and run the following script from the project root:</p> <pre><code>npm install fs\n</code></pre> <p>Go to <code>src/app/app.ts</code> and add the following parameter in your  <code>OpenAIModel</code>:</p> <pre><code>azureApiVersion: '2024-02-15-preview'\n</code></pre> <p>Add the following import on top of the <code>src/app/app.ts</code> file:</p> <pre><code>import fs from 'fs';\n</code></pre> <p>In <code>src/app/app.ts</code>, replace the <code>defaultPrompt</code> inside the <code>ActionPlanner</code> with the following code snippet:</p> <pre><code>defaultPrompt: async () =&gt; {\n    const template = await prompts.getPrompt('chat');\n    const skprompt = fs.readFileSync(path.join(__dirname, '..', 'prompts', 'chat', 'skprompt.txt'));\n\n    const dataSources = (template.config.completion as any)['data_sources'];\n\n    dataSources.forEach((dataSource: any) =&gt; {\n      if (dataSource.type === 'azure_search') {\n        dataSource.parameters.authentication.key = config.azureSearchKey;\n        dataSource.parameters.endpoint = config.azureSearchEndpoint;\n        dataSource.parameters.indexName = config.indexName;\n        dataSource.parameters.embedding_dependency.deployment_name =\n          config.azureOpenAIEmbeddingDeploymentName;\n        dataSource.parameters.role_information = `${skprompt.toString('utf-8')}`;\n      }\n    });\n\n    return template;\n}\n</code></pre> <p></p>"},{"location":"pages/custom-engine/teams-ai/02-rag/#step-3-debug-your-app-and-chat-with-your-data","title":"Step 3: Debug your app and chat with your data","text":"<p>Disclaimer: Debug locally instead of using the Test Tool</p> <p>Note that some advanced features you've added in your app may not show up properly in the App Test Tool. Therefore, you are going to debug your app locally on Teams instead of using the Test Tool moving forward.</p> <p>Let's test Career Genie on Teams this time. Start debugging your app by selecting Run and Debug tab on Visual Studio Code and Debug in Teams (Edge) or Debug in Teams (Chrome). Microsoft Teams will pop up on your browser. Once your app details show up on Teams, select Add and start chatting with your app.</p> <p>Tip: Testing this exercise locally</p> <p>Make sure to test and debug this exercise on Teams locally, as some of the Teams AI library capabilities you've implemented in your app so far won't smoothly work in the Teams App Test Tool.</p> <p>Ensure your questions are related to your dataset. Go through pdf documents in the <code>resumes</code> folder to understand more about your data. Challenge your custom engine agent by combining requirements and asking complex questions! Some suggestions would be:</p> <ul> <li>Can you suggest a candidate who is suitable for spanish speaking role that requires at least 2 years of .NET experience?</li> <li>Who are the other good candidates?</li> <li>Who would be suitable for a position that requires 5+ python development experience?</li> <li>Can you suggest any candidates for a senior developer position with 7+ year experience that requires Japanese speaking?</li> </ul> <p></p> <p></p> <p>CONGRATULATIONS!</p> <p>You have completed Lab BTA2 - Index your data in Azure AI Search to bring your data into your custom engine agent! If you want explore further, the source code of this lab is available in the Copilot Developer Camp repo.</p> <p>You are now ready to proceed to Lab BTA3 - Enhance User Experience with the Powered by AI kit! Select Next. </p> <p></p> <p></p>"},{"location":"pages/custom-engine/teams-ai/03-powered-by-ai/","title":"Lab BTA3 - Enhance User Experience","text":"<p>In this lab you will learn about the Powered by AI, a set of features Teams AI library provides, and utilize them in your custom engine agent to enhance the user experience.</p> <p>In this lab you will:</p> <ul> <li>Learn what are the Powered by AI features</li> <li>Enable Feedback Loop to collect user feedback</li> <li>Customize citations with Adaptive Cards</li> <li>Enable Generated by AI label</li> <li>Enable Sensitivity Label</li> </ul> Get a quick overview of the lab in this video. <p>Do these labs if you want to build a Custom engine agent with custom AI model and orchestration using Azure OpenAI and Teams AI library</p> <ul> <li>BTA0 - Setup</li> <li>BTA1 - First custom engine agent</li> <li>BTA2 - Index your data in Azure AI Search</li> <li>BTA3 - Enhance the user experience</li> <li>BTA4 - Add single sign on authentication</li> <li>BTA5 - Add actions to handle complex tasks</li> </ul>"},{"location":"pages/custom-engine/teams-ai/03-powered-by-ai/#introduction","title":"Introduction","text":"What is Powered by AI? <p>Powered by AI is a set of features provided by the Teams AI library that enhances interactions with custom engine agents, making them more engaging and user-friendly. These features include:</p> <ul> <li> <p>Feedback Loop: Users can rate AI responses with a thumbs up or down. This feedback helps refine the AI's accuracy and usefulness over time.</p> </li> <li> <p>Citations: The AI provides references to the sources of information, ensuring transparency and credibility.</p> </li> <li> <p>Generated by AI: Messages created by the AI system are labeled as \"AI generated,\" so users can distinguish between AI and human responses.</p> </li> <li> <p>Sensitivity Information: If the information shared is sensitive, a sensitivity label will appear, advising whether it can be shared outside your organization.</p> </li> </ul> <p>In the previous exercise, you explored Retrieval-Augmented Generation (RAG) and its integration into your custom engine agent. In this exercise, you'll enhance the user experience by leveraging \"Powered by AI\" features. Follow these steps:</p> <ul> <li>Implement the Feedback Loop</li> <li>Customize Citations</li> <li>Label AI-Generated messages</li> <li>Display Sensitivity information</li> </ul> <p>By incorporating these \"Powered by AI\" features, you'll make your custom engine agent more transparent, reliable, and user-friendly, which will enhance the overall user experience.</p>"},{"location":"pages/custom-engine/teams-ai/03-powered-by-ai/#exercise-1-enable-feedback-loop","title":"Exercise 1: Enable Feedback Loop","text":"<p>In this exercise, you can continue using the same source code you developed in the previous lab.</p>"},{"location":"pages/custom-engine/teams-ai/03-powered-by-ai/#step-1-integrate-feedback-loop-in-your-app","title":"Step 1: Integrate Feedback Loop in your app","text":"<p>In your project, open <code>src/app/app.ts</code>, locate your application instance and add <code>enable_feedback_loop: true</code> inside the ai property brackets. The updated application instance will look like the following:</p> <pre><code>const app = new Application({\n  storage,\n  ai: {\n    planner,\n    //feedback loop is enabled\n    enable_feedback_loop: true\n  },\n});\n</code></pre> <p>To handle the feedback responses, add the following code snippet in the <code>src/app/app.ts</code>:</p> <pre><code>app.feedbackLoop(async (_context, _state, feedbackLoopData) =&gt; {\n  if (feedbackLoopData.actionValue.reaction === 'like') {\n      console.log('\ud83d\udc4d' + ' ' + feedbackLoopData.actionValue.feedback!);\n  } else {\n      console.log('\ud83d\udc4e' + ' ' + feedbackLoopData.actionValue.feedback!);\n  }\n});\n</code></pre> <p></p>"},{"location":"pages/custom-engine/teams-ai/03-powered-by-ai/#step-2-test-the-feedback-loop-feature","title":"Step 2: Test the Feedback Loop feature","text":"<p>Let's test Career Genie with the Feedback Loop feature. Start debugging your app by selecting Run and Debug tab on Visual Studio Code and Debug in Teams (Edge) or Debug in Teams (Chrome). This will open Microsoft Teams in your browser. When your app details appear in Teams, select Add to start chatting with your app.</p> <p>Tip: Testing this exercise locally</p> <p>Make sure to test and debug this exercise on Teams locally, as some of the Teams AI library capabilities you've implemented in your app so far won't smoothly work in the Teams App Test Tool.</p> <p>Before testing the Feedback Loop, type \"Hi\" or ask a question similar to \"Suggest me .NET developers who can speak Spanish.\" You'll notice that the response from your custom engine agent includes thumbs up and down buttons at the bottom left corner.</p> <p></p> <p>Now, let's test the feedback loop. Click on either the thumbs up or down button. A feedback card will immediately pop up. Provide your feedback in the text field on the card and click Submit.</p> <p></p> <p>To verify that your feedback was recorded, return to Visual Studio Code and check your terminal. You'll see the feedback you provided, including whether you gave a thumbs up or down and your comment.</p> <p></p> <p>Dive deeper into the Feedback Loop by debugging</p> <p>Debugging the code is an excellent way to understand how it works. To delve deeper into how the Feedback Loop handler functions, set a breakpoint at <code>app.feedbackLoop</code>. Run the app and test the Feedback Loop by clicking thumbs up or down. You'll observe that <code>feedbackLoopData.actionValue.reaction</code> captures the reaction, while <code>feedbackLoopData.actionValue.feedback</code> captures the text feedback you provide.</p> <p></p>"},{"location":"pages/custom-engine/teams-ai/03-powered-by-ai/#exercise-2-customize-citations-with-adaptive-cards","title":"Exercise 2: Customize citations with Adaptive Cards","text":"<p>When you define a data source in a custom engine agent, the Teams AI library dynamically enables citations to reference related documents. Recognize the current experience in your custom engine agent, ask a question similar to \"Suggest me .NET developers who can speak Spanish.\". You will realize that you can hover over the citation to see the beginning of the document.</p> <p></p> <p>In this exercise, you'll tailor this citation experience further and use Adaptive Cards to customize the way citations are presented.</p>"},{"location":"pages/custom-engine/teams-ai/03-powered-by-ai/#step-1-create-an-adaptive-card-for-citations","title":"Step 1: Create an Adaptive Card for citations","text":"<p>Go to <code>src/app/</code> folder and create a new file named card.ts. Add the following code snippet inside the <code>card.ts</code> file:</p> <pre><code>import { AdaptiveCard, Message, Utilities } from '@microsoft/teams-ai';\n/**\n * Create an adaptive card from a prompt response.\n * @param {Message&lt;string&gt;} response The prompt response to create the card from.\n * @returns {AdaptiveCard} The response card.\n */\n\n//Adaptive card to display the response and citations\nexport function createResponseCard(response: Message&lt;string&gt;): AdaptiveCard {\n    const citationCards = response.context?.citations.map((citation, i) =&gt; ({\n            type: 'Action.ShowCard',\n            title: `${i+1}`,\n            card: {\n                type: 'AdaptiveCard',\n                body: [\n                    {\n                        type: 'TextBlock',\n                        text: citation.title,\n                        fontType: 'Default',\n                        weight: 'Bolder'\n                    },\n                    {\n                        type: 'TextBlock',\n                        text: citation.content,\n                        wrap: true\n                    }\n                ]\n            }\n        }));\n\n    const text = Utilities.formatCitationsResponse(response.content!);\n    return {\n        type: 'AdaptiveCard',\n        body: [\n            {\n                type: 'TextBlock',\n                text: text,\n                wrap: true\n            },\n            {\n                type: 'TextBlock',\n                text: 'Citations',\n                wrap: true,\n                fontType: 'Default',\n                weight: 'Bolder'\n            },\n            {\n                type: 'ActionSet',\n                actions: citationCards\n            }\n        ],\n        $schema: 'http://adaptivecards.io/schemas/adaptive-card.json',\n        version: '1.5'\n    };\n}\n</code></pre> <p>This Adaptive Card allows you to list citations as <code>Action.ShowCard</code> buttons which show more details when clicked. It also displays the main content of the response alongside the citation buttons. If a user wants to learn more about a citation, they can click the button to read the entire document.</p> <p></p>"},{"location":"pages/custom-engine/teams-ai/03-powered-by-ai/#step-2-use-predictedsaycommand-to-customize-the-citation-experience","title":"Step 2: Use PredictedSayCommand to customize the citation experience","text":"What does <code>PredictedSayCommand</code> do? <p>A PredictedSayCommand is a response directive that the AI system executes. By customizing PredictedSayCommand, you gain granular control over integrating Powered by AI features like citations, feedback loops into the custom engine agent's activities. This allows you to precisely tailor the AI responses to meet your application needs.</p> <p>Go to <code>src/app/app.ts</code> and add the following snippet on top of your code to import your adaptive card:</p> <pre><code>import { createResponseCard } from './card';\n</code></pre> <p>Add <code>CardFactory</code> inside the \"botbuilder\" import,  the updated version of the import will look like the following:</p> <pre><code>import { CardFactory, MemoryStorage, MessageFactory, TurnContext } from \"botbuilder\";\n</code></pre> <p>Add <code>AI</code> and <code>PredictedSayCommand</code> inside the \"@microsoft/teams-ai\" import, the updated version of the import will look like the following:</p> <pre><code>import { Application, ActionPlanner, OpenAIModel, PromptManager, AI, PredictedSayCommand} from \"@microsoft/teams-ai\";\n</code></pre> <p>Add the following PredictedSayCommand action in the <code>src/app/app.ts</code> to customize the citation:</p> <pre><code>app.ai.action&lt;PredictedSayCommand&gt;(AI.SayCommandActionName, async (context, state, data, action) =&gt; {\n  let activity;\n  if (data.response.context &amp;&amp; data.response.context.citations.length &gt; 0 ) {\n      const attachment = CardFactory.adaptiveCard(createResponseCard(data.response));\n      activity = MessageFactory.attachment(attachment);\n  }\n  else {\n      activity = MessageFactory.text(data.response.content);\n  }\n\n  activity.entities = [\n    {\n        type: \"https://schema.org/Message\",\n        \"@type\": \"Message\",\n        \"@context\": \"https://schema.org\",\n        \"@id\": \"\"\n    }\n  ];\n  activity.channelData = {\n    feedbackLoopEnabled: true\n  };\n\n  await context.sendActivity(activity);\n\n  return \"success\";\n\n});\n</code></pre> <p></p>"},{"location":"pages/custom-engine/teams-ai/03-powered-by-ai/#step-3-test-the-customized-citation-experience","title":"Step 3: Test the customized citation experience","text":"<p>Let's test Career Genie with the customized citation experience. Start debugging your app by selecting Run and Debug tab on Visual Studio Code and Debug in Teams (Edge) or Debug in Teams (Chrome). Microsoft Teams will pop up on your browser. This will open Microsoft Teams in your browser. When your app details appear in Teams, select Add to start chatting with your app.</p> <p>Tip: Testing this exercise locally</p> <p>Make sure to test and debug this exercise on Teams locally, as some of the Teams AI library capabilities you've implemented in your app so far won't smoothly work in the Teams App Test Tool.</p> <p>To test the new citation experience, start by greeting Career Genie with \"Hi\" or \"Hello\". Then, try to ask questions similar to \"Can you suggest any candidates for a senior developer position with 7+ year experience that requires Japanese speaking?\"</p> <p></p> <p>Now, recognize that the customized citation experience with Adaptive Cards provides a button for each citation. Click on citation buttons to extend the document view and review the resume details for each candidate.</p> <p></p>"},{"location":"pages/custom-engine/teams-ai/03-powered-by-ai/#exercise-3-enable-the-generated-by-ai-label","title":"Exercise 3: Enable the Generated by AI label","text":"<p>In this exercise, you will continue customizing the user experience of your custom engine agent using <code>PredictedSayCommand</code>. To help users differentiate between AI and human responses, you'll enable the \"AI generated\" label that appears on top of the messages created by the AI system.</p>"},{"location":"pages/custom-engine/teams-ai/03-powered-by-ai/#step-1-use-predictedsaycommand-to-enable-the-generated-by-ai-label","title":"Step 1: Use PredictedSayCommand to enable the Generated by AI label","text":"<p>Go to <code>src/app/app.ts</code> and locate your <code>PredictedSayCommand</code> action. Add the following code snippet inside <code>activity.entities</code>:</p> <pre><code>// Generated by AI label\nadditionalType: [\"AIGeneratedContent\"]\n</code></pre> <p>The update <code>activity.entities</code> will look like the following:</p> <pre><code>activity.entities = [\n    {\n        type: \"https://schema.org/Message\",\n        \"@type\": \"Message\",\n        \"@context\": \"https://schema.org\",\n        \"@id\": \"\",\n        // Generated by AI label\n        additionalType: [\"AIGeneratedContent\"],\n    },\n\n];\n</code></pre> <p></p>"},{"location":"pages/custom-engine/teams-ai/03-powered-by-ai/#step-2-test-the-generated-by-ai-label","title":"Step 2: Test the Generated by AI label","text":"<p>Let's test Career Genie with the \"Generated by AI\" label. Start debugging your app by selecting Run and Debug tab on Visual Studio Code and Debug in Teams (Edge) or Debug in Teams (Chrome). This will open Microsoft Teams in your browser. When your app details appear in Teams, select Add to start chatting with your app.</p> <p>Tip: Testing this exercise locally</p> <p>Make sure to test and debug this exercise on Teams locally, as some of the Teams AI library capabilities you've implemented in your app so far won't smoothly work in the Teams App Test Tool.</p> <p>To test the \"Generated by AI\" label, simply greet Career Genie. The first message you receive will have a small \"AI generated\" label on top.</p> <p></p> <p></p>"},{"location":"pages/custom-engine/teams-ai/03-powered-by-ai/#exercise-4-enable-the-sensitivity-label","title":"Exercise 4: Enable the Sensitivity label","text":"<p>In this final exercise, you will continue utilizing <code>PredictedSayCommand</code> to enable the sensitivity label. Remember, Career Genie is an expert in Human Resources tasks that often require sharing confidential information within your organization. For scenarios like Career Genie, where the information shared is sensitive, a sensitivity label will appear on top of the AI-generated messages, advising whether it can be shared outside your organization.</p>"},{"location":"pages/custom-engine/teams-ai/03-powered-by-ai/#step-1-use-predictedsaycommand-to-enable-the-sensitivity-label","title":"Step 1: Use PredictedSayCommand to enable the Sensitivity label","text":"<p>Go to <code>src/app/app.ts</code> and locate your <code>PredictedSayCommand</code> action. Add the following code snippet inside <code>activity.entities</code>:</p> <pre><code>// Sensitivity label\nusageInfo: {\n    \"@type\": \"CreativeWork\",\n    name: \"Confidential\",\n    description: \"Sensitive information, do not share outside of your organization.\",\n}\n</code></pre> <p>The updated <code>activity.entities</code> will look like the following:</p> <pre><code>activity.entities = [\n    {\n        type: \"https://schema.org/Message\",\n        \"@type\": \"Message\",\n        \"@context\": \"https://schema.org\",\n        \"@id\": \"\",\n        // Generated by AI label\n        additionalType: [\"AIGeneratedContent\"],\n        // Sensitivity label\n        usageInfo: {\n          \"@type\": \"CreativeWork\",\n          name: \"Confidential\",\n          description: \"Sensitive information, do not share outside of your organization.\",\n        }\n    },\n\n  ];\n</code></pre> <p></p>"},{"location":"pages/custom-engine/teams-ai/03-powered-by-ai/#step-2-test-the-sensitivity-label","title":"Step 2: Test the Sensitivity label","text":"<p>Let's test Career Genie with the Sensitivity label. Start debugging your app by selecting Run and Debug tab on Visual Studio Code and Debug in Teams (Edge) or Debug in Teams (Chrome). Microsoft Teams will pop up on your browser. Once your app details show up on Teams, select Add and start chatting with your app.</p> <p>Tip: Testing this exercise locally</p> <p>Make sure to test and debug this exercise on Teams locally, as some of the Teams AI library capabilities you've implemented in your app so far won't smoothly work in the Teams App Test Tool.</p> <p>To test the Sensitivity label, greet Career Genie or try to ask questions similar to \"Can you suggest a candidate who is suitable for spanish speaking role that requires at least 2 years of .NET experience?\".</p> <p></p> <p>Notice that the sensitivity label appears right next to the \"AI Generated\" label in Career Genie's message. Hover over the sensitivity label to read the guidance specific to your organization.</p> <p></p> <p>CONGRATULATIONS!</p> <p>You have completed Lab BTA3 - Enhance User Experience with the Powered by AI kit!  If you want explore further, the source code of this lab is available in the Copilot Developer Camp repo.</p> <p>You are now ready to proceed to Lab BTA4 - Secure your solution using authentication. Select Next.</p> <p></p> <p></p>"},{"location":"pages/custom-engine/teams-ai/04-authentication/","title":"Lab BTA4 - Add single sign on authentication","text":"<p>In this lab, you'll learn how to authenticate users with Entra Single Sign-On in Career Genie, and to call the Microsoft Graph API using the token to get logged in user information.</p> <p>In this lab you will learn to:</p> <ul> <li>Add Entra ID single sign-on (SSO) in your app, so users can seamlessly log into your app with the same account they use in Microsoft Teams</li> <li>Use Teams AI library and Bot Framework to implement the single sign on.</li> <li>Acquire and use tokens for app users to enhance security and user experience.</li> </ul> Get a quick overview of the lab in this video. <p>Do these labs if you want to build a Custom engine agent with custom AI model and orchestration using Azure OpenAI and Teams AI library</p> <ul> <li>BTA0 - Setup</li> <li>BTA1 - First custom engine agent</li> <li>BTA2 - Index your data in Azure AI Search</li> <li>BTA3 - Enhance the user experience</li> <li>BTA4 - Add single sign on authentication</li> <li>BTA5 - Add actions to handle complex tasks</li> </ul>"},{"location":"pages/custom-engine/teams-ai/04-authentication/#introduction","title":"Introduction","text":"<p>Get ready to enhance your CareerGenie by integrating Entra ID (formerly Azure AD) single sign-on (SSO). This will allow your app to seamlessly acquire tokens for accessing Microsoft 365 data via Microsoft Graph, ensuring smooth authentication and authorization. You'll be incorporating this SSO capability using the Teams AI library and the Bot Framework, specifically focusing on a multi-tenant configuration.</p>"},{"location":"pages/custom-engine/teams-ai/04-authentication/#exercise-1-set-up-your-project-for-entra-id-single-sign-on","title":"Exercise 1: Set up your project for Entra ID Single Sign-on","text":"<p>Applications secured with Entra ID must be registered and granted permission. M365 Agents Toolkit will do this work for you, but you have to update your project to make that happen. In this exercise, you'll modify the M365 Agents Toolkit project files to provision your app registration in Entra ID.</p> <p>In this exercise, use the source code for Lab B3 as the base project and proceed to next steps.</p>"},{"location":"pages/custom-engine/teams-ai/04-authentication/#step-1-add-an-entra-id-app-manifest-file-to-define-the-entra-id-application","title":"Step 1: Add an Entra ID App manifest file to define the Entra ID Application","text":"<p>In this step, you'll add a file that defines the application that M365 Agents Toolkit will register for your application in Entra ID. This manifest file allows you to customize various aspects of your application registration. For example, this one sets up <code>User.Read</code> permission on the Microsoft Graph API so your app can read the user's profile.</p> <p>Create a file aad.manifest.json in the root of your project folder, and paste in this JSON:</p> <pre><code>{\n    \"id\": \"${{AAD_APP_OBJECT_ID}}\",\n    \"appId\": \"${{AAD_APP_CLIENT_ID}}\",\n    \"name\": \"CareerGenieBot-aad\",\n    \"accessTokenAcceptedVersion\": 2,\n    \"signInAudience\": \"AzureADMultipleOrgs\",\n    \"optionalClaims\": {\n        \"idToken\": [],\n        \"accessToken\": [\n            {\n                \"name\": \"idtyp\",\n                \"source\": null,\n                \"essential\": false,\n                \"additionalProperties\": []\n            }\n        ],\n        \"saml2Token\": []\n    },\n    \"requiredResourceAccess\": [\n        {\n            \"resourceAppId\": \"Microsoft Graph\",\n            \"resourceAccess\": [\n                {\n                    \"id\": \"User.Read\",\n                    \"type\": \"Scope\"\n                }\n            ]\n        }\n    ],\n    \"oauth2Permissions\": [\n        {\n            \"adminConsentDescription\": \"Allows Teams to call the app's web APIs as the current user.\",\n            \"adminConsentDisplayName\": \"Teams can access app's web APIs\",\n            \"id\": \"${{AAD_APP_ACCESS_AS_USER_PERMISSION_ID}}\",\n            \"isEnabled\": true,\n            \"type\": \"User\",\n            \"userConsentDescription\": \"Enable Teams to call this app's web APIs with the same rights that you have\",\n            \"userConsentDisplayName\": \"Teams can access app's web APIs and make requests on your behalf\",\n            \"value\": \"access_as_user\"\n        }\n    ],\n    \"preAuthorizedApplications\": [\n        {\n            \"appId\": \"1fec8e78-bce4-4aaf-ab1b-5451cc387264\",\n            \"permissionIds\": [\n                \"${{AAD_APP_ACCESS_AS_USER_PERMISSION_ID}}\"\n            ]\n        },\n        {\n            \"appId\": \"5e3ce6c0-2b1f-4285-8d4b-75ee78787346\",\n            \"permissionIds\": [\n                \"${{AAD_APP_ACCESS_AS_USER_PERMISSION_ID}}\"\n            ]\n        }\n    ],\n    \"identifierUris\":[\n        \"api://botid-${{BOT_ID}}\"\n    ],\n    \"replyUrlsWithType\":[\n        {\n          \"url\": \"https://${{BOT_DOMAIN}}/auth-end.html\",\n          \"type\": \"Web\"\n        }\n    ]\n}\n</code></pre> <p></p>"},{"location":"pages/custom-engine/teams-ai/04-authentication/#step-2-update-m365-agents-toolkit-configuration-file-to-create-the-entra-id-app","title":"Step 2: Update M365 Agents Toolkit configuration file to create the Entra ID App","text":"<p>Open the <code>teamsapp.local.yml</code> file. This is a YAML file that defines the steps M365 Agents Toolkit takes to run your project. There are 3 steps in the \"LIFECYCLE\" section of the M365 Agents Toolkit user interface.</p> <ul> <li> <p>Provision - In this phase, any infrastructure needed by your app is created. This includes things like the bot registration, the Teams app package, and, in this case, the Entra ID app registration</p> </li> <li> <p>Deploy - In this phase, the code is built and run locally, or uploaded to Azure for environments other than \"local\"</p> </li> <li> <p>Publish - In this phase, the app package is published to Microsoft Teams</p> </li> </ul> <p>To provision your Entra ID app, add these lines to teamsapp.local.yml. You can put them directly below the <code>provision</code>:</p> <pre><code>  - uses: aadApp/create # Creates a new Entra ID (AAD) app to authenticate users if the environment variable that stores clientId is empty\n    with:\n      name: CareerGenieBot-aad # Note: when you run aadApp/update, the AAD app name will be updated based on the definition in manifest. If you don't want to change the name, make sure the name in AAD manifest is the same with the name defined here.\n      generateClientSecret: true # If the value is false, the action will not generate client secret for you\n      signInAudience: \"AzureADMultipleOrgs\" # Authenticate users with a Microsoft work or school account in your organization's Entra ID tenant (for example, single tenant).\n    writeToEnvironmentFile: # Write the information of created resources into environment file for the specified environment variable(s).\n      clientId: AAD_APP_CLIENT_ID\n      clientSecret: SECRET_AAD_APP_CLIENT_SECRET # Environment variable that starts with `SECRET_` will be stored to the .env.{envName}.user environment file\n      objectId: AAD_APP_OBJECT_ID\n      tenantId: AAD_APP_TENANT_ID\n      authority: AAD_APP_OAUTH_AUTHORITY\n      authorityHost: AAD_APP_OAUTH_AUTHORITY_HOST\n\n</code></pre> <p>And after <code>botFramework/create</code> add below to update the existing AAD app.</p> <pre><code>  - uses: aadApp/update # Apply the AAD manifest to an existing AAD app. Will use the object id in manifest file to determine which AAD app to update.\n    with:\n      manifestPath: ./aad.manifest.json # Relative path to teamsfx folder. Environment variables in manifest will be replaced before apply to AAD app\n      outputFilePath: ./build/aad.manifest.${{TEAMSFX_ENV}}.json\n</code></pre> <p>Tip: YAML requires proper indentation</p> <p>YAML requires proper indentation; each level in the object hierarchy must be indented to indicate the structure. 2 spaces (not tabs) is a good choice. Visual Studio Code will help you here, and will underline any syntax errors in red. You'll know you got it right when the red lines disappear!</p> <p>Now scroll down and find the <code>file/createOrUpdateEnvironmentFile</code> directive in the deploy phase. Add these variables to the envs: collection, right below the ones you added in the previous lab:</p> <pre><code> BOT_DOMAIN: ${{BOT_DOMAIN}}\n AAD_APP_CLIENT_ID: ${{AAD_APP_CLIENT_ID}}\n AAD_APP_CLIENT_SECRET: ${{SECRET_AAD_APP_CLIENT_SECRET}}\n AAD_APP_TENANT_ID: ${{AAD_APP_TENANT_ID}}\n AAD_APP_OAUTH_AUTHORITY_HOST: ${{AAD_APP_OAUTH_AUTHORITY_HOST}}\n AAD_APP_OAUTH_AUTHORITY: ${{AAD_APP_OAUTH_AUTHORITY}}\n</code></pre> <p></p>"},{"location":"pages/custom-engine/teams-ai/04-authentication/#exercise-2-add-sso-in-teams-app-manifest","title":"Exercise 2: Add SSO in Teams app manifest","text":"<p>In this exercise, you'll update the Teams app manifest to add single sign on.</p>"},{"location":"pages/custom-engine/teams-ai/04-authentication/#step-1-update-your-teams-app-manifest-for-sso","title":"Step 1: Update your Teams app manifest for SSO","text":"<p>In the single sign-on process, Teams will hand your code an Entra ID access token for your application. Teams can't provide this access token, however, unless it knows about your application; specifically, it needs to know the application (client) ID and the ID of the bot that's connected to Teams. So you need to add this information to your Teams app manifest.</p> <p>Find the Teams app manifest template in ./appPackage/manifest.json and add the following:</p> <pre><code> \"webApplicationInfo\": {\n        \"id\": \"${{BOT_ID}}\",\n        \"resource\": \"api://botid-${{BOT_ID}}\"\n    }\n</code></pre> <p>Add it below the <code>validDomains</code> node, with a comma in between.</p> <p>While we're here, we need to tell Teams to display web pages from your bot's domain, which allows access to the <code>auth-start.html</code> and <code>auth-end.html</code> pages used for user consent to call the Microsoft Graph. This only happens the first time a user accesses the custom engine agent.</p> <p>So you need to add your bot's domain, ${{BOT_DOMAIN}} to the <code>validDomains</code> array. After making these changes, the end of your <code>manifest.json</code> file should look like this:</p> <pre><code>  \"validDomains\": [\n        \"${{BOT_DOMAIN}}\",\n        \"*.botframework.com\"\n    ],\n</code></pre> <p></p>"},{"location":"pages/custom-engine/teams-ai/04-authentication/#exercise-3-update-the-application-code-for-sso","title":"Exercise 3: Update the application code for SSO","text":"<p>In this exercise, you'll modify the code to accommodate the SSO process.</p>"},{"location":"pages/custom-engine/teams-ai/04-authentication/#step-1-provide-html-pages-for-the-consent-dialog","title":"Step 1: Provide HTML pages for the consent dialog","text":"<p>The first time users access your application, they may need to consent to giving the app permission to read their profile information. This is performed by the Teams AI library. It will display a pop-up window; these HTML pages are to be displayed in that pop-up, and will redirect to Entra ID to do the actual consent.</p> <p>The code snippets for pop up for permission grant are from official teams-ai library sample for Teams SSO.</p> <p>Create a new folder called public inside the src folder of the project.</p> <p>Create a file auth-start.html and paste in the contents below:</p> <pre><code>&lt;!--This file is used during the Teams Bot authentication flow to assist with retrieval of the access token.--&gt;\n&lt;!--If you're not familiar with this, do not alter or remove this file from your project.--&gt;\n&lt;html lang=\"en\"&gt;\n\n&lt;head&gt;\n    &lt;title&gt;Login Start Page&lt;/title&gt;\n    &lt;meta charset=\"utf-8\" /&gt;\n    &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" /&gt;\n&lt;/head&gt;\n\n&lt;body&gt;\n    &lt;script type=\"text/javascript\"&gt;\n        popUpSignInWindow();\n\n        async function popUpSignInWindow() {\n            // Generate random state string and store it, so we can verify it in the callback\n            let state = _guid();\n            localStorage.setItem('state', state);\n            localStorage.removeItem('codeVerifier');\n            var currentURL = new URL(window.location);\n            var clientId = currentURL.searchParams.get('clientId');\n            var tenantId = currentURL.searchParams.get('tenantId');\n            var loginHint = currentURL.searchParams.get('loginHint');\n            var scope = currentURL.searchParams.get('scope');\n            if (!loginHint) {\n                loginHint = '';\n            }\n            var originalCode = _guid();\n            var codeChallenge = await pkceChallengeFromVerifier(originalCode);\n            localStorage.setItem('codeVerifier', originalCode);\n            let queryParams = {\n                client_id: clientId,\n                response_type: 'code',\n                response_mode: 'fragment',\n                scope: scope,\n                redirect_uri: window.location.origin + '/auth-end.html',\n                nonce: _guid(),\n                login_hint: loginHint,\n                state: state,\n                code_challenge: codeChallenge,\n                code_challenge_method: 'S256'\n            };\n            let authorizeEndpoint = `https://login.microsoftonline.com/common/oauth2/v2.0/authorize?${toQueryString(queryParams)}`;     \n            window.location.assign(authorizeEndpoint);\n        }\n\n        // Build query string from map of query parameter\n        function toQueryString(queryParams) {\n            let encodedQueryParams = [];\n            for (let key in queryParams) {\n                encodedQueryParams.push(key + '=' + encodeURIComponent(queryParams[key]));\n            }\n            return encodedQueryParams.join('&amp;');\n        }\n\n        // Converts decimal to hex equivalent      \n        function _decimalToHex(number) {\n            var hex = number.toString(16);\n            while (hex.length &lt; 2) {\n                hex = '0' + hex;\n            }\n            return hex;\n        }\n\n        // Generates RFC4122 version 4 guid (128 bits)\n        function _guid() {\n            // RFC4122: The version 4 UUID is meant for generating UUIDs from truly-random or\n            // pseudo-random numbers.\n            // The algorithm is as follows:\n            //     Set the two most significant bits (bits 6 and 7) of the\n            //        clock_seq_hi_and_reserved to zero and one, respectively.\n            //     Set the four most significant bits (bits 12 through 15) of the\n            //        time_hi_and_version field to the 4-bit version number from\n            //        Section 4.1.3. Version4\n            //     Set all the other bits to randomly (or pseudo-randomly) chosen\n            //     values.\n            // UUID                   = time-low \"-\" time-mid \"-\"time-high-and-version \"-\"clock-seq-reserved and low(2hexOctet)\"-\" node\n            // time-low               = 4hexOctet\n            // time-mid               = 2hexOctet\n            // time-high-and-version  = 2hexOctet\n            // clock-seq-and-reserved = hexOctet:\n            // clock-seq-low          = hexOctet\n            // node                   = 6hexOctet\n            // Format: xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx\n            // y could be 1000, 1001, 1010, 1011 since most significant two bits needs to be 10\n            // y values are 8, 9, A, B\n            var cryptoObj = window.crypto || window.msCrypto; // for IE 11\n            if (cryptoObj &amp;&amp; cryptoObj.getRandomValues) {\n                var buffer = new Uint8Array(16);\n                cryptoObj.getRandomValues(buffer);\n                //buffer[6] and buffer[7] represents the time_hi_and_version field. We will set the four most significant bits (4 through 7) of buffer[6] to represent decimal number 4 (UUID version number).\n                buffer[6] |= 0x40; //buffer[6] | 01000000 will set the 6 bit to 1.\n                buffer[6] &amp;= 0x4f; //buffer[6] &amp; 01001111 will set the 4, 5, and 7 bit to 0 such that bits 4-7 == 0100 = \"4\".\n                //buffer[8] represents the clock_seq_hi_and_reserved field. We will set the two most significant bits (6 and 7) of the clock_seq_hi_and_reserved to zero and one, respectively.\n                buffer[8] |= 0x80; //buffer[8] | 10000000 will set the 7 bit to 1.\n                buffer[8] &amp;= 0xbf; //buffer[8] &amp; 10111111 will set the 6 bit to 0.\n                return (\n                    _decimalToHex(buffer[0]) +\n                    _decimalToHex(buffer[1]) +\n                    _decimalToHex(buffer[2]) +\n                    _decimalToHex(buffer[3]) +\n                    '-' +\n                    _decimalToHex(buffer[4]) +\n                    _decimalToHex(buffer[5]) +\n                    '-' +\n                    _decimalToHex(buffer[6]) +\n                    _decimalToHex(buffer[7]) +\n                    '-' +\n                    _decimalToHex(buffer[8]) +\n                    _decimalToHex(buffer[9]) +\n                    '-' +\n                    _decimalToHex(buffer[10]) +\n                    _decimalToHex(buffer[11]) +\n                    _decimalToHex(buffer[12]) +\n                    _decimalToHex(buffer[13]) +\n                    _decimalToHex(buffer[14]) +\n                    _decimalToHex(buffer[15])\n                );\n            } else {\n                var guidHolder = 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx';\n                var hex = '0123456789abcdef';\n                var r = 0;\n                var guidResponse = '';\n                for (var i = 0; i &lt; 36; i++) {\n                    if (guidHolder[i] !== '-' &amp;&amp; guidHolder[i] !== '4') {\n                        // each x and y needs to be random\n                        r = (Math.random() * 16) | 0;\n                    }\n                    if (guidHolder[i] === 'x') {\n                        guidResponse += hex[r];\n                    } else if (guidHolder[i] === 'y') {\n                        // clock-seq-and-reserved first hex is filtered and remaining hex values are random\n                        r &amp;= 0x3; // bit and with 0011 to set pos 2 to zero ?0??\n                        r |= 0x8; // set pos 3 to 1 as 1???\n                        guidResponse += hex[r];\n                    } else {\n                        guidResponse += guidHolder[i];\n                    }\n                }\n                return guidResponse;\n            }\n        }\n\n        // Calculate the SHA256 hash of the input text.\n        // Returns a promise that resolves to an ArrayBuffer\n        function sha256(plain) {\n            const encoder = new TextEncoder();\n            const data = encoder.encode(plain);\n            return window.crypto.subtle.digest('SHA-256', data);\n        }\n\n        // Base64-urlencodes the input string\n        function base64urlencode(str) {\n            // Convert the ArrayBuffer to string using Uint8 array to convert to what btoa accepts.\n            // btoa accepts chars only within ascii 0-255 and base64 encodes them.\n            // Then convert the base64 encoded to base64url encoded\n            //   (replace + with -, replace / with _, trim trailing =)\n            return btoa(String.fromCharCode.apply(null, new Uint8Array(str)))\n                .replace(/\\+/g, '-')\n                .replace(/\\//g, '_')\n                .replace(/=+$/, '');\n        }\n\n        // Return the base64-urlencoded sha256 hash for the PKCE challenge\n        async function pkceChallengeFromVerifier(v) {\n            hashed = await sha256(v);\n            return base64urlencode(hashed);\n        }\n    &lt;/script&gt;\n&lt;/body&gt;\n\n&lt;/html&gt;\n</code></pre> <p>Create a file auth-end.html and paste in the contents below:</p> <pre><code>&lt;html lang=\"en\"&gt;\n    &lt;head&gt;\n        &lt;title&gt;Login End Page&lt;/title&gt;\n        &lt;meta charset=\"utf-8\" /&gt;\n        &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" /&gt;\n    &lt;/head&gt;\n\n    &lt;body&gt;\n        &lt;script\n            src=\"https://statics.teams.cdn.office.net/sdk/v1.6.0/js/MicrosoftTeams.min.js\"\n            integrity=\"sha384-mhp2E+BLMiZLe7rDIzj19WjgXJeI32NkPvrvvZBrMi5IvWup/1NUfS5xuYN5S3VT\"\n            crossorigin=\"anonymous\"\n        &gt;&lt;/script&gt;\n        &lt;div id=\"divError\"&gt;&lt;/div&gt;\n        &lt;script type=\"text/javascript\"&gt;\n            microsoftTeams.initialize();\n            let hashParams = getHashParameters();\n\n            if (hashParams['error']) {\n                // Authentication failed\n                handleAuthError(hashParams['error'], hashParams);\n            } else if (hashParams['code']) {\n                // Get the stored state parameter and compare with incoming state\n                let expectedState = localStorage.getItem('state');\n                if (expectedState !== hashParams['state']) {\n                    // State does not match, report error\n                    handleAuthError('StateDoesNotMatch', hashParams);\n                } else {\n                    microsoftTeams.authentication.notifySuccess();\n                }\n            } else {\n                // Unexpected condition: hash does not contain error or access_token parameter\n                handleAuthError('UnexpectedFailure', hashParams);\n            }\n\n            // Parse hash parameters into key-value pairs\n            function getHashParameters() {\n                let hashParams = {};\n                location.hash\n                    .substr(1)\n                    .split('&amp;')\n                    .forEach(function (item) {\n                        let s = item.split('='),\n                            k = s[0],\n                            v = s[1] &amp;&amp; decodeURIComponent(s[1]);\n                        hashParams[k] = v;\n                    });\n                return hashParams;\n            }\n\n            // Show error information\n            function handleAuthError(errorType, errorMessage) {\n                const err = JSON.stringify({\n                    error: errorType,\n                    message: JSON.stringify(errorMessage)\n                });\n                let para = document.createElement('p');\n                let node = document.createTextNode(err);\n                para.appendChild(node);\n\n                let element = document.getElementById('divError');\n                element.appendChild(para);\n            }\n        &lt;/script&gt;\n    &lt;/body&gt;\n&lt;/html&gt;\n\n</code></pre> <p></p>"},{"location":"pages/custom-engine/teams-ai/04-authentication/#step-2-update-code-to-handle-sso","title":"Step 2: Update code to handle SSO","text":"<ul> <li>Changes to index.ts file is as follows:</li> </ul> <p>To serve static files from the public folder, include the following import for <code>path</code>:</p> <pre><code>import * as path from 'path';\n</code></pre> <p>And then add below code after the line that initializes the <code>server</code> object with the result of the <code>expressApp.listen</code> method.</p> <pre><code>const authFilePattern = /^\\/auth-(start|end)\\.html$/;\nexpressApp.get(\n  authFilePattern, (req, res) =&gt; {\n    const fileName = req.path;\n    const filePath = path.join(__dirname, 'public', fileName);\n    res.sendFile(filePath);\n});\n</code></pre> <p>Change the adapter.ts file is as follows:</p> <ul> <li>Import the <code>TeamsAdapter</code> from teams-ai library.</li> </ul> <pre><code>import { TeamsAdapter } from '@microsoft/teams-ai';\n</code></pre> <ul> <li>Replace the adapter definition with <code>TeamsAdapter</code> instead of <code>CloudAdapter</code> for Teams SSO.</li> </ul> <pre><code>const adapter = new TeamsAdapter(\n  {},\n  new ConfigurationServiceClientCredentialFactory({\n    MicrosoftAppId: config.MicrosoftAppId,\n    MicrosoftAppPassword: config.MicrosoftAppPassword,\n    MicrosoftAppType: 'MultiTenant',\n  })\n);\n\n</code></pre> <ul> <li>Comment out the definition for <code>botFrameworkAuthentication</code> which is not needed anymore.</li> </ul> <p>Change the config.ts file is as follows:</p> <ul> <li>Add below properties to the constant <code>config</code>. Add a comma and after <code>process.env.INDEX_NAME</code> and append below snippet:</li> </ul> <pre><code>aadAppClientId: process.env.AAD_APP_CLIENT_ID,\naadAppClientSecret: process.env.AAD_APP_CLIENT_SECRET,\naadAppOauthAuthorityHost: process.env.AAD_APP_OAUTH_AUTHORITY_HOST,\naadAppTenantId: process.env.AAD_APP_TENANT_ID,\nbotDomain: process.env.BOT_DOMAIN,\naadAppOauthAuthority: process.env.AAD_APP_OAUTH_AUTHORITY,\n</code></pre> <p>Change the app.ts file is as follows:</p> <ul> <li>We will be using the <code>TurnState</code> and <code>AuthError</code> modules so include them in your import statement from the <code>@microsoft/teams-ai</code> library as shown below:</li> </ul> <pre><code>import { Application, ActionPlanner, OpenAIModel, PromptManager, AI, PredictedSayCommand, AuthError, TurnState } from \"@microsoft/teams-ai\";\n</code></pre> <ul> <li>Now to pass authentication setting to the Application definition, replace <code>const app</code> definition with below code snippet:</li> </ul> <pre><code>const app = new Application({\n  storage,\n  authentication: {settings: {\n    graph: {\n      scopes: ['User.Read'],\n      msalConfig: {\n        auth: {\n          clientId: config.aadAppClientId!,\n          clientSecret: config.aadAppClientSecret!,\n          authority: `${config.aadAppOauthAuthorityHost}/common`\n        }\n      },\n      signInLink: `https://${config.botDomain}/auth-start.html`,\n      endOnInvalidMessage: true\n    }\n  }},\n  ai: {\n    planner,\n    //feedback loop is enabled\n    enable_feedback_loop: true\n  },\n});\n</code></pre> <p>Teams AI library handles exchange of token between your custom engine agent and Microsoft Teams, so you can just call Microsoft Graph immediately upon receiving the token. Now let's add code to define and handle various authentication and messaging events using the Teams AI library. Paste below code after the app definition method:</p> <pre><code>interface ConversationState {\n  count: number;\n}\ntype ApplicationTurnState = TurnState&lt;ConversationState&gt;;\napp.authentication.get('graph').onUserSignInSuccess(async (context: TurnContext, state: ApplicationTurnState) =&gt; {\n  const token = state.temp.authTokens['graph'];\n  await context.sendActivity(`Hello ${await getUserDisplayName(token)}. You have successfully logged in to CareerGenie!`);     \n});\napp.authentication\n    .get('graph')\n    .onUserSignInFailure(async (context: TurnContext, _state: ApplicationTurnState, error: AuthError) =&gt; {\n        await context.sendActivity('Failed to login');\n        await context.sendActivity(`Error message: ${error.message}`);\n    });\n\n    // Listen for user to say '/reset' and then delete conversation state\napp.message('/reset', async (context: TurnContext, state: ApplicationTurnState) =&gt; {\n  state.deleteConversationState();\n  await context.sendActivity(`Ok I've deleted the current conversation state.`);\n});\n\napp.message('/signout', async (context: TurnContext, state: ApplicationTurnState) =&gt; {\n  await app.authentication.signOutUser(context, state);\n\n  // Echo back users request\n  await context.sendActivity(`You have signed out`);\n});\n\n</code></pre> <p>The above code called a function <code>getUserDisplayName()</code> after token is successfully received with which we can now call Microsoft Graph to get user information. So let's add the function definition. You will install the Graph SDK first. </p> <p>Run below script in the terminal to install the npm package:</p> <pre><code>npm install @microsoft/microsoft-graph-client @microsoft/microsoft-graph-types\n</code></pre> <p>Now, import module needed from the package in app.ts file.</p> <pre><code>import { Client } from \"@microsoft/microsoft-graph-client\";\n</code></pre> <p>Paste below code snippet after <code>app.message</code> method:</p> <pre><code>async function getUserDisplayName(token: string): Promise&lt;string | undefined&gt; {\n  let displayName: string | undefined;\n\n  const client = Client.init({\n    authProvider: (done) =&gt; {\n      done(null, token);\n    }\n  });\n\n  try {\n    const user = await client.api('/me').get();\n    displayName = user.displayName;\n  } catch (error) {\n    console.log(`Error calling Graph SDK in getUserDisplayName: ${error}`);\n  }\n\n  return displayName;\n}\n</code></pre> To make this app only work in single tenant, make below changes <ul> <li>Go to <code>aad.manifest.json</code> and update signInAudience node as <code>\"signInAudience\": \"AzureADMyOrg\"</code></li> <li>Got to <code>teamsapp.local.yml</code> and update signInAudience node for the aadApp\\create as <code>\"signInAudience: \"AzureADMyOrg\"</code></li> <li>Got to <code>src\\app\\app.ts</code> and update application definition's auth setting's authority as <code>authority: config.aadAppOauthAuthority</code></li> <li>Got to <code>src\\public\\auth-start.html</code> and set variable <code>authorizeEndpoint</code> to <code>https://login.microsoftonline.com/${tenantId}/oauth2/v2.0/authorize?${toQueryString(queryParams)}</code> </li> <li>Go to <code>src\\adapter.ts</code> and update the adapter definition <code>MicrosoftAppType: 'SingleTenant'</code> </li> </ul> <p></p>"},{"location":"pages/custom-engine/teams-ai/04-authentication/#exercise-4-run-the-application","title":"Exercise 4: Run the application","text":"<p>Now we are code complete for Teams SSO in Career Genie. Let's take it for a ride.</p>"},{"location":"pages/custom-engine/teams-ai/04-authentication/#step-1-app-installation-in-teams","title":"Step 1: App installation in Teams","text":"<p>Start debugging your app by selecting Run and Debug tab on Visual Studio Code and Debug in Teams (Edge) or Debug in Teams (Chrome). This will open Microsoft Teams in your browser. When your app details appear in Teams, select Add to start chatting with your app.</p> <p>Tip: Testing this exercise locally</p> <p>Make sure to test and debug this exercise on Teams locally, as some of the Teams AI library capabilities you've implemented in your app so far won't smoothly work in the Teams App Test Tool.</p> <p></p>"},{"location":"pages/custom-engine/teams-ai/04-authentication/#step-2-giving-consent","title":"Step 2: Giving consent","text":"<p>To start a conversation with the Career Genie, simply type a message. For example, you can begin by typing and sending 'Hi'.</p> <p>Tip: Check pop up settings in your browser</p> <p>Make sure <code>Pop up</code> is not blocked by browser for a smoother experience for below instructions.</p> <p>You will see a small dialog box for the additional permissions with \u2018Cancel\u2019 and \u2018Continue\u2019 buttons. This dialog is for logging in and giving your consent to the required permissions. Select Continue.</p> <p></p> <p>Known issues</p> <ul> <li>There is a delay for the consent dialog to show up in Teams chat. This has been identified as a platform issue and we are monitoring it. Keep pinging 2-3 times.</li> </ul> <p>Since you're running locally with Developer Tunnels, you'll see a warning screen, select Continue. Users won't see this when your app is deployed.</p> <p></p> <p>You'll be redirected to Entra ID, where you'll be asked to consent to the app's permissions. (You were directed there by public/auth-start.html which gets displayed when it found you hadn't consented).</p> <p></p> <p>Tip: Consent on behalf of your organization</p> <p>If you're a Microsoft 365 administrator, you will also be given the option to \"Consent on behalf of your organization\" which will consent for every user in your tenant.</p> <p>Select Accept to consent to the permissions and run Career Genie.</p> <p>You will now get this message from the custom engine agent with your logged in name showing successful authentication.</p> <p></p> <p>You can start chatting with your custom engine agent.</p> <p></p> <p>CONGRATULATIONS!</p> <p>You have completed Lab BTA4 - Add single sign on authentication to secure your custom engine agent!  If you want explore further, the source code of this lab is available in the Copilot Developer Camp repo.</p> <p>You can now proceed to Lab BTA5 - Add actions to handle complex tasks. Select Next.</p> <p></p> <p></p>"},{"location":"pages/custom-engine/teams-ai/05-actions/","title":"Lab BTA5 - Add actions to handle complex tasks","text":"<p>In this lab you will:</p> <ul> <li>Learn what actions are and how to handle complex tasks with them</li> <li>Integrate multi-prompt in your custom engine agent to handle actions</li> <li>Implement actions in your custom engine agent</li> <li>Utilize Microsoft Graph and actions together to automate workflows</li> </ul> Get a quick overview of the lab in this video. <p>Do these labs if you want to build a Custom engine agent with custom AI model and orchestration using Azure OpenAI and Teams AI library</p> <ul> <li>BTA0 - Setup</li> <li>BTA1 - First custom engine agent</li> <li>BTA2 - Index your data in Azure AI Search</li> <li>BTA3 - Enhance the user experience</li> <li>BTA4 - Add single sign on authentication</li> <li>BTA5 - Add actions to handle complex tasks</li> </ul>"},{"location":"pages/custom-engine/teams-ai/05-actions/#introduction","title":"Introduction","text":"<p>It's time to add some actions for Career Genie to handle complex tasks and workflows! In this lab, you'll integrate a new prompt in Career Genie's logic that can handle lists of candidates. That basically means that when you are searching for candidates with Career Genie, you can also create lists for candidates and add their names in. Once you are done, you can also send these lists to HR for scheduling interviews. All these will be handled by actions you'll implement in Career Genie! Let's get started.</p> What are actions in Custom engine agents? <p>An action in an AI system is like a basic function or method in your code\u2014it's a specific task that the system can perform. Actions are the building blocks that the AI uses to accomplish various tasks based on the user\u2019s input. The AI system decides which action to execute depending on what the user asks for.</p> <p>For example, actions could include:</p> <ul> <li> <p>Creating a new list.</p> </li> <li> <p>Removing a list.</p> </li> <li> <p>Adding items to an existing list.</p> </li> <li> <p>Removing items from an existing list.</p> </li> </ul> <p>When a user interacts with the AI system, the system interprets the prompt and selects the appropriate actions to carry out. It\u2019s like having a toolbox of functions, and the AI picks the right tool for the job based on the user\u2019s needs.</p>"},{"location":"pages/custom-engine/teams-ai/05-actions/#exercise-1-create-a-new-prompt-with-actions","title":"Exercise 1: Create a new prompt with actions","text":"<p>In this exercise, you'll create a new prompt in \"prompts\" folder to handle actions.</p>"},{"location":"pages/custom-engine/teams-ai/05-actions/#step-1-create-a-monologue-prompt","title":"Step 1: Create a \"monologue\" prompt","text":"<p>In your project, go to <code>src/prompts/</code> and add a new folder with a name monologue. In <code>src/prompts/monologue/</code> folder, create a new file with a name config.json and copy the following code snippet in the file:</p> <pre><code>{\n  \"schema\": 1.1,\n  \"description\": \"A bot that can chat with users\",\n  \"type\": \"completion\",\n  \"completion\": {\n    \"completion_type\": \"chat\",\n    \"include_history\": true,\n    \"include_input\": true,\n    \"max_input_tokens\": 2800,\n    \"max_tokens\": 1000,\n    \"temperature\": 0.9,\n    \"top_p\": 0.0,\n    \"presence_penalty\": 0.6,\n    \"frequency_penalty\": 0.0\n  },\n  \"augmentation\": {\n      \"augmentation_type\": \"monologue\"\n  }\n}\n</code></pre> <p>Brief intro about <code>augmentation</code> in config.json</p> <p>Augmentations help simplify prompt engineering by automatically adding specific instructions to your prompts. With augmentations, you can configure whether you want the AI to handle multi-step tasks (sequence) or think through its actions step by step (monologue).</p> <p>In <code>src/prompts/monologue/</code> folder, create a new file with a name skprompt.txt and copy the following text in the file:</p> <pre><code>You are a career specialist named \"Career Genie\" that helps Human Resources team who can manage lists of Candidates. \nYou are friendly and professional. You like using emojis where appropriate.\nAlways share the lists in bullet points.\n\nrules:\n- only create lists the user has explicitly asked to create.\n- only add Candidates to a list that the user has asked to have added.\n- if multiple lists are being manipulated, call a separate action for each list.\n- if Candidates are being added and removed from a list, call a separate action for each operation.\n- if user asks for a summary, share all the lists and candidates. \n- only send an email to HR if user has explicitly asked to send.\n\nCurrent lists:\n{{$conversation.lists}}\n</code></pre> <p>In <code>src/prompts/monologue/</code> folder, create a new file with a name actions.json and copy the following code snippet in the file:</p> <pre><code>[\n    {\n        \"name\": \"createList\",\n        \"description\": \"Creates a new list with an optional set of initial Candidates\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"list\": {\n                    \"type\": \"string\",\n                    \"description\": \"The name of the list to create\"\n                },\n                \"Candidates\": {\n                    \"type\": \"array\",\n                    \"description\": \"The Candidates to add to the list\",\n                    \"Candidates\": {\n                        \"type\": \"string\"\n                    }\n                }\n            },\n            \"required\": [\n                \"list\"\n            ]\n        }\n    },\n    {\n        \"name\": \"deleteList\",\n        \"description\": \"Deletes a list\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"list\": {\n                    \"type\": \"string\",\n                    \"description\": \"The name of the list to delete\"\n                }\n            },\n            \"required\": [\n                \"list\"\n            ]\n        }\n    },\n    {\n        \"name\": \"addCandidates\",\n        \"description\": \"Adds one or more Candidates to a list\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"list\": {\n                    \"type\": \"string\",\n                    \"description\": \"The name of the list to add the item to\"\n                },\n                \"Candidates\": {\n                    \"type\": \"array\",\n                    \"description\": \"The Candidates to add to the list\",\n                    \"Candidates\": {\n                        \"type\": \"string\"\n                    }\n                }\n            },\n            \"required\": [\n                \"list\",\n                \"Candidates\"\n            ]\n        }\n    },\n    {\n        \"name\": \"removeCandidates\",\n        \"description\": \"Removes one or more Candidates from a list\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"list\": {\n                    \"type\": \"string\",\n                    \"description\": \"The name of the list to remove the item from\"\n                },\n                \"Candidates\": {\n                    \"type\": \"array\",\n                    \"description\": \"The Candidates to remove from the list\",\n                    \"Candidates\": {\n                        \"type\": \"string\"\n                    }\n                }\n            },\n            \"required\": [\n                \"list\",\n                \"Candidates\"\n            ]\n        }\n    }\n]\n</code></pre> <p></p>"},{"location":"pages/custom-engine/teams-ai/05-actions/#exercise-2-implement-a-logic-in-the-planner-to-choose-between-prompts","title":"Exercise 2: Implement a logic in the planner to choose between prompts","text":"<p>In this exercise, you'll write a function that checks the user prompt and decides between \"chat\" or \"monologue\" prompts.</p>"},{"location":"pages/custom-engine/teams-ai/05-actions/#step-1-create-a-function-for-defaultprompt-in-the-planner","title":"Step 1: Create a function for <code>defaultPrompt</code> in the planner","text":"<p>In your project, go to <code>src/app/app.ts</code> file, and add the following function in your project:</p> <pre><code>async function choosePrompt(context){\n  if (context.activity.text.includes('list')){\n    const template = await prompts.getPrompt('monologue');\n    return template;\n  }\n  else {\n    const template = await prompts.getPrompt('chat');\n    const skprompt = fs.readFileSync(path.join(__dirname, '..', 'prompts', 'chat', 'skprompt.txt'));\n\n    const dataSources = (template.config.completion as any)['data_sources'];\n\n    dataSources.forEach((dataSource: any) =&gt; {\n      if (dataSource.type === 'azure_search') {\n        dataSource.parameters.authentication.key = config.azureSearchKey;\n        dataSource.parameters.endpoint = config.azureSearchEndpoint;\n        dataSource.parameters.indexName = config.indexName;\n        dataSource.parameters.embedding_dependency.deployment_name =\n          config.azureOpenAIEmbeddingDeploymentName;\n        dataSource.parameters.role_information = `${skprompt.toString('utf-8')}`;\n      }\n    });\n\n    return template;\n  }\n}\n</code></pre> <p>Review <code>choosePrompt</code> function</p> <p>Recognize that the choosePrompt function checks if user prompt includes \"list\". If yes, then it returns monologue prompt, if no, then it returns the chat that is currently our default prompt.</p> <p>In <code>src/app/app.ts</code> file, find the <code>planner</code> and remove the code assigned to the defaultPrompt. Then, define <code>choosePrompt</code> function as the defaultPrompt. The final version of the planner will look like below:</p> <pre><code>const planner = new ActionPlanner({\n  model,\n  prompts,\n  defaultPrompt: choosePrompt,\n});\n</code></pre> <p></p>"},{"location":"pages/custom-engine/teams-ai/05-actions/#exercise-3-implement-actions-in-the-app","title":"Exercise 3: Implement actions in the app","text":"<p>In this exercise, you'll create functions for your actions and register the action handlers in the app.</p>"},{"location":"pages/custom-engine/teams-ai/05-actions/#step-1-update-conversationstate-and-define-functions-for-each-action","title":"Step 1: Update <code>ConversationState</code> and define functions for each action","text":"<p>In <code>src/app/app.ts</code>, update the <code>@microsoft/teams-ai</code> with DefaultConversationState. The final version of the import will look as below:</p> <pre><code>import { AuthError, ActionPlanner, OpenAIModel, PromptManager, AI, PredictedSayCommand, Application, TurnState, DefaultConversationState } from \"@microsoft/teams-ai\";\n</code></pre> <p>In <code>src/app/app.ts</code>, find the ConversationState and ApplicationTurnState, replace them with the following code:</p> <pre><code>// Strongly type the applications turn state\ninterface ConversationState extends DefaultConversationState {\n  lists: Record&lt;string, string[]&gt;;\n}\nexport type ApplicationTurnState = TurnState&lt;ConversationState&gt;;\n</code></pre> <p>In <code>src/app/</code> folder, create another file with a name actions.ts and add the following source code to define functions for the actions:</p> <pre><code>import { ApplicationTurnState } from './app';\n\nfunction getCandidates(state: ApplicationTurnState, list: string): string[] {\n    ensureListExists(state, list);\n    return state.conversation.lists[list];\n}\n\nfunction setCandidates(state: ApplicationTurnState, list: string, Candidates: string[]): void {\n    ensureListExists(state, list);\n    state.conversation.lists[list] = Candidates ?? [];\n}\n\nfunction ensureListExists(state: ApplicationTurnState, listName: string): void {\n    if (typeof state.conversation.lists != 'object') {\n        state.conversation.lists = {};\n    }\n\n    if (!Object.prototype.hasOwnProperty.call(state.conversation.lists, listName)) {\n        state.conversation.lists[listName] = [];\n    }\n}\n\nfunction deleteList(state: ApplicationTurnState, listName: string): void {\n    if (\n        typeof state.conversation.lists == 'object' &amp;&amp;\n        Object.prototype.hasOwnProperty.call(state.conversation.lists, listName)\n    ) {\n        delete state.conversation.lists[listName];\n    }\n}\n\nexport { getCandidates, setCandidates, ensureListExists, deleteList };\n</code></pre> <p></p>"},{"location":"pages/custom-engine/teams-ai/05-actions/#step-2-register-action-handlers-in-the-app","title":"Step 2: Register action handlers in the app","text":"<p>In<code>src/app/app.ts</code>, add the following action imports on top of the file:</p> <pre><code>import { ensureListExists, getCandidates, setCandidates, deleteList } from \"./actions\";\n</code></pre> <p>Then add the following code snippet in the <code>src/app/app.ts</code> to register action handlers in the AI System:</p> <pre><code>// Register action handlers\ninterface ListOnly {\n  list: string;\n}\n\ninterface ListAndCandidates extends ListOnly {\n  Candidates?: string[];\n}\n\napp.ai.action('createList', async (context: TurnContext, state: ApplicationTurnState, parameters: ListAndCandidates) =&gt; {\n  ensureListExists(state, parameters.list);\n  if (Array.isArray(parameters.Candidates) &amp;&amp; parameters.Candidates.length &gt; 0) {\n      await app.ai.doAction(context, state, 'addCandidates', parameters);\n      return `List created and Candidates added. Summarize your action.`;\n  } else {\n      return `List created. Summarize your action.`;\n  }\n});\n\napp.ai.action('deleteList', async (context: TurnContext, state: ApplicationTurnState, parameters: ListOnly) =&gt; {\n  deleteList(state, parameters.list);\n  return `list deleted. Summarize your action.`;\n});\n\napp.ai.action('addCandidates', async (context: TurnContext, state: ApplicationTurnState, parameters: ListAndCandidates) =&gt; {\n  const Candidates = getCandidates(state, parameters.list);\n  Candidates.push(...(parameters.Candidates ?? []));\n  setCandidates(state, parameters.list, Candidates);\n  return `Candidates added. Summarize your action.`;\n});\n\napp.ai.action('removeCandidates', async (context: TurnContext, state: ApplicationTurnState, parameters: ListAndCandidates) =&gt; {\n  const Candidates = getCandidates(state, parameters.list);\n  (parameters.Candidates ?? []).forEach((candidate: string) =&gt; {\n      const index = Candidates.indexOf(candidate);\n      if (index &gt;= 0) {\n          Candidates.splice(index, 1);\n      }\n  });\n  setCandidates(state, parameters.list, Candidates);\n  return `Candidates removed. Summarize your action.`;\n});\n\n</code></pre> <p></p>"},{"location":"pages/custom-engine/teams-ai/05-actions/#step-3-test-your-app-with-the-new-actions","title":"Step 3: Test your app with the new actions","text":"<p>Let's test Career Genie with the new actions. Start debugging your app by selecting Run and Debug tab on Visual Studio Code and Debug in Teams (Edge) or Debug in Teams (Chrome). Microsoft Teams will pop up on your browser. Once your app details show up on Teams, select Add and start chatting with your app.</p> <p>Tip: Testing this exercise locally</p> <p>Make sure to test and debug this exercise on Teams locally, as some of the Teams AI library capabilities you've implemented in your app so far won't smoothly work in the Teams App Test Tool.</p> <p>To understand how the flow works, you may ask the following questions in order:</p> <ul> <li>Hello</li> <li>Can you suggest candidates who have experience in .NET?</li> <li>Great, add Isaac Talbot in the .NET Developer Candidates list</li> <li>Add Anthony Ivanov in the same list with Isaac</li> <li>Can you summarize my lists</li> <li>Suggest candidates who have experience in Python and are able to speak Spanish</li> <li>Nice! Add Sara Folgueroles in the Python Developer Candidates (Spanish speaking) list</li> <li>Can you suggest candidates who have 10+ years of experience</li> <li>Ok, remove Anthony from the .NET Developer Candidates list</li> <li>Add Anthony Ivanov in the Talent list</li> <li>Summarize my lists</li> </ul> <p></p> <p></p>"},{"location":"pages/custom-engine/teams-ai/05-actions/#exercise-4-utilize-actions-together-with-the-microsoft-graph-to-automate-workflows","title":"Exercise 4: Utilize actions together with the Microsoft Graph to automate workflows","text":"<p>In this exercise, you'll implement a new action that utilizes Microsoft Graph to send the candidates lists to the HR for scheduling interviews.</p>"},{"location":"pages/custom-engine/teams-ai/05-actions/#step-1-define-a-new-action-in-your-prompt-for-sending-emails","title":"Step 1: Define a new action in your prompt for sending emails","text":"<p>In your project, go to <code>src/prompts/monologue/actions.json</code> and add the following action:</p> <pre><code>,\n{\n    \"name\": \"sendLists\",\n    \"description\": \"Send list of Candidates to Human Resources, aka HR for scheduling interviews\",\n    \"parameters\": {\n        \"type\": \"object\",\n        \"properties\": {\n            \"list\": {\n                \"type\": \"string\",\n                \"description\": \"The name of the list to send Human Resources, aka HR for scheduling interviews\"\n            },\n            \"Candidates\": {\n                \"type\": \"array\",\n                \"description\": \"The Candidates in the list to send Human Resources, aka HR for scheduling interviews\",\n                \"Candidates\": {\n                    \"type\": \"string\"\n                }\n            }\n        },\n        \"required\": [\n            \"list\",\n            \"Candidates\"\n        ]\n    }\n}\n</code></pre> <p></p>"},{"location":"pages/custom-engine/teams-ai/05-actions/#step-2-create-a-new-function-for-the-new-sendlists-action","title":"Step 2: Create a new function for the new <code>sendLists</code> action","text":"<p>In your project, go to <code>src/app/app.ts</code>, locate the <code>getUserDisplayName</code> and add export in front of the function. The final version of the function will look like below:</p> <pre><code>export async function getUserDisplayName {\n...\n...\n...\n}\n\n</code></pre> <p>Locate <code>app</code> in the <code>src/app/app.ts</code> and update the scope with 'Mail.Send'. The final version of the app will look like below:</p> <pre><code>const app = new Application({\n  storage,\n  authentication: {settings: {\n    graph: {\n      scopes: ['User.Read', 'Mail.Send'],\n        ...\n        ...\n    }\n  }}});\n</code></pre> <p>Go to <code>env/.env.local.user</code> and add the following HR email as an environment variable:</p> <pre><code>HR_EMAIL=&lt;YOUR-EMAIL-ADDRESS&gt;\n</code></pre> <p><code>HR_EMAIL</code> details to test this lab</p> <p>Please enter your own account email address in <code>HR_EMAIL</code> to test this lab. In an ideal scenario, you'll use an email address of a Human Resources Team to send interview scheduling emails. Note that this lab is only for prototyping purposes and shouldn't be used in production.</p> <p>Go to <code>teamsapp.local.yml</code> and add the following line under the <code>file/createOrUpdateEnvironmentFile</code>, envs list:</p> <pre><code>HR_EMAIL: ${{HR_EMAIL}}\n</code></pre> <p>Go to <code>src/config.ts</code> and add the following line in the config:</p> <pre><code>HR_EMAIL: process.env.HR_EMAIL\n</code></pre> <p>Go to <code>src/app/actions.ts</code> and update the imports on top of the code as below:</p> <pre><code>import { getUserDisplayName, ApplicationTurnState } from './app';\nimport { Client } from \"@microsoft/microsoft-graph-client\";\nimport config from '../config';\n</code></pre> <p>Then, add the following functions in the <code>actions.ts</code>:</p> <pre><code>async function sendLists(state: ApplicationTurnState, token): Promise&lt;string&gt; {\n    const email = await createEmailContent(state.conversation.lists, token);\n    try {\n        const client = Client.init({\n            authProvider: (done) =&gt; {\n                done(null, token);\n            }\n        });\n        const sendEmail = await client.api('/me/sendMail').post(JSON.stringify(email));\n        if (sendEmail.ok) {\n            return email.message.body.content;\n        }\n        else {\n            console.log(`Error ${sendEmail.status} calling Graph in sendToHR: ${sendEmail.statusText}`);\n            return 'Error sending email';\n        }\n    } catch (error) {\n        console.error('Error in sendLists:', error);\n        throw error;\n    }\n}\n\nasync function createEmailContent(lists, token) {\n    let emailContent = '';\n    for (const listName in lists) {\n        if (lists.hasOwnProperty(listName)) {\n        emailContent += `${listName}:\\n`;\n        lists[listName].forEach(candidate =&gt; {\n            emailContent += `  \u2022 ${candidate}\\n`;\n        });\n        emailContent += '\\n'; // Add an extra line between different lists\n        }\n    }\n\n    const profileName = await getUserDisplayName(token);\n\n    const email ={\n        \"message\": {\n        \"subject\": \"Request to Schedule Interviews with Shortlisted Candidates\",\n        \"body\": {\n            \"contentType\": \"Text\",\n            \"content\": `Hello HR Team, \\nI hope this email finds you well. \\n\\nCould you please assist in scheduling 1:1 interviews with the following shortlisted candidates? \\n\\n${emailContent} Please arrange suitable times and send out the calendar invites accordingly. \\n\\n Best Regards, \\n ${profileName}`\n        },\n        \"toRecipients\": [\n            {\n            \"emailAddress\": {\n                \"address\": `${config.HR_EMAIL}`\n            }\n            }\n        ]\n        },\n        \"saveToSentCandidates\": \"true\"\n    };\n    return await email;\n}\n</code></pre> <p>Finally in <code>src/app/actions.ts</code>, add sendLists in the<code>actions.ts</code> exports. The final version of the exports will look like below:</p> <pre><code>export { getCandidates, setCandidates, ensureListExists, deleteList, sendLists };\n</code></pre> <p></p>"},{"location":"pages/custom-engine/teams-ai/05-actions/#step-3-register-sendlists-action-handler","title":"Step 3: Register <code>sendLists</code> action handler","text":"<p>Go to <code>src/app/app.ts</code> and update the <code>./actions</code> import with the sendLists function. The final version of the import will look as below:</p> <pre><code>import { ensureListExists, getCandidates, setCandidates, deleteList, sendLists } from \"./actions\";\n</code></pre> <p>Then, add the following code snippet to register <code>sendLists</code> action in the AI System:</p> <pre><code>app.ai.action('sendLists', async (context: TurnContext, state: ApplicationTurnState, parameters: ListAndCandidates) =&gt; {\n  await sendLists(state, state.temp.authTokens['graph']);\n  return `Email sent to HR. Summarize your action.`;\n});\n</code></pre> <p></p>"},{"location":"pages/custom-engine/teams-ai/05-actions/#step-4-update-your-entra-id-app-registration","title":"Step 4: Update your Entra ID app registration","text":"<p>Update the script for your Entra ID app for new scope <code>Mail.Send</code>. Go to file aad.manifest.json and inside the node <code>requiredResourceAccess</code> find <code>\"resourceAppId\": \"Microsoft Graph\",</code>. In the <code>resourceAccess</code> array add below scope after adding a comma.</p> <pre><code> {\n    \"id\": \"Mail.Send\",\n    \"type\": \"Scope\"\n}\n</code></pre> <p></p>"},{"location":"pages/custom-engine/teams-ai/05-actions/#step-5-test-your-app-and-the-new-sendlists-action","title":"Step 5: Test your app and the new <code>sendLists</code> action","text":"<p>Let's test Career Genie with the new sendLists actions. Start debugging your app by selecting Run and Debug tab on Visual Studio Code and Debug in Teams (Edge) or Debug in Teams (Chrome). Microsoft Teams will pop up on your browser. Once your app details show up on Teams, select Add and start chatting with your app.</p> <p>Tip: Testing this exercise locally</p> <p>Make sure to test and debug this exercise on Teams locally, as some of the Teams AI library capabilities you've implemented in your app so far won't smoothly work in the Teams App Test Tool.</p> <p>To start a conversation with Career Genie, simply type a message. For example, you can begin with 'Hi'.</p> <p>Tip: Check pop up settings in your browser</p> <p>Make sure <code>Pop up</code> is not blocked by browser for a smoother experience for below instructions.</p> <p>You will see a small dialog box for the additional permissions with \u2018Cancel\u2019 and \u2018Continue\u2019 buttons. This dialog is for logging in and giving your consent to the required permissions. Select Continue.</p> <p></p> <p>Since you're running locally with Developer Tunnels, you'll see a warning screen, select Continue. Users won't see this when your app is deployed. You'll be redirected to login and consent to the app's permissions.</p> <p>Tip: Consent on behalf of your organization</p> <p>If you're a Microsoft 365 administrator, you will also be given the option to \"Consent on behalf of your organization\" which will consent for every user in your tenant.</p> <p>Select Accept to consent to the permissions.</p> <p>You will now get a message from Career Genie with your logged in name showing successful authentication. Now, you can start testing the new action in Career Genie!</p> <p>To understand how the flow works, you may ask the following questions in order:</p> <ul> <li>Hello</li> <li>Can you suggest candidates who have experience in .NET?</li> <li>Great, add Isaac Talbot in the .NET Developer Candidates list</li> <li>Add Anthony Ivanov in the same list with Isaac</li> <li>Can you summarize my lists</li> <li>Suggest candidates who have experience in Python and are able to speak Spanish</li> <li>Nice! Add Sara Folgueroles in the Python Developer Candidates (Spanish speaking) list</li> <li>Can you suggest candidates who have 10+ years of experience</li> <li>Ok, remove Anthony from the .NET Developer Candidates list</li> <li>Add Anthony Ivanov in the Talent list</li> <li>Summarize my lists</li> <li>Add Pedro Armijo in the same list with Sara</li> <li>Summarize my lists</li> <li>Send my lists to HR</li> </ul> <p>Check your mailbox</p> <p>After the last step, check your mailbox to see if you received any email for the lists of candidates.</p> <p></p> <p></p> <p>CONGRATULATIONS!</p> <p>You have completed BTA5 - Add actions to handle complex tasks!  If you want explore further, the source code of this lab is available in the Copilot Developer Camp repo.</p> <p>This is the end of the Build your own agent path! Did you enjoy building Career Genie? Let us know about your experience and feedback. \ud83d\udc9c</p> <p></p> <p></p>"},{"location":"pages/extend-m365-copilot/","title":"Extend Microsoft 365 Copilot","text":"<p>Declarative agents are a type of agents for Microsoft 365. You can build one by extending Microsoft 365 Copilot. You define custom knowledge and custom actions to create agents tailored to a specific scenario.</p> <p>Declarative agents use the same infrastructure, orchestrator, foundation model, and security controls as Microsoft 365 Copilot, which ensures a consistent and familiar user experience.</p> <p></p>"},{"location":"pages/extend-m365-copilot/#what-youre-going-to-do","title":"What you're going to do","text":"<p>During Extend Path of the Copilot Developer Camp, you will construct a customized assistant tailored for a Human Resources department. The process will begin with understanding the fundamentals on creating a declarative agent, the creation of a basic declarative agent, and progress towards developing fully skilled assistant. This advanced assistant will be equipped with security features, including authentication mechanism linked to the Microsoft 365 tenant to get organizational data.</p> Section Purpose Setup Gets you ready with prerequisites. Declarative Agent Fundamentals Focuses on declarative agent concepts, start with a base template and explore more. Build and Integrate API Covers API creation and connecting API to agents. Upgrade the user interface with Adaptive cards. Authentication Contains all auth-related labs as sub-items. Integration Expands capability with Copilot connectors, etc."},{"location":"pages/extend-m365-copilot/#start-here-with-lab-e0-where-youll-set-up-development-your-environment","title":"Start here with Lab E0, where you'll set up development your environment","text":""},{"location":"pages/extend-m365-copilot/00-prerequisites/","title":"Lab E0 - Setup","text":"<p>In this lab, you will set up the development environment to build, test, and deploy the Copilot agents, that will help you achieve tailor made AI assitance using Microsoft 365 Copilot. </p> <p>Set up your development environment for Microsoft 365 Copilot</p> <p>This lab currently assumes you already have a tenant to setup. You can reference off to the page here that explains the current way you can get a tenant.</p> <p>In this lab you will learn:</p> <ul> <li>How to configure your Microsoft 365 tenant's Teams upload policy for lab use</li> <li>How to install and configure Microsoft 365 Agents Toolkit for Visual Studio Code</li> </ul> Get a quick overview of the lab in this video.              \u26a0\ufe0f Disclaimer: These samples and labs are intended for instructive and demonstration purposes and are not intended for use in production. Do not put them into production without upgrading them to production quality.          <p>Do these labs if you want to build a Declarative agent where Microsoft 365 provides the AI model and               orchestration</p> <ul> <li>\ud83c\udfc1 Welcome</li> <li>\ud83d\udd27 Set up <ul> <li>Lab E0 - Setup</li> </ul> </li> <li>\ud83e\uddf0 Declarative agent fundamentals <ul> <li> Lab E1 - Build a  Declarative Agent using TypeSpec </li> <li> Lab E1a - Geo locator game</li> </ul> </li> <li>\ud83d\udee0\ufe0f Build and integrate API from scratch <ul> <li>Lab E2 - Build an API</li> <li> Lab E3 - Add Declarative Agent + API</li> <li> Lab E4 - Enhance API + Plugin</li> <li>Lab E5 - Add Adaptive Cards</li> <li> Lab E6a - Add Authentication</li> </ul> </li> <li>\ud83d\udd0c Integration <ul> <li> Lab E7 - Add Copilot Connector</li> </ul> <ul> <li> Lab E8 - Connect Declarative agent to MCP Server</li> </ul> <ul> <li> Lab E9 - Connected Agents</li> </ul> </li> </ul>"},{"location":"pages/extend-m365-copilot/00-prerequisites/#exercise-1-configure-teams-upload-policy","title":"Exercise 1 : Configure Teams upload policy","text":""},{"location":"pages/extend-m365-copilot/00-prerequisites/#step-1-enable-teams-custom-application-uploads","title":"Step 1: Enable Teams custom application uploads","text":"<p>By default, end users can't upload applications directly; instead a Teams Administrator needs to upload them into the enterprise app catalog. In this step you will ensure your tenant is set up for direct uploads by Agents Toolkit.</p> <p>1\ufe0f\u20e3 Navigate to https://admin.microsoft.com/, which is the Microsoft 365 Admin Center.</p> <p>2\ufe0f\u20e3 In the left pane of the admin center, select Show all to open up the entire navigation. When the pane opens, select Teams to open the Microsoft Teams admin center.</p> <p>3\ufe0f\u20e3 In the left pane of the Microsoft Teams admin center, open the Teams apps accordion. Select Setup policies, you will see a list of App setup policies. Then, select the Global (Org-wide default) policy.</p> <p>4\ufe0f\u20e3 Ensure the first switch, Upload custom apps is turned On.</p> <p>5\ufe0f\u20e3 Be sure to scroll down and select the Save button to persist your change.</p> <p>The change can take up to 24 hours to take effect, but usually it's much faster.</p> <p></p>"},{"location":"pages/extend-m365-copilot/00-prerequisites/#exercise-2-install-agents-toolkit-and-prerequisites","title":"Exercise 2: Install Agents Toolkit and prerequisites","text":"<p>You can complete these labs on a Windows, Mac, or Linux machine, but you do need the ability to install the prerequisites. If you are not permitted to install applications on your computer, you'll need to find another machine (or virtual machine) to use throughout the workshop.</p>"},{"location":"pages/extend-m365-copilot/00-prerequisites/#step-1-install-visual-studio-code","title":"Step 1: Install Visual Studio Code","text":"<p>It should be no surprise that Agents Toolkit for Visual Studio Code requires Visual Studio Code! You can download it here: Visual Studio Code. The version of VS Code used for authoring these labs : 1.106.3</p> <p></p>"},{"location":"pages/extend-m365-copilot/00-prerequisites/#step-2-install-nodejs","title":"Step 2: Install Node.js","text":"<p>Node.js is a program that allows you to run JavaScript on your computer; it uses the open source \"V8\" engine, which is used in popular web browsers such as Microsoft Edge and Google Chrome. You will need Node.js to run the web server code used throughout this workshop.</p> <p>Browse to https://nodejs.org/en/download/ and install version v22. This lab was last tested in Node Version v22.18.0.  If you already have another version of Node.js installed, you may want to set up the Node Version Manager (or this variation for Microsoft Windows), which allows you to easily switch Node.js versions on the same computer.</p> <p></p>"},{"location":"pages/extend-m365-copilot/00-prerequisites/#step-3-install-agents-toolkit","title":"Step 3: Install Agents Toolkit","text":"<p>These labs are based on Microsoft 365 Agents Toolkit version 6.4.1.</p> <p>What is Agents Toolkit?</p> <p>Microsoft 365 Agents Toolkit is an evolution of Microsoft Teams Toolkit, is designed to help you develop agents and apps for Microsoft 365 Copilot, Microsoft Teams, and Microsoft 365.</p> <p>Follow the steps as shown in the screen shot below.</p> <p>1\ufe0f\u20e3 Open Visual Studio Code and click on the Extensions toolbar button</p> <p>2\ufe0f\u20e3 Search for \"Microsoft 365 Agents\" and locate Agents Toolkit</p> <p>3\ufe0f\u20e3 Click Install</p> <p></p> <p>If you have Agents Toolkit installed but hidden</p> <p>If you previously installed Agents Toolkit, and then hid it on the Visual Studio sidebar, you might wonder why you can't see it. Right-click on the left sidebar and check off Agents Toolkit to bring it back into view.</p> <p></p> <p>CONGRATULATIONS!</p> <p>Now you are all set to create your first extensibility feature for Microsoft 365 Copilot. Proceed to create a Declarative Agent in the next lab. </p> <p></p> <p></p>"},{"location":"pages/extend-m365-copilot/01-typespec-declarative-agent/","title":"Lab E1 - Build your first Declarative agent with TypeSpec definition using Microsoft 365 Agents Toolkit","text":"<p>In this lab your will build a Declarative Agent with TypeSpec definition using Microsoft 365 Agents Toolkit. You will create an agent called <code>RepairServiceAgent</code>, which interacts with repairs data via an existing API service to help users manage car repair records.  You will find the source code to the finished agent here.</p> <p>This lab has been updated to reflect Ignite 2025 announcements. TypeSpec is now GA, and Toolkit version 6.4.1 is released. This lab is based on Lab 560, the hands-on session delivered at Ignite in Nov 2025.</p> Get a quick overview of the lab in this video. <p>Do these labs if you want to build a Declarative agent where Microsoft 365 provides the AI model and               orchestration</p> <ul> <li>\ud83c\udfc1 Welcome</li> <li>\ud83d\udd27 Set up <ul> <li>Lab E0 - Setup</li> </ul> </li> <li>\ud83e\uddf0 Declarative agent fundamentals <ul> <li> Lab E1 - Build a  Declarative Agent using TypeSpec </li> <li> Lab E1a - Geo locator game</li> </ul> </li> <li>\ud83d\udee0\ufe0f Build and integrate API from scratch <ul> <li>Lab E2 - Build an API</li> <li> Lab E3 - Add Declarative Agent + API</li> <li> Lab E4 - Enhance API + Plugin</li> <li>Lab E5 - Add Adaptive Cards</li> <li> Lab E6a - Add Authentication</li> </ul> </li> <li>\ud83d\udd0c Integration <ul> <li> Lab E7 - Add Copilot Connector</li> </ul> <ul> <li> Lab E8 - Connect Declarative agent to MCP Server</li> </ul> <ul> <li> Lab E9 - Connected Agents</li> </ul> </li> </ul>"},{"location":"pages/extend-m365-copilot/01-typespec-declarative-agent/#what-are-declarative-agents","title":"What are Declarative Agents?","text":"<p>Declarative Agents leverage the same scalable infrastructure and platform of Microsoft 365 Copilot, tailored specifically to meet focus on a special area of your needs. They function as subject matter experts in a specific area or business need, allowing you to use the same interface as a standard Microsoft 365 Copilot chat while ensuring they focus exclusively on the specific task at hand.</p>"},{"location":"pages/extend-m365-copilot/01-typespec-declarative-agent/#anatomy-of-a-declarative-agent","title":"Anatomy of a Declarative Agent","text":"<p>As you build more agents for Copilot, you\u2019ll notice that the final output is a set of a few files bundled into a zip file what we call an app package, that you'll install and use. So it's important you have a basic understanding of what the app package consists of. The app package of a Declarative Agent is similar to a Teams app if you have built one before with additonal elements. See the table to see all the core elements. You will also see that the app deployment process is very similar to deploying a Teams app.</p> File Type Description Required App manifest A JSON file (manifest.json) that defines the standard Teams app manifest. Yes Declarative agents manifest A JSON file containing the agent's name, instructions, capabilities, conversation starters, and actions (if applicable). Yes Plugin manifest A JSON file used to configure your action as an API plugin. Includes authentication, required fields, adaptive card responses, etc. Only needed if actions exist. No App icons A color and outline icon for your declarative agent. Yes"},{"location":"pages/extend-m365-copilot/01-typespec-declarative-agent/#capabilities-of-a-declarative-agent","title":"Capabilities of a Declarative Agent","text":"<p>You can enhance the agent's focus on context and data by not only adding instructions but also specifying the knowledge base it should access. They are called capabilities. Below are the ones supported in a Declarative Agent today: </p> <ul> <li>Copilot Connectors - let you centralize content on Microsoft 365. By importing external content to Microsoft 365, you not only make it easier to find relevant information, but you also let others in your organization discover new content.</li> <li>OneDrive and SharePoint - let you provide URLs of files/sites in OneDrive and SharePoint, which will part of the agent's knowledge base.</li> <li>Web search - let you enable or disable web content as part of the agent's knowledge base. You can also pass around 4 websites URLs as source. </li> <li>Code interpreter - enables you to build an agent with capabilities to better solve math problems and, when needed, leverage Python code for complex data analysis or chart generation.</li> <li>GraphicArt - enables you to build an agent for image or video generation using DALL\u00b7E.</li> <li>Email knowledge - enables you to build an agent to acces a personal or shared mailbox, and optionally, a specific mailbox folder as knowledge.</li> <li>People knowledge - enables you to build an agent to answer questions about individuals in an organization.</li> <li>Teams messages - enables you to equip the agent to search through Teams channels, teams, meetings, 1:1 chats, and group chats.</li> <li>Dataverse knowledge - enables you to add a Dataverse instance as a knowledge source.</li> <li>Scenario models - enables you to add task-specific models.</li> <li>Teams Meetings- enables you to build an agent to search for information about meetings in the organization.</li> </ul> <p>OnDrive and SharePoint</p> <p>URLs should be full path to SharePoint items (site, document library, folder, or file). You can use the \"Copy direct link\" option in SharePoint to get the full path of files and folders. To achieve this, right-click on the file or folder and select Details. Navigate to Path and click on the copy icon. Not specifying the URLs, the entire corpus of OneDrive and SharePoint content available to the logged in user will be used by the agent.</p> <p>Microsoft Copilot Connector</p> <p>Not specifying the connections, the entire corpus of Copilot Connectors content available to the logged in user will be used by the agent.</p> <p>Web search</p> <p>Not specifying the sites, the agent is allowed to search all the sites. You can specify up to four sites with no more than 2 path segments and no querystring parameters. </p>"},{"location":"pages/extend-m365-copilot/01-typespec-declarative-agent/#significance-of-typespec-for-declarative-agents","title":"Significance of TypeSpec for Declarative Agents","text":""},{"location":"pages/extend-m365-copilot/01-typespec-declarative-agent/#what-is-typespec","title":"What is TypeSpec","text":"<p>TypeSpec is a language developed by Microsoft for designing and describing API contracts in a structured and type-safe way. Think of it like a blueprint for how an API should look and behave including what data it accepts, returns, and how different parts of the API and its actions are connected.</p>"},{"location":"pages/extend-m365-copilot/01-typespec-declarative-agent/#why-typespec-for-agents","title":"Why TypeSpec for Agents?","text":"<p>If you like how TypeScript enforces structure in your frontend/backend code, you'll love how TypeSpec enforces structure in your agent and its API services like actions. It fits perfectly in design-first development workflows that align with tools like Visual Studio Code.</p> <ul> <li> <p>Clear Communication - provides a single source of truth that defines how your agent should behave, avoiding confusion when dealing with multiple manifest files like in the case of Declarative Agents.</p> </li> <li> <p>Consistency - ensures all parts of your agent and its actions, capabilities etc are designed consistently following the same pattern.</p> </li> <li> <p>Automation Friendly - automatically generates OpenAPI specs and other manifests saving time and reducing human errors.</p> </li> <li> <p>Early Validation - catches design issues early before writing actual code for example, mismatched data types or unclear definitions.</p> </li> <li> <p>Design-First Approach - encourages thinking about agent and API structure and contracts before jumping into implementation, leading to better long-term maintainability.</p> </li> </ul> <p>\u2611\ufe0f Well done understanding all the basic concepts you need to know about Declarative agents and TypeSpec! Proceed to the first exercise.</p>"},{"location":"pages/extend-m365-copilot/01-typespec-declarative-agent/#exercise-1-build-your-first-declarative-agent-with-one-action-that-performs-a-single-operation","title":"Exercise 1: Build your first Declarative Agent with one action that performs a single operation","text":"<p>It\u2019s time to build your first Declarative Agent using Microsoft 365 Agents Toolkit.  You will create an agent called RepairServiceAgent, which interacts with repairs data via an existing Repairs API service to help users manage car repair records. Checkout the  additional prerequisites for this lab, please install them now.</p> <ul> <li>REST Client add-in for Visual Studio Code: You will use one of these toolkits to test your API locally.</li> <li>Microsoft 365 Agents Toolkit version 6.4.0 and up. If you have an older version, update now.</li> </ul>"},{"location":"pages/extend-m365-copilot/01-typespec-declarative-agent/#step-1-scaffold-your-base-agent-project-using-microsoft-365-agents-toolkit","title":"Step 1: Scaffold your base agent project using Microsoft 365 Agents Toolkit","text":"<ul> <li>Open VS Code, locate the Microsoft 365 Agents Toolkit icon  from the VS Code menu on the left and select it. An activity bar will be open. </li> <li>Select the \"Create a New Agent/App\" button in the activity bar which will open the palette with a list of app templates available on Microsoft 365 Agents Toolkit.</li> <li>Choose \"Declarative Agent\" from the list of templates.</li> <li>Next, select \"Start with TypeSpec for Microsoft 365 Copilot\" to define your agent using TypeSpec.</li> <li>Next, select the Default folder where you want the agents toolkit to scaffold the agent project.</li> <li>Next, give an application name like - <code>RepairServiceAgent</code> and select Enter to complete the process. You will get a new VSCode window with the agent project preloaded.</li> </ul> <p>Note</p> <p>You may get a prompt window asking if you trust the authors of the files in the folder. This is expected and you can safely select Yes, I trust the authors. The dialog is a security safeguard that helps you decide whether to run all features or limit execution based on the trustworthiness of the code authors. If you're opening your own code or from a reliable source, it's safe to trust.</p> <p></p>"},{"location":"pages/extend-m365-copilot/01-typespec-declarative-agent/#step-2-sign-into-the-microsoft-365-agents-toolkit","title":"Step 2: Sign into the Microsoft 365 Agents Toolkit","text":"<p>You'll need to sign into the Microsoft 365 Agents Toolkit in order to upload and test your agent from within it.</p> <ul> <li>Within the project window, select the Microsoft 365 Agents Toolkit icon  again from the left side menu. This will open the Agent Toolkit\u2019s activity bar with sections like Accounts, Environment, Development etc. </li> <li>Under \"Accounts\" section select \"Sign in to Microsoft 365\". This will open a dialog from the editor to sign in or create a Microsoft 365 developer sandbox or Cancel. Select \"Sign in\". </li> <li>Once signed in, close the browser and go back to the project window.</li> </ul> <p></p>"},{"location":"pages/extend-m365-copilot/01-typespec-declarative-agent/#step-3-define-your-agent","title":"Step 3: Define your agent","text":"<p>The Declarative Agent project scaffolded by the Agents Toolkit provides a template that includes code for connecting an agent to the GitHub API to display repository issues. In this lab, you'll build your own agent that integrates with a Repairs API service, supporting multiple operations to manage repair data.</p> <p>Before proceeding with the agent definition, take a moment to examine the Repairs API service to gain a clearer understanding of its functionality.</p>"},{"location":"pages/extend-m365-copilot/01-typespec-declarative-agent/#get-to-know-the-repair-api-service","title":"Get to know the repair API service","text":"<p>You'll need to explore endpoints and payloads of the API service interactively. Using a .http file in Visual Studio Code with the REST Client extension, which is already installed for you, allows you to define and send HTTP requests directly from your editor. It's a lightweight, code-friendly way to test APIs, inspect responses, and iterate quickly without switching to external tools.</p> <p>Inside the root folder of the project you just created, create a folder called http. Create a new file named <code>repairs-api.http</code> inside the http folder.</p> <p>Note</p> <p>Creating folders and files in VS Code:</p> <ul> <li> <p>To create a new folder: Right-click in the Explorer panel (file tree) on the left side of VS Code, select \"New Folder\", and type the folder name.</p> </li> <li> <p>To create a new file: Right-click on the folder where you want to add the file, select \"New File\", and type the filename with its extension.</p> </li> <li> <p>Alternatively, you can use the icons in the Explorer panel: the folder icon (\ud83d\udcc1) creates a new folder, and the file icon (\ud83d\udcc4) creates a new file in the currently selected location.</p> </li> </ul> <p>Copy paste below content into the file.</p> <pre><code>@base_url = https://repairshub.azurewebsites.net\n\n### Get all repair requests\n{{base_url}}/repairs\n\n### Get a specific repair request by ID\n{{base_url}}/repairs/1\n\n### Create a new repair request\nPOST {{base_url}}/repairs\nContent-Type: application/json\n\n{\n  \"description\": \"Repair broken screen\",\n  \"date\": \"2023-10-01T12:00:00Z\",\n  \"image\": \"https://example.com/image.png\"\n}\n\n### Update an existing repair request\nPATCH {{base_url}}/repairs/1\nContent-Type: application/json  \n\n{\n  \"id\": 1,\n  \"description\": \"Repair broken screen - updated\",\n  \"date\": \"2023-10-01T12:00:00Z\",\n  \"image\": \"https://example.com/image-updated.png\"\n}\n\n\n### Delete a repair request by ID\nDELETE {{base_url}}/repairs/10\nContent-Type: application/json\n\n{\n  \"id\": 10\n}\n</code></pre> <p>Note there is a small delay to process the request from the editor, but the response should come back in a few seconds.</p> <p>To run each request, hover over each request line (e.g., GET {{base_url}}/repairs) and click Send Request to see the response. Observe the structure of requests and responses and use the response data to understand how your agent will interact with the API.</p> <p></p>"},{"location":"pages/extend-m365-copilot/01-typespec-declarative-agent/#repairs-api-overview","title":"Repairs API Overview","text":"<p>Base URL: https://repairshub.azurewebsites.net</p> Operation Method Endpoint Payload required Purpose Get all repair requests GET /repairs No Retrieve all repair jobs Get repair by ID GET /repairs/{id} No Fetch a specific repair job Create a repair request POST /repairs Yes Submit a new repair job Update a repair request PATCH /repairs/{id} Yes Modify an existing repair job Delete a repair request DELETE /repairs/{id} No Remove a repair job by ID <p>Now that you're familiar with the API service, let's move on to integrating it with your agent.</p>"},{"location":"pages/extend-m365-copilot/01-typespec-declarative-agent/#project-structure","title":"Project structure","text":"<p>Within your agent project under src folder, you'll discover the core TypeSpec configuration files: main.tsp and env.tsp.</p> <p>The main.tsp file serves as the primary definition point for your agent, containing essential metadata, behavioral instructions, and capability specifications.</p> <p>The env.tsp file is used by the toolkit to process environment variables during compilation. This file is generated from env/.env.* files and offer variables for other TypeSpec files, so manual updates are not required.</p> <p>You'll also find an actions folder containing template files - initially including github.tsp which demonstrates GitHub API integration. For this lab, you'll replace this template with your own action definitions to establish connectivity with the Repairs API service.</p> <p>Additionally, there's a prompts folder housing the instructions.tsp file, which allows you to define detailed behavioral instructions and guidance for your agent.</p>"},{"location":"pages/extend-m365-copilot/01-typespec-declarative-agent/#update-the-agent-metadata-and-instructions","title":"Update the Agent Metadata and Instructions","text":"<p>Open main.tsp and inspect what is there in the default template, which you will modify for our agent's repair service scenario.</p> <p>In the main.tsp file, you will find the basic structure of the agent. Review the content provided by the agents toolkit template which includes: -   Agent name and description 1\ufe0f\u20e3 -   Basic instructions 2\ufe0f\u20e3 -   Placeholder code for actions and capabilities (commented out) 3\ufe0f\u20e3</p> <p></p> <p>Begin by defining your agent for the repair scenario. Replace the @agent metadata with below code snippet.</p> <pre><code>@agent(\n  \"RepairServiceAgent\",\n  \"An agent for managing repair information\"\n)\n\n</code></pre> <p>Next, configure a conversation starter, the initial prompt that begins user-agent interaction. Uncomment the default template section and update the title and text fields to match the agent scenario.</p> <pre><code>// Uncomment this part to add a conversation starter to the agent.\n// This will be shown to the user when the agent is first created.\n@conversationStarter(#{\n  title: \"List repairs\",\n  text: \"List all repairs\"\n})\n\n</code></pre> <p>This starter prompt needs to trigger a GET operation to retrieve all repairs from the service. To enable this behaviour in the agent, you' ll need to define the corresponding action. Proceed to the next step to do so.</p> <p>Next, go to prompts/instructions.tsp and update the instructions. Replace the entire code block in the file with below code:</p> <pre><code>namespace Prompts {\n  const INSTRUCTIONS = \"\"\"\n    ## Purpose\n    You will assist the user in finding car repair records based on the information provided by the user.\n  \"\"\";\n}\n\n</code></pre>"},{"location":"pages/extend-m365-copilot/01-typespec-declarative-agent/#define-the-action-for-the-agent","title":"Define the action for the agent","text":"<p>Next, you will define the action for your agent by opening the actions/github.tsp file. Rename this file to actions.tsp.  You can rename a file in VSCode by right clicking on the file and choosing \"Rename\". </p> <p>You'll return to the main.tsp file later to complete the agent metadata with the action reference, but first, the action itself must be defined. For that open the file actions.tsp.</p> <p>The default actions.tsp template demonstrates how to define an agent action, including metadata, service URL, and operation structure. Replace the sample GitHub logic entirely with definitions relevant to the Repairs API service.</p> <p>After the module-level directives like import and using statements, replace the existing code up to the point where the \"SERVER_URL\" is defined with the snippet below. </p> <pre><code>@service\n@server(RepairsAPI.SERVER_URL)\n@actions(RepairsAPI.ACTIONS_METADATA)\nnamespace RepairsAPI{\n  /**\n   * Metadata for the API actions.\n   */\n  const ACTIONS_METADATA = #{\n    nameForHuman: \"Repair Service Agent\",\n    descriptionForHuman: \"Manage your repairs and maintenance tasks.\",\n    descriptionForModel: \"Plugin to add, update, remove, and view repair objects.\",\n    legalInfoUrl: \"https://docs.github.com/en/site-policy/github-terms/github-terms-of-service\",\n    privacyPolicyUrl: \"https://docs.github.com/en/site-policy/privacy-policies/github-general-privacy-statement\"\n  };\n\n  /**\n   * The base URL for the  API.\n   */\n  const SERVER_URL = \"https://repairshub.azurewebsites.net\";\n\n</code></pre> <p>Next, replace the operation in the template code from \"searchIssues\" to \"listRepairs\" to get the list of repairs. Replace the entire block of code starting just after the SERVER_URL definition and ending just before the final closing braces with the snippet below. Be sure to leave the closing braces intact. </p> <p>Remember to alway copy the code comment section as well here, do not ignore as they form the documentation for this action and is needed at compile time. </p> <pre><code>  /**\n   * List repairs from the API \n   * @param assignedTo The user assigned to a repair item.\n   */\n\n  @route(\"/repairs\")\n  @get  op listRepairs(@query assignedTo?: string): string;\n\n</code></pre> <p>Now go back to main.tsp file and verify the import statement for actions. If it still references ./actions/github.tsp, replace import \"./actions/github.tsp\"; with the statement below:</p> <pre><code>import \"./actions/actions.tsp\";\n</code></pre> <p>Next, in the same file, add the action you just defined into the agent. After the conversation starters replace the entire \"RepairServiceAgent\" namespace with below snippet:</p> <pre><code>namespace RepairServiceAgent{  \n\n  op listRepairs is global.RepairsAPI.listRepairs;   \n\n}\n\n</code></pre> <p></p>"},{"location":"pages/extend-m365-copilot/01-typespec-declarative-agent/#step-4-optional-understand-the-decorators","title":"Step 4: (Optional) Understand the decorators","text":"<p>This is an optional step but if curious to know what we have defined in the TypeSpec file just read through this step. In the TypeSpec files main.tsp and actions.tsp, you'll find decorators (starting with @), namespaces, models, and other definitions for your agent.</p> <p>Check this table to understand some of the decorators used in these files </p> Annotation Description @agent Defines the namespace (name) and description of the agent @instructions Defines the instructions that prescribe the behaviour of the agent. 8000 characters or less @conversationStarter Defines conversation starters for the agent @op Defines any operation. Either it can be an operation to define agent's capabilities like op GraphicArt, op CodeInterpreter etc., or define API operations like op listRepairs. For a post operation, define it like: op createRepair(@body repair: Repair): Repair; @server Defines the server endpoint of the API and its name @capabilities When used inside a function, it defines simple adaptive cards with small definitions like a confirmation card for the operation <p>\u2611\ufe0f You've successfully completed the first exercise! You learned how to add an action to list repairs which is the GET operation. In the next exercise, you'll add more operations for managing repairs and test and debug them.</p> <p>Continue to the next exercise.</p> <p></p>"},{"location":"pages/extend-m365-copilot/01-typespec-declarative-agent/#exercise-2-add-more-operations-test-the-agent-and-learn-debugging-techniques","title":"Exercise 2: Add more operations, test the agent, and learn debugging techniques","text":"<p>Next, you will enhance the agent by adding more operations in the Repairs API service and enabling responses with Adaptive Cards. Let's explore each of these enhancements step by step. If you are in the browser, go back to your project in VS Code.</p>"},{"location":"pages/extend-m365-copilot/01-typespec-declarative-agent/#step-1-modify-agent-to-add-more-operations","title":"Step 1: Modify agent to add more operations","text":"<ul> <li>Go to file actions/actions.tsp and copy paste below snippet just after listRepairs operation to add new operations createRepair, updateRepair and deleteRepair. Here you will also define the Repair item data model.</li> </ul> <pre><code>/**\n   * Create a new repair using the API. \n   * When creating a repair, the `id` field is optional and will be generated by the server.\n   * The `date` field should be in ISO 8601 format (e.g., \"2023-10-01T12:00:00Z\").\n   * The `title` field based on what repair user wants to create\n   * @param repair The repair to create.\n   */\n  @route(\"/repairs\")  \n  @post  op createRepair(@body repair: Repair): Repair;\n\n  /**\n   * Update an existing repair.\n   * The `id` field is required to identify the repair to update.\n   * The `date` field should be in ISO 8601 format (e.g., \"2023-10-01T12:00:00Z\").\n   * The `image` field should be a valid URL pointing to the image associated with the repair.\n   * @param repair The repair to update.\n   */\n  @route(\"/repairs\")  \n  @patch(#{implicitOptionality: true})\n  op updateRepair(@body repair: Repair): Repair;\n\n\n  /**\n   * Delete a repair.\n   * The `id` field is required to identify the repair to delete.\n   * @param repair The repair to delete.\n   */\n  @route(\"/repairs\") \n  @delete  op deleteRepair(@body repair: Repair): Repair;\n\n  /**\n   * A model representing a repair.\n   */\n  model Repair {\n    /**\n     * The unique identifier for the repair.\n     */\n    id?: string;\n\n    /**\n     * The short summary or title of the repair.\n     */\n    title: string;\n\n    /**\n     * The detailed description of the repair.\n     */\n    description?: string;\n\n    /**\n     * The user who is assigned to the repair.\n     */\n    assignedTo?: string;\n\n    /**\n     * The optional date and time when the repair is scheduled or completed.\n     */\n    @format(\"date-time\")\n    date?: string;\n\n    /**\n     * The URL of the image associated with the repair.\n     */\n    @format(\"uri\")\n    image?: string;\n  }\n\n</code></pre> <ul> <li>Next, go back to main.tsp file and make sure the new operations are also added as the agent's action. Paste the below snippet after the line op listRepairs is global.RepairsAPI.listRepairs; inside the RepairServiceActions namespace</li> </ul> <pre><code>op createRepair is global.RepairsAPI.createRepair;\nop updateRepair is global.RepairsAPI.updateRepair;\nop deleteRepair is global.RepairsAPI.deleteRepair;   \n\n</code></pre> <ul> <li>Also add a new conversation starter for creating a new repair item just after the first conversation starter definition.</li> </ul> <pre><code>@conversationStarter(#{\n  title: \"Create repair\",\n  text: \"Create a new repair titled \\\"[TO_REPLACE]\\\" and assign it to me\"\n})\n\n</code></pre>"},{"location":"pages/extend-m365-copilot/01-typespec-declarative-agent/#step-2-add-adaptive-card-to-function-reference","title":"Step 2: Add adaptive card to function reference","text":"<p>Next, you will enhance the reference cards or response cards using adaptive cards. Let's create an adaptive card for the repair items.</p> <ul> <li>In the project, go to the adaptiveCards folder under appPackage folder. Create a new file named <code>repair.json</code> and paste the provided code snippet. This will define a new adaptive card for the repair object. Ignore the default template card that is already present in this folder.</li> </ul> <pre><code>{\n    \"$schema\": \"http://adaptivecards.io/schemas/adaptive-card.json\",\n    \"type\": \"AdaptiveCard\",\n    \"version\": \"1.5\",\n    \"body\": [\n  {\n    \"type\": \"Container\",\n    \"$data\": \"${$root}\",\n    \"items\": [\n      {\n        \"type\": \"TextBlock\",\n        \"text\": \"Title: ${if(title, title, 'N/A')}\",\n        \"weight\": \"Bolder\",\n        \"wrap\": true\n      },\n      {\n        \"type\": \"TextBlock\",\n        \"text\": \"Description: ${if(description, description, 'N/A')}\",\n        \"wrap\": true\n      },\n      {\n        \"type\": \"TextBlock\",\n        \"text\": \"Assigned To: ${if(assignedTo, assignedTo, 'N/A')}\",\n        \"wrap\": true\n      },\n      {\n        \"type\": \"TextBlock\",\n        \"text\": \"Date: ${if(date, date, 'N/A')}\",\n        \"wrap\": true\n      },\n      {\n        \"type\": \"Image\",\n        \"url\": \"${image}\",\n        \"$when\": \"${image != null}\"\n      }\n    ]\n  }\n],  \n    \"actions\": [\n      {\n        \"type\": \"Action.OpenUrl\",\n        \"title\": \"View Image\",\n        \"url\": \"https://www.howmuchisit.org/wp-content/uploads/2011/01/oil-change.jpg\"\n      }\n    ]\n  }\n\n\n</code></pre> <ul> <li>Next, go back to actions.tsp file and locate the listRepairs operation. Just above the operation definition @get  op listRepairs(@query assignedTo?: string): string;, paste the card definition using below snippet.</li> </ul> <pre><code>\n@card(#{  dataPath: \"$\", file: \"adaptiveCards/repair.json\",    properties: #{ title: \"$.title\", url: \"$.image\" } })\n\n</code></pre> <p>The above card response will be sent by the agent when you ask about a repair item or when agent brings a list of items as its reference.</p> <p>To keep things simple for this lab, you'll reuse the same card. In practice, you could create separate cards for different operations based on your needs.</p> <p>Continue to add card response for the createRepair operation to show what the agent created after the POST operation.</p> <ul> <li>Copy paste below snippet just above the code @post  op createRepair(@body repair: Repair): Repair;</li> </ul> <pre><code>\n@card(#{  dataPath: \"$\", file: \"adaptiveCards/repair.json\",    properties: #{ title: \"$.title\", url: \"$.image\" } })\n\n</code></pre> <p></p>"},{"location":"pages/extend-m365-copilot/01-typespec-declarative-agent/#step-3-update-agent-instruction-for-new-operations","title":"Step 3: Update agent instruction for new operations","text":"<p>In the prompts/instructions.tsp file, update instructions definition to have additional directives for the agent. Replace the INSTRUCTIONS constant with below code:</p> <pre><code>const INSTRUCTIONS =\"\"\"  \n    ## Purpose\n    You will assist the user in finding car repair records based on the information provided by the user.\n\n    ## Guidelines\n    - You are a repair service agent.\n    - You can use the actions to create, update, and delete repairs.\n    - When creating a repair item, if the user did not provide a description or date, use the title as the description and put today's date in the format YYYY-MM-DD.\n    - Do not use any technical jargon or complex terms.\n  \"\"\";\n</code></pre> <p></p>"},{"location":"pages/extend-m365-copilot/01-typespec-declarative-agent/#step-4-provision-and-test-the-agent","title":"Step 4:  Provision and Test the Agent","text":""},{"location":"pages/extend-m365-copilot/01-typespec-declarative-agent/#provision","title":"Provision","text":"<p>Next step is to test the Repair Service Agent. For this first you need to provision the agent to your tenant. </p> <p>Follow below steps:</p> <ul> <li> <p>Open your .env.dev file  in folder env in the root of the project to see if you have a variable AGENT_SCOPE. If present, change the variable value from <code>shared</code> to <code>personal</code>.</p> </li> <li> <p>Select the Agents toolkit extension icon . This will open the activity bar for agents toolkit from within your project.</p> </li> <li> <p>In the activity bar of the agents toolkit under \"LifeCycle\" select \"Provision\". This will build the app package consisting of the generated manifest files and icons and side load the app package into the catalog only for you to test.</p> </li> </ul> <p>Note</p> <p>Here the agents toolkit also helps validate all the definitions provided in the TypeSpec file to ensure accuracy. It also identifies errors to streamline the developer experience.</p> <p>This will take a while and you will be able to see a toaster message in VS Code, showing the progress of the task to provision.</p> <p>Warning</p> <p>There are couple of known issues where the Provision action in Agents Toolkit may fail with the errors shown below. If this happens, simply retry the provisioning process until it succeeds.  </p> <ul> <li> <p>Next, open Microsoft Edge from lab machine from the taskbar and go to <code>https://m365.cloud.microsoft/chat</code> in the browser to open Copilot app. Login using your credentials.</p> </li> <li> <p>Select the RepairServiceAgent from the left side of the screen under Agents. </p> </li> </ul> <p>If you don't see left navigation to choose agent,  look for below icon and select it to show the navigation. </p>"},{"location":"pages/extend-m365-copilot/01-typespec-declarative-agent/#test-list-operation","title":"Test list operation","text":"<ul> <li> <p>Select the conversation starter - List repairs and send the prompt to the chat to initiate conversation with your agent and check out the response. When prompted to connect the agent to process a query, you\u2019ll usually get a message with buttons to Allow accessing your service through agent. </p> </li> <li> <p>To streamline your experience in this lab, select \"Always allow\" when it appears.</p> </li> </ul> <p>Once accepted you will see the response from the agent as below: </p> <p></p>"},{"location":"pages/extend-m365-copilot/01-typespec-declarative-agent/#diagnosing-and-debugging-agent","title":"Diagnosing and Debugging Agent","text":"<p>You can enable developer mode in a chat to allow you as a developer to understand how well the agent understands the tasks, ensure it calls your services appropriately, identify areas that need fine-tuning, detect performance issues, and generally help you track and analyse its interactions.</p> <ul> <li>Send <code>-developer on</code> to the chat to enable debugging mode.</li> </ul> <p>The agent will respond with a success message if everything went well Successfully enabled developer mode.</p> <p>Note</p> <p>Refresh the browser by pressing F5 to activate the agent debug info.</p> <ul> <li>Next to test, send a prompt to interact with the agent like the one below.</li> </ul> <p><code>Find out what Karin is working on</code>.</p> <ul> <li>You will get a response with information from the repair service but also get the Agent debug info card along with the response.</li> <li>Expand the Agent debug info card to view all the details. You will be able to see:</li> <li>Agent information 1\ufe0f\u20e3</li> <li>Capabilities of the agent 2\ufe0f\u20e3</li> <li>Actions and what function were selected 3\ufe0f\u20e3</li> <li>Executed action info with detailed information about the request, latency, response data, etc. 4\ufe0f\u20e3</li> </ul> <p></p> <ul> <li>Try expanding the Executed Actions and you will see the request url, parameters passed, request header, response, latency, etc.</li> </ul>"},{"location":"pages/extend-m365-copilot/01-typespec-declarative-agent/#test-create-operation","title":"Test create operation","text":"<p>Now let's try to invoke a POST call to create a repair item.</p> <ul> <li> <p>Start by using the conversation starter 'Create repair'. Replace parts of the prompt to add a title, then send it to the chat to initiate the interaction. For e.g.</p> <p><code>Create a new repair titled \"360 camera issue\" and assign it to me.</code></p> </li> <li> <p>The confirmation dialog if you notice has more metadata that what you sent, thanks to updated instructions.</p> </li> </ul> <p></p> <ul> <li>Proceed to add the item by confirming the dialog.</li> </ul> <p>The agent responds is with created item shown in a rich adaptive card.</p> <p></p> <ul> <li> <p>Next, recheck reference cards work. Open a new chat and then send below prompt in the conversation</p> <p><code>List all my repairs.</code></p> </li> </ul> <p>The agent with the list with each referenced with an adaptive card.</p> <p></p> <p>\u2611\ufe0f You've successfully completed the second exercise! You've enhanced your agent with additional repair operations and learned how to test and debug it. Continue to the bonus exercise.</p> <p></p>"},{"location":"pages/extend-m365-copilot/01-typespec-declarative-agent/#bonus-exercise-add-code-interpreter-capability-to-the-agent","title":"Bonus Exercise: Add code interpreter capability to the agent","text":""},{"location":"pages/extend-m365-copilot/01-typespec-declarative-agent/#step-1-add-code-interpreter-capability-to-your-agent","title":"Step 1: Add code interpreter capability to your agent","text":"<p>Declarative Agents can be extended to have many capabilities like OneDriveAndSharePoint, WebSearch, CodeInterpreter etc Next, you will enhance the agent by adding code interpreter capability to it.</p> <ul> <li> <p>To do this, open the main.tsp file and locate the RepairServiceAgent namespace which is where you define the agent behaviour.</p> </li> <li> <p>Inside the namespace RepairServiceAgent, insert the following snippet above op listRepairs to define a new capability that enables the agent to interpret and execute code.</p> </li> </ul> <pre><code>op codeInterpreter is AgentCapabilities.CodeInterpreter;\n</code></pre> <p>Note</p> <p>When you add above codeinterpreter operation, paste it inside the outer RepairServiceAgent namespace which defines the agent's behaviour including the capabilities and not the RepairServiceActions namespace which defines the agent's actions.</p> <p>Since the agent now supports additional capability, update the instructions accordingly to reflect this enhancement.</p> <ul> <li>In the prompts/instructions.tsp file, update INSTRUCTIONS constant to have additional directives for the agent for new capability. Replace the const with below snippet:</li> </ul> <pre><code>\n  const INSTRUCTIONS =\"\"\"\n   ## Purpose\n    You will assist the user in finding car repair records based on the information provided by the user. You can generate charts based on data. Use python execution for charting/visualization.\n\n    ## Guidelines\n    - You are a repair service agent.\n    - You can use the actions to create, update, and delete repairs.\n    - When creating a repair item, if the user did not provide a description or date, use the title as the description and put today's date in the format YYYY-MM-DD.\n    - when asked to generate report, generate charts using existing data.\n    - Do not use any technical jargon or complex terms.\n\"\"\";\n\n</code></pre> <p></p>"},{"location":"pages/extend-m365-copilot/01-typespec-declarative-agent/#step-2-test-your-agents-new-capability","title":"Step 2: Test your agent's new capability","text":"<p>Next, you will test the new analytical capability of your agent. You will need to reprovision the agent. Follow below steps:</p> <ul> <li>Update the version of your agent. Go to appPackage/manifest.json and update from \"version\": \"1.0.0\" to \"version\": \"1.0.1\"</li> <li>Save all changes, select the Agents toolkit extension icon , to open the activity bar from within your project.</li> <li>In the activity bar of the agents toolkit under \"LifeCycle\" select \"Provision\". This will reprovision the agent.</li> <li>If you already have chat with the agent open, then open a new chat by selecting the New chat button on the top right corner of your agent.</li> <li> <p>If not, open Microsoft Edge from lab machine from the taskbar and go to <code>https://m365.cloud.microsoft/chat</code> in the browser to open Copilot app. Login using your credentials.</p> </li> <li> <p>Select the RepairServiceAgent from the left side of the screen under Agents. </p> </li> </ul> <p>If you don't see left navigation to choose agent,  look for below icon and select it to show the navigation. </p> <ul> <li>Next, copy the prompt below and paste it to the message box and hit enter to send it.</li> </ul> <p><code>Classify repair items based on title into three distinct categories: Routine Maintenance, Critical, and Low Priority. Then, generate a pie chart displaying the percentage representation of each category. Use unique colours for each group and incorporate tooltips to show the precise values for each segment.</code></p> <p>You should get some response similar to below screen. It may vary sometimes. </p> <p>Warning</p> <p>Known issue with code interpreter: If you see an error message in the response as below, don't worry\u2014the chart will still be generated and displayed correctly. You can safely ignore the error. </p> <p></p> <p>\u2611\ufe0f Great job completing all the exercises!</p> <p>CONGRATULATIONS!</p> <p>Great job on building your first agent using TypeSpec \ud83c\udf89 </p> <p>Proceed to create, build, and integrate an API selecting Next.  </p> <p>Continue practicing by building a Geolocator game agent\u2014select Create a game below.  </p> <p></p>"},{"location":"pages/extend-m365-copilot/01a-geolocator/","title":"Lab E1 - Instructions based Gelocator game agent","text":"<p>In this lab, you'll create a basic declarative agent using instructions and supplementary knowledge provided through files.  Your agent is designed to give you a fun and educational break from work by helping you explore cities across the globe. It presents abstract clues for you to guess a city, with fewer points awarded the more clues you use. At the end, your final score will be revealed.</p> <p>In this lab you will learn how to:</p> <ul> <li>create a declarative agent using Agents Toolkit template</li> <li>customise the agent to create the geo locator game using instructions </li> <li>learn how to run and test your app </li> <li>for bonus exercise, you will need a SharePoint teams site</li> </ul> Get a quick overview of the lab in this video. <p>Do these labs if you want to build a Declarative agent where Microsoft 365 provides the AI model and               orchestration</p> <ul> <li>\ud83c\udfc1 Welcome</li> <li>\ud83d\udd27 Set up <ul> <li>Lab E0 - Setup</li> </ul> </li> <li>\ud83e\uddf0 Declarative agent fundamentals <ul> <li> Lab E1 - Build a  Declarative Agent using TypeSpec </li> <li> Lab E1a - Geo locator game</li> </ul> </li> <li>\ud83d\udee0\ufe0f Build and integrate API from scratch <ul> <li>Lab E2 - Build an API</li> <li> Lab E3 - Add Declarative Agent + API</li> <li> Lab E4 - Enhance API + Plugin</li> <li>Lab E5 - Add Adaptive Cards</li> <li> Lab E6a - Add Authentication</li> </ul> </li> <li>\ud83d\udd0c Integration <ul> <li> Lab E7 - Add Copilot Connector</li> </ul> <ul> <li> Lab E8 - Connect Declarative agent to MCP Server</li> </ul> <ul> <li> Lab E9 - Connected Agents</li> </ul> </li> </ul>"},{"location":"pages/extend-m365-copilot/01a-geolocator/#introduction","title":"Introduction","text":"<p>Declarative agents leverage the same scalable infrastructure and platform of Microsoft 365 Copilot, tailored specifically to meet focus on a special area of your needs. They function as subject matter experts in a specific area or business need, allowing you to use the same interface as a standard Microsoft 365 Copilot chat while ensuring they focus exclusively on the specific task at hand. </p> <p>In this lab you will start out building a declarative agent using Agents Toolkit with a default template used in the tool. This is to help you get started with something. Next, you will modify your agent to be focused on a geo location game. </p> <p>The goal of your AI is to provide a fun break from work while helping you learn about different cities around the world. It offers abstract clues for you to identify a city. The more clues you need, the fewer points you earn. At the end of the game, it will reveal your final score.</p> <p></p> <p>As a bonus you will also give your agent some files to refer to a secret diary \ud83d\udd75\ud83c\udffd and a map \ud83d\uddfa\ufe0f to give more challenges to the player. </p> <p>So let's begin \ud83d\udcaa\ud83c\udffc</p>"},{"location":"pages/extend-m365-copilot/01a-geolocator/#exercise-1-scaffold-a-declarative-agent-from-template","title":"Exercise 1: Scaffold a declarative agent from template","text":"<p>You can use just any editor to create a declarative agent if you know the structure of the files in the app package mentioned above. But things are easier if you use a tool like Agents Toolkit to not only create these files for you but also help you deploy and publish your app.  So to keep things as simple as possible you will use Agents Toolkit.</p>"},{"location":"pages/extend-m365-copilot/01a-geolocator/#step-1-install-agents-toolkit","title":"Step 1: Install Agents Toolkit","text":"<ul> <li>Go to extensions tab of your Visual Studio Code and look for Microsoft 365 Agents Toolkit.</li> <li>Select it and install.</li> </ul>"},{"location":"pages/extend-m365-copilot/01a-geolocator/#step-2-use-agents-toolkit-to-create-a-declarative-agent-app","title":"Step 2: Use Agents Toolkit to create a declarative agent app","text":"<p>Go to the Agents Toolkit extension in your Visual Studio Code editor in the left 1\ufe0f\u20e3 and select Create a New Agent/App 2\ufe0f\u20e3.</p> <p></p> <p>A panel opens up where you need to select Declarative Agent from the list of project types.</p> <p></p> <p>Next, you will be asked to choose want to create a basic declarative agent or one with an API plugin.  Choose the No Action option.</p> <p></p> <p>Why not create one with an action here? </p> <p>You will build a REST API in the next lab and you will also learn how to integrate that API in a declarative agent with an action in the following one in this same path. Here we are just going to create a declarative agent. Baby steps!</p> <p>Next, type in the directory where the project folder has to be created.</p> <p></p> <p>Next, give it an application name <code>Geo Locator Game</code> and select Enter. </p> <p></p> <p>The project will be created in a few seconds in the folder you mentioned and will open up in a new project window of Visual Studio Code. This is your working folder.</p> <p></p> <p>Well done! You have successfully set up the base declarative agent! Now, proceed to examine the files contained within to be able to customise it to make the geo locator game app. </p> <p></p>"},{"location":"pages/extend-m365-copilot/01a-geolocator/#step-3-set-up-accounts-in-agents-toolkit","title":"Step 3: Set up accounts in Agents Toolkit","text":"<p>Now select the Agents Toolkit icon in the left 1\ufe0f\u20e3 . Under \"Accounts\" click \"Sign in to Microsoft 365\" 2\ufe0f\u20e3 and log in with your own Microsoft 365 account.</p> <p></p> <p>A browser window will pop up and offer to log into Microsoft 365. When it says \"You are signed in now and close this page\", please do so.</p> <p>Now verify that the \"Custom App Upload Enabled\" checker has a green checkmark. If it doesn't, that means that your user account doesn't have permission to upload Teams applications. Follow steps in Exercise 1 of this lab. </p> <p>Now verify that the \"Copilot Access Enabled\" checker has a green checkmark. If it doesn't, that means that your user account does not have a license for Copilot. This is required to continue the labs.</p> <p></p> <p>Now, let's do a code tour.</p> <p></p>"},{"location":"pages/extend-m365-copilot/01a-geolocator/#step-4-understanding-the-files-in-the-app","title":"Step 4: Understanding the files in the app","text":"<p>Here's how the base project looks: </p> Folder/File Contents <code>.vscode</code> VSCode files for debugging <code>appPackage</code> Templates for the Teams application manifest, the agent manifest, and the API specification, if any <code>env</code> Environment files with a default  <code>.env.dev</code>    file <code>appPackage/color.png</code> Application logo image <code>appPackage/outline.png</code> Application logo outline image <code>appPackage/declarativeAgent.json</code> Defines settings and configurations of the declarative agent. <code>appPackage/instruction.txt</code> Defines the behaviour of declarative agent. <code>appPackage/manifest.json</code> Teams application manifest that defines metadata for your declarative agent. <code>m365agent.yml</code> Main Agents Toolkit project file. The project file defines two primary things: Properties and configuration Stage definitions. <p>The file of interest for our lab is primarily the appPackage/instruction.txt file which is the core directives needed for your agent. It's a plain text file and you can write natural language instructions in it. </p> <p>Another important file is appPackage/declarativeAgent.json where there is a schema to be followed to extend Microsoft 365 Copilot with the new declarative agent. Let's look at what properties the schema of this file has. </p> <ul> <li>The <code>$schema</code> is the schema reference </li> <li>The <code>version</code> is the schema version </li> <li>The <code>name</code> key represents the name of the declarative agent.</li> <li>The <code>description</code> provides a description.</li> <li>The <code>instructions</code> provides the path to the instructions.txt file which holds directives which will determine the operational behavior. You can also put your instructions as plain text as a value here. But for this lab we will use the instructions.txt file.</li> </ul> <p>Another important file is the <code>appPackage/manifest.json</code> file, which contains crucial metadata, including the package name, the developer\u2019s name, and references to the agents utilised by the application. The following excerpt from the manifest.json file illustrates these details:</p> <pre><code>\"copilotAgents\": {\n        \"declarativeAgents\": [            \n            {\n                \"id\": \"declarativeAgent\",\n                \"file\": \"declarativeAgent.json\"\n            }\n        ]\n    },\n</code></pre> <p>You could also update the logo files <code>color.png</code> and <code>outline.png</code> to make it match your application's brand. In today's lab you will change color.png icon for the agent to stand out. </p> <p></p>"},{"location":"pages/extend-m365-copilot/01a-geolocator/#exercise-2-update-instructions-and-icons","title":"Exercise 2: Update instructions and icons","text":""},{"location":"pages/extend-m365-copilot/01a-geolocator/#step-1-update-icons-and-manifests","title":"Step 1: Update icons and manifests","text":"<p>First we will do the easy bit which is replacing the logo. Copy the image located here and replace it with the image of same name in the folder appPackage in your root project. </p> <p>Next, go to the file appPackage/manifest.json  in your root project and find the node copilotAgents. Update the id value of the declarativeAgents array's first entry from <code>declarativeAgent</code> to <code>dcGeolocator</code> to make this ID unique.</p> <pre>\n \"copilotAgents\": {\n        \"declarativeAgents\": [            \n            {\n                \"id\": \"dcGeolocator\",\n                \"file\": \"declarativeAgent.json\"\n            }\n        ]\n    },\n\n</pre> <p>Next, go to the file appPackage/instruction.txt and copy paste the below instruction to overwrite the existing contents of the file.</p> <pre><code>System Role: You are the game host for a geo-location guessing game. Your goal is to provide the player with clues about a specific city and guide them through the game until they guess the correct answer. You will progressively offer more detailed clues if the player guesses incorrectly. You will also reference PDF files in special rounds to create a clever and immersive game experience.\n\nGame play Instructions:\nGame Introduction Prompt\nUse the following prompt to welcome the player and explain the rules:\nWelcome to the Geo Location Game! I\u2019ll give you clues about a city, and your task is to guess the name of the city. After each wrong guess, I\u2019ll give you a more detailed clue. The fewer clues you use, the more points you score! Let\u2019s get started. Here\u2019s your first clue:\nClue Progression Prompts\nStart with vague clues and become progressively specific if the player guesses incorrectly. Use the following structure:\nClue 1: Provide a general geographical clue about the city (e.g., continent, climate, latitude/longitude).\nClue 2: Offer a hint about the city\u2019s landmarks or natural features (e.g., a famous monument, a river).\nClue 3: Give a historical or cultural clue about the city (e.g., famous events, cultural significance).\nClue 4: Offer a specific clue related to the city\u2019s cuisine, local people, or industry.\nResponse Handling\nAfter the player\u2019s guess, respond accordingly:\n\nIf the player guesses correctly, say:\nThat\u2019s correct! You\u2019ve guessed the city in [number of clues] clues and earned [score] points. Would you like to play another round?\nIf the guess is wrong, say:\nNice try! [followed by more clues]\nPDF-Based Scenario\nFor special rounds, use a PDF file to provide clues from a historical document, traveler's diary, or ancient map:\nThis round is different! I\u2019ve got a secret document to help us. I\u2019ll read clues from this [historical map/traveler\u2019s diary] and guide you to guess the city. Here\u2019s the first clue:\nReference the specific PDF to extract details: Do not provide the citations and also link to the document since its a secret document for generating the questions.\nTraveler's Diary PDF,Historical Map PDF. Do not provide the citations and also link to the document since its a secret document for generating the questions.\nUse emojis where necessary to have friendly tone. \nScorekeeping System\nTrack how many clues the player uses and calculate points:\n\n1 clue: 10 points\n2 clues: 8 points\n3 clues: 5 points\n4 clues: 3 points\nEnd of Game Prompt\nAfter the player guesses the city or exhausts all clues, prompt:\nWould you like to play another round, try a special challenge?\n\n</code></pre> <p>Follow the next step to make sure our agent can help user engage with it by giving conversation starters.  </p> <p>Include your own files in appPackage files</p> <p>Notice this line in appPackage/declarativeAgent.json:</p> <p><code>\"instructions\": \"$[file('instruction.txt')]\",</code></p> <p>This brings in your instructions from the instruction.txt file. If you want to modularize your packaging files, you can use this technique in any of the JSON files in the appPackage folder.</p> <p></p>"},{"location":"pages/extend-m365-copilot/01a-geolocator/#step-2-add-conversation-starters","title":"Step 2 : Add conversation starters","text":"<p>You can enhance user engagement with the declarative agent by adding conversation starters to it. </p> <p>Some of the benefits of having conversation starters are: </p> <ul> <li> <p>Engagement: They help initiate interaction, making users feel more comfortable and encouraging participation.</p> </li> <li> <p>Context Setting: Starters set the tone and topic of the conversation, guiding users on how to proceed.</p> </li> <li> <p>Efficiency: By leading with a clear focus, starters reduce ambiguity, allowing the conversation to progress smoothly.</p> </li> <li> <p>User Retention: Well-designed starters keep users interested, encouraging repeat interactions with the AI.</p> </li> </ul> <p>Open file <code>declarativeAgent.json</code> and right after the <code>instructions</code> node add a comma <code>,</code> and paste below code.</p> <pre><code> \"conversation_starters\": [\n      { \n            \"title\": \"Getting Started\",\n            \"text\":\"I am ready to play the Geo Location Game! Give me a city to guess, and start with the first clue.\"          \n\n         },\n        {\n            \"title\": \"Ready for a Challenge\",\n            \"text\": \"Let us try something different. Can we play a round using the travelers diary?\"\n        },\n        { \n            \"title\": \"Feeling More Adventurous\",\n            \"text\": \"I am in the mood for a challenge! Can we play the game using the historical map? I want to see if I can figure out the city from those ancient clues.\"\n        }\n    ]\n</code></pre> <p>Now all the changes are done to the agent, it's time to test it.</p> <p></p>"},{"location":"pages/extend-m365-copilot/01a-geolocator/#step-3-test-the-app","title":"Step 3: Test the app","text":"<p>To test the app go to the <code>Agents Toolkit</code> extension in <code>Visual Studio Code</code>. This will open up the left pane. Under \"LIFECYCLE\" select \"Provision\".  You can see the value of Agents Toolkit here, as it makes publishing so simple. </p> <p></p> <p>In this step Agents Toolkit will package up all the files inside the <code>appPackage</code> folder as a zip file and install the declarative agent to your own app catalog.</p> <p>Open the Microsoft 365 Copilot BizChat https://microsoft365.com/copilot/ logged into your developer tenant.</p> <p>Once the Copilot app is loaded, Find the \"Geo Locator Game\" from the right panel as shown. </p> <p></p> <p>If you can't find it, this may be a long list and you can find your agent by expanding the list by selecting \"see more\"</p> <p>Once launched, you will be in this focused chat window with the agent. And you will see the conversation starters as marked below:</p> <p></p> <p>Select one of the conversation starters and it will fill your compose message box with the starter prompt, just waiting for you to hit \"Enter\". It is still only your assistant and will wait for you to take action \ud83d\udfe2</p> <p>Check out the demo of the game. </p> <p></p> <p></p>"},{"location":"pages/extend-m365-copilot/01a-geolocator/#exercise-3-add-files-for-reference-bonus-exercise","title":"Exercise 3: Add files for reference (Bonus exercise)","text":"<p>Playing the same game over and over can get dull. To keep things fun and engaging, the game needs access to data that\u2019s regularly updated. Let\u2019s give the agent a new ability to refresh the game and ramp up the challenge. As we covered earlier, declarative agents can have three main capabilities, one of which is referencing SharePoint sites and OneDrive. So, let's go ahead and add the ability for your agent to access a couple of files.</p>"},{"location":"pages/extend-m365-copilot/01a-geolocator/#step-1-upload-files-to-sharepoint","title":"Step 1: Upload files to SharePoint.","text":"<p>Download this zip file consisting of two PDF files by selecting this link</p> <p>Extract the two files from the zip and upload to a SharePoint Teams site in the same tenant in the document library Documents. These documents are historical_map.pdf and travelers_diary to help make the game more challenging. </p> <p>Copy the absolute url of the site. For eg. <code>https://xyz.sharepoint.com/sites/contoso</code>.</p> <p>[!NOTE] To get the full path of a file or folder, you can use the \"Copy direct link\" option in SharePoint. Right-click on the file or folder and select Details, then navigate to Path and click on the copy icon.</p> <p>Then proceed to next step.</p> <p></p>"},{"location":"pages/extend-m365-copilot/01a-geolocator/#step-2-update-declarative-agent-manifest","title":"Step 2: Update declarative agent manifest","text":"<p>Go to the environment file called .env.dev and create a new variable called \"SP_SITE_URL\" and paste the absolute url of the SharePoint site as its value.</p> <p>Next, go to the agent manifest appPackage/declarativeAgent.json and add a comma <code>,</code> after conversation_starters array and paste the below new array object for extending the agent's capability to refer to SharePoint data of a particular site.</p> <pre><code> \"capabilities\": [\n        {\n\n            \"name\": \"OneDriveAndSharePoint\",\n            \"items_by_url\": [\n            {\n                \"url\": \"${{SP_SITE_URL}}\"\n            }\n        ]\n        }\n    ]\n</code></pre> <p>This widens declarative agent's knowledge to read documents in this SharePoint site specifically to help spice up the game.  There is no limit to how many URLs you can add \ud83d\udcaa\ud83c\udffc</p> <p></p>"},{"location":"pages/extend-m365-copilot/01a-geolocator/#step-3-upgrade-app-manifest","title":"Step 3: Upgrade app manifest","text":"<p>Next, go to the file appPackage/manifest.json and upgrade the app <code>version</code> from \"1.0.0\"\" to \"1.0.1\" so the changes are reflected when you install. </p> <p></p>"},{"location":"pages/extend-m365-copilot/01a-geolocator/#step-4-test-the-app","title":"Step 4: Test the app","text":"<ul> <li> <p>To test the app go back to the <code>Agents Toolkit</code> extension in <code>Visual Studio Code</code>. This will open up the left pane. Under \"LIFECYCLE\" select \"Provision\" for packaging and installing the upgraded declarative agent to your own app catalog.</p> </li> <li> <p>Open the Microsoft 365 Copilot BizChat https://microsoft365.com/copilot/ logged into your developer tenant.</p> </li> <li> <p>Launch the \"Geo Locator Game\" again.</p> </li> </ul> <p></p> <p>This time, try the challenge which will be based on the travel diary. Choose the second converation starter.</p> <p></p> <p>You have basically become a declarative agent boss. Find out more from this video we did.</p> Introducing Declarative agents <p></p>"},{"location":"pages/extend-m365-copilot/01a-geolocator/#resources","title":"Resources","text":"<ul> <li>Declarative agents</li> <li>Declarative agent manifest schema</li> <li>Supported content types</li> <li>Capabilities of Declarative agents</li> <li>Validation guidelines for Agents</li> </ul> <p>CONGRATULATIONS!</p> <p>Great job on building your game agent \ud83c\udf89 ! In the next lab, you\u2019ll create a REST API, use it to build a plugin, and dive into a real-world business scenario solved by another agent. Exciting stuff ahead. Select Next to advance to the next lab.</p> <p></p> <p></p>"},{"location":"pages/extend-m365-copilot/02-build-the-api/","title":"Lab E2 - Build an API","text":"<p>In this lab you will set up an API based on Azure Functions and install it as an API plugin for Microsoft 365 Copilot.</p> Get a quick overview of the lab in this video. <p>Do these labs if you want to build a Declarative agent where Microsoft 365 provides the AI model and               orchestration</p> <ul> <li>\ud83c\udfc1 Welcome</li> <li>\ud83d\udd27 Set up <ul> <li>Lab E0 - Setup</li> </ul> </li> <li>\ud83e\uddf0 Declarative agent fundamentals <ul> <li> Lab E1 - Build a  Declarative Agent using TypeSpec </li> <li> Lab E1a - Geo locator game</li> </ul> </li> <li>\ud83d\udee0\ufe0f Build and integrate API from scratch <ul> <li>Lab E2 - Build an API</li> <li> Lab E3 - Add Declarative Agent + API</li> <li> Lab E4 - Enhance API + Plugin</li> <li>Lab E5 - Add Adaptive Cards</li> <li> Lab E6a - Add Authentication</li> </ul> </li> <li>\ud83d\udd0c Integration <ul> <li> Lab E7 - Add Copilot Connector</li> </ul> <ul> <li> Lab E8 - Connect Declarative agent to MCP Server</li> </ul> <ul> <li> Lab E9 - Connected Agents</li> </ul> </li> </ul>"},{"location":"pages/extend-m365-copilot/02-build-the-api/#introduction","title":"Introduction","text":"<p>In this lab you will set up a REST API for Trey Research, a hypothetical consulting company. It provides API's for accessing information about consultants (using the <code>/api/consultants</code> path) and about the current user (using the <code>/api/me</code> path). For now the API doesn't support authentication, so the current user will always be \"Avery Howard\"; in Lab E6 you will add authentication and the ability to access the logged in user.</p> <p>The code consists of Azure Functions written in TypeScript, backed by a database in Azure Table storage. When you run the app locally, table storage will be provided by the Azurite storage emulator.</p> How did you create this API? <p>The project was created using Microsoft 365 Agents Toolkit. You can create the same scaffolding for your own project by opening an empty folder in VS Code and going to Agents Toolkit. Read more.</p>"},{"location":"pages/extend-m365-copilot/02-build-the-api/#exercise-1-configure-and-run-the-starting-application","title":"Exercise 1: Configure and run the starting application","text":""},{"location":"pages/extend-m365-copilot/02-build-the-api/#step-1-install-additional-prerequisites","title":"Step 1: Install additional prerequisites","text":"<p>This lab calls for a couple of additional prerequisites; please install them now.</p> <ul> <li>Azure functions core tool </li> <li>REST Client add-in for Visual Studio Code: You will use one of these toolkits to test your API locally</li> <li>(optional) Azure Storage Explorer: This will allow you to view and modify the Trey Research database</li> </ul> <p></p>"},{"location":"pages/extend-m365-copilot/02-build-the-api/#step-2-download-the-starting-application","title":"Step 2: Download the starting application","text":"<p>Begin by downloading the source code zip file for the base project using this link</p> <p>Unzip and copy <code>path-e-lab02-build-api</code> folder to a location on your computer where you want to do your work. These instructions will refer to this as the \"working folder\" going forward.</p> <p>Note</p> <p>The next several labs build on this one, and you should be able to continue working in the same folder for labs E2-E6. At the completion of this lab you will not have changed any of the files visible in Github, so the folder /src/extend-m365-copilot/path-e-lab02-build-api/trey-research is the same at the beginning and end of the lab.</p> <p></p>"},{"location":"pages/extend-m365-copilot/02-build-the-api/#step-3-set-up-the-local-environment-files","title":"Step 3: Set up the local environment files","text":"<p>Open your working folder in Visual Studio Code. You might see a popup dialog asking you to \"trust the authors of the files in this folder\". If that is the case, select the button \"Yes, I trust the authors\" to proceed. Copy the /env/.env.local.user.sample file to /env/.env.local.user. If env.local.user already exists, ensure this line is present:</p> <pre><code>SECRET_STORAGE_ACCOUNT_CONNECTION_STRING=UseDevelopmentStorage=true\n</code></pre> <p></p>"},{"location":"pages/extend-m365-copilot/02-build-the-api/#step-4-install-the-dependencies","title":"Step 4: Install the dependencies","text":"<p>Open a command line / VS Code terminal in your working folder to type and enter:</p> <pre><code>npm install\n</code></pre> <p></p>"},{"location":"pages/extend-m365-copilot/02-build-the-api/#step-5-run-the-application","title":"Step 5: Run the application","text":"<p>In Visual Studio Code, click the logo for Microsoft 365 Agents Toolkit in the left sidebar to open Agents Toolkit. Ensure you are logged into Microsoft 365 and that Custom App Uploads and Copilot Access Enabled indicators are both showing green checkmarks.</p> <p>You'll need to sign into the Microsoft 365 Agents Toolkit in order to upload and test your agent from within it. Within the project window, select the Microsoft 365 Agents Toolkit icon from the left side menu. This will open the Agent Toolkit\u2019s activity bar with sections like Accounts, Environment, Development etc. Under \"Accounts\" section select \"Sign in to Microsoft 365\". This will open a dialog from the editor to sign in or create a Microsoft 365 developer sandbox or Cancel. Select \"Sign in\". Once signed in, close the browser and go back to the project window.</p> <p></p> <p>Now you can just hit F5 to debug using Microsoft Edge or in VS Code menu select Run &gt; Start Debugging.</p> <p>Or you can hover over the \"local\" enviroment and click the debugger symbol that will be displayed 1\ufe0f\u20e3, then select the browser of your choice 2\ufe0f\u20e3.</p> <p></p> <p>Eventually a browser will open (it's faster after the first time). You'll log into this in the next lab to test with Copilot, but for now just minimize the browser so your app keeps running, and we'll proceed to test the API.</p> <p></p> <p></p>"},{"location":"pages/extend-m365-copilot/02-build-the-api/#exercise-2-test-the-apps-web-services","title":"Exercise 2: Test the app's web services","text":"<p>The Trey Resarch project is an API plugin, so naturally it includes an API. In this exercise you'll test the API manually and, in the process, learn about what it does. </p>"},{"location":"pages/extend-m365-copilot/02-build-the-api/#step-1-get-the-me-resource","title":"Step 1: GET the /me resource","text":"<p>With the debugger still running 1\ufe0f\u20e3, switch to the code view in Visual Studio Code 2\ufe0f\u20e3. Open the http folder and select the treyResearchAPI.http file 3\ufe0f\u20e3.</p> <p>Before proceeding, ensure the log file is in view by opening the \"Debug console\" tab 4\ufe0f\u20e3 and ensuring that the console called \"Attach to Backend\" is selected 5\ufe0f\u20e3.</p> <p>Now click the \"Send Request\" link in treyResearchAAPI.http just above the link <code>{{base_url}}/me</code> 6\ufe0f\u20e3.</p> <p></p> <p>You should see the response in the right panel, and a log of the request in the bottom panel. The response shows the information about the logged-in user, but since we haven't implemented authentication as yet (that's coming in Lab 6a), the app will return information on the fictitious consultant \"Avery Howard\". Take a moment to scroll through the response to see details about Avery, including a list of project assignments.</p> <p></p> <p></p>"},{"location":"pages/extend-m365-copilot/02-build-the-api/#step-2-try-the-other-methods-and-resources","title":"Step 2: Try the other methods and resources","text":"<p>Now try sending the POST request for <code>{{base_url}}/me/chargeTime</code>. This will charge 3 hours of Avery's time to the Woodgrove Bank project. This is stored in the project database, which is a locally hosted emulation of Azure Table Storage, so the system will remember that Avery has delivered these hours. (To test this, call the <code>/me</code> resource again and look at the <code>\"deliveredThisMonth\"</code> property under the Woodgrove project).</p> <p>Continue to try the various GET requests in the .http file to find consultants with various skills, certifications, roles, and availability. All this information will be available to your agent so it can answer user prompts.</p> <p>Once done testing, stop the debugger by going to the VS Code menu Run &gt; Stop Debugging. Also close all windows inside VS Code like .http file 1\ufe0f\u20e3 as well as the Response view 2\ufe0f\u20e3.</p> <p></p> <p></p>"},{"location":"pages/extend-m365-copilot/02-build-the-api/#step-3-examine-the-database-optional","title":"Step 3: Examine the database (optional)","text":"<p>If you've installed the Azure Storage Explorer, you can examine and modify the application's data. The data is stored in Azure Table Storage, which in this case is running locally using the Azurite emulator.</p> <p>Note</p> <p>When you ran <code>npm install</code> in the previous exercise you installed the Azurite storage emulator. For more information check the Azurite documention here, and when you start the project, Azurite is automatically started up. So as long as your project is started successfully you can view the storage.</p> <p>Within the Azure Storage Explorer, open the \"Emulator &amp; Attached\" selection and pick the \"(Emulator: Default Ports)\" collection; then drill down to \"Tables\". You shold see 3 tables:</p> <ul> <li>Consultant: This table stores details about Trey Research consultants</li> <li>Project: This table stores details about Trey Research projects</li> <li>Assignment: This table stores consultant assignments to projects, such as Avery Howard's assignment to the Woodgrove Bank project. This table includes a \"delivered\" field that contains a JSON representation of the hours delivered by that consultant on the project over time.</li> </ul> <p></p> <p></p> <p>CONGRATULATIONS!</p> <p>You've successfully built the lab sample API! You can now proceed to make it into a plugin, and expose it via a Declarative agent.</p> <p></p> <p></p>"},{"location":"pages/extend-m365-copilot/03-add-declarative-agent/","title":"Lab E3 - Add a declarative agent and API plugin","text":"<p>In this lab you will add a declarative agent which is grounded in the API plugin you created in the previous lab, as well as in specific SharePoint files</p> Get a quick overview of the lab in this video.              \ud83d\udcd8 Note: This lab builds on the previous one, Lab E2. You should be able to continue working in the same folder for labs E2-E6, but solution folders have been provided for your reference.     The finished solution for this lab is in the /src/extend-m365-copilot/path-e-lab03-build-declarative-agent/trey-research-lab03-END folder.          <p>Do these labs if you want to build a Declarative agent where Microsoft 365 provides the AI model and               orchestration</p> <ul> <li>\ud83c\udfc1 Welcome</li> <li>\ud83d\udd27 Set up <ul> <li>Lab E0 - Setup</li> </ul> </li> <li>\ud83e\uddf0 Declarative agent fundamentals <ul> <li> Lab E1 - Build a  Declarative Agent using TypeSpec </li> <li> Lab E1a - Geo locator game</li> </ul> </li> <li>\ud83d\udee0\ufe0f Build and integrate API from scratch <ul> <li>Lab E2 - Build an API</li> <li> Lab E3 - Add Declarative Agent + API</li> <li> Lab E4 - Enhance API + Plugin</li> <li>Lab E5 - Add Adaptive Cards</li> <li> Lab E6a - Add Authentication</li> </ul> </li> <li>\ud83d\udd0c Integration <ul> <li> Lab E7 - Add Copilot Connector</li> </ul> <ul> <li> Lab E8 - Connect Declarative agent to MCP Server</li> </ul> <ul> <li> Lab E9 - Connected Agents</li> </ul> </li> </ul>"},{"location":"pages/extend-m365-copilot/03-add-declarative-agent/#exercise-1-upload-sample-documents","title":"Exercise 1: Upload sample documents","text":"<p>In this step you will upload sample documents which will be used by your declarative agent to respond to user prompts. These include some consulting documents such as Statements of Work, and a simple spreadsheet containing your hours as a consultant.</p>"},{"location":"pages/extend-m365-copilot/03-add-declarative-agent/#step-1-create-a-sharepoint-site","title":"Step 1: Create a SharePoint site","text":"<p>Go to https://m365.cloud.microsoft/apps/ and find \"SharePoint\" app under \"Apps\"</p> <p></p> <p>Then click \"Create Site\" 1\ufe0f\u20e3 and choose a \"Team site\" 2\ufe0f\u20e3.</p> <p></p> <p>Select the Standard team site template; you will be shown a preview of the site. Click \"Use Template\" to continue.</p> <p></p> <p>Give your site a name such as \"Trey Research legal documents\" 1\ufe0f\u20e3 and click \"Next\" 2\ufe0f\u20e3.</p> <p></p> <p>Then select your privacy settings and language, and click \"Create Site\"</p> <p></p> <p>After a few moments, you will be presented with a new SharePoint site. </p> <p></p>"},{"location":"pages/extend-m365-copilot/03-add-declarative-agent/#step-2-upload-the-sample-documents","title":"Step 2: Upload the sample documents","text":"<p>In the Documents web part, select \"See all\" to view the document library page.</p> <p></p> <p>Next, click the \"Upload\" 1\ufe0f\u20e3 toolbar button and select \"Files\" 2\ufe0f\u20e3.</p> <p></p> <p>Navigate to your working folder; you will find a directory called sampleDocs within. Highlight all the sample documents 1\ufe0f\u20e3 and click \"Open\" 2\ufe0f\u20e3.</p> <p>Make note of the site url, which will resemble \"https://&lt;your-tenant&gt;.sharepoint.com/sites/TreyResearchlegaldocuments\", as you will need it in the next exercise.</p> <p></p> <p></p>"},{"location":"pages/extend-m365-copilot/03-add-declarative-agent/#exercise-2-create-the-declarative-agent","title":"Exercise 2: Create the declarative agent","text":""},{"location":"pages/extend-m365-copilot/03-add-declarative-agent/#step-1-add-the-declarative-agent-json-to-your-project","title":"Step 1: Add the declarative agent JSON to your project","text":"<p>Create a new file called trey-declarative-agent.json within your appPackage folder. Copy the following JSON into this file and save it.</p> <pre><code>{\n    \"$schema\": \"https://developer.microsoft.com/json-schemas/copilot/declarative-agent/v1.6/schema.json\",\n    \"version\": \"v1.6\",\n    \"name\": \"Trey Genie Local\",\n    \"description\": \"You are a handy assistant for consultants at Trey Research, a boutique consultancy specializing in software development and clinical trials. \",\n    \"instructions\": \"You are consulting agent. Greet users professionally and introduce yourself as the Trey Genie. Offer assistance with their consulting projects and hours. Remind users of the Trey motto, 'Always be Billing!'. Your primary role is to support consultants by helping them manage their projects and hours. Using the TreyResearch action, you can: You can assist users in retrieving consultant profiles or project details for administrative purposes but do not participate in decisions related to hiring, performance evaluation, or assignments. You can assist users to find consultants data based on their names, project assignments, skills, roles, and certifications. You can assist users to retrieve project details based on the project or client name. You can assist users to charge hours to a project. You can assist users to add a consultant to a project. If a user inquires about the hours they have billed, charged, or worked on a project, rephrase the request to ask about the hours they have delivered. Additionally, you may provide general consulting advice. If there is any confusion, encourage users to consult their Managing Consultant. Avoid providing legal advice.\",\n    \"conversation_starters\": [\n        {\n            \"title\": \"Find consultants\",\n            \"text\": \"Find consultants with TypeScript skills\"\n        },\n        {\n            \"title\": \"My Projects\",\n            \"text\": \"What projects am I assigned to?\"\n        },\n        {\n            \"title\": \"My Hours\",\n            \"text\": \"How many hours have I delivered on projects this month?\"\n        }\n    ],\n    \"capabilities\": [\n        {\n            \"name\": \"OneDriveAndSharePoint\",\n            \"items_by_url\": [\n                {\n                    \"url\": \"${{SHAREPOINT_DOCS_URL}}\"\n                }\n            ]\n        }\n    ],\n    \"actions\": [\n        {\n            \"id\": \"treyresearch\",\n            \"file\": \"trey-plugin.json\"\n        }\n    ]\n}\n</code></pre> <p>Notice that the file includes a name, description, and instructions for the declarative agent. Notice that as part of the instructions, Copilot is instructed to \"Always remind users of the Trey motto, 'Always be Billing!'.\" You should see this when you prompt Copilot in the next exercise.</p> <p></p>"},{"location":"pages/extend-m365-copilot/03-add-declarative-agent/#step-2-add-the-url-of-your-sharepoint-site-to-the-declarative-agent","title":"Step 2: Add the URL of your SharePoint site to the declarative agent","text":"<p>Under \"Capabilities\" you will notice a SharePoint file container. While Microsoft 365 Copilot may reference any documents in SharePoint or OneDrive, this declarative agent will only access files in the Trey Research Legal Documents site you created in Exercise 1. </p> <pre><code>\"capabilities\": [\n    {\n        \"name\": \"OneDriveAndSharePoint\",\n        \"items_by_url\": [\n            {\n                    \"url\": \"${{SHAREPOINT_DOCS_URL}}\"\n            }\n        ]\n    }\n],\n</code></pre> <p>Notice that the SharePoint URL is actually an environment variable <code>SHAREPOINT_DOCS_URL</code>, so you need to add that to your .env.local file in the env folder. Add this in its own line at the end of the file, using your SharePoint URL:</p> <pre><code>SHAREPOINT_DOCS_URL=https://mytenant.sharepoint.com/sites/TreyResearchLegaldocuments\n</code></pre> <p></p>"},{"location":"pages/extend-m365-copilot/03-add-declarative-agent/#step-3-examine-the-api-plugin-files","title":"Step 3: Examine the API Plugin files","text":"<p>Within the trey-declarative-agent.json file, you'll find an \"actions\" section, which tells the declarative agent to access the Trey Research API.</p> <pre><code>\"actions\": [\n    {\n        \"id\": \"treyresearch\",\n        \"file\": \"trey-plugin.json\"\n    }\n]\n</code></pre> <p>In this step we'll look at trey-plugin.json and how it and another file describe the API to Copilot so it can make the REST calls.</p> <p>These two files are used to describe your API to Copilot. They were already included in the project you downloaded in Lab 2, so you can examine them now:</p> <ul> <li>appPackage/apiSpecificationFile/trey-definition.json - This is the OpenAPI Specification (OAS) or \"Swagger\" file, which is an industry standard format for describing a REST API</li> <li>appPackage/trey-plugin.json - This file contains all the Copilot-specific details that aren't described in the OAS file</li> </ul> <p>In this step, take a moment to examine these files. In the next few labs you'll get to know them better as we add more features to the solution.</p> <p>In appPackage/apiSpecificationFile/trey-definition.json, you'll find the general description of the application. This includes the server URL; Agents Toolkit will create a developer tunnel to expose your local API on the Internet, and replace the token <code>\"${{OPENAPI_SERVER_URL}}</code> with the public URL. It then goes on to describe every resource path, verb, and paremeter in the API. Notice the detailed descriptions; these are important to help Copilot understand how the API is to be used.</p> <pre><code>{\n  \"openapi\": \"3.0.1\",\n  \"info\": {\n      \"version\": \"1.0.0\",\n      \"title\": \"Trey Research API\",\n      \"description\": \"API to streamline consultant assignment and project management.\"\n  },\n  \"servers\": [\n      {\n          \"url\": \"${{OPENAPI_SERVER_URL}}/api/\",\n          \"description\": \"Production server\"\n      }\n  ],\n  \"paths\": {\n      \"/consultants/\": {\n          \"get\": {\n              \"operationId\": \"getConsultants\",\n              \"summary\": \"Get consultants working at Trey Research based on consultant name, project name, certifications, skills, roles and hours available\",\n              \"description\": \"Returns detailed information about consultants identified from filters like name of the consultant, name of project, certifications, skills, roles and hours available. Multiple filters can be used in combination to refine the list of consultants returned\",\n              \"parameters\": [\n                  {\n                      \"name\": \"consultantName\",\n                      \"in\": \"query\",\n                      \"description\": \"Name of the consultant to retrieve\",\n                      \"required\": false,\n                      \"schema\": {\n                          \"type\": \"string\"\n                      }\n                  },\n      ...\n</code></pre> <p>The appPackage/trey-plugin.json file has the Copilot-specific details. This includes breaking the API calls down into functions which can be called when Copilot has a particular use case. For example, all GET requests for <code>/consultants</code> look up one or more consultants with various parameter options, and they are grouped into a function <code>getConsultants</code>:</p> <pre><code>  \"functions\": [\n    {\n      \"name\": \"getConsultants\",\n      \"description\": \"Returns detailed information about consultants identified from filters like name of the consultant, name of project, certifications, skills, roles and hours available. Multiple filters can be used in combination to refine the list of consultants returned\",\n      \"capabilities\": {\n        \"response_semantics\": {\n          \"data_path\": \"$.results\",\n          \"properties\": {\n            \"title\": \"$.name\",\n            \"subtitle\": \"$.id\",\n            \"url\": \"$.consultantPhotoUrl\"\n          }\n        }\n      }\n    },\n</code></pre> <p>Scrolling down you can find the runtime settings: </p> <pre><code>\"runtimes\": [\n  {\n    \"type\": \"OpenApi\",\n    \"auth\": {\n      \"type\": \"None\"\n    },\n    \"spec\": {\n      \"url\": \"apiSpecificationFile/trey-definition.json\"\n    },\n    \"run_for_functions\": [\n      \"getConsultants\",\n      \"getUserInformation\",\n      \"postBillhours\"\n    ]\n  }\n],\n</code></pre> <p>They include a pointer to the trey-definition.json file, and an enumeration of the available functions.</p> <p></p>"},{"location":"pages/extend-m365-copilot/03-add-declarative-agent/#step-4-add-the-declarative-agent-to-your-app-manifest","title":"Step 4: Add the declarative agent to your app manifest","text":"<p>Now open the manifest.json file within the appPackage directory. Add, just before the <code>staticTabs</code> object, a new <code>copilotAgents</code> object with a <code>declarativeAgents</code> object inside as follows, so it references the declarative agent JSON file you created in the previous step.</p> <pre><code>  \"copilotAgents\": {\n    \"declarativeAgents\": [\n      {\n        \"id\": \"treygenie\",\n        \"file\": \"trey-declarative-agent.json\"\n      }\n    ]\n  }, \n</code></pre> <p>Be sure to save your work. </p> <p></p>"},{"location":"pages/extend-m365-copilot/03-add-declarative-agent/#step-5-remove-the-dummy-feature-from-the-app-manifest","title":"Step 5: Remove the dummy feature from the app manifest","text":"<p>The initial solution that you ran in Lab E2 didn't have a declarative agent yet, so the manifest would not install because it had no features. So we added a \"dummy\" feature, which is a static tab pointing to the Copilot Developer Camp home page. This would allow users to view the Copilot Developer Camp web site in a tab within Teams, Outlook, and the the Microsoft 365 app (https://office.com).</p> <p>If you ever tried Teams App Camp you would know all about them. If not, don't worry about it, just delete these lines from manifest.json as they aren't needed anymore.</p> <pre><code>\"staticTabs\": [\n  {\n    \"entityId\": \"index\",\n    \"name\": \"Copilot Camp\",\n    \"contentUrl\": \"https://microsoft.github.io/copilot-camp/\",\n    \"websiteUrl\": \"https://microsoft.github.io/copilot-camp/\",\n    \"scopes\": [\n      \"personal\"\n    ]\n  }\n],\n\"validDomains\": [\n  \"microsoft.github.io\"\n],\n</code></pre> <p></p>"},{"location":"pages/extend-m365-copilot/03-add-declarative-agent/#exercise-3-run-and-test-the-declarative-agent","title":"Exercise 3: Run and test the declarative agent","text":""},{"location":"pages/extend-m365-copilot/03-add-declarative-agent/#step-1-run-the-new-project","title":"Step 1: Run the new project","text":"<p>If you're still in the debugger, stop it to force a complete re-deloyment. Then start the debugger by clicking the arrow or pressing F5.</p> <p>You should be automatically redirected to a browser tab where the \"Trey Genie local\" agent is launched in an immersive experience. If not, Open the Copilot chat and the left flyout 1\ufe0f\u20e3 to show your previous chats and declarative agents and select the Trey Genie Local agent 2\ufe0f\u20e3.</p> <p></p> <p></p>"},{"location":"pages/extend-m365-copilot/03-add-declarative-agent/#step-2-test-the-declarative-agent","title":"Step 2: Test the declarative agent","text":"<p>Start chatting with your agent. Try a prompt such as:</p> <p>Please list my projects along with details from the Statement of Work doc. 1\ufe0f\u20e3</p> <p>You should see a list of your projects from the API plugin 2\ufe0f\u20e3, enhanced with details from each project's Statement of Work 3\ufe0f\u20e3. Notice links the references to the documents as citations. Click on one of the references to check out the document.</p> <p>If you see a message to connect to the your service to process query, select \"Always allow\" to proceed.</p> <p></p> <p>Note</p> <p>If the SharePoint documents aren't referenced, perhaps there is an issue accessing the files. Has there been time for Search to index the site? Does the end user have permission to the site? Has an administrator excluded the site from Search? Try doing a Search (outside of Copilot) such as </p> <p><code>woodgrove path:\"https://&lt;tenant&gt;.sharepoint.com/sites/&lt;sitename&gt;\"</code></p> <p>filling in your tenant and site name to match the one in the capability. You should see three Woodgrove documents; if you don't you need to troubleshoot Search since Copilot won't be able to find them either.</p> <p>Let's also see how the API is getting called. Try to send another prompt:</p> <p>List my information. 1\ufe0f\u20e3 to instruct the agent to retrieve details from the <code>api/me</code> endpoint of the Trey Research project API 2\ufe0f\u20e3.</p> <p>See below how it brought back my information (Avery Howard is logged in user as we have not yet implemented Auth, coming up in later labs), and my projects.</p> <p></p> <p>If you go back to your VS Code project under \"Terminal\", you will also see how the agent called the API as shown below:</p> <p></p> <p></p> <p>CONGRATULATIONS!</p> <p>You've completed adding a declarative agent to your API plugin. You are now ready to enhance your API and the plugin for your agent. </p> <p></p> <p></p>"},{"location":"pages/extend-m365-copilot/04-enhance-api-plugin/","title":"Lab E4 - Enhance the API and Plugin","text":"<p>In this lab you will add additional REST calls to the API and add them to the API Plugin packaging so Copilot can call them. In the process you will learn all the places where an API needs to be defined for Copilot.</p> Get a quick overview of the lab in this video.              \ud83d\udcd8 Note:    This lab builds on the previous one, Lab E3. You should be able to continue working in the same folder for labs E2-E6, but solution folders have been provided for your reference.     The finished solution for this lab is in the /src/extend-m365-copilot/path-e-lab04-enhance-api-plugin/trey-research-lab04-END <p>Do these labs if you want to build a Declarative agent where Microsoft 365 provides the AI model and               orchestration</p> <ul> <li>\ud83c\udfc1 Welcome</li> <li>\ud83d\udd27 Set up <ul> <li>Lab E0 - Setup</li> </ul> </li> <li>\ud83e\uddf0 Declarative agent fundamentals <ul> <li> Lab E1 - Build a  Declarative Agent using TypeSpec </li> <li> Lab E1a - Geo locator game</li> </ul> </li> <li>\ud83d\udee0\ufe0f Build and integrate API from scratch <ul> <li>Lab E2 - Build an API</li> <li> Lab E3 - Add Declarative Agent + API</li> <li> Lab E4 - Enhance API + Plugin</li> <li>Lab E5 - Add Adaptive Cards</li> <li> Lab E6a - Add Authentication</li> </ul> </li> <li>\ud83d\udd0c Integration <ul> <li> Lab E7 - Add Copilot Connector</li> </ul> <ul> <li> Lab E8 - Connect Declarative agent to MCP Server</li> </ul> <ul> <li> Lab E9 - Connected Agents</li> </ul> </li> </ul>"},{"location":"pages/extend-m365-copilot/04-enhance-api-plugin/#exercise-1-add-projects-resource","title":"Exercise 1: Add /projects resource","text":"<p>In this exercise you will add a /projects resource to the Trey Research API. This will allow you to request information about projects using GET requests, and to assign a consultant to a project using a POST request. In the process, you'll learn about the appPackage/trey-plugin.json and trey-definition.json files as you modify them to add the new projects API calls.</p>"},{"location":"pages/extend-m365-copilot/04-enhance-api-plugin/#step-1-add-azure-function-code","title":"Step 1: Add Azure function code","text":"<p>To begin, create a new file, projects.ts in the /src/functions folder of your solution. Then copy the code from here.</p> <p>This will implement a new Azure function to provide access to Trey Research projects</p> <p></p>"},{"location":"pages/extend-m365-copilot/04-enhance-api-plugin/#step-2-review-the-azure-function-code-optional","title":"Step 2: Review the Azure function code (optional)","text":"<p>Let's take a moment to review the code.</p> <p>This is a version 4 Azure function, so the code looks a lot like traditional Express code for NodeJS. The <code>projects</code> class implements an HTTP request trigger, which is called when the \"/projects\" path is accessed. This is followed by some in-line code that defines the methods and route. For now, access is anonymous; we'll add authentication, checkout out pathways for authentication.</p> <pre><code>export async function projects(\n    req: HttpRequest,\n    context: InvocationContext\n): Promise&lt;Response&gt; {\n    // ...\n}\napp.http(\"projects\", {\n    methods: [\"GET\", \"POST\"],\n    authLevel: \"anonymous\",\n    route: \"projects/{*id}\",\n    handler: projects,\n});\n</code></pre> <p>The class includes a switch statement for handling GET vs. POST requests, and obtains the parameters from the URL path (in the case of a project ID), query strings (such as ?projectName=foo, in the case of a GET), and the request body (in the case of a POST). It then accesses the project data using the ProjectApiService, which was part of the starting solution. It also sends responses for each request and logging of requests to the debug console.</p> <p></p>"},{"location":"pages/extend-m365-copilot/04-enhance-api-plugin/#step-3-add-http-test-requests","title":"Step 3: Add HTTP test requests","text":"<p>Now let's add the new requests to the http/treyResearchAPI.http file so we can try them out. Open the file and add this text to the bottom, then save your changes, or copy the updated file from here </p> <pre><code>########## /api/projects - working with projects ##########\n\n### Get all projects\n{{base_url}}/projects\n\n### Get project by id\n{{base_url}}/projects/1\n\n### Get project by project or client name\n{{base_url}}/projects/?projectName=supply\n\n### Get project by consultant name\n{{base_url}}/projects/?consultantName=dominique\n\n### Add consultant to project\nPOST {{base_url}}/projects/assignConsultant\nContent-Type: application/json\n\n{\n    \"projectName\": \"contoso\",\n    \"consultantName\": \"sanjay\",\n    \"role\": \"architect\",\n    \"forecast\": 30\n}\n</code></pre> <p></p>"},{"location":"pages/extend-m365-copilot/04-enhance-api-plugin/#step-4-test-the-new-resource","title":"Step 4: Test the new resource","text":"<p>If your app is still running from previous lab, stop the debugger and restart it. Or, just start the debugger normally and wait for the app to start. When everything is ready, Agents Toolkit will display a web browser wanting you to log into Microsoft 365. Minimize this browser as you don't need it yet, but closing it would stop the debugger.</p> <p>Now try sending the new requests and you should be able to see Trey Research project details or assign a new consultant to a project using the POST request.</p> <p></p> <p></p>"},{"location":"pages/extend-m365-copilot/04-enhance-api-plugin/#exercise-2-add-projects-to-the-application-package","title":"Exercise 2: Add projects to the application package","text":"<p>The API plugin's application package is a zip file that contains all the information Copilot needs to use the API. In this exercise, you'll add information about the new /projects resource to the app package.</p>"},{"location":"pages/extend-m365-copilot/04-enhance-api-plugin/#step-1-update-the-open-api-specification-file","title":"Step 1: Update the Open API Specification file","text":"<p>An important part of the application package is the Open API Specification (OAS) definition file. OAS defines a standard format for describing a REST API, and is based on the popular \"Swagger\" definition.</p> <p>To begin, in the /appPackage/apiSpecificationFile folder, open the file trey-definition.json.  Since editing large JSON files can be tricky, please just copy the updated file from here and save the new trey-definition.json. In the steps that follow, you can review and understand the changes.</p> <p></p>"},{"location":"pages/extend-m365-copilot/04-enhance-api-plugin/#step-2-review-the-updates-optional","title":"Step 2: Review the updates (optional)","text":"<p>The first update was to add the <code>/projects/</code> path to the <code>paths</code> collection in the JSON.  As you can see, this includes all the available query strings when retrieving the <code>/projects/</code> resource, along with data types and required fields. It also includes the data that will be returned in API responses, including different payloads for status 200 (successful) and 400 (failed) responses.</p> <pre><code>\"/projects/\": {\n    \"get\": {\n        \"operationId\": \"getProjects\",\n        \"summary\": \"Get projects matching a specified project name and/or consultant name\",\n        \"description\": \"Returns detailed information about projects matching the specified project name and/or consultant name\",\n        \"parameters\": [\n            {\n                \"name\": \"consultantName\",\n                \"in\": \"query\",\n                \"description\": \"The name of the consultant assigned to the project\",\n                \"required\": false,\n                \"schema\": {\n                    \"type\": \"string\"\n                }\n            },\n            {\n                \"name\": \"projectName\",\n                \"in\": \"query\",\n                \"description\": \"The name of the project or name of the client\",\n                \"required\": false,\n                \"schema\": {\n                    \"type\": \"string\"\n                }\n            }\n        ],\n        \"responses\": {\n            \"200\": {\n                \"description\": \"Successful response\",\n                \"content\": {\n                    \"application/json\": {\n                        \"schema\": {\n                            \"type\": \"object\",\n                            \"properties\": {\n                                \"results\": {\n                                    \"type\": \"array\",\n                                    \"items\": {\n                                        \"type\": \"object\",\n                                        \"properties\": {\n                                            \"name\": {\n                                                \"type\": \"string\"\n                                            },\n                                            \"description\": {\n                                                \"type\": \"string\"\n                                            },\n                                            \"location\": {\n                                                \"type\": \"object\",\n                                                \"properties\": {\n                                                    \"street\": {\n                                                        \"type\": \"string\"\n                                                    },\n                                                    \"city\": {\n                                                        \"type\": \"string\"\n                                                    },\n                                                    \"state\": {\n                                                        \"type\": \"string\"\n                                                    },\n                                                    \"country\": {\n                                                        \"type\": \"string\"\n                                                    },\n                                                    \"postalCode\": {\n                                                        \"type\": \"string\"\n                                                    },\n                                                    \"latitude\": {\n                                                        \"type\": \"number\"\n                                                    },\n                                                    \"longitude\": {\n                                                        \"type\": \"number\"\n                                                    },\n                                                    \"mapUrl\": {\n                                                        \"type\": \"string\",\n                                                        \"format\": \"uri\"\n                                                    }\n                                                }\n                                            },\n                                            \"role\": {\n                                                \"type\": \"string\"\n                                            },\n                                            \"forecastThisMonth\": {\n                                                \"type\": \"integer\"\n                                            },\n                                            \"forecastNextMonth\": {\n                                                \"type\": \"integer\"\n                                            },\n                                            \"deliveredLastMonth\": {\n                                                \"type\": \"integer\"\n                                            },\n                                            \"deliveredThisMonth\": {\n                                                \"type\": \"integer\"\n                                            }\n                                        }\n                                    }\n                                },\n                                \"status\": {\n                                    \"type\": \"integer\"\n                                }\n                            }\n                        }\n                    }\n                }\n            },\n            \"404\": {\n                \"description\": \"Project not found\"\n            }\n        }\n    }\n},\n</code></pre> <p>You will also find that a path has been added at <code>/projects/assignConsultant</code> to handle the POST requests.</p> <p>Descriptions are important!</p> <p>This file, along with all the files in the app package, are going to be read by an intelligence. It may be artificial, but it's still intelligent enough to read the descriptions! You can help Copilot properly use your API by using descriptive names and descriptions in this and all the application package files!</p> <p></p>"},{"location":"pages/extend-m365-copilot/04-enhance-api-plugin/#step-3-add-projects-to-the-plugin-definition-file","title":"Step 3: Add projects to the plugin definition file","text":"<p>Now open the file trey-plugin.json within the /appPackage folder. This file contains extra information not included in the OAS definition file. Replace the contents of trey-plugin.json with this updated JSON.</p> <p></p>"},{"location":"pages/extend-m365-copilot/04-enhance-api-plugin/#step-4-review-the-changes-to-the-plugin-definition-file-optional","title":"Step 4: Review the changes to the plugin definition file (optional)","text":"<p>The plugin JSON file contains a collection of functions, each of which corresponds to a type of API call. Copilot will choose among these functions when utilizing your plugin at runtime.</p> <p>The new trey-plugin.json file includes new functions <code>getProjects</code> and <code>postAssignConsultant</code>. For example, here is <code>getProjects</code>:</p> <pre><code>{\n    \"name\": \"getProjects\",\n    \"description\": \"Returns detailed information about projects matching the specified project name and/or consultant name\",\n    \"capabilities\": {\n        \"response_semantics\": {\n            \"data_path\": \"$.results\",\n            \"properties\": {\n            \"title\": \"$.name\",\n            \"subtitle\": \"$.description\"\n            }\n        }\n    }\n},\n</code></pre> <p>Notice that it includes some <code>response_semantics</code> which instruct Copilot's orchestrator how to interpret the response payload. It defines the mapping of structured data in a response payload to specific properties required by the function. It enables the orchestrator to interpret and transform raw response data into meaningful content for rendering or further processing. For e.g. look at the response semantics below:</p> <pre><code>\n\"functions\": [\n    {\n      \"name\": \"getConsultants\",\n      \"description\": \"Returns detailed information about consultants identified from filters like name of the consultant, name of project, certifications, skills, roles and hours available. Multiple filters can be used in combination to refine the list of consultants returned\",\n      \"capabilities\": {\n        \"response_semantics\": {\n          \"data_path\": \"$.results\",\n          \"properties\": {\n            \"title\": \"$.name\",\n            \"subtitle\": \"$.id\",\n            \"url\": \"$.consultantPhotoUrl\"\n          }\n        }\n      }\n    },..]\n\n</code></pre> <p>Here <code>data_path</code> is : <code>$.results</code> in the <code>response_semantics</code> of function <code>getConsultants</code>. It means the main data resides under the <code>results</code> key in the JSON, which ensures the system extracts data starting at that path. It also defines mappings of specific fields from the raw data to corresponding semantic properties under <code>properties</code> field to readily use it for rendering.</p> <p>e.g. </p> <pre><code>     \"title\": \"$.name\",\n      \"subtitle\": \"$.id\",\n      \"url\": \"$.consultantPhotoUrl\"\n</code></pre> <p>The POST request has a similar function:</p> <pre><code>{\n    \"name\": \"postAssignConsultant\",\n    \"description\": \"Assign (add) consultant to a project when name, role and project name is specified.\",\n    \"capabilities\": {\n    \"response_semantics\": {\n        \"data_path\": \"$\",\n        \"properties\": {\n        \"title\": \"$.results.clientName\",\n        \"subtitle\": \"$.results.status\"\n        }\n    },\n    \"confirmation\": {\n        \"type\": \"AdaptiveCard\",\n        \"title\": \"Assign consultant to a project when name, role and project name is specified.\",\n        \"body\": \"**ProjectName**: {{function.parameters.projectName}}\\n* **ConsultantName**: {{function.parameters.consultantName}}\\n* **Role**: {{function.parameters.role}}\\n* **Forecast**: {{function.parameters.forecast}}\"\n    }\n    }\n}\n</code></pre> <p>It includes an adaptive card to be used in the confirmation card, which is shown to users to confirm an action prior to issuing a POST request.</p> <p>Scrolling down, you can see the <code>runtimes</code> object which defines the type of plugin, the OAS definition file location, and a list of functions. The new functions have been added to the list.</p> <pre><code>\"runtimes\": [\n{\n    \"type\": \"OpenApi\",\n    \"auth\": {\n    \"type\": \"None\"\n    },\n    \"spec\": {\n    \"url\": \"trey-definition.json\"\n    },\n    \"run_for_functions\": [\n    \"getConsultants\",\n    \"getUserInformation\",\n    \"getProjects\",\n    \"postBillhours\",\n    \"postAssignConsultant\"\n    ]\n}\n],\n</code></pre> <p>Finally, it includes some conversation starters which are prompt suggestions shown to users; the new file has a conversation starter relating to projects.</p> <pre><code>\"capabilities\": {\n\"localization\": {},\n\"conversation_starters\": [\n    {\n    \"text\": \"What Trey projects am i assigned to?\"\n    },\n    {\n    \"text\": \"Charge 5 hours to the Contoso project for Trey Research\"\n    },\n    {\n    \"text\": \"Which Trey consultants are Azure certified?\"\n    },\n    {\n    \"text\": \"Find a Trey consultant who is available now and has Python skills\"\n    },\n    {\n    \"text\": \"Add Avery as a developer on the Contoso project for Trey\"\n    }\n]\n}\n</code></pre> <p></p>"},{"location":"pages/extend-m365-copilot/04-enhance-api-plugin/#exercise-3-test-the-plugin-in-copilot","title":"Exercise 3: Test the plugin in Copilot","text":"<p>Before you test the application, update the manifest version of your app package in the <code>appPackage\\manifest.json</code> file, follow these steps:</p> <ol> <li> <p>Open the <code>manifest.json</code> file located in the <code>appPackage</code> folder of your project.</p> </li> <li> <p>Locate the <code>version</code> field in the JSON file. It should look something like this: <code>json    \"version\": \"1.0.0\"</code></p> </li> <li> <p>Increment the version number to a small increment. For example, change it to: <code>json    \"version\": \"1.0.1\"</code></p> </li> <li> <p>Save the file after making the change.</p> </li> </ol>"},{"location":"pages/extend-m365-copilot/04-enhance-api-plugin/#step-1-restart-the-application","title":"Step 1: Restart the application","text":"<p>Stop and restart your project to force it to re-deploy the application package. You will be in a window with direct chat with your agent in Copilot.</p> <p></p>"},{"location":"pages/extend-m365-copilot/04-enhance-api-plugin/#step-2-prompt-the-trey-genie","title":"Step 2: Prompt the Trey Genie","text":"<p>Now try a prompt such as \"what projects are we doing for adatum?\"</p> <p></p> <p>Your agent will ask permission to allow this action even for the GET request. Select \"Always allow\" and proceed to the request to view the project details.</p> <p></p> <p></p> <p>CONGRATULATIONS!</p> <p>You've now completed enhancing your API plugin. But as you can see, the citation cards are very basic. So let's proceed to the next lab to add rich card citations and responses using adaptive cards. </p> <p></p> <p></p>"},{"location":"pages/extend-m365-copilot/05-add-adaptive-card/","title":"Lab E5 - Add adaptive cards","text":"<p>In this lab you will further enhance the response from Microsoft 365 Copilot from text to rich cards using Adaptive Cards. </p> <p>In this lab you will learn:</p> <ul> <li>What are Adaptive Cards</li> <li>How to create and test an Adaptive Card</li> <li>How to update Microsoft 365 Copilot responses to use Adaptive Cards for rich content</li> </ul> Get a quick overview of the lab in this video.              \ud83d\udcd8 Note: This lab builds on the previous one, Lab E4. You should be able to continue working in the same folder for labs E2-E6, but solution folders have been provided for your reference.     The finished solution for this lab is in the /src/extend-m365-copilot/path-e-lab05-add-adaptive-cards/trey-research-lab05-END <p>Do these labs if you want to build a Declarative agent where Microsoft 365 provides the AI model and               orchestration</p> <ul> <li>\ud83c\udfc1 Welcome</li> <li>\ud83d\udd27 Set up <ul> <li>Lab E0 - Setup</li> </ul> </li> <li>\ud83e\uddf0 Declarative agent fundamentals <ul> <li> Lab E1 - Build a  Declarative Agent using TypeSpec </li> <li> Lab E1a - Geo locator game</li> </ul> </li> <li>\ud83d\udee0\ufe0f Build and integrate API from scratch <ul> <li>Lab E2 - Build an API</li> <li> Lab E3 - Add Declarative Agent + API</li> <li> Lab E4 - Enhance API + Plugin</li> <li>Lab E5 - Add Adaptive Cards</li> <li> Lab E6a - Add Authentication</li> </ul> </li> <li>\ud83d\udd0c Integration <ul> <li> Lab E7 - Add Copilot Connector</li> </ul> <ul> <li> Lab E8 - Connect Declarative agent to MCP Server</li> </ul> <ul> <li> Lab E9 - Connected Agents</li> </ul> </li> </ul>"},{"location":"pages/extend-m365-copilot/05-add-adaptive-card/#introduction","title":"Introduction","text":"What are Adaptive Cards?  Adaptive Cards are platform-independent UI snippets authored in JSON that can be exchanged between apps and services. Once delivered to an app, the JSON transforms into native UI that automatically adapts to its environment. This enables the design and integration of lightweight UI across major platforms and frameworks.      Adaptive cards are everywhere"},{"location":"pages/extend-m365-copilot/05-add-adaptive-card/#exercise-1-create-and-test-a-simple-adaptive-card","title":"Exercise 1: Create and test a simple Adaptive Card","text":"<p>Let's dive in and discover how fun it is to create adaptive cards.</p>"},{"location":"pages/extend-m365-copilot/05-add-adaptive-card/#step-1-define-your-adaptive-card-in-json","title":"Step 1: Define Your Adaptive Card in JSON","text":"<p>Here is an adaptive card in JSON. Begin by copying it to your clipboard.</p> <pre><code>{\n  \"type\": \"AdaptiveCard\",\n  \"body\": [\n    {\n      \"type\": \"TextBlock\",\n      \"text\": \"Hello, Adaptive Cards!\",\n      \"size\": \"large\",\n      \"weight\": \"bolder\"\n    }\n  ],\n  \"actions\": [\n    {\n      \"type\": \"Action.OpenUrl\",\n      \"title\": \"Click me\",\n      \"url\":\"https://www.contoso.com\"\n    }\n  ],\n  \"$schema\": \"http://adaptivecards.io/schemas/adaptive-card.json\",\n  \"version\": \"1.3\"\n}\n</code></pre> <p>This JSON defines a simple Adaptive Card with a text block and a button.</p> <p></p>"},{"location":"pages/extend-m365-copilot/05-add-adaptive-card/#step-2-test-your-adaptive-card","title":"Step 2: Test Your Adaptive Card","text":"<p>To test your Adaptive Card, you can use the Adaptive Cards Designer.</p> <ol> <li>Open the Adaptive Cards Designer.</li> <li>Paste the JSON content into the \"Card Payload Editor\" section on the lower part of the designer.</li> <li>You will see a live preview of your Adaptive Card on the upper part of the designer.</li> </ol> <p>Congrats! You are now fully skilled to develop Adaptive cards for your plugin!</p> <p></p>"},{"location":"pages/extend-m365-copilot/05-add-adaptive-card/#exercise-2-update-agent-response-to-be-richer","title":"Exercise 2: Update agent response to be richer","text":""},{"location":"pages/extend-m365-copilot/05-add-adaptive-card/#step-1-add-adaptive-card-files","title":"Step 1: Add adaptive card files","text":"<p>We are going to add some visibly appealing cards for functions <code>getConsultants</code>, <code>getUserInformation</code> and <code>postBillhours</code>.</p> <p>Create three files <code>getConsultants.json</code>, <code>postBillhours.json</code> and <code>getUserInformation.json</code> in the appPackage/adaptiveCards folder. </p> <p>Copy contents from these raw files and paste them into appropriate files:</p> <ul> <li>getConsultants.json</li> <li>getUserInformation.json</li> <li>postBillhours.json</li> </ul> <p>If you open this JSON file, you'll see the card's structure and how it uses data binding to connect with the API response. Template expressions in the card automatically populate with real data from your API, allowing your agent to present information in a polished, visually appealing format instead of plain text.</p> <p></p>"},{"location":"pages/extend-m365-copilot/05-add-adaptive-card/#step-2-update-plugin-manifest-to-inlcude-adaptive-cards","title":"Step 2: Update plugin manifest to inlcude adaptive cards","text":"<ol> <li>Open appPackage/trey-plugin.json</li> <li>Find the <code>getConsultants</code> function</li> <li>Inside <code>response_semantics</code>, add the following after the <code>properties</code> field (include the comma also from the snippet):</li> </ol> <pre><code>,\n  \"static_template\": {\n            \"file\": \"adaptiveCards/getConsultants.json\"\n          }\n</code></pre> <p>After modification the function getConsultants looks as below:</p> <pre><code>    {\n      \"name\": \"getConsultants\",\n      \"description\": \"Returns detailed information about consultants identified from filters like name of the consultant, name of project, certifications, skills, roles and hours available. Multiple filters can be used in combination to refine the list of consultants returned\",\n      \"capabilities\": {\n        \"response_semantics\": {\n          \"data_path\": \"$.results\",\n          \"properties\": {\n            \"title\": \"$.name\",\n            \"subtitle\": \"$.id\",\n            \"url\": \"$.consultantPhotoUrl\"\n          },\n           \"static_template\": {\n            \"file\": \"adaptiveCards/getConsultants.json\"\n          }\n        }\n      }\n    }\n</code></pre> <p>Repeat for getUserInformation function with below:</p> <pre><code>  ,\n  \"static_template\": {\n            \"file\": \"adaptiveCards/getUserInformation.json\"\n          }\n</code></pre> <p>And finally for postBillhours function with below:</p> <pre><code>  ,\n  \"static_template\": {\n            \"file\": \"adaptiveCards/postBillhours.json\"\n          }\n</code></pre> <p></p>"},{"location":"pages/extend-m365-copilot/05-add-adaptive-card/#exercise-3-test-the-plugin-in-copilot","title":"Exercise 3: Test the plugin in Copilot","text":"<p>Before you test the application, update the manifest version of your app package in the <code>appPackage\\manifest.json</code> file, follow these steps:</p> <ol> <li> <p>Open the <code>manifest.json</code> file located in the <code>appPackage</code> folder of your project.</p> </li> <li> <p>Locate the <code>version</code> field in the JSON file. It should look something like this: <code>json    \"version\": \"1.0.1\"</code></p> </li> <li> <p>Increment the version number to a small increment. For example, change it to: <code>json    \"version\": \"1.0.2\"</code></p> </li> <li> <p>Save the file after making the change.</p> </li> </ol>"},{"location":"pages/extend-m365-copilot/05-add-adaptive-card/#step-1-install-the-plugin","title":"Step 1: Install the plugin","text":"<p>Stop and restart your project to force it to re-deploy the application package. You will be in a window with direct chat with your agent in Copilot.</p> <p></p> <p></p>"},{"location":"pages/extend-m365-copilot/05-add-adaptive-card/#step-2-display-an-adaptive-card","title":"Step 2: Display an adaptive card","text":"<p>Now try a prompt such below:</p> <p>Find consultants with TypeScript skills</p> <p>Instead of just the text response you will also get a rich card with information of the project. </p> <p>Now try a POST operation prompt such below</p> <p>please charge 1 hour to woodgrove bank in trey research</p> <p>Since the request requires Copilot to send some data via POST to the API plugin, you need to confirm that you want to allow Copilot to do so selecting the Confirm button.</p> <p></p> <p>Once confirmed, instead of just the text response you will also get a rich card with information of the project.</p> <p></p> <p>You can now test other prompts as well to see the improved responses from Microsoft 365 Copilot.</p> <p></p> <p>CONGRATULATIONS!</p> <p>You've completed adding adaptive card responses to your first API plugin. You are now ready to proceed to the next lab to add authentication to your API.</p> <p></p> <p></p>"},{"location":"pages/extend-m365-copilot/06a-add-authentication-ttk/","title":"Lab E6a - Add Entra ID authentication with OAuth (Agents Toolkit)","text":"<p>In this lab you will add authentication to your API plugin using OAuth 2.0 with Entra ID as the identity provider. You will learn how to set up Agents Toolkit to automate the Entra ID and Teams Developer Portal registrations.</p> Get a quick overview of the lab in this video.              \ud83d\udcd8 Note:    This lab builds on the previous one, Lab E5. If you have completed lab E5, you can continue working in the same folder. If not, please copy the solution folder for Lab E5 from /src/extend-m365-copilot/path-e-lab05-add-adaptive-cards/trey-research-lab05-END     and work there.     The finished solution for this lab is in the src/extend-m365-copilot/path-e-lab06a-add-oauth/trey-research-lab06a-END  folder.          <p>Do these labs if you want to build a Declarative agent where Microsoft 365 provides the AI model and               orchestration</p> <ul> <li>\ud83c\udfc1 Welcome</li> <li>\ud83d\udd27 Set up <ul> <li>Lab E0 - Setup</li> </ul> </li> <li>\ud83e\uddf0 Declarative agent fundamentals <ul> <li> Lab E1 - Build a  Declarative Agent using TypeSpec </li> <li> Lab E1a - Geo locator game</li> </ul> </li> <li>\ud83d\udee0\ufe0f Build and integrate API from scratch <ul> <li>Lab E2 - Build an API</li> <li> Lab E3 - Add Declarative Agent + API</li> <li> Lab E4 - Enhance API + Plugin</li> <li>Lab E5 - Add Adaptive Cards</li> <li> Lab E6a - Add Authentication</li> </ul> </li> <li>\ud83d\udd0c Integration <ul> <li> Lab E7 - Add Copilot Connector</li> </ul> <ul> <li> Lab E8 - Connect Declarative agent to MCP Server</li> </ul> <ul> <li> Lab E9 - Connected Agents</li> </ul> </li> </ul>"},{"location":"pages/extend-m365-copilot/06a-add-authentication-ttk/#exercise-1-update-the-local-agents-toolkit-configuration","title":"Exercise 1: Update the local Agents Toolkit configuration","text":"<p>In this exercise you will modify the Agents Toolkit configuration files to instruct it to register the application in Entra ID and to place the information in the Teams Developer Portal \"vault\".</p>"},{"location":"pages/extend-m365-copilot/06a-add-authentication-ttk/#step-1-add-an-entra-id-app-manifest","title":"Step 1: Add an Entra ID app manifest","text":"<p>Create a new file aad.manifest.json in the root of your working folder. Copy these lines into this file.</p> <pre><code>{\n  \"id\": \"${{AAD_APP_OBJECT_ID}}\",\n  \"appId\": \"${{AAD_APP_CLIENT_ID}}\",\n  \"displayName\": \"Trey-Research-OAuth-aad\",\n  \"identifierUris\": [\n    \"api://${{AAD_APP_CLIENT_ID}}\"\n  ],\n  \"signInAudience\": \"AzureADMyOrg\",\n  \"api\": {\n    \"requestedAccessTokenVersion\": 2,\n    \"oauth2PermissionScopes\": [\n      {\n        \"adminConsentDescription\": \"Allows Copilot to access the Trey Research API on the user's behalf.\",\n        \"adminConsentDisplayName\": \"Access Trey Research API\",\n        \"id\": \"${{AAD_APP_ACCESS_AS_USER_PERMISSION_ID}}\",\n        \"isEnabled\": true,\n        \"type\": \"User\",\n        \"userConsentDescription\": \"Allows Copilot to access the Trey Research API on your behalf.\",\n        \"userConsentDisplayName\": \"Access Trey Research API\",\n        \"value\": \"access_as_user\"\n      }\n    ]\n  },\n  \"info\": {},\n  \"optionalClaims\": {\n    \"idToken\": [],\n    \"accessToken\": [\n      {\n        \"name\": \"idtyp\",\n        \"source\": null,\n        \"essential\": false,\n        \"additionalProperties\": []\n      }\n    ],\n    \"saml2Token\": []\n  },\n  \"publicClient\": {\n    \"redirectUris\": []\n  },\n  \"web\": {\n    \"redirectUris\": [\n      \"https://teams.microsoft.com/api/platform/v1.0/oAuthRedirect\"\n    ],\n    \"implicitGrantSettings\": {}\n  },\n  \"spa\": {\n    \"redirectUris\": []\n  }\n}\n\n</code></pre> <p>This file contains details for the Entra ID application to be registered or updated. Notice that it contains various tokens such as <code>${{AAD_APP_CLIENT_ID}}</code> which will be replaced with actual values when Agents Toolkit provisions the application.</p> <p>Note</p> <p>Entra ID was previously called \"Azure Active Directory\"; references to \"AAD\" refer to Entra ID under its old name.</p> <p></p>"},{"location":"pages/extend-m365-copilot/06a-add-authentication-ttk/#step-2-update-the-file-version-number-in-teamsapplocalyml","title":"Step 2: Update the file version number in teamsapp.local.yml","text":"<p>The m365agents.local.yml file contains instructions for Agents Toolkit for running and debugging your solution locally. This is the file you will update in remainder of this exercise.</p> <p>Warning</p> <p>Editing yaml files is sometimes tricky because containment is indicated by indentation. Be sure to indent properly when making each change or the lab won't work. If in doubt, you can refer to the completed solution file here.</p> <p></p>"},{"location":"pages/extend-m365-copilot/06a-add-authentication-ttk/#step-3-provision-an-entra-id-application","title":"Step 3: Provision an Entra ID application","text":"<p>In order for an application to authenticate a user and authorize it to do something, the application must first be registered in Entra ID. In this step we'll add this app registration if it's not already present.</p> <p>Locate these lines in the file:</p> <pre><code>provision:\n  # Creates a Teams app\n</code></pre> <p>Insert the following yaml between these lines, directly under the <code>provision:</code> line. You may leave blank lines for readability if you wish.</p> <pre><code>  # Creates a new Microsoft Entra app to authenticate users if\n  # the environment variable that stores clientId is empty\n  - uses: aadApp/create\n    with:\n      # Note: when you run aadApp/update, the Microsoft Entra app name will be updated\n      # based on the definition in manifest. If you don't want to change the\n      # name, make sure the name in Microsoft Entra manifest is the same with the name\n      # defined here.\n      name: trey-oauth-aad\n      # If the value is false, the action will not generate client secret for you\n      generateClientSecret: true\n      # Authenticate users with a Microsoft work or school account in your\n      # organization's Microsoft Entra tenant (for example, single tenant).\n      signInAudience: AzureADMyOrg\n    # Write the information of created resources into environment file for the\n    # specified environment variable(s).\n    writeToEnvironmentFile:\n      clientId: AAD_APP_CLIENT_ID\n      # Environment variable that starts with `SECRET_` will be stored to the\n      # .env.{envName}.user environment file\n      clientSecret: SECRET_AAD_APP_CLIENT_SECRET\n      objectId: AAD_APP_OBJECT_ID\n      tenantId: AAD_APP_TENANT_ID\n      authority: AAD_APP_OAUTH_AUTHORITY\n      authorityHost: AAD_APP_OAUTH_AUTHORITY_HOST\n</code></pre> <p>Notice that by setting <code>signInAudience</code> to <code>AzureADMyOrg</code>, Agents Toolkit creates a single tenant application that can only be used within the Entra ID tenant where it is registered. If you want to allow the app to be used in other tenants, such as your customer's tenants, you would set this to <code>AzureADMultipleOrgs</code>. All three steps use the aad.manifest.json file you created in the previous step.</p> <p>Also note that this step will write several values into your environment files, where they will be inserted into aad.manifest.json as well as in your application package.</p> <p></p>"},{"location":"pages/extend-m365-copilot/06a-add-authentication-ttk/#step-4-update-the-entra-id-application","title":"Step 4: Update the Entra ID application","text":"<p>Locate this line in m365agents.local.yml</p> <pre><code>  # Build app package with latest env value\n</code></pre> <p>Insert the following yaml before this line:</p> <pre><code>  - uses: oauth/register\n    with:\n      name: oAuth2AuthCode\n      flow: authorizationCode\n      appId: ${{TEAMS_APP_ID}}\n      clientId: ${{AAD_APP_CLIENT_ID}}\n      clientSecret: ${{SECRET_AAD_APP_CLIENT_SECRET}}\n      # Path to OpenAPI description document\n      apiSpecPath: ./appPackage/apiSpecificationFile/trey-definition.json\n    writeToEnvironmentFile:\n      configurationId: OAUTH2AUTHCODE_CONFIGURATION_ID\n\n  - uses: oauth/update\n    with:\n      name: oAuth2AuthCode\n      appId: ${{TEAMS_APP_ID}}\n      clientId: ${{AAD_APP_CLIENT_ID}}\n      # Path to OpenAPI description document\n      apiSpecPath: ./appPackage/apiSpecificationFile/trey-definition.json\n      configurationId: ${{OAUTH2AUTHCODE_CONFIGURATION_ID}}\n\n  # Apply the Microsoft Entra manifest to an existing Microsoft Entra app. Will use the object id in\n  # manifest file to determine which Microsoft Entra app to update.\n  - uses: aadApp/update\n    with:\n      # Relative path to this file. Environment variables in manifest will\n      # be replaced before apply to Microsoft Entra app\n      manifestPath: ./aad.manifest.json\n      outputFilePath: ./build/aad.manifest.${{TEAMSFX_ENV}}.json\n</code></pre> <p>The <code>oauth/register</code> and <code>oauth/update</code> steps will register the application in the Teams Developer Portal's vault, where Copilot can obtain the necessary details to implement the OAuth 2.0 Auth Code authorization flow. The <code>aadApp/update</code> step will update the Entra ID application itself with the details for this app. These details are in a separte file, aad.manifest.json, which we'll add in the next exercise.</p> <p></p>"},{"location":"pages/extend-m365-copilot/06a-add-authentication-ttk/#step-5-make-the-entra-id-values-available-to-your-application-code","title":"Step 5: Make the Entra ID values available to your application code","text":"<p>Locate these lines:</p> <pre><code>deploy:\n  # Install development tool(s)\n  - uses: devTool/install\n    with:\n      func:\n        version: ~4.0.5530\n        symlinkDir: ./devTools/func\n    # Write the information of installed development tool(s) into environment\n    # file for the specified environment variable(s).\n    writeToEnvironmentFile:\n      funcPath: FUNC_PATH\n          # Generate runtime environment variables\n  - uses: file/createOrUpdateEnvironmentFile\n    with:\n      target: ./.localConfigs\n      envs:\n        STORAGE_ACCOUNT_CONNECTION_STRING: ${{SECRET_STORAGE_ACCOUNT_CONNECTION_STRING}}\n</code></pre> <p>This code publishes environment variables for use within your application code. Add these lines under the <code>STORAGE_ACCOUNT_CONNECTION_STRING</code> to make them available:</p> <pre><code>        AAD_APP_TENANT_ID: ${{AAD_APP_TENANT_ID}}\n        AAD_APP_CLIENT_ID: ${{AAD_APP_CLIENT_ID}}\n</code></pre> <p></p>"},{"location":"pages/extend-m365-copilot/06a-add-authentication-ttk/#exercise-2-update-your-application-package","title":"Exercise 2: Update your application package","text":"<p>Now that you've got Agents Toolkit setting up the Entra ID registrations, it's time to update the application package so Copilot knows about the authentication. In this exercise you'll update the necessary files.</p>"},{"location":"pages/extend-m365-copilot/06a-add-authentication-ttk/#step-1-update-the-open-api-specification-file","title":"Step 1: Update the Open API Specification file","text":"<p>Open your working folder in Visual Studio Code. In the appPackag/apiSpecificationFile folder, open the trey-definition.json file. Locate the line:</p> <pre><code>    \"paths\": {\n</code></pre> <p>and insert the following JSON before it:</p> <pre><code>    \"components\": {\n        \"securitySchemes\": {\n            \"oAuth2AuthCode\": {\n                \"type\": \"oauth2\",\n                \"description\": \"OAuth configuration for the Trey Research service\",\n                \"flows\": {\n                    \"authorizationCode\": {\n                        \"authorizationUrl\": \"https://login.microsoftonline.com/${{AAD_APP_TENANT_ID}}/oauth2/v2.0/authorize\",\n                        \"tokenUrl\": \"https://login.microsoftonline.com/${{AAD_APP_TENANT_ID}}/oauth2/v2.0/token\",\n                        \"scopes\": {\n                            \"api://${{AAD_APP_CLIENT_ID}}/access_as_user\": \"Access Trey Research API as the user\"\n                        }\n                    }\n                }\n            }\n        }\n    },\n</code></pre> <p>This sets up a new security scheme to be used when calling the API.</p> <p>Now you need to add this scheme to each API path. Find each instance of a path and look for the <code>responses</code> object:</p> <pre><code>    \"responses\": {\n      ...\n</code></pre> <p>Insert the following JSON before each of the <code>responses</code> (you will find 5 of them in the file; make sure you insert this before each one):</p> <pre><code>    \"security\": [\n        {\n            \"oAuth2AuthCode\": []\n        }\n    ],\n</code></pre> <p>Be sure to save your changes after editing.</p> <p></p>"},{"location":"pages/extend-m365-copilot/06a-add-authentication-ttk/#step-2-update-the-plugin-file","title":"Step 2: Update the Plugin file","text":"<p>In the appPackage/ folder, open the trey-plugin.json file. This is where information is stored that Copilot needs, but is not already in the Open API Specification (OAS) file.</p> <p>Under <code>Runtimes</code> you will find an <code>auth</code> property with <code>type</code> of <code>\"None\"</code>, indicating the API is currently not authenticated. Change it as follows to tell Copilot to authenticate using the OAuth settings you saved in the vault.</p> <pre><code>  \"auth\": {\n    \"type\": \"OAuthPluginVault\",\n    \"reference_id\": \"${{OAUTH2AUTHCODE_CONFIGURATION_ID}}\"\n  },\n</code></pre> <p>In the next exercise you'll update the application code to check for a valid login and access the API as the actual Microsoft 365 user instead of \"Avery Howard\" (which is a name from Microsoft's fictitious name generator).</p> <p></p>"},{"location":"pages/extend-m365-copilot/06a-add-authentication-ttk/#exercise-3-update-the-application-code","title":"Exercise 3: Update the application code","text":""},{"location":"pages/extend-m365-copilot/06a-add-authentication-ttk/#step-1-install-the-jwt-validation-library","title":"Step 1: Install the JWT validation library","text":"<p>From a command line in your working directory, type:</p> <pre><code>npm i jwt-validate\n</code></pre> <p>This will install a library for validating the incoming Entra ID authorization token.</p> <p>Warning</p> <p>Microsoft does not provide a supported library for validating Entra ID tokens in NodeJS, but instead provides this detailed documentation on how to write your own. Another useful article is also available from Microsoft MVP Andrew Connell.</p> <p>This lab uses a community provided library written by Waldek Mastykarz, which is intended to follow this guidance. Note that this library is not supported by Microsoft and is under an MIT License, so use it at your own risk.</p> <p>If you want to track progress on a supported library, please follow this Github issue.</p> <p></p>"},{"location":"pages/extend-m365-copilot/06a-add-authentication-ttk/#step-2-update-the-identity-service","title":"Step 2: Update the identity service","text":"<p>At this point, OAuth login should work and provide a valid access token, but the solution isn't secure unless the code checks to make sure the token is valid. In this step, you'll add code to validate the is token and extract information such as the user's name and ID.</p> <p>In the src/services folder, open IdentityService.ts.  At the top of the file along with the other <code>import</code> statements, add this one:</p> <pre><code>import { TokenValidator, ValidateTokenOptions, getEntraJwksUri } from 'jwt-validate';\n</code></pre> <p>Then, right under the <code>class Identity</code> statement, add this line:</p> <pre><code>    private validator: TokenValidator;\n</code></pre> <p>Now look for the comment</p> <pre><code>// ** INSERT REQUEST VALIDATION HERE (see Lab E6) **\n</code></pre> <p>Replace the comment with this code:</p> <pre><code>  // Try to validate the token and get user's basic information\n  try {\n      const { AAD_APP_CLIENT_ID, AAD_APP_TENANT_ID } = process.env;\n      const token = req.headers.get(\"Authorization\")?.split(\" \")[1];\n      if (!token) {\n          throw new HttpError(401, \"Authorization token not found\");\n      }\n\n      // create a new token validator for the Microsoft Entra common tenant\n      if (!this.validator) {\n        // We need a new validator object which we will continue to use on subsequent\n        // requests so it can cache the Entra ID signing keys\n        // For multitenant, use:\n        // const entraJwksUri = await getEntraJwksUri();\n        const entraJwksUri = await getEntraJwksUri(AAD_APP_TENANT_ID);\n        this.validator = new TokenValidator({\n            jwksUri: entraJwksUri\n        });\n        console.log (\"Token validator created\");\n      }\n\n      const options: ValidateTokenOptions = {\n          allowedTenants: [AAD_APP_TENANT_ID],\n          audience: `${AAD_APP_CLIENT_ID}`,\n          issuer: `https://login.microsoftonline.com/${AAD_APP_TENANT_ID}/v2.0`,\n          scp: [\"access_as_user\"]\n      };\n\n      // validate the token\n      const validToken = await this.validator.validateToken(token, options);\n\n      userId = validToken.oid;\n      userName = validToken.name;\n      userEmail = validToken.preferred_username;\n      console.log(`Request ${this.requestNumber++}: Token is valid for user ${userName} (${userId})`);\n  }\n  catch (ex) {\n      // Token is missing or invalid - return a 401 error\n      console.error(ex);\n      throw new HttpError(401, \"Unauthorized\");\n  }\n</code></pre> <p>Learn from the code</p> <p>Have a look at the new source code. First, it obtains the token from the <code>Authorization</code> header in the HTTPs request. This header contains the word \"Bearer\", a space, and then the token, so a JavaScript <code>split(\" \")</code> is used to obtain only the token.</p> <p>Also note that the code will throw an exception if authentication should fail for any reason; the Azure function will then return the appropriate error.</p> <p>The code then creates a validator for use with the <code>jwks-validate</code> library. This call reads the latest private keys from Entra ID, so it is an async call that may take some time to run.</p> <p>Next, the code sets up a <code>ValidateTokenOptions</code> object. Based on this object, in addition to validating that the token was signed with Entra ID's private key, the library will validate that:</p> <ul> <li> <p>the audience must be the same as the API service app URI; this ensures that the token is intended for our web service and no other</p> </li> <li> <p>the issuer must be from the security token service for our tenant</p> </li> <li> <p>the scope must match the scope defined in our app registration, which is <code>\"access_as_user\"</code>.</p> </li> </ul> <p>If the token is valid, the library returns an object with all the \"claims\" that were inside, including the user's unique ID, name, and email. We will use these values instead of relying on the fictitious \"Avery Howard\".</p> <p></p>"},{"location":"pages/extend-m365-copilot/06a-add-authentication-ttk/#exercise-4-test-the-application","title":"Exercise 4: Test the application","text":""},{"location":"pages/extend-m365-copilot/06a-add-authentication-ttk/#step-1-bump-the-application-version-number-in-the-app-manifest","title":"Step 1: Bump the application version number in the app manifest","text":"<p>Before you test the application, update the manifest version of your app package in the <code>appPackage\\manifest.json</code> file, follow these steps:</p> <ol> <li> <p>Open the <code>manifest.json</code> file located in the <code>appPackage</code> folder of your project.</p> </li> <li> <p>Locate the <code>version</code> field in the JSON file. It should look something like this: <code>json    \"version\": \"1.0.0\"</code></p> </li> <li> <p>Increment the version number to a small increment. For example, change it to: <code>json    \"version\": \"1.0.1\"</code></p> </li> <li> <p>Save the file after making the change.</p> </li> </ol> <p>Compile issue with jwt-validate package </p> <p>At the moment, the jwt-validate package throws typing error for @types/jsonwebtoken package. To work around the issue, edit the tsconfig.json file, found at the root of the project, and add \"skipLibCheck\":true. This will be fixed in a future version of the library, and may no longer be necessary by the time you do the lab.</p> <p></p>"},{"location":"pages/extend-m365-copilot/06a-add-authentication-ttk/#step-2-restart-the-application","title":"Step 2: (Re)start the application","text":"<p>If your app is still running from an earlier lab, stop it to force it to re-create the application package.</p> <p>Then press F5 to run the application again, and install it as before.</p> <p></p>"},{"location":"pages/extend-m365-copilot/06a-add-authentication-ttk/#step-3-run-the-declarative-agent","title":"Step 3: Run the declarative agent","text":"<p>Proceed back to Microsoft 365 Copilot and select the Trey Research agent. Enter the prompt, </p> <p>What Trey projects am I assigned to?</p> <p>You will be asked to \"Sign in\". This shows you that your agent is now using some sort of an authentication mechanism.</p> <p>Click \"Sign in to Trey-Researchlocal\" to sign in. At first you should see a pop-up window asking you to log in and to consent to permissions. On subsequent vists this may be hidden as your credentials have been cached by Entra ID in your local browser.</p> <p></p> <p>You might need admin approval</p> <p>There are cases where your admin has not allowed you to consent as a user and may see something like below:</p> <p></p> <p>This is because the admin has restricted the ability for users to consent to grant permissions to applications. In this case, you have to request admin to manually grant global consent for all users for the plugin API registration as below. Find the app registration in Microsoft 365 Admin / Identity / Applications / App Registrations and do the consent from there.</p> <p></p> <p>The login card should be replaced by agent's response to your prompt. Since you were just added to the database, you aren't assigned to any projects.</p> <p>Recall that the user was hard coded to the fictitious user \"Avery Howard\". When the new code runs for the first time, it won't find your user ID, so it will create a new consultant record that's not (yet) assigned to any projects.</p> <p>Updating your user information</p> <p>Since this is just a lab, we have hard-coded the details such as skills and location for your new user account. If you want to change them, you can do that using the Azure Storage Explorer</p> <p></p> <p></p>"},{"location":"pages/extend-m365-copilot/06a-add-authentication-ttk/#step-4-add-yourself-to-a-project","title":"Step 4: Add yourself to a project","text":"<p>Since you were just added to the database, you're not assigned to any projects. Note that project assignments are stored in the <code>Assignment</code> table and reference the project ID and the assigned consultant's consultant ID. When you ask Agent what projects you are asigned to, it says it cannot find any project assigned but identifies your skills and roles and offers to help.</p> <p></p> <p>Ask Agent to add you to the Woodgrove project. Agent will press you for details if you forgot to include any required values.</p> <p></p> <p>Finally once you confirm, agent fullfills the task by adding you to the project with right role and forecast.</p> <p></p> <p>Now check out your default skills and confirm the project assignment by asking:</p> <p>What are my skills and what projects am I assigned to?</p> <p></p> <p>CONGRATULATIONS!</p> <p>You have completed lab Ea6, Add Entra ID authentication with Agents Toolkit!</p> <p>Want to try something cool? How about adding a Copilot Connector to your solution?</p> <p></p> <p></p>"},{"location":"pages/extend-m365-copilot/06b-add-authentication/","title":"Lab E6b - Add Entra ID authentication with OAuth (Manual Setup)","text":"<p>In this lab you will add authentication to your API plugin using OAuth 2.0 with Entra ID as the identity provider.</p> Get a quick overview of the lab in this video.              \ud83d\udcd8 Note:   This lab builds on the previous one, Lab E5. If you have completed lab E5, you can continue working in the same folder. If not, please copy the solution folder for Lab E5 from /src/extend-m365-copilot/path-e-lab05-add-adaptive-cards/trey-research-lab05-END      and work there.     The finished solution for this lab is in the /src/extend-m365-copilot/path-e-lab06b-add-oauth/trey-research-lab06b-ENDfolder.          <p>Do these labs if you want to build a Declarative agent where Microsoft 365 provides the AI model and               orchestration</p> <ul> <li>\ud83c\udfc1 Welcome</li> <li>\ud83d\udd27 Set up <ul> <li>Lab E0 - Setup</li> </ul> </li> <li>\ud83e\uddf0 Declarative agent fundamentals <ul> <li> Lab E1 - Build a  Declarative Agent using TypeSpec </li> <li> Lab E1a - Geo locator game</li> </ul> </li> <li>\ud83d\udee0\ufe0f Build and integrate API from scratch <ul> <li>Lab E2 - Build an API</li> <li> Lab E3 - Add Declarative Agent + API</li> <li> Lab E4 - Enhance API + Plugin</li> <li>Lab E5 - Add Adaptive Cards</li> <li> Lab E6a - Add Authentication</li> </ul> </li> <li>\ud83d\udd0c Integration <ul> <li> Lab E7 - Add Copilot Connector</li> </ul> <ul> <li> Lab E8 - Connect Declarative agent to MCP Server</li> </ul> <ul> <li> Lab E9 - Connected Agents</li> </ul> </li> </ul> <p>Note</p> <p>There are many detailed setup steps for Entra ID in this lab. A new version of Agents Toolkit is available which will automate many of these steps for you; we plan to provide a more streamlined version of the lab shortly.</p> <p>In this lab you will register Entra ID applications that are used to secure your plugin and API. Before you begin, choose a safe place for your app information. Here are the values you'll need to save:</p> <pre><code>API Base URL: \nAPI service Application (client) ID: \nAPI service Directory (tenant) ID: \nAuthorization endpoint: \nToken endpoint: \nAPI service client secret: \nAPI scope: \nPlugin service application (client) ID: \nPlugin service client secret: \n</code></pre>"},{"location":"pages/extend-m365-copilot/06b-add-authentication/#exercise-1-set-up-a-persistent-developer-tunnel-optional","title":"Exercise 1: Set up a persistent developer tunnel (optional)","text":"<p>By default, Agents Toolkit creates a new developer tunnel - and thus a new URL for accesing your locally running API - every time you start the project. Normally this is fine because Agents Toolkit automatically updates the URL where needed, but since this lab will be a manual setup, you'll have to manually update the URL in Entra ID and in Teams Developer Portal each time you start the debugger. For that reason, you may wish to set up a persistent developer tunnel with a URL that does not change.</p> If you don't want to set up a persistent tunnel, open this note \u25b6\u25b6\u25b6 <p>You are free to skip this exercise and use the developer tunnel provided by Agents Toolkit. Once your project is running, you can copy this URL from the terminal tab 1\ufe0f\u20e3 by choosing the \"Start local tunnel\" terminal 2\ufe0f\u20e3; copy the Forwarding URL 3\ufe0f\u20e3. Note this URL will change every time you start the project, and you will need to manually update the app registration reply URL (exercise 2 step 1) and the Teams Developer Portal URL (exercise 5 step 1). </p>"},{"location":"pages/extend-m365-copilot/06b-add-authentication/#step-1-install-the-developer-tunnel-cli","title":"Step 1: Install the developer tunnel CLI","text":"<p>Here are the command lines for installing the developer tunnel. Full instructions and download links for the Developer Tunnel are here.. </p> OS Command Windows <code>winget install Microsoft.devtunnel</code> Mac OS <code>brew install --cask devtunnel</code> Linux <code>curl -sL https://aka.ms/DevTunnelCliInstall | bash</code> <p>Tip</p> <p>You may have to restart your command line to update the file path before devtunnel commands will work</p> <p>Once you have it installed, you'll need to log in. You can use your Microsoft 365 account to log in.</p> <pre><code>devtunnel user login\n</code></pre> <p>Be sure to leave the devtunnel command running as you do the exercises in this lab. If you need to restart it, just repeat the last command <code>devtunnel user login</code>.</p> <p></p>"},{"location":"pages/extend-m365-copilot/06b-add-authentication/#step-2-create-and-host-the-tunnel","title":"Step 2: Create and host the tunnel","text":"<p>Then you'll need to set up a persistent tunnel to the Azure Functions local port (7071). You can use these commands and substitute your own name instead of \"mytunnel\" if you wish.</p> <pre><code>devtunnel create mytunnel -a --host-header unchanged\ndevtunnel port create mytunnel -p 7071\ndevtunnel host mytunnel\n</code></pre> <p>The command line will display the connection information, such as:</p> <p></p> <p>Copy the \"Connect via browser\" URL and save it as the \"API Base URL\".</p> <p></p>"},{"location":"pages/extend-m365-copilot/06b-add-authentication/#step-3-disable-the-dynamically-created-tunnel-in-your-project","title":"Step 3: Disable the dynamically created tunnel in your project","text":"<p>If your project is running locally, stop it. Then edit .vscode\\tasks.json and locate the \"Start Teams App task. Comment out the \"Start local tunnel\" depdendency and add its dependency, \"Start Azurite emulator\" instead. The resulting task should look like this:</p> <pre><code>{\n    \"label\": \"Start Teams App Locally\",\n    \"dependsOn\": [\n        \"Validate prerequisites\",\n        //\"Start local tunnel\",\n        \"Start Azurite emulator\",\n        \"Create resources\",\n        \"Build project\",\n        \"Start application\"\n    ],\n    \"dependsOrder\": \"sequence\"\n},\n</code></pre> <p></p>"},{"location":"pages/extend-m365-copilot/06b-add-authentication/#step-4-manually-override-the-server-url","title":"Step 4: Manually override the server URL","text":"<p>Open env/.env.local and change the value of OPENAPI_SERVER_URL to the persistent tunnel URL.</p> <p></p>"},{"location":"pages/extend-m365-copilot/06b-add-authentication/#exercise-2-register-an-entra-id-application-for-your-api","title":"Exercise 2: Register an Entra ID application for your API","text":""},{"location":"pages/extend-m365-copilot/06b-add-authentication/#step-1-add-a-new-entra-id-app-registration","title":"Step 1: Add a new Entra ID app registration","text":"<p>Browse to the Entra ID admin center either via the Microsoft 365 Admin center or directly at https://entra.microsoft.com/. Make sure you are logged into your development tenant and not some other.</p> <p>Once you're there, click \"Identity\" 1\ufe0f\u20e3, then \"Applications\" 2\ufe0f\u20e3, and then \"App registrations\" 3\ufe0f\u20e3. Then click the \"+\" 4\ufe0f\u20e3 to add a new app registration.</p> <p></p> <p>Give your application a unique and descriptive name such as \"My API Service\" 1\ufe0f\u20e3. Under \"Supported account types\", select \"Accounts in this organizational directory only (Microsoft only - single tenant) 2\ufe0f\u20e3. Under \"Redirect URI (optional)\" select \"Web\" and enter the URL of your developer tunnel 3\ufe0f\u20e3. </p> <p>If you didn't make a persistent developer tunnel URL...</p> <p>...you will have to update the \"Redirect URI\" field with the new tunnel URL after each time you start your application in Agents Toolkit</p> <p>Then click \"Register\" 4\ufe0f\u20e3 to register your application.</p> <p></p> <p></p>"},{"location":"pages/extend-m365-copilot/06b-add-authentication/#step-2-copy-application-info-to-a-safe-place","title":"Step 2: Copy application info to a safe place","text":"<p>Copy the Application ID (also called the Client ID) 1\ufe0f\u20e3 and the Directory ID (also called the Tenant ID) 2\ufe0f\u20e3 to a safe place; you'll need them later. Then click on the Endpoints button 3\ufe0f\u20e3 to open the Endpoints flyout.</p> <p></p> <p>Now copy the two endpoint URLs with name \"OAuth 2.0 authorization endpoint (v2)\" 1\ufe0f\u20e3 and \"OAuth 2.0 token endpoint (v2)\" 2\ufe0f\u20e3 and save them in the same safe place.</p> <p></p> <p></p>"},{"location":"pages/extend-m365-copilot/06b-add-authentication/#step-3-create-client-secret","title":"Step 3: Create client secret","text":"<p>Next, navigate to \"Certificates &amp; secrets\" 1\ufe0f\u20e3 and click \"+ New client secret\" 2\ufe0f\u20e3. Give your secret a name and choose a duration, then select the Add button. The secret will be displayed; this is your one and only chance to view it as secrets are only displayed in the portal when they're first created. Copy the secret 3\ufe0f\u20e3 to your safe storage place.</p> <p></p> <p></p>"},{"location":"pages/extend-m365-copilot/06b-add-authentication/#step-4-expose-an-api-scope","title":"Step 4: Expose an API Scope","text":"<p>In order to validate calls to your API, you need to expose an API Scope, which represents the permission to call the API. Though these could be very specific - allowing permission to do specific operations via the API - in this case we'll set up a simple scope called \"access_as_user\".</p> <p>First, browse to \"Expose an API\" 1\ufe0f\u20e3 and, next to \"Application ID URI\" click \"Add\" 2\ufe0f\u20e3. A flyout will open on the right; you can stay with the default value which is api://&lt;your application (client) ID&gt;. Go ahead and click \"Save and continue\" 3\ufe0f\u20e3 to proceed.</p> <p></p> <p>Under \"Add a scope\" enter \"access_as_user\" as the scope name 1\ufe0f\u20e3. Fill in the remaining fields as follows:</p> Field Value Who can consent? Admins and users Admin consent display name Access My API as the user Admin consent description Allows an API to access My API as a user User consent display name Access My API as you User consent description Allows an app to access My API as you State Enabled <p>When you're done, click \"Add Scope\" 2\ufe0f\u20e3.</p> <p></p> <p></p>"},{"location":"pages/extend-m365-copilot/06b-add-authentication/#step-5-save-the-api-scope","title":"Step 5: Save the API Scope","text":"<p>Copy the scope to your safe place as the \"API Scope\".</p> <p></p> <p></p>"},{"location":"pages/extend-m365-copilot/06b-add-authentication/#exercise-3-register-an-entra-id-application-for-your-plugin","title":"Exercise 3: Register an Entra ID application for your plugin","text":"<p>Now that you've registered an API for the application, it's time to register the plugin itself.</p> <p>About two Entra ID app registrations</p> <p>This lab is a guide on how to adapt assuming you already have a registered application for your API and want to integrate it into the agent as a plugin. That is why we have two app registrations.  When creating an API from scratch, you may not always need two app registrations to implement OAuth securely to plug into the agent. Instead, you can use an existing app registration. Here is how you can do it in one single app registration in this learn module</p>"},{"location":"pages/extend-m365-copilot/06b-add-authentication/#step-1-register-the-plugin","title":"Step 1: Register the plugin","text":"<p>Return to the \"App registrations\" section and register a second application. This time call it \"My API Plugin\" 1\ufe0f\u20e3, and once again set \"Supported account types\" to \"Accounts in this organizational directory only\" 2\ufe0f\u20e3.</p> <p>Under \"Redirect URL\" select \"Web\", and this time set it to <code>https://teams.microsoft.com/api/platform/v1.0/oAuthRedirect</code> 3\ufe0f\u20e3. This is the Teams location that will handle completed logins to the API Plugin application.</p> <p>Click the \"Register\" button 4\ufe0f\u20e3 to complete the registration.</p> <p></p> <p>As before, view the app's \"Overview\" page and save the Application (client) ID for the API Plugin app.</p> <p></p>"},{"location":"pages/extend-m365-copilot/06b-add-authentication/#step-2-create-a-client-secret","title":"Step 2: Create a client secret","text":"<p>As before, create a client secret and save it under \"Plugin service client secret\" in your safe location.</p> <p></p>"},{"location":"pages/extend-m365-copilot/06b-add-authentication/#step-3-grant-permission","title":"Step 3: Grant permission","text":"<p>Your plugin needs to call your API service, so naturally it needs permission to do that. Begin by navigating to \"API permissions\". Then click the \"APIs my organization uses\" tab 1\ufe0f\u20e3 and search for your API service 2\ufe0f\u20e3. Select your API service from the results 3\ufe0f\u20e3.</p> <p></p> <p>Now you should see your API service application. Select the \"access_as_user\" permission and click \"Add permission\".</p> <p></p> <p></p>"},{"location":"pages/extend-m365-copilot/06b-add-authentication/#exercise-4-update-the-api-app-registration-with-the-plugin-application-id","title":"Exercise 4: Update the API app registration with the plugin application ID","text":""},{"location":"pages/extend-m365-copilot/06b-add-authentication/#step-1-add-the-plugin-apps-id-to-the-api-service-app","title":"Step 1: Add the Plugin app's ID to the API service app","text":"<p>Now the API Service application needs to allow the API Plugin application to issue tokens for it. To enable this, return to the App Registration for your API Service application. Select \"Manifest\" and find the entry for <code>knownClientApplications</code> 1\ufe0f\u20e3. Add your My Plugin App's client ID to this entry as follows:</p> <pre><code>\"knownClientApplications\": [\n    \"&lt;your-plugin-client-id&gt;\"\n]\n</code></pre> <p>Remember to click \"Save\" 2\ufe0f\u20e3 when you're done.</p> <p></p> <p></p>"},{"location":"pages/extend-m365-copilot/06b-add-authentication/#exercise-5-register-the-oauth-information-in-the-teams-developer-portal","title":"Exercise 5: Register the OAuth information in the Teams Developer Portal","text":"<p>Now you're apps are all set up, but Microsoft 365 doesn't know anything about it. It wouldn't be safe to store secrets in the app manifest, so Teams has set up a place in the Teams Developer Portal to safely store this information. In this exercise you'll use the Teams Developer Portal to register your OAuth client application so Copilot can authenticate users for it.</p>"},{"location":"pages/extend-m365-copilot/06b-add-authentication/#step-1-create-a-new-oauth-client-registration","title":"Step 1: Create a new OAuth client registration","text":"<p>Browse to the Teams Developer Portal at https://dev.teams.microsoft.com. Select \"Tools\" 1\ufe0f\u20e3 and then \"OAuth client registration\" 2\ufe0f\u20e3.</p> <p></p> <p>Click \"Register client\", if you don't have any already registered client application, or \"+ New OAuth client registration\", if you already have existing client applications, and fill in the form. Several of the fields are from your safely stored information you've been building up over the last few exercises.</p> Field Value Name Choose a name you'll remember Base URL your API service Base URL Restrict usage by org select \"My organization only\" Restrict usage by app select \"Any Teams app\" Client ID Your Plugin Application (client) ID Client secret Your Plugin Application client secret Authorization endpoint Your authorization endpoint (same for both API Service and API Plugin apps) Token endpoint Your token endpoint (same for both API Service and API Plugin apps) Refresh endpoint Your token endpoint (same for both API Service and API Plugin apps) API scope Your API Service application's scope <p></p> <p>If you didn't make a persistent developer tunnel URL...</p> <p>...you will have to update the \"Base URL\" field with your new tunnel URL each time you start your application in Agents Toolkit</p> <p></p>"},{"location":"pages/extend-m365-copilot/06b-add-authentication/#step-2-save-your-oauth-registration-id","title":"Step 2: Save your OAuth registration ID","text":"<p>The portal will display your OAuth client registration ID. Save this for the next step.</p> <p></p>"},{"location":"pages/extend-m365-copilot/06b-add-authentication/#exercise-6-update-your-application-package","title":"Exercise 6: Update your application package","text":""},{"location":"pages/extend-m365-copilot/06b-add-authentication/#step-1-update-the-plugin-file","title":"Step 1: Update the Plugin file","text":"<p>Open your working folder in Visual Studio Code. In the appPackage folder, open the trey-plugin.json file. This is where information is stored that Copilot needs, but is not already in the Open API Specification (OAS) file.</p> <p>Under <code>Runtimes</code> you will find an <code>auth</code> property with <code>type</code> of <code>\"None\"</code>, indicating the API is currently not authenticated. Change it as follows to tell Copilot to authenticate using the OAuth settings you saved in the vault.</p> <pre><code>\"auth\": {\n  \"type\": \"OAuthPluginVault\",\n  \"reference_id\":  \"${{OAUTH_CLIENT_REGISTRATION_ID}}\"\n},\n</code></pre> <p>Then add this line to your env/.env.local file:</p> <pre><code>OAUTH_CLIENT_REGISTRATION_ID=&lt;registration id you saved in the previous exercise&gt;\n</code></pre> <p>The next time you start and prompt your API plugin, it should prompt you to sign in. However we've done nothing to secure the application; anyone on the Internet can call it! In the next step you'll update the application code to check for a valid login and access the API as the actual Microsoft 365 user instead of \"Avery Howard\" (which is a name from Microsoft's fictitious name generator).</p> <p></p>"},{"location":"pages/extend-m365-copilot/06b-add-authentication/#exercise-7-update-the-application-code","title":"Exercise 7: Update the application code","text":""},{"location":"pages/extend-m365-copilot/06b-add-authentication/#step-1-install-the-jwt-validation-library","title":"Step 1: Install the JWT validation library","text":"<p>From a command line in your working directory, type:</p> <pre><code>npm i jwt-validate\n</code></pre> <p>This will install a library for validating the incoming Entra ID authorization token.</p> <p>Warning</p> <p>Microsoft does not provide a supported library for validating Entra ID tokens in NodeJS, but instead provides this detailed documentation on how to write your own. Another useful article is also available from Microsoft MVP Andrew Connell.</p> <p>This lab uses a community provided library written by Waldek Mastykarz, which is intended to follow this guidance. Note that this library is not supported by Microsoft and is under an MIT License, so use it at your own risk.</p> <p>If you want to track progress on a supported library, please follow this Github issue.</p> <p></p>"},{"location":"pages/extend-m365-copilot/06b-add-authentication/#step-2-add-environment-variables-for-your-api","title":"Step 2: Add environment variables for your API","text":"<p>In the env folder in your working directory, open env.local and add these lines for your API Service app's client ID and tenant ID.</p> <pre><code>API_APPLICATION_ID=&lt;your-api-service-client-id&gt;\nAPI_TENANT_ID=&lt;your-tenant-id&gt;\n</code></pre> <p>To make these values available inside your code running in Agents Toolkit, you also need to update the teamsapp.local.yml file in the root of your working folder. Look for the comment \"Generate runtime environment variables\" and add the new values under the STORAGE_ACCOUNT_CONNECTION_STRING:</p> <pre><code>  - uses: file/createOrUpdateEnvironmentFile\n    with:\n      target: ./.localConfigs\n      envs:\n        STORAGE_ACCOUNT_CONNECTION_STRING: ${{SECRET_STORAGE_ACCOUNT_CONNECTION_STRING}},\n        API_APPLICATION_ID: ${{API_APPLICATION_ID}}\n        API_TENANT_ID: ${{API_TENANT_ID}}\n</code></pre> <p></p>"},{"location":"pages/extend-m365-copilot/06b-add-authentication/#step-3-update-the-identity-service","title":"Step 3: Update the identity service","text":"<p>At this point, OAuth login should work and provide a valid access token, but the solution isn't secure unless the code checks to make sure the token is valid. In this step, you'll add code to validate the is token and extract information such as the user's name and ID.</p> <p>In the src/services folder, open IdentityService.ts.  At the top of the file along with the other <code>import</code> statements, add this one:</p> <pre><code>import { TokenValidator, ValidateTokenOptions, getEntraJwksUri } from 'jwt-validate';\n</code></pre> <p>Then, right under the <code>class Identity</code> statement, add this line:</p> <pre><code>    private validator: TokenValidator;\n</code></pre> <p>Now look for the comment</p> <pre><code>// ** INSERT REQUEST VALIDATION HERE (see Lab E6) **\n</code></pre> <p>Replace the comment with this code:</p> <pre><code>// Try to validate the token and get user's basic information\ntry {\n    const { API_APPLICATION_ID, API_TENANT_ID } = process.env;\n    const token = req.headers.get(\"Authorization\")?.split(\" \")[1];\n    if (!token) {\n        throw new HttpError(401, \"Authorization token not found\");\n    }\n\n    // create a new token validator for the Microsoft Entra common tenant\n    if (!this.validator) {\n        // We need a new validator object which we will continue to use on subsequent\n        // requests so it can cache the Entra ID signing keys\n        // For multitenant, use:\n        // const entraJwksUri = await getEntraJwksUri();\n        const entraJwksUri = await getEntraJwksUri(API_TENANT_ID);\n        this.validator = new TokenValidator({\n            jwksUri: entraJwksUri\n        });\n        console.log (\"Token validator created\");\n    }\n\n    // Use these options for single-tenant applications\n    const options: ValidateTokenOptions = {\n        audience: `api://${API_APPLICATION_ID}`,\n        issuer: `https://sts.windows.net/${API_TENANT_ID}/`,\n        // NOTE: If this is a multi-tenant app, look for \n        // issuer: \"https://sts.windows.net/common/\",\n        // Also you may wish to manage a list of allowed tenants\n        // and test them as well\n        //   allowedTenants: [process.env[\"AAD_APP_TENANT_ID\"]],\n        scp: [\"access_as_user\"]\n    };\n\n    // validate the token\n    const validToken = await this.validator.validateToken(token, options);\n\n    userId = validToken.oid;\n    userName = validToken.name;\n    userEmail = validToken.upn;\n    console.log(`Request ${this.requestNumber++}: Token is valid for user ${userName} (${userId})`);\n}\ncatch (ex) {\n    // Token is missing or invalid - return a 401 error\n    console.error(ex);\n    throw new HttpError(401, \"Unauthorized\");\n}\n</code></pre> <p>Learn from the code</p> <p>Have a look at the new source code. First, it obtains the token from the <code>Authorization</code> header in the HTTPs request. This header contains the word \"Bearer\", a space, and then the token, so a JavaScript <code>split(\" \")</code> is used to obtain only the token.</p> <p>Also note that the code will throw an exception if authentication should fail for any reason; the Azure function will then return the appropriate error.</p> <p>The code then creates a validator for use with the <code>jwks-validate</code> library. This call reads the latest private keys from Entra ID, so it is an async call that may take some time to run.</p> <p>Next, the code sets up a <code>ValidateTokenOptions</code> object. Based on this object, in addition to validating that the token was signed with Entra ID's private key, the library will validate that:</p> <ul> <li> <p>the audience must be the same as the API service app URI; this ensures that the token is intended for our web service and no other</p> </li> <li> <p>the issuer must be from the security token service for our tenant</p> </li> <li> <p>the scope must match the scope defined in our app registration, which is <code>\"access_as_user\"</code>.</p> </li> </ul> <p>If the token is valid, the library returns an object with all the \"claims\" that were inside, including the user's unique ID, name, and email. We will use these values instead of relying on the fictitious \"Avery Howard\".</p> <p>If your app will be multi-tenant</p> <p>Check the comments in the above code for notes about validating tokens for a multi-tenant app</p> <p>Once the code has a <code>userId</code> it will look for a Consultant record for the user. This was hard-coded to Avery Howard's ID in the original code. Now it will use the user ID for the logged in user, and create a new Consultant record if it doesn't find one in the database.</p> <p>As a result, when you run the app for the first time, it should create a new Consultant for your logged-in user with a default set of skills, roles, etc. If you want to change them to make your own demo, you can do that using the Azure Storage Explorer</p> <p></p> <p>Note that project assignments are stored in the <code>Assignment</code> table and reference the project ID and the assigned consultant's consultant ID.</p> <p></p>"},{"location":"pages/extend-m365-copilot/06b-add-authentication/#exercise-8-test-the-application","title":"Exercise 8: Test the application","text":"<p>Before you test the application, update the manifest version of your app package in the <code>appPackage\\manifest.json</code> file, follow these steps:</p> <ol> <li> <p>Open the <code>manifest.json</code> file located in the <code>appPackage</code> folder of your project.</p> </li> <li> <p>Locate the <code>version</code> field in the JSON file. It should look something like this: <code>json    \"version\": \"1.0.0\"</code></p> </li> <li> <p>Increment the version number to a small increment. For example, change it to: <code>json    \"version\": \"1.0.1\"</code></p> </li> <li> <p>Save the file after making the change.</p> </li> </ol>"},{"location":"pages/extend-m365-copilot/06b-add-authentication/#step-1-restart-the-application","title":"Step 1: (Re)start the application","text":"<p>If your app is still running from an earlier lab, stop it to force it to re-create the application package.</p> <p>Then press F5 to run the application again, and install it as before.</p> <p>Prompt the plugin, \"What Trey projects am I assigned to?\". You may see a confirmation card asking if it's OK to call your API. No authentication is happening here; click \"Allow Once\" to proceed.</p> <p></p> <p>The confirmation card will be replaced with a login card. Click \"Sign in to Trey\" to sign in. At first you should see a pop-up window asking you to log in and to consent to permissions. On subsequent vists this may be hidden as your credentials have been cached by Entra ID in your local browser.</p> <p></p> <p>There are cases where your admin has not allowed you to consent as a user and may see something like below: </p> <p>This is because the admin has restricted applications to allow user consent tenant wide. In this case, you have to request admin to manually grant global consent for all users for the plugin API registration as below:</p> <p></p> <p>The login card should be replaced by Copilot's response to your prompt. Since you were just added to the database, you aren't assigned to any projects.</p> <p>Since you were just added to the database, you're not assigned to any projects.</p> <p></p> <p>Ask Copilot to add you to the Woodgrove project. Copilot will press you for details if you forgot to include any required values.</p> <p></p> <p>Now check out your default skills and confirm the project assignment by asking, \"What are my skills and what projects am I assigned to?\"</p> <p></p> <p></p> <p>CONGRATULATIONS!</p> <p>You have completed lab E6b, Add Entra ID authentication with Manual Setup!</p> <p>Want to try something cool? How about adding a Copilot Connector to your solution?</p> <p></p> <p></p>"},{"location":"pages/extend-m365-copilot/06c-add-sso/","title":"Lab E6c - Add Entra ID authentication with Single Sign-on","text":"<p>In this lab you will add Microsoft Entra ID SSO authentication enabling users to authenticate with their existing Entra ID credentials.</p> Get a quick overview of the lab in this video.              \ud83d\udcd8 Note:   This lab builds on the previous one, Lab E5. If you have completed lab E5, you can continue working in the same folder. If not, please copy the solution folder for Lab E5 from /src/extend-m365-copilot/path-e-lab05-add-adaptive-cards/trey-research-lab05-END      and work there.     The finished solution for this lab is in the /src/extend-m365-copilot/path-e-lab06c-add-sso/trey-research-lab06c-END folder.          <p>Do these labs if you want to build a Declarative agent where Microsoft 365 provides the AI model and               orchestration</p> <ul> <li>\ud83c\udfc1 Welcome</li> <li>\ud83d\udd27 Set up <ul> <li>Lab E0 - Setup</li> </ul> </li> <li>\ud83e\uddf0 Declarative agent fundamentals <ul> <li> Lab E1 - Build a  Declarative Agent using TypeSpec </li> <li> Lab E1a - Geo locator game</li> </ul> </li> <li>\ud83d\udee0\ufe0f Build and integrate API from scratch <ul> <li>Lab E2 - Build an API</li> <li> Lab E3 - Add Declarative Agent + API</li> <li> Lab E4 - Enhance API + Plugin</li> <li>Lab E5 - Add Adaptive Cards</li> <li> Lab E6a - Add Authentication</li> </ul> </li> <li>\ud83d\udd0c Integration <ul> <li> Lab E7 - Add Copilot Connector</li> </ul> <ul> <li> Lab E8 - Connect Declarative agent to MCP Server</li> </ul> <ul> <li> Lab E9 - Connected Agents</li> </ul> </li> </ul> <p>Note</p> <p>In the finished sample we have used persistent developer tunnel so you will have to make adjustments if you are not using persistent developer tunnel. Check Exercise 1. </p> <p>In this lab, as you register your API, you'll need to save a few values from the Entra ID portal and Teams Developer Portal for use in later steps. Here's what you'll need to save:</p> <pre><code>API Base URL: \nAPI's Entra ID application ID: \nAPI's Tenant ID: \nSSO Client registration: \nAPI ID URI: \n</code></pre>"},{"location":"pages/extend-m365-copilot/06c-add-sso/#exercise-1-set-up-a-persistent-developer-tunnel-optional","title":"Exercise 1: Set up a persistent developer tunnel (optional)","text":"<p>By default, Agents Toolkit creates a new developer tunnel - and thus a new URL for accesing your locally running API - every time you start the project. Normally this is fine because Agents Toolkit automatically updates the URL where needed, but since this lab will be a manual setup, you'll have to manually update the URL in Entra ID and in Teams Developer Portal each time you start the debugger. For that reason, you may wish to set up a persistent developer tunnel with a URL that does not change.</p> If you don't want to set up a persistent tunnel, open this note \u25b6\u25b6\u25b6 <p>You are free to skip this exercise and use the developer tunnel provided by Agents Toolkit. Once your project is running, you can copy this URL from the terminal tab 1\ufe0f\u20e3 by choosing the \"Start local tunnel\" terminal 2\ufe0f\u20e3; copy the Forwarding URL 3\ufe0f\u20e3. Note this URL will change every time you start the project, and you will need to manually update the app registration reply URL (exercise 2 step 1) and the Teams Developer Portal URL (exercise 5 step 1). </p>"},{"location":"pages/extend-m365-copilot/06c-add-sso/#step-1-install-the-developer-tunnel-cli","title":"Step 1: Install the developer tunnel CLI","text":"<p>Here are the command lines for installing the developer tunnel. Full instructions and download links for the Developer Tunnel are here. </p> OS Command Windows <code>winget install Microsoft.devtunnel</code> Mac OS <code>brew install --cask devtunnel</code> Linux <code>curl -sL https://aka.ms/DevTunnelCliInstall | bash</code> <p>Tip</p> <p>You may have to restart your command line to update the file path before devtunnel commands will work.</p> <p>Once you have it installed, you'll need to log in. You can use your Microsoft 365 account to log in.</p> <pre><code>devtunnel user login\n</code></pre> <p>Be sure to leave the devtunnel command running as you do the exercises in this lab. If you need to restart it, just repeat the last command <code>devtunnel user login</code>.</p> <p></p>"},{"location":"pages/extend-m365-copilot/06c-add-sso/#step-2-create-and-host-the-tunnel","title":"Step 2: Create and host the tunnel","text":"<p>Then you'll need to set up a persistent tunnel to the Azure Functions local port (7071). You can use these commands and substitute your own name instead of \"mytunnel\" if you wish.</p> <pre><code>devtunnel create mytunnel -a --host-header unchanged\ndevtunnel port create mytunnel -p 7071\ndevtunnel host mytunnel\n</code></pre> <p>The command line will display the connection information, such as:</p> <p></p> <p>Copy the \"Connect via browser\" URL and save it as the \"API Base URL\".</p> <p></p>"},{"location":"pages/extend-m365-copilot/06c-add-sso/#step-3-disable-the-dynamically-created-tunnel-in-your-project","title":"Step 3: Disable the dynamically created tunnel in your project","text":"<p>If your project is running locally, stop it. Then edit .vscode\\tasks.json and locate the \"Start Teams App Locally\" task. Comment out the \"Start local tunnel\" dependency and add the \"Start Azurite emulator\" dependency instead. The resulting task should look like this:</p> <pre><code>{\n    \"label\": \"Start Teams App Locally\",\n    \"dependsOn\": [\n        \"Validate prerequisites\",\n        //\"Start local tunnel\",\n        \"Start Azurite emulator\",\n        \"Create resources\",\n        \"Build project\",\n        \"Start application\"\n    ],\n    \"dependsOrder\": \"sequence\"\n},\n</code></pre> <p></p>"},{"location":"pages/extend-m365-copilot/06c-add-sso/#step-4-manually-override-the-server-url","title":"Step 4: Manually override the server URL","text":"<p>Open env/.env.local and change the value of OPENAPI_SERVER_URL to the persistent tunnel URL. This is the <code>API base URL</code> that is needed for the configuration in the steps later.</p> <p></p>"},{"location":"pages/extend-m365-copilot/06c-add-sso/#exercise-2-register-an-entra-id-application-for-your-api","title":"Exercise 2: Register an Entra ID application for your API","text":""},{"location":"pages/extend-m365-copilot/06c-add-sso/#step-1-add-a-new-entra-id-app-registration","title":"Step 1: Add a new Entra ID app registration","text":"<p>Browse to the Entra ID admin center either via the Microsoft 365 Admin center or directly at https://entra.microsoft.com/. Make sure you are logged into your development tenant and not some other.</p> <p>Once you're there, click \"Identity\" 1\ufe0f\u20e3, then \"Applications\" 2\ufe0f\u20e3, and then \"App registrations\" 3\ufe0f\u20e3. Then click the \"+\" 4\ufe0f\u20e3 to add a new app registration.</p> <p></p> <p>Give your application a unique and descriptive name such as \"Trey API Service\" 1\ufe0f\u20e3. Under \"Supported account types\", select \"Accounts in this organizational directory only (Microsoft only - single tenant) 2\ufe0f\u20e3. </p> <p>Then click \"Register\" 3\ufe0f\u20e3 to register your application.</p> <p></p> <p></p>"},{"location":"pages/extend-m365-copilot/06c-add-sso/#step-2-copy-application-info-to-a-safe-place","title":"Step 2: Copy application info to a safe place","text":"<p>Copy the Application ID (also called the Client ID) 1\ufe0f\u20e3 which is the <code>API's Entra ID application ID</code> and <code>Directory (tenant) ID</code> 2\ufe0f\u20e3 that is needed for the configuration in the steps later.</p> <p></p> <p></p>"},{"location":"pages/extend-m365-copilot/06c-add-sso/#exercise-3-register-microsoft-entra-sso-client-id-in-the-teams-developer-portal","title":"Exercise 3: Register Microsoft Entra SSO client ID  in the Teams Developer Portal","text":"<p>Now you're API is all set up with Microsoft Entra ID, but Microsoft 365 doesn't know anything about it. To ensure secure connection of your API without requiring extra credentials, let's register it in the Teams Developer Portal.</p>"},{"location":"pages/extend-m365-copilot/06c-add-sso/#step-1-register-an-sso-client-in-teams-developer-portal","title":"Step 1: Register an SSO client in Teams developer portal","text":"<p>Browse to the Teams Developer Portal at https://dev.teams.microsoft.com. Select \"Tools\" 1\ufe0f\u20e3 and then \"Microsoft Entra SSO client ID registration.\" 2\ufe0f\u20e3.</p> <p></p> <p>Select Register client ID and fill up the values.</p> Field Value Name Choose a name you'll remember Base URL API base URL Restrict usage by org select \"My organization only\" Restrict usage by app select \"Any Teams app\" Client (application) ID API's Entra ID application ID <p></p> <p>Now once you select Save, the registration generates a Microsoft Entra SSO registration ID and an Application ID URI. Copy them to a note, to configure the plugin manifest file to enable SSO.</p> <p></p> <p>If you didn't make a persistent developer tunnel URL...</p> <p>...you will have to update the \"Base URL\" field with your new tunnel URL each time you start your application in Agents Toolkit</p> <p></p>"},{"location":"pages/extend-m365-copilot/06c-add-sso/#exercise-4-update-your-application-package","title":"Exercise 4: Update your application package","text":""},{"location":"pages/extend-m365-copilot/06c-add-sso/#step-1-update-the-plugin-file","title":"Step 1: Update the Plugin file","text":"<p>Open your working folder in Visual Studio Code. In the appPackage folder, open the trey-plugin.json file. This is where information is stored that Copilot needs, but is not already in the Open API Specification (OAS) file.</p> <p>Under <code>Runtimes</code> you will find an <code>auth</code> property with <code>type</code> of <code>\"None\"</code>, indicating the API is currently not authenticated. Change it as follows to tell Copilot to authenticate using the Microsoft Entra SSO registration ID you saved in the vault.</p> <pre><code>\"auth\": {\n  \"type\": \"OAuthPluginVault\",\n  \"reference_id\": \"&lt;Microsoft Entra SSO registration ID&gt;\"\n},\n</code></pre> <p></p>"},{"location":"pages/extend-m365-copilot/06c-add-sso/#exercise-5-update-the-apis-microsoft-entra-app-registration","title":"Exercise 5: Update the API's Microsoft Entra app registration","text":""},{"location":"pages/extend-m365-copilot/06c-add-sso/#step-1-update-application-id-uri","title":"Step 1: Update Application ID URI","text":"<ul> <li>Go back to the Microsoft Entra admin center and find the Microsoft Entra app registration of your API, we called it here Trey API Service. </li> <li>Open  Expose an API and add/edit Application ID URI.  Paste the entire Application ID URI generated by the Teams developer portal here and select Save</li> </ul>"},{"location":"pages/extend-m365-copilot/06c-add-sso/#step-2-add-api-scope","title":"Step 2: Add API Scope","text":"<p>In order to validate calls to your API, you need to expose an API Scope, which represents the permission to call the API. Though these could be very specific - allowing permission to do specific operations via the API - in this case we'll set up a simple scope called \"access_as_user\".</p> <p>Under \"Add a scope\" enter \"access_as_user\" as the scope name 1\ufe0f\u20e3. Fill in the remaining fields as follows:</p> Field Value Who can consent? Admins and users Admin consent display name Access My API as the user Admin consent description Allows an API to access My API as a user User consent display name Access My API as you User consent description Allows an app to access My API as you State Enabled <p>When you're done, click \"Add Scope\" 2\ufe0f\u20e3.</p> <p></p> <p></p>"},{"location":"pages/extend-m365-copilot/06c-add-sso/#step-3-add-authorized-client-apps","title":"Step 3: Add authorized client apps","text":"<p>Select Add a client application 1\ufe0f\u20e3 in the same Expose an API page and add the client ID of Microsoft's enterprise token store, <code>ab3be6b7-f5df-413d-ac2d-abf1e3fd9c0b</code> 2\ufe0f\u20e3. Authorize it for the access scope by selecting 3\ufe0f\u20e3. Select Add application 4\ufe0f\u20e3</p> <p></p> <p></p>"},{"location":"pages/extend-m365-copilot/06c-add-sso/#step-4-redirect-uris-for-authentication","title":"Step 4: Redirect URIs for Authentication","text":"<p>Now in the left navigation, go to Authentication 1\ufe0f\u20e3 , Add a platform 2\ufe0f\u20e3, select Web 3\ufe0f\u20e3. </p> <p></p> <p>Paste the url <code>https://teams.microsoft.com/api/platform/v1.0/oAuthConsentRedirect</code> as the Redirect URIs 1\ufe0f\u20e3 and select Configure 2\ufe0f\u20e3.</p> <p></p> <p></p>"},{"location":"pages/extend-m365-copilot/06c-add-sso/#exercise-6-update-the-application-code","title":"Exercise 6: Update the application code","text":""},{"location":"pages/extend-m365-copilot/06c-add-sso/#step-1-install-the-jwt-validation-library","title":"Step 1: Install the JWT validation library","text":"<p>From a command line in your working directory, type:</p> <pre><code>npm i jwt-validate\n</code></pre> <p>This will install a library for validating the incoming Entra ID authorization token.</p> <p>Warning</p> <p>Microsoft does not provide a supported library for validating Entra ID tokens in NodeJS, but instead provides this detailed documentation on how to write your own. Another useful article is also available from Microsoft MVP Andrew Connell. This lab uses a community provided library written by Waldek Mastykarz, which is intended to follow this guidance. Note that this library is not supported by Microsoft and is under an MIT License, so use it at your own risk.</p> <p></p>"},{"location":"pages/extend-m365-copilot/06c-add-sso/#step-2-add-environment-variables-for-your-api","title":"Step 2: Add environment variables for your API","text":"<p>In the env folder in your working directory, open .env.local and add these lines for your API Service app's tenant ID, application ID URL</p> <pre><code>APP_ID_URI=&lt;Application ID URI&gt;\nAPI_TENANT_ID=&lt;Directory (tenant) ID&gt;\n</code></pre> <p>Generate Application ID URI manually</p> <p>In case the Application ID URI isn't available, please construct it using the below steps temporarily: Go to Base64 Decode and Encode -  Copy and paste the auth registration ID generated in Exercise 3, Step 1 and decode. Construct the application ID URI using the second part of the decoded value (after ##) as highlighted below \u2013 api://auth-, e.g., api://auth-16cfcd90-803e-40ba-8106-356aa4927bb9  <p>To make these values available inside your code running in Agents Toolkit, you also need to update the teamsapp.local.yml file in the root of your working folder. Look for the comment \"Generate runtime environment variables\" and add the new values under the STORAGE_ACCOUNT_CONNECTION_STRING:</p> <pre><code>        APP_ID_URI: ${{APP_ID_URI}}\n        API_TENANT_ID: ${{API_TENANT_ID}}\n</code></pre> <p>The finished yaml should look like this:</p> <pre><code>  - uses: file/createOrUpdateEnvironmentFile\n    with:\n      target: ./.localConfigs\n      envs:\n        STORAGE_ACCOUNT_CONNECTION_STRING: ${{SECRET_STORAGE_ACCOUNT_CONNECTION_STRING}},\n        APP_ID_URI: ${{APP_ID_URI}}\n        API_TENANT_ID: ${{API_TENANT_ID}}\n</code></pre> <p></p>"},{"location":"pages/extend-m365-copilot/06c-add-sso/#step-3-update-the-identity-service","title":"Step 3: Update the identity service","text":"<p>At this point, Single Sign-on should work and provide a valid access token, but the solution isn't secure unless the code checks to make sure the token is valid. In this step, you'll add code to validate the is token and extract information such as the user's name and ID.</p> <p>In the src/services folder, open IdentityService.ts.  At the top of the file along with the other <code>import</code> statements, add this one:</p> <pre><code>import { TokenValidator, ValidateTokenOptions, getEntraJwksUri } from 'jwt-validate';\n</code></pre> <p>Then, right under the <code>class Identity</code> statement, add this line:</p> <pre><code>    private validator: TokenValidator;\n</code></pre> <p>Now look for the comment</p> <pre><code>// ** INSERT REQUEST VALIDATION HERE (see Lab E6) **\n</code></pre> <p>Replace the comment with this code:</p> <pre><code>// Try to validate the token and get user's basic information\ntry {\n    const { APP_ID_URI, API_TENANT_ID } = process.env;\n    const token = req.headers.get(\"Authorization\")?.split(\" \")[1];\n    if (!token) {\n        throw new HttpError(401, \"Authorization token not found\");\n    }\n\n    // create a new token validator for the Microsoft Entra common tenant\n    if (!this.validator) {\n        // We need a new validator object which we will continue to use on subsequent\n        // requests so it can cache the Entra ID signing keys\n        // For multitenant, use:\n        // const entraJwksUri = await getEntraJwksUri();\n        const entraJwksUri = await getEntraJwksUri(API_TENANT_ID);\n        this.validator = new TokenValidator({\n            jwksUri: entraJwksUri\n        });\n        console.log (\"Token validator created\");\n    }\n\n\n    const options: ValidateTokenOptions = {\n                audience: APP_ID_URI, \n                issuer: `https://sts.windows.net/${API_TENANT_ID}/`,              \n                scp: [\"access_as_user\"],\n\n            };\n\n    // validate the token\n    const validToken = await this.validator.validateToken(token, options);\n\n    userId = validToken.oid;\n    userName = validToken.name;\n    userEmail = validToken.upn;\n    console.log(`Request ${this.requestNumber++}: Token is valid for user ${userName} (${userId})`);\n}\ncatch (ex) {\n    // Token is missing or invalid - return a 401 error\n    console.error(ex);\n    throw new HttpError(401, \"Unauthorized\");\n}\n</code></pre> <p>Learn from the code</p> <p>Have a look at the new source code. First, it obtains the token from the <code>Authorization</code> header in the HTTPs request. This header contains the word \"Bearer\", a space, and then the token, so a JavaScript <code>split(\" \")</code> is used to obtain only the token.</p> <p>Also note that the code will throw an exception if authentication should fail for any reason; the Azure function will then return the appropriate error.</p> <p>The code then creates a validator for use with the <code>jwks-validate</code> library. This call reads the latest private keys from Entra ID, so it is an async call that may take some time to run.</p> <p>Next, the code sets up a <code>ValidateTokenOptions</code> object. Based on this object, in addition to validating that the token was signed with Entra ID's private key, the library will validate that:</p> <ul> <li> <p>the audience must be the same as the API service app URI; this ensures that the token is intended for our web service and no other</p> </li> <li> <p>the issuer must be from the security token service for our tenant</p> </li> <li> <p>the scope must match the scope defined in our app registration, which is <code>\"access_as_user\"</code>.</p> </li> </ul> <p>If the token is valid, the library returns an object with all the \"claims\" that were inside, including the user's unique ID, name, and email. We will use these values instead of relying on the fictitious \"Avery Howard\".</p> <p>If your app will be multi-tenant</p> <p>Check the comments in the above code for notes about validating tokens for a multi-tenant app</p> <p>Once the code has a <code>userId</code> it will look for a Consultant record for the user. This was hard-coded to Avery Howard's ID in the original code. Now it will use the user ID for the logged in user, and create a new Consultant record if it doesn't find one in the database.</p> <p>As a result, when you run the app for the first time, it should create a new Consultant for your logged-in user with a default set of skills, roles, etc. If you want to change them to make your own demo, you can do that using the Azure Storage Explorer</p> <p></p> <p>Note that project assignments are stored in the <code>Assignment</code> table and reference the project ID and the assigned consultant's consultant ID.</p> <p></p>"},{"location":"pages/extend-m365-copilot/06c-add-sso/#step-4-work-around-library-versioning-issue","title":"Step 4: Work around library versioning issue","text":"<p>At the moment, the <code>jwt-validate</code> package throws typing error for <code>@types/jsonwebtoken</code> package. To work around the issue, edit the tsconfig.json file, found at the root of the project, and add <code>\"skipLibCheck\":true</code>. This will be fixed in a future version of the library, and may no longer be necessary by the time you do the lab.</p> <p></p>"},{"location":"pages/extend-m365-copilot/06c-add-sso/#exercise-7-test-the-application","title":"Exercise 7: Test the application","text":"<p>Before you test the application, update the manifest version of your app package in the <code>appPackage\\manifest.json</code> file, follow these steps:</p> <ol> <li> <p>Open the <code>manifest.json</code> file located in the <code>appPackage</code> folder of your project.</p> </li> <li> <p>Locate the <code>version</code> field in the JSON file. It should look something like this: </p> </li> </ol> <pre><code>\"version\": \"1.0.0\"\n</code></pre> <ol> <li>Increment the version number to a small increment. For example, change it to:  </li> </ol> <pre><code>\"version\": \"1.0.1\"\n</code></pre> <ol> <li>Save the file after making the change.</li> </ol>"},{"location":"pages/extend-m365-copilot/06c-add-sso/#step-1-restart-the-application","title":"Step 1: (Re)start the application","text":"<p>Restart the application if it was already running and open Trey Genie in Copilot app.</p> <p>Prompt - \"What projects am I assigned to?\"  After allowing the agent, you will be asked to sign in as below (this is one time)</p> <p></p> <p>Once you select the sign in button, you need to allow the application's API to access as the current user, so go ahead and give the permission by selecting \"Accept.\"</p> <p></p> <p>From now on, the sign in will be smooth for the user when interacting with the agent, without having to sign in each time.</p> <p></p> <p></p> <p>CONGRATULATIONS!</p> <p>You have completed lab E6c, Add SSO!</p> <p>Want to try something cool? How about adding a Copilot Connector to your solution?</p> <p></p> <p></p>"},{"location":"pages/extend-m365-copilot/07-add-graphconnector/","title":"Lab E7 - Integration: Add Knowledge capability to Trey Genie using a Microsoft Copilot Connector","text":"<p>Do these labs if you want to build a Declarative agent where Microsoft 365 provides the AI model and             orchestration</p> <ul> <li>\ud83c\udfc1 Welcome</li> <li>\ud83d\udd27 Set up <ul> <li>Lab E0 - Setup</li> </ul> </li> <li>\ud83e\uddf0 Declarative agent fundamentals <ul> <li> Lab E1 - Build a  Declarative Agent using TypeSpec </li> <li> Lab E1a - Geo locator game</li> </ul> </li> <li>\ud83d\udee0\ufe0f Build and integrate API from scratch <ul> <li>Lab E2 - Build an API</li> <li> Lab E3 - Add Declarative Agent + API</li> <li> Lab E4 - Enhance API + Plugin</li> <li>Lab E5 - Add Adaptive Cards</li> <li> Lab E6a - Add Authentication</li> </ul> </li> <li>\ud83d\udd0c Integration <ul> <li> Lab E7 - Add Copilot Connector</li> </ul> <ul> <li> Lab E8 - Connect Declarative agent to MCP Server</li> </ul> <ul> <li> Lab E9 - Connected Agents</li> </ul> </li> </ul> <p>In this lab you will learn how to add your own data into the Microsoft Graph to be then organically utilised by the declarative agent as it's own knowledge.  In the process you will learn all how to deploy a Microsoft Copilot Connector and use the connector in Trey Genie declarative agent. </p> <p>In this lab you will learn to:</p> <ul> <li>deploy a Microsoft Copilot Connector of your own data into Microsoft Graph and have it power various Microsoft 365 experiences</li> <li>customise the trey genie declarative agent to use the Copilot Connector as a capability to extend its knowledge</li> <li>learn how to run and test your app </li> </ul>              \ud83d\udcd8 Note:       This lab builds on the Lab E4. You should be able to continue working in the same folder for labs E2-E6, but solution folders have been provided for your reference.     The finished Trey Genie declarative solution for this lab is in the /src/extend-m365-copilot/path-e-bonus-gc-lab/trey-research-labEB-END folder.     The Microsoft Copilot Connector source code is in /src/extend-m365-copilot/path-e-bonus-gc-lab/trey-feedback-connector folder.          <p>Prerequisites: Tenant Admin Access</p> <p>Additonal prerequisites are needed to run this lab. You will need tenant administrator privileges as Microsoft Copilot Connectors use app-only authentication to access the connector APIs.</p> <p>Prerequisites: Azure Functions Visual Studio Code extension</p> <ul> <li>Azure Functions Visual Studio Code extension</li> </ul>"},{"location":"pages/extend-m365-copilot/07-add-graphconnector/#exercise-1-deploy-copilot-connector","title":"Exercise 1 : Deploy Copilot Connector","text":""},{"location":"pages/extend-m365-copilot/07-add-graphconnector/#step-1-download-sample-project","title":"Step 1: Download sample project","text":"<ul> <li>In your browser, go to this link</li> <li>Extract the trey-feedback-connector.zip file</li> </ul> <p>Note</p> <p>The extracted folder of the sample project is trey-feedback-connector. It has a folder called content which consist of feedback files from various clients for consultants at Trey Research. The files are all created by AI and are for demo purposes only.  The aim is to deploy these external files into Microsoft 365 data to be available as knowledge base for our declarative agent Trey Genie. </p> <p></p>"},{"location":"pages/extend-m365-copilot/07-add-graphconnector/#step-2-create-external-connection","title":"Step 2: Create external connection","text":"<ul> <li>Open the folder trey-feedback-connector in Visual Studio Code</li> <li>In the Activity Bar of Visual Studio Code, open the Agents Toolkit extension</li> <li>Create a file .env.local in the env folder of the root folder trey-feedback-connector</li> <li>Paste below contents in the newly created file</li> </ul> <pre><code>APP_NAME=TreyFeedbackConnectorApp\nCONNECTOR_ID=tfcfeedback\nCONNECTOR_NAME=Trey Feedback Connector\nCONNECTOR_DESCRIPTION=The Trey Feedback Connector seamlessly integrate feedback data from various clients about consultants in Trey Research.\nCONNECTOR_BASE_URL=https://localhost:3000/\n\n</code></pre> <ul> <li>Select F5, which will then kick off the creation of the Entra ID app registration needed for your connector API to authenicate and load data into Microsoft Graph </li> <li>In the <code>Terminal</code> window, for the <code>func:host start</code> Task, you will notice below link provided. Using this link you can grant the app-only permission for the Entra ID app</li> </ul> <ul> <li>Copy the link and open in a browser where you are logged in as the tenant admin for the Microsoft 365 tenant. </li> <li>Grant the required permissions to the app using the Grant admin consent button.</li> </ul> <ul> <li>Once granted, the connector creates an external connection, provisions the schema and ingests the sample contents in the content folder to your Microsoft 365 tenant. This takes a while, so keep the project running. </li> <li>Once all files in the content folder are loaded, the debugger can be stopped. </li> <li>You can also close this connector project folder.</li> </ul>"},{"location":"pages/extend-m365-copilot/07-add-graphconnector/#step-3-test-the-connector-data-in-microsoft365-app","title":"Step 3: Test the connector data in Microsoft365 app","text":"<p>Now that your data is loaded into Microsoft 365 tenant, let's test if a regular search is picking up the contents in Microsoft365.com.</p> <p>Go to https://www.microsoft365.com/ and in the search box above, type <code>thanks Avery</code>.</p> <p>You will see the results as below from the external connection which are basically the clients' feedback for consultant Avery Howard.</p> <p></p> <p>Now that your data is part of Microsoft 365 data or Microsoft Graph, let's go ahead and add this connector data as focused knowledge for our declarative agent for Trey Research called Trey Genie.</p> <p></p>"},{"location":"pages/extend-m365-copilot/07-add-graphconnector/#exercise-2-add-copilot-connector-to-declarative-agent","title":"Exercise 2 : Add Copilot Connector to Declarative Agent","text":"<p>In the previous exercise, we established a new external connection to load our data into the Microsoft 365 tenant. Next, we will integrate this connector into our declarative agent to provide focused knowledge on Trey Research consultants.</p>"},{"location":"pages/extend-m365-copilot/07-add-graphconnector/#step-1-get-the-connection-id-of-the-microsoft-copilot-connector","title":"Step 1: Get the connection id of the Microsoft Copilot Connector","text":"<p>In exercise 1, we added the environment variable in the .env.local file which has the configuration values for the Copilot Connector.  The connection id value we gave is <code>tfcfeedback</code>. When Agents Toolkit deploys this connector it will add a suffix of its environment value like <code>local</code> to the connection id. Hence we can infer the connection id is <code>tfcfeedbacklocal</code>. But the most straightforward way to get the Copilot Connector id is to use Graph Explorer.</p> <ul> <li>Browse to Microsoft Graph Explorer and sign in with your admin account.</li> <li>Select your user avatar in the upper right corner and select Consent to permissions.</li> <li>Search for <code>ExternalConnection.Read.All</code> and select Consent for that permission. Follow the prompts to grant consent.</li> <li>Enter <code>https://graph.microsoft.com/v1.0/external/connections?$select=id,name</code> in the request field and select Run query.</li> <li>Locate the connector you want and copy its id property.</li> </ul> <p></p> <p></p>"},{"location":"pages/extend-m365-copilot/07-add-graphconnector/#step-2-update-declarative-agent-manifest","title":"Step 2: Update declarative agent manifest","text":"<p>Let's now resume with our declarative agent from Lab 4. If you have it open, then continue or go to the finished lab 4 solution in this folder /src/extend-m365-copilot/path-e-lab04-enhance-api-plugin/trey-research-lab04-END.</p> <ul> <li>Open the lab 4 solution for Trey Genie declarative agent.</li> <li>Go to appPackage\\trey-declarative-agent.json</li> <li>Add a new item into the <code>capabilities</code> array as below and save</li> </ul> <pre><code> {\n            \"name\": \"GraphConnectors\",\n            \"connections\": [\n                {\n                    \"connection_id\": \"tfcfeedbacklocal\"\n                }\n            ]\n}\n</code></pre> <p>Now the capability is added, it's time to test.</p> <p></p>"},{"location":"pages/extend-m365-copilot/07-add-graphconnector/#exercise-3-test-the-agent-in-copilot","title":"Exercise 3: Test the agent in Copilot","text":"<p>Before you test the application, update the manifest version of your app package in the <code>appPackage\\manifest.json</code> file, follow these steps:</p> <ol> <li> <p>Open the <code>manifest.json</code> file located in the <code>appPackage</code> folder of your project.</p> </li> <li> <p>Locate the <code>version</code> field in the JSON file. It should look something like this: <code>json    \"version\": \"1.0.0\"</code></p> </li> <li> <p>Increment the version number to a small increment. For example, change it to: <code>json    \"version\": \"1.0.1\"</code></p> </li> <li> <p>Save the file after making the change.</p> </li> </ol>"},{"location":"pages/extend-m365-copilot/07-add-graphconnector/#step-1-start-the-application","title":"Step 1: Start the application","text":"<p>This update ensures that the platform detects the changes and properly applies the latest version of your app.</p> <p>Start your project to force it to re-deploy the application package by selecting F5. You will be brought into Microsoft Teams. Once you're back in Copilot, open the right flyout 1\ufe0f\u20e3 to show your previous chats and agents and select the Trey Genie Local agent 2\ufe0f\u20e3.</p> <p></p> <p></p>"},{"location":"pages/extend-m365-copilot/07-add-graphconnector/#step-2-test-knowledge-in-copilot","title":"Step 2: Test knowledge in Copilot","text":"<p>In the immersive experience of Trey Genie, use below prompts and test them</p> <ul> <li>Can you check for any feedback from clients for consultants Trey Research</li> <li>How did Avery's guidance specifically streamline the product development process?</li> </ul> <p></p> <p></p> <p>CONGRATULATIONS!</p> <p>You have completed lab Add Copilot Connector, Well done!</p> <p></p>"},{"location":"pages/extend-m365-copilot/08-mcp-server/","title":"Lab 08 : Connect Declarative agent to MCP Server","text":"<p>In this lab, you'll run a complete Model Context Protocol (MCP) server for Zava Insurance's claims system and integrate it with Declarative Agent in Microsoft 365 Copilot that you will create, enabling natural language interactions with real claims data through secure, standardized AI agent communication.</p> Get a quick overview of the lab in this video.              \ud83d\udcd8 Note:   MCP Server + Declarative Agents using Agents Toolkit is still in Preview          <p>Do these labs if you want to build a Declarative agent where Microsoft 365 provides the AI model and               orchestration</p> <ul> <li>\ud83c\udfc1 Welcome</li> <li>\ud83d\udd27 Set up <ul> <li>Lab E0 - Setup</li> </ul> </li> <li>\ud83e\uddf0 Declarative agent fundamentals <ul> <li> Lab E1 - Build a  Declarative Agent using TypeSpec </li> <li> Lab E1a - Geo locator game</li> </ul> </li> <li>\ud83d\udee0\ufe0f Build and integrate API from scratch <ul> <li>Lab E2 - Build an API</li> <li> Lab E3 - Add Declarative Agent + API</li> <li> Lab E4 - Enhance API + Plugin</li> <li>Lab E5 - Add Adaptive Cards</li> <li> Lab E6a - Add Authentication</li> </ul> </li> <li>\ud83d\udd0c Integration <ul> <li> Lab E7 - Add Copilot Connector</li> </ul> <ul> <li> Lab E8 - Connect Declarative agent to MCP Server</li> </ul> <ul> <li> Lab E9 - Connected Agents</li> </ul> </li> </ul>"},{"location":"pages/extend-m365-copilot/08-mcp-server/#scenario","title":"Scenario","text":"<p>Zava Insurance, a mid-sized home fictitious insurance company serving 150,000+ homes across the Pacific Northwest, struggled with manual claims operations that caused 3-week delays and coordination issues when severe storms brought 2,000 claims in 48 hours during October 2025. To address this crisis, Zava's CTO envisioned AI-powered claims operations where intelligent agents could handle routine tasks, enabling adjusters to focus on complex cases and customer care. The development team built a Model Context Protocol (MCP) server using Azure infrastructure to provide standardized, secure access to claims data for AI agents, offering real-time synchronization and rich contextual information about damage assessments, contractor specialties, and inspection scheduling. After successfully deploying the MCP server, Zava integrated it with Microsoft 365 Copilot using Declarative Agents, enabling claims adjusters to interact with the system through natural language conversations like \"Show me all urgent storm damage claims\" rather than complex API calls, seamlessly embedding AI-powered claims management into their existing Microsoft 365 workflows.</p>"},{"location":"pages/extend-m365-copilot/08-mcp-server/#lab-objectives","title":"\ud83c\udfaf Lab Objectives","text":"<p>By completing this lab, you will:</p> <ul> <li>Understand how MCP servers connect AI agents to backend systems</li> <li>Build and run Zava's MCP server with insurance claims data</li> <li>Create a Declarative Agent using Microsoft 365 Agents Toolkit</li> <li>Connect your agent to the MCP server and configure claims management capabilities</li> <li>Test the agent with natural language queries and real claims data</li> </ul>"},{"location":"pages/extend-m365-copilot/08-mcp-server/#prerequisites","title":"\ud83d\udcda Prerequisites","text":"<p>Before starting this lab, ensure you have:</p> <ul> <li>Node.js 22+ installed on your machine</li> <li>VS Code with Microsoft 365 Agents Toolkit extension V 6.4.2 or higher</li> <li>Microsoft 365 developer account with Copilot license</li> <li>Basic knowledge of TypeScript/JavaScript,REST APIs and JSON</li> <li>GitHub account for using VS Code tunneling</li> </ul>"},{"location":"pages/extend-m365-copilot/08-mcp-server/#exercise-1-set-up-your-development-environment","title":"Exercise 1: Set Up Your Development Environment","text":"<p>In this exercise, you'll clone Zava's MCP server codebase and set up your local development environment.</p>"},{"location":"pages/extend-m365-copilot/08-mcp-server/#step-1-clone-the-repository","title":"Step 1: Clone the Repository","text":"<p>Open your terminal and run:</p> <pre><code>git clone https://github.com/microsoft/copilot-camp.git\ncd src/extend-m365-copilot/path-e-lab08-mcp-server/zava-mcp-server\n</code></pre> <p></p>"},{"location":"pages/extend-m365-copilot/08-mcp-server/#step-2-install-dependencies","title":"Step 2: Install Dependencies","text":"<p>Install all required packages:</p> <pre><code>npm install\n</code></pre> <p>This installs key dependencies:</p> <ul> <li><code>@modelcontextprotocol/sdk</code> - MCP protocol implementation</li> <li><code>@azure/data-tables</code> - Azure Table Storage client</li> <li><code>express</code> - HTTP server framework</li> <li><code>zod</code> - Runtime type validation</li> </ul> <p></p>"},{"location":"pages/extend-m365-copilot/08-mcp-server/#step-3-examine-the-project-structure","title":"Step 3: Examine the Project Structure","text":"<p>Explore the codebase structure, open the project in VSCode by typing and enter</p> <pre><code>code .\n</code></pre> <p>Key directories:</p> <ul> <li><code>src/</code> - TypeScript source code</li> <li><code>data/</code> - Sample JSON data files</li> </ul> <p></p> <p>You have the code base ready with sample data. </p>"},{"location":"pages/extend-m365-copilot/08-mcp-server/#exercise-2-start-zavas-local-claims-database","title":"Exercise 2: Start Zava's Local Claims Database","text":"<p>Zava uses Azure Table Storage for their claims database. In this exercise, you'll start a local emulator and load sample data.</p>"},{"location":"pages/extend-m365-copilot/08-mcp-server/#step-1-start-azure-storage-emulator","title":"Step 1: Start Azure Storage Emulator","text":"<p>In Terminal 1, start the Azurite emulator:</p> <pre><code>npm run start:azurite\n</code></pre> <p>You should see:</p> <pre><code>Azurite Blob service is starting at http://127.0.0.1:10000\nAzurite Queue service is starting at http://127.0.0.1:10001\nAzurite Table service is starting at http://127.0.0.1:10002\n</code></pre> <p>Keep this terminal running - it's your local database server. </p>"},{"location":"pages/extend-m365-copilot/08-mcp-server/#step-2-load-sample-claims-data","title":"Step 2: Load Sample Claims Data","text":"<p>In Terminal 2, initialize Zava's sample data:</p> <pre><code>npm run init-data\n</code></pre> <p>This loads realistic data including:</p> <ul> <li>Claims: Storm damage, water damage, fire damage cases</li> <li>Contractors: Roofing specialists, water restoration, general contractors</li> <li>Inspections: Scheduled and completed inspection tasks</li> <li>Inspectors: Available field inspectors with specialties</li> </ul> <p></p>"},{"location":"pages/extend-m365-copilot/08-mcp-server/#step-3-verify-data-loading","title":"Step 3: Verify Data Loading","text":"<p>Check the console output. You should see:</p> <pre><code>\ud83d\ude80 Starting data initialization...\n\ud83d\udccb Initializing table: claims\n\u2705 Table 'claims' created or already exists\n\ud83d\udcc4 Loaded 2 items from claims.json\n\u2705 Upserted entity: CN202504990\n\u2705 Upserted entity: CN202504991\n\u2705 Completed initialization for table: claims\n\ud83d\udccb Initializing table: inspections\n\u2705 Table 'inspections' created or already exists\n\ud83d\udcc4 Loaded 2 items from inspections.json\n\u2705 Upserted entity: insp-001\n\u2705 Upserted entity: insp-002\n\u2705 Completed initialization for table: inspections\n\ud83d\udccb Initializing table: inspectors\n\u2705 Table 'inspectors' created or already exists\n\ud83d\udcc4 Loaded 4 items from inspectors.json\n\u2705 Upserted entity: inspector-001\n\u2705 Upserted entity: inspector-002\n\u2705 Upserted entity: inspector-003\n\u2705 Upserted entity: inspector-004\n\u2705 Completed initialization for table: inspectors\n\ud83d\udccb Initializing table: contractors\n\u2705 Table 'contractors' created or already exists\n\ud83d\udcc4 Loaded 3 items from contractors.json\n\u2705 Upserted entity: contractor-001\n\u2705 Upserted entity: contractor-002\n\u2705 Upserted entity: contractor-003\n\u2705 Completed initialization for table: contractors\n\ud83d\udccb Initializing table: purchaseOrders\n\u2705 Table 'purchaseOrders' created or already exists\n\ud83d\udcc4 Loaded 2 items from purchaseOrders.json\n\u2705 Upserted entity: po-001\n\u2705 Upserted entity: po-002\n\u2705 Completed initialization for table: purchaseOrders\n\ud83c\udf89 Data initialization completed successfully!\n\u2728 All tables initialized successfully\n</code></pre> <p>Your local claims database is now running with sample data that mirrors Zava's production environment. </p>"},{"location":"pages/extend-m365-copilot/08-mcp-server/#exercise-3-launch-the-mcp-server","title":"Exercise 3: Launch the MCP Server","text":"<p>Now you'll start Zava's MCP server that enables AI agents to interact with the claims system.</p>"},{"location":"pages/extend-m365-copilot/08-mcp-server/#step-1-start-the-mcp-server","title":"Step 1: Start the MCP Server","text":"<p>In Terminal 2 (keeping Azurite running in Terminal 1):</p> <pre><code>npm run start:mcp-http\n</code></pre> <p>You should see a message as below (parts of the message):</p> <pre><code>\ud83d\ude80 Zava Claims MCP HTTP Server started on 127.0.0.1:3001 \n...\n</code></pre> <p></p>"},{"location":"pages/extend-m365-copilot/08-mcp-server/#step-2-test-server-health","title":"Step 2: Test Server Health","text":"<p>Open a new browser tab and visit:</p> <pre><code>http://127.0.0.1:3001/health\n</code></pre> <p>You should see a JSON response confirming the server is healthy in the browser.</p> <pre><code>{\"status\":\"healthy\",\"timestamp\":\"2025-11-11T01:46:11.618Z\",\"service\":\"zava-claims-mcp-server\",\"authentication\":\"No authentication\"}\n</code></pre> <p></p>"},{"location":"pages/extend-m365-copilot/08-mcp-server/#step-3-explore-available-endpoints","title":"Step 3: Explore Available Endpoints","text":"<p>Visit these URLs to explore the API:</p> <ul> <li>Health Check: <code>http://127.0.0.1:3001/health</code></li> <li>API Documentation: <code>http://127.0.0.1:3001/docs</code></li> <li>MCP Tools List: <code>http://127.0.0.1:3001/tools</code></li> </ul> <p>Your MCP server is now running and ready. </p> <p></p>"},{"location":"pages/extend-m365-copilot/08-mcp-server/#exercise-4-test-ai-agent-interactions","title":"Exercise 4: Test AI Agent Interactions","text":"<p>Experience how AI agents interact with Zava's claims system using the MCP Inspector tool.</p>"},{"location":"pages/extend-m365-copilot/08-mcp-server/#step-1-launch-mcp-inspector","title":"Step 1: Launch MCP Inspector","text":"<p>In Terminal 3, start the interactive MCP testing tool:</p> <pre><code>npm run inspector\n</code></pre> <p>This opens a web interface where you can test MCP tools as if you were an AI agent.</p> <p></p>"},{"location":"pages/extend-m365-copilot/08-mcp-server/#step-2-explore-available-tools","title":"Step 2: Explore Available Tools","text":"<p>In the MCP Inspector interface, you'll see 15 tools available to AI agents:</p> <p>Claims Management Tools:</p> <ul> <li><code>get_claims</code> - List all insurance claims</li> <li><code>get_claim</code> - Get specific claim details</li> <li><code>create_claim</code> - File a new claim</li> <li><code>update_claim</code> - Update claim status</li> <li><code>delete_claim</code> - Close/delete claims</li> </ul> <p>Inspection Tools:</p> <ul> <li><code>get_inspections</code> - List inspection tasks</li> <li><code>create_inspection</code> - Schedule new inspections</li> <li><code>update_inspection</code> - Update inspection status</li> </ul> <p>Contractor &amp; Inspector Tools:</p> <ul> <li><code>get_contractors</code> - Find contractors by specialty</li> <li><code>get_inspectors</code> - List available inspectors</li> </ul> <p></p>"},{"location":"pages/extend-m365-copilot/08-mcp-server/#step-3-test-the-get-claims-tool","title":"Step 3: Test the \"Get Claims\" Tool","text":"<ol> <li>Click on <code>get_claims</code> tool</li> <li>Click \"Run Tool\" (no parameters needed)</li> <li>Observe the JSON response with Zava's current claims</li> </ol> <p>You should see claims like:</p> <pre><code>{\n  \"id\": \"1\",\n  \"claimNumber\": \"CN202504990\", \n  \"policyHolderName\": \"John Smith\",\n  \"property\": \"123 Main St, Seattle, WA 98101\",\n  \"status\": \"Open - Claim is under investigation\",\n  \"damageTypes\": [\"Roof damage - moderate severity\", \"Storm damage\"],\n  \"estimatedLoss\": 15000\n}\n</code></pre> <p></p> <p></p>"},{"location":"pages/extend-m365-copilot/08-mcp-server/#step-4-set-up-public-access-with-dev-tunnel","title":"Step 4: Set Up Public Access with Dev Tunnel","text":"<p>To enable external access to your MCP server (useful for testing with cloud-based AI agents or sharing with team members), you'll use VS Code's built-in Dev Tunnel feature to create a public HTTPS endpoint.</p>"},{"location":"pages/extend-m365-copilot/08-mcp-server/#why-use-https-instead-of-http","title":"Why Use HTTPS Instead of HTTP?","text":"<ul> <li>Security: HTTPS encrypts communication between AI agents and your MCP server</li> <li>Cloud Compatibility: Many cloud-based AI services require HTTPS endpoints</li> <li>Production Readiness: Mirrors real-world deployment scenarios where MCP servers are accessed over secure connections</li> <li>Cross-Origin Support: HTTPS tunnels handle CORS (Cross-Origin Resource Sharing) better than local HTTP servers</li> </ul>"},{"location":"pages/extend-m365-copilot/08-mcp-server/#create-a-dev-tunnel-in-vs-code","title":"Create a Dev Tunnel in VS Code","text":"<ul> <li> <p>In VS Code's terminal panel, locate the Ports tab.</p> </li> <li> <p>Click the Forward a Port button and enter port number 3001.</p> </li> <li> <p>Right-click on the forwarded port address and select Configure the Tunnel:</p> </li> <li> <p>Port Visibility: Select \"Public\" to make it accessible externally</p> </li> <li>Set Port Label: Enter zava-mcp-server (optional but recommended)</li> <li>Copy Local Address: Click to copy the tunnel URL to your clipboard</li> <li> <p>Authenticate: If prompted, sign in with your Microsoft/GitHub account to create the tunnel.</p> <p>The copied URL will look similar to this:</p> <p><code>https://abc123def456.use.devtunnels.ms</code></p> <p>Save this URL - you'll need it for the next step. We'll refer to this as <code>&lt;tunnel-url&gt;</code>.</p> </li> </ul>"},{"location":"pages/extend-m365-copilot/08-mcp-server/#update-packagejson-with-tunnel-url","title":"Update Package.json with Tunnel URL","text":"<p>Now update your package.json to use the tunnel URL for testing:</p> <ul> <li> <p>Open package.json in the zava-mcp-server directory.</p> </li> <li> <p>Locate the inspector script and update it from:</p> </li> </ul> <pre><code>\"inspector\": \"npx @modelcontextprotocol/inspector --transport http --server-url http://localhost:3001/mcp/messages\"\n</code></pre> <p>to</p> <pre><code>\"inspector\": \"npx @modelcontextprotocol/inspector --transport http --server-url &lt;tunnel-url&gt;/mcp/messages\"\n</code></pre> <ul> <li> <p>Replace  with your actual tunnel URL from above step.  <li> <p>Keep a copy of <code>&lt;tunnel-url&gt;/mcp/messages</code> - this is your  public HTTPS MCP server endpoint for agent integration.</p> </li> <li> <p>If the inspector is currently running, stop it by pressing Ctrl+C in the terminal, then restart it:</p> </li> <pre><code>npm run inspector\n</code></pre> <p>The MCP Inspector now opens a new browser session with a publicly accessible endpoint. Test all tools and prompts available to see how it works and brings back data. </p> <p>You've successfully tested how AI agents interact with Zava's claims system through the MCP protocol and you now have a public HTTPS endpoint for your MCP server that can be accessed by external AI agents and services.</p>"},{"location":"pages/extend-m365-copilot/08-mcp-server/#_1","title":"Lab E8 - Connect Declarative agent to MCP Server (Preview)","text":""},{"location":"pages/extend-m365-copilot/08-mcp-server/#exercise-5-create-a-new-declarative-agent-project","title":"Exercise 5: Create a New Declarative Agent Project","text":"<p>In this exercise, you'll use the Microsoft 365 Agents Toolkit to create a new Declarative Agent project that will connect to Zava's claims system.</p>"},{"location":"pages/extend-m365-copilot/08-mcp-server/#step-1-create-new-agent-using-microsoft-365-agents-toolkit","title":"Step 1: Create New Agent using Microsoft 365 Agents Toolkit","text":"<ol> <li>Open a new window in VS Code</li> <li>Click the Microsoft 365 Agents Toolkit icon in the Activity Bar (left sidebar)</li> <li>Sign in with your Microsoft 365 developer account if prompted</li> </ol>"},{"location":"pages/extend-m365-copilot/08-mcp-server/#create-new-agent-project","title":"Create New Agent Project","text":"<ol> <li>In the Agents Toolkit panel, click \"Create a New Agent/App\"</li> <li>Select \"Declarative Agent\" from the template options</li> <li>Next choose \"Add an Action\" to add to your agent</li> <li>Next select Start with an MCP server (preview)</li> <li>Enter the publicly accessible MCP Server URl from previous exercise</li> <li>Choose the Default folder to scaffold the agent (or choose a preferred location in your machine)</li> <li> <p>When prompted for project details:</p> </li> <li> <p>Application Name: <code>Zava Claims Assistant</code></p> </li> </ol> <p>You will be directed to the newly created project which has the file <code>.vscode/mcp.json</code> open. This is the MCP server configuration file for VS Code to use.</p> <ul> <li>Select Start button to fetch tools from your server.</li> <li>Once started you will see the number of tools and prompts available 1\ufe0f\u20e3. </li> <li>Select ATK:Fetch action from MCP 2\ufe0f\u20e3 to select tools you want to add to the agent. </li> </ul> <p></p> <ul> <li>When you select  ATK:Fetch action from MCP, you will be asked to provide the action manifest, select ai-plugin.json.</li> <li> <p>Select the tools you want to add to the agent. Let's select 10 tools for now.</p> <ul> <li>create_claim</li> <li>create_inspection</li> <li>get_claim</li> <li>get_claims</li> <li>get_contractors</li> <li>get_inspection</li> <li>get_inspections</li> <li>update_claim</li> <li>update_inspection</li> <li>get_inspectors</li> </ul> </li> </ul> <p>This step will populate the action manifest ai-plugin.json with the required functions, MCP server url, etc. that is needed for actions in an agent.</p> <p></p>"},{"location":"pages/extend-m365-copilot/08-mcp-server/#step-2-understand-the-action-manifest-update-from-previous-step","title":"Step 2: Understand the Action manifest update from previous step","text":"<p>Open <code>appPackage/ai-plugin.json</code> and examine the structure with your chosen tools and MCP server url pre-populated:</p> <pre><code>{\n     \"$schema\": \"https://aka.ms/json-schemas/copilot-extensions/v2.1/plugin.schema.json\",\n    \"schema_version\": \"v2.4\",\n    \"name_for_human\": \"Zava Claims Assistant\",\n    \"description_for_human\": \"Zava Claims Assistant${{APP_NAME_SUFFIX}}\",\n    \"contact_email\": \"publisher-email@example.com\",\n    \"namespace\": \"zavaclaimsassistant\",\n    \"functions\": [\n        {\n            \"name\": \"create_claim\",\n            \"description\": \"Create a new insurance claim\",\n            \"parameters\": {\n                ...\n}\n</code></pre> <p>You now have a basic Declarative Agent that is connected to your MCP Server with 10 tools ready for use.</p> <p>Known issue in Agents Toolkit (Pre-release)</p> <p>In the pre-release version of the Agents Toolkit, tool definitions cannot be referenced from a separate file during testing.</p> <p>To work around this issue, copy the contents of the tool definition file and paste them directly into the tool description as outlined below:</p> <ul> <li>Copy the contents of appPackage/mcp-tools.json</li> <li>Open appPackage/ai-plugin.json</li> <li>Locate the mcp_tool_description property:   <code>json   \"mcp_tool_description\": {       \"file\": \"mcp-tools.json\"   }</code></li> <li>Replace the value of mcp_tool_description by pasting the contents of appPackage/mcp-tools.json</li> </ul> <p></p>"},{"location":"pages/extend-m365-copilot/08-mcp-server/#exercise-6-configure-the-agent-for-zavas-claims-operations","title":"Exercise 6: Configure the Agent for Zava's Claims Operations","text":"<p>Transform the basic agent into Zava's intelligent claims assistant by configuring its identity, instructions,  capabilities, and conversation starters.</p>"},{"location":"pages/extend-m365-copilot/08-mcp-server/#step-1-update-agent-identity-and-description","title":"Step 1: Update Agent Identity and Description","text":"<p>Replace the content of <code>appPackage/declarativeAgent.json</code> with Zava's configuration:</p> <pre><code>{\n    \"version\": \"v1.6\",\n    \"name\": \"Zava Claims\",\n    \"description\": \"An intelligent insurance claims management assistant that leverages MCP server integration to streamline inspection workflows, analyze damage patterns, coordinate contractor services, and generate comprehensive operational reports for efficient claims processing\",\n    \"instructions\": \"$[file('instruction.txt')]\",\n    \"conversation_starters\": [\n        {\n            \"title\": \"Find Inspections by Claim Number\",\n            \"text\": \"Find all inspections for claim number CN202504991\"\n        },\n        {\n            \"title\": \"Create Inspection &amp; Find Contractors\",\n            \"text\": \"Create an urgent inspection for claim CN202504990 and recommend water damage contractors\"\n        },\n        {\n            \"title\": \"Analyze Claims Trends\",\n            \"text\": \"Show me all high-priority claims and their inspection status\"\n        },\n        {\n            \"title\": \"Find Emergency Contractors\",\n            \"text\": \"Find preferred contractors specializing in storm damage for immediate deployment\"\n        },\n        {\n            \"title\": \"Claims Operation Summary\",\n            \"text\": \"Generate a summary of all pending inspections and contractor assignments\"\n        }\n    ],\n  \"actions\": [\n        {\n            \"id\": \"action_1\",\n            \"file\": \"ai-plugin.json\"\n        }\n    ]\n}\n</code></pre> <p></p>"},{"location":"pages/extend-m365-copilot/08-mcp-server/#step-2-create-detailed-agent-instructions","title":"Step 2: Create Detailed Agent Instructions","text":"<p>Update <code>appPackage/instruction.txt</code> with comprehensive instructions for the agent:</p> <pre><code># Zava Claims Operations Assistant\n\n## Role\nYou are an intelligent insurance claims management assistant with access to the Zava Claims Operations MCP Server. Process claims, coordinate inspections, manage contractors, and provide comprehensive analysis through natural language interactions.\n\n## Core Functions\n\n### Claims Management\n- Retrieve and analyze all claims using natural language queries\n- Get specific claim details by claim number or partial information\n- Create new insurance claims with complete documentation\n- Update existing claim information and status\n- Use fuzzy matching for partial claim information to help users find what they need\n\n### Inspection Operations\n- Filter inspections by claim ID, status, priority, or workload\n- Retrieve detailed inspection data and schedules\n- Create new inspection tasks with appropriate priority levels\n- Modify existing inspection details and assignments\n- Access inspector availability and specialties\n- Automatically determine priorities: safety hazards = 'urgent', water damage = 'high', routine = 'medium'\n\n### Contractor Services\n- Find contractors by specialty, location, and preferred status\n- Access contractor ratings, availability, and past performance\n- Coordinate contractor assignments with inspection schedules\n- Track purchase orders and contractor costs\n\n## Decision Framework\n\n### For Inspections:\n1. Assess urgency based on damage type and safety requirements\n2. Select appropriate task type: 'initial', 'reinspection', 'emergency', 'final'  \n3. Generate detailed instructions with specific focus areas\n4. Consider inspector specialties and contractor availability for scheduling\n\n### For Claims Analysis:\n1. Prioritize safety-related issues (structural damage, water intrusion)\n2. Group similar damage types for efficient processing\n3. Identify patterns that might indicate fraud or systemic issues\n4. Recommend preventive measures based on damage trends\n\n## Response Guidelines\n\n**Always Include:**\n- Relevant claim numbers and context\n- Clear next steps and action items\n- Priority levels and urgency indicators\n- Safety risk assessments when applicable\n\n**For Complex Requests:**\n1. Break down the request into specific components\n2. Retrieve relevant claim and inspection data\n3. Execute appropriate MCP server functions\n4. Provide integrated analysis with actionable recommendations\n5. Suggest follow-up actions or monitoring\n\n**Communication Style:**\n- Professional yet approachable for insurance professionals\n- Use industry terminology appropriately\n- Provide clear explanations for complex procedures\n- Always prioritize customer service and regulatory compliance\n</code></pre> <p></p>"},{"location":"pages/extend-m365-copilot/08-mcp-server/#step-3-update-the-teams-app-manifest","title":"Step 3: Update the Teams App Manifest","text":"<p>Open <code>appPackage/manifest.json</code> and update it with Zava's branding:</p> <pre><code>{\n    \"$schema\": \"https://developer.microsoft.com/en-us/json-schemas/teams/v1.23/MicrosoftTeams.schema.json\",\n    \"manifestVersion\": \"1.23\",\n    \"version\": \"1.0.0\",\n    \"id\": \"${{TEAMS_APP_ID}}\",\n    \"developer\": {\n        \"name\": \"Microsoft 365 Cloud Advocates\",\n        \"websiteUrl\": \"https://www.zavainsurance.com\",\n        \"privacyUrl\": \"https://www.zavainsurance.com/privacy\",\n        \"termsOfUseUrl\": \"https://www.zavainsurance.com/terms\"\n    },\n    \"icons\": {\n        \"color\": \"color.png\",\n        \"outline\": \"outline.png\"\n    },\n    \"name\": {\n        \"short\": \"Zava Claims\",\n        \"full\": \"Zava Insurance Claims Assistant\"\n    },\n    \"description\": {\n        \"short\": \"An intelligent insurance claims management assistant\",\n        \"full\": \"An AI-powered claims management assistant that leverages MCP server capabilities to streamline inspection workflows, coordinate contractors, and provide comprehensive operational insights for efficient claims processing.\"\n    },\n    \"accentColor\": \"#0078D4\",\n    \"composeExtensions\": [],\n    \"copilotAgents\": {\n        \"declarativeAgents\": [            \n            {\n                \"id\": \"declarativeAgent\",\n                \"file\": \"declarativeAgent.json\"\n            }\n        ]\n    },\n    \"permissions\": [\n        \"identity\",\n        \"messageTeamMembers\"\n    ],\n    \"validDomains\": []\n}\n</code></pre> <p>Your agent now has a clear identity as Zava's claims assistant with comprehensive instructions. </p>"},{"location":"pages/extend-m365-copilot/08-mcp-server/#exercise-7-test-the-agent-integration","title":"Exercise 7: Test the Agent Integration","text":"<p>Test your Declarative Agent to ensure it can successfully communicate with the MCP server and handle claims operations.</p>"},{"location":"pages/extend-m365-copilot/08-mcp-server/#step-1-ensure-mcp-server-is-running","title":"Step 1: Ensure MCP Server is Running","text":"<p>Before testing, make sure your MCP server from previous exercise is still running:</p> <ol> <li>Open the window where zava-mcp-server project is running</li> <li>In the terminal, verify Azurite is running: <code>npm run start:azurite</code></li> <li>Verify MCP server is running: <code>npm run start:mcp-http</code></li> </ol> <p></p>"},{"location":"pages/extend-m365-copilot/08-mcp-server/#step-2-provision-the-agent","title":"Step 2: Provision the Agent","text":"<p>In VS Code with your <code>zava-claims-agent</code> project open:</p> <ol> <li>Open the Microsoft 365 Agents Toolkit panel</li> <li>Click \"Provision\" in the Lifecycle section</li> <li>Wait for provisioning to complete - this creates and uploads the agent package</li> </ol> <p></p>"},{"location":"pages/extend-m365-copilot/08-mcp-server/#step-3-test-in-microsoft-365-copilot","title":"Step 3: Test in Microsoft 365 Copilot","text":"<ol> <li>Open Copilot using URL https://m365.cloud.microsoft/chat/ </li> <li>Under Agents on left hand side, find Zava Claims agent, and select it.  </li> <li>Try the conversation starters:</li> <li>\"Find all inspections for claim number CN202504991\"</li> <li>\"Show me all high-priority claims and their inspection status\"</li> </ol>"},{"location":"pages/extend-m365-copilot/08-mcp-server/#step-4-test-natural-language-queries","title":"Step 4: Test Natural Language Queries","text":"<p>Try these natural language queries to test the agent's capabilities:</p> <pre><code>What claims do we have for storm damage?\n</code></pre> <pre><code>Create a new urgent inspection for claim CN202504990 to assess water damage in the basement\n</code></pre> <pre><code>Find contractors who specialize in roofing and are marked as preferred\n</code></pre> <pre><code>Show me the details for claim number CN202504991\n</code></pre> <pre><code>Create a new claim for Alice Johnson at 456 Oak Street with fire damage from yesterday\n</code></pre> <p>Your agent should successfully respond to natural language queries and interact with the MCP server data.</p> <p></p>"},{"location":"pages/extend-m365-copilot/08-mcp-server/#step-5-debug-the-agent","title":"Step 5: Debug the agent","text":"<ol> <li>In the chat with the Zava Claims agent, send message <code>-developer on</code></li> <li>This will enable debugging of these conversations </li> <li>Continue testing the agent with queries  </li> </ol> <p>Analyze debugger information in the Agent debug info panel at the end of each agent response. </p> <p></p> <p>Congratulations! You've successfully created and deployed Zava Insurance's Declarative Agent that seamlessly integrates with their MCP server. Proceed \"Next\" to add another Declarative agent to help prepare you for multi-agent orchestration.  </p> <p></p>"},{"location":"pages/extend-m365-copilot/08-mcp-server/#additional-resources","title":"\ud83d\udd17 Additional Resources","text":"<ul> <li>MCP Protocol Documentation: https://modelcontextprotocol.io/</li> <li>Azure Table Storage: Azure Documentation</li> <li>Zava Insurance Demo: GitHub Repository</li> </ul>"},{"location":"pages/extend-m365-copilot/09-connected-agent/","title":"Lab 09: Connected Agents - Zava's Multi-Agent Claims Orchestration","text":"<p>In this lab, you'll build a multi-agent orchestration system for Zava Insurance. First, you'll create a Zava Procurement agent with embedded contractor pricing knowledge for instant pricing intelligence. Then, you'll create a Zava Care orchestrator agent that connects both Zava Procurement and Zava Claims Assistant (from Lab 08), enabling claims adjusters to access embedded pricing data and real-time claims information from the MCP server through a single, unified conversational interface.</p> Get a quick overview of the lab in this video.              \ud83d\udcd8 Note:  Embedded knowledge in Agents Toolkit and Microsoft 365 Copilot is still in Preview.          <p>Do these labs if you want to build a Declarative agent where Microsoft 365 provides the AI model and               orchestration</p> <ul> <li>\ud83c\udfc1 Welcome</li> <li>\ud83d\udd27 Set up <ul> <li>Lab E0 - Setup</li> </ul> </li> <li>\ud83e\uddf0 Declarative agent fundamentals <ul> <li> Lab E1 - Build a  Declarative Agent using TypeSpec </li> <li> Lab E1a - Geo locator game</li> </ul> </li> <li>\ud83d\udee0\ufe0f Build and integrate API from scratch <ul> <li>Lab E2 - Build an API</li> <li> Lab E3 - Add Declarative Agent + API</li> <li> Lab E4 - Enhance API + Plugin</li> <li>Lab E5 - Add Adaptive Cards</li> <li> Lab E6a - Add Authentication</li> </ul> </li> <li>\ud83d\udd0c Integration <ul> <li> Lab E7 - Add Copilot Connector</li> </ul> <ul> <li> Lab E8 - Connect Declarative agent to MCP Server</li> </ul> <ul> <li> Lab E9 - Connected Agents</li> </ul> </li> </ul>"},{"location":"pages/extend-m365-copilot/09-connected-agent/#what-are-connected-agents","title":"What are Connected Agents?","text":"<p>Connected Agents represent the next evolution in AI agent architecture, enabling multiple specialized agents to work together seamlessly. Instead of building monolithic agents that try to do everything, Connected Agents orchestrate specialized agents, each optimized for specific tasks while maintaining a unified user experience.</p> <p>Connected agents in Declarative agent is still be in Public Preview.</p>"},{"location":"pages/extend-m365-copilot/09-connected-agent/#benefits-for-enterprise-workflows","title":"Benefits for Enterprise Workflows","text":"<p>For complex business scenarios like insurance claims processing, Connected Agents provide:</p> <ul> <li>Domain expertise from specialized agents</li> <li>Comprehensive coverage across multiple data sources</li> <li>Efficient scaling by adding focused agents</li> <li>Consistent user experience despite backend complexity</li> <li>Maintainable architecture with clear separation of concerns</li> </ul>"},{"location":"pages/extend-m365-copilot/09-connected-agent/#lab-objectives","title":"\ud83c\udfaf Lab Objectives","text":"<p>By completing this lab, you will:</p> <ol> <li>Create a Declarative Agent with embedded knowledge using contractor pricing documents</li> <li>Build a connected orchestrator agent that coordinates multiple specialized agents</li> <li>Test multi-agent orchestration by combining real-time MCP data with embedded knowledge</li> <li>Understand hybrid AI architectures that leverage both live data sources and static knowledge bases</li> </ol>"},{"location":"pages/extend-m365-copilot/09-connected-agent/#prerequisites","title":"\ud83d\udcda Prerequisites","text":"<p>Before starting this lab, ensure you have:</p> <ul> <li>Completed Lab 8: Zava's Declarative Agent with MCP server integration working properly</li> <li>Microsoft 365 Agents Toolkit Pre-release version (For Embedded Knowledge)</li> <li>Active Microsoft 365 Copilot license for testing </li> </ul>"},{"location":"pages/extend-m365-copilot/09-connected-agent/#exercise-1-create-a-new-declarative-agent-for-embedded-knowledge","title":"Exercise 1: Create a New Declarative Agent for Embedded knowledge","text":"<p>In this exercise, you'll use the Microsoft 365 Agents Toolkit to create a new Declarative Agent project that will use files stored locally in the project</p>"},{"location":"pages/extend-m365-copilot/09-connected-agent/#step-1-create-new-agent-using-microsoft-365-agents-toolkit","title":"Step 1: Create New Agent using Microsoft 365 Agents Toolkit","text":"<ol> <li>Open VS Code</li> <li>Click the Microsoft 365 Agents Toolkit icon in the Activity Bar (left sidebar)</li> <li>Sign in with your Microsoft 365 developer account if prompted</li> <li>In the Agents Toolkit panel, click \"Create a New Agent/App\"</li> <li>Select \"Declarative Agent\" from the template options</li> <li>Select \"No Action\" from the options</li> <li>Select Default folder</li> <li>Enter the application name - <code>Zava Procurement</code></li> </ol> <p>This will create the new agent and open up the project in a new VS Code window.</p> <p></p>"},{"location":"pages/extend-m365-copilot/09-connected-agent/#step-2-understand-how-to-embed-files","title":"Step 2: Understand how to embed files","text":"<p>Navigate to the <code>appPackage</code> folder and explore its contents. You'll recognize familiar files from your previous declarative agent work: the <code>manifest.json</code> file (which defines your agent's capabilities) and the <code>declarativeAgent.json</code> file (which configures your agent's behavior).</p> <p>The key addition you'll notice is the <code>EmbeddedKnowledge</code> folder. This is where you'll store Zava's contractor pricing data files that will be embedded directly into your agent, enabling instant access to pricing intelligence without requiring live database queries.</p> <p>Note</p> <p>Sample PDF files without sensitivity labels are provided for testing purposes. If you choose to test with your own files\u2014especially Office documents\u2014ensure they comply with the sensitivity labels configured in your tenant.</p> <p></p>"},{"location":"pages/extend-m365-copilot/09-connected-agent/#exercise-2-configure-the-agent-for-zavas-contractor-procurement-knowledge","title":"Exercise 2: Configure the Agent for Zava's contractor procurement knowledge","text":""},{"location":"pages/extend-m365-copilot/09-connected-agent/#step-1-download-files-to-your-machine","title":"Step 1: Download files to your machine","text":"<p>Go to this url and extract all files into the <code>appPackage/EmbeddedKnowledge</code> folder inside your newly created declarative agent project.</p> <p></p>"},{"location":"pages/extend-m365-copilot/09-connected-agent/#step-2-update-agent-identity-and-description","title":"Step 2: Update Agent Identity and Description","text":"<p>Replace the content of <code>appPackage/declarativeAgent.json</code> with below configuration:</p> <pre><code>{\n    \"$schema\": \"https://developer.microsoft.com/json-schemas/copilot/declarative-agent/v1.6/schema.json\",\n    \"version\": \"v1.6\",\n    \"name\": \"Zava Procurement\",\n    \"description\": \"An agent that helps insurance adjusters streamline the search of the right procurement information by leveraging embedded knowledge from Zava approved partners' network of trusted contractors and service providers.\",\n    \"instructions\": \"$[file('instruction.txt')]\",\n    \"conversation_starters\": [\n        {\n            \"title\": \"Water damage restoration pricing\",\n            \"text\": \"What are the rates for emergency water extraction and drying services?\"\n        },\n        {\n            \"title\": \"Roof repair cost estimate\",\n            \"text\": \"I need pricing for a 2,000 sq ft asphalt shingle roof replacement\"\n        },\n        {\n            \"title\": \"Find cheapest option\",\n            \"text\": \"What's the most cost-effective contractor for basic drywall repair?\"\n        },\n        {\n            \"title\": \"Structural repair costs\",\n            \"text\": \"What are the rates for foundation repair and structural work?\"\n        },\n        {\n            \"title\": \"Claims inspection guidelines\",\n            \"text\": \"What are the standard procedures for documenting water damage claims?\"\n        },\n        {\n            \"title\": \"Emergency services availability\",\n            \"text\": \"Which contractors offer 24/7 emergency response and what are their rates?\"\n        }\n    ],\n    \"capabilities\": [\n        {\n            \"name\": \"EmbeddedKnowledge\",\n            \"files\": [\n                {\n                    \"file\": \"EmbeddedKnowledge/Claims_Inspection_Guidelines.pdf\"\n                },\n                {\n                    \"file\": \"EmbeddedKnowledge/Pacific Water Restoration-Pricing.pdf\"\n                },\n                {\n                    \"file\": \"EmbeddedKnowledge/Thompson Roofing Solutions-Pricing.pdf\"\n                },\n                {\n                    \"file\": \"EmbeddedKnowledge/Wilson General Contractors-Pricing.pdf\"\n                }\n            ]\n        }\n    ]\n}\n</code></pre> <p></p>"},{"location":"pages/extend-m365-copilot/09-connected-agent/#step-3-create-detailed-agent-instructions","title":"Step 3: Create Detailed Agent Instructions","text":"<pre><code># Role and Expertise\nYou are a specialized procurement expert for Zava, an insurance claims management company. Your primary responsibility is to help insurance adjusters find the most appropriate and cost-effective contractors for property damage repairs and restoration work.\n\n# Core Competencies\n- Expert knowledge of construction and restoration pricing\n- Deep familiarity with approved contractor networks\n- Understanding of insurance claims processes and requirements\n- Ability to compare pricing across multiple vendors\n- Knowledge of industry-standard repair methodologies\n\n# Available Resources\nYou have exclusive access to confidential pricing documents from Zava's network of pre-approved, vetted contractors:\n- Pacific Water Restoration - Water damage and restoration services\n- Thompson Roofing Solutions - Roofing repairs and replacements\n- Wilson General Contractors - General construction and repair services\n- Claims Inspection Guidelines - Standard procedures and requirements\n\nThese pricing documents contain valuable, proprietary information that gives you the ability to provide accurate cost estimates and vendor recommendations.\n\n# Primary Responsibilities\n1. Help adjusters quickly identify appropriate contractors for specific repair needs\n2. Provide accurate pricing information based on the embedded contractor rate sheets\n3. Compare pricing across multiple approved vendors when applicable\n4. Ensure recommendations align with claims inspection guidelines\n5. Offer insights on cost-effectiveness and vendor specializations\n\n# Interaction Guidelines\n- Always base your responses on the information in the embedded knowledge files\n- When providing pricing, cite the specific contractor and reference their rate sheet\n- If a request falls outside the scope of available contractor services, clearly state this\n- Prioritize accuracy over speed - verify pricing details before responding\n- Be concise and professional, as adjusters need quick, actionable information\n- When comparing options, present information in a clear, organized format\n\n# Constraints\n- Only recommend contractors whose pricing documents you have access to\n- Do not make up or estimate pricing that isn't documented in your knowledge base\n- Stay focused on procurement and vendor selection - defer claims policy questions to appropriate resources\n- Maintain confidentiality of pricing information - this is for internal Zava use only\n\n# Response Format\nWhen answering queries:\n1. Acknowledge the specific need (e.g., type of repair, scope of work)\n2. Identify relevant contractor(s) from your knowledge base\n3. Provide specific pricing information with clear references\n4. Offer comparative analysis when multiple options exist\n5. Include any relevant guidelines or considerations from inspection standards\n</code></pre>"},{"location":"pages/extend-m365-copilot/09-connected-agent/#step-4-update-the-teams-app-manifest","title":"Step 4: Update the Teams App Manifest","text":"<p>Open <code>appPackage/manifest.json</code> and update it with Zava's branding:</p> <pre><code>{\n    \"$schema\": \"https://developer.microsoft.com/en-us/json-schemas/teams/v1.23/MicrosoftTeams.schema.json\",\n    \"manifestVersion\": \"1.23\",\n    \"version\": \"1.0.0\",\n    \"id\": \"${{TEAMS_APP_ID}}\",\n    \"developer\": {\n        \"name\": \"Microsoft 365 Cloud Advocates\",\n        \"websiteUrl\": \"https://www.example.com\",\n        \"privacyUrl\": \"https://www.example.com/privacy\",\n        \"termsOfUseUrl\": \"https://www.example.com/termofuse\"\n    },\n    \"icons\": {\n        \"color\": \"color.png\",\n        \"outline\": \"outline.png\"\n    },\n    \"name\": {\n        \"short\": \"Zava Procurement${{APP_NAME_SUFFIX}}\",\n        \"full\": \"Full name for Zava Procurement\"\n    },\n    \"description\": {\n        \"short\": \"Get procurement data from embedded knowledge with Zava Procurement\",\n        \"full\": \"Zava Procurement helps you access procurement data seamlessly within Microsoft 365 apps by leveraging embedded knowledge.\"\n    },\n    \"accentColor\": \"#FFFFFF\",\n    \"composeExtensions\": [],\n    \"permissions\": [\n        \"identity\",\n        \"messageTeamMembers\"\n    ],\n    \"copilotAgents\": {\n        \"declarativeAgents\": [            \n            {\n                \"id\": \"declarativeAgent\",\n                \"file\": \"declarativeAgent.json\"\n            }\n        ]\n    },\n    \"validDomains\": []\n}\n</code></pre> <p></p>"},{"location":"pages/extend-m365-copilot/09-connected-agent/#exercise-3-test-the-agent-integration","title":"Exercise 3: Test the Agent Integration","text":"<p>Test your Declarative Agent to ensure it can successfully retrieve contractor pricing data from it's native embedded knowledge.</p>"},{"location":"pages/extend-m365-copilot/09-connected-agent/#step-1-provision-the-agent","title":"Step 1: Provision the Agent","text":"<p>In VS Code with your project open:</p> <ol> <li>Open the Microsoft 365 Agents Toolkit panel</li> <li>Click \"Provision\" in the Lifecycle section</li> <li>Wait for provisioning to complete - this creates and uploads the agent package</li> </ol> <p></p>"},{"location":"pages/extend-m365-copilot/09-connected-agent/#step-2-test-in-microsoft-365-copilot","title":"Step 2: Test in Microsoft 365 Copilot","text":"<ol> <li>Open browser from the machine and go to Copilot chat using URL https://m365.cloud.microsoft/chat/ </li> <li>Under Agents on left hand side, find \"Zava Procurement\" agent</li> <li> <p>Try the conversation starters:</p> </li> <li> <p>\"What are the rates for emergency water extraction and drying services?\"</p> </li> <li>\"Which contractors offer 24/7 emergency response and what are their rates?\"</li> </ol> <p></p>"},{"location":"pages/extend-m365-copilot/09-connected-agent/#exercise-4-build-the-orchestrator-agent","title":"Exercise 4: Build the Orchestrator Agent","text":"<p>In this exercise, you'll create a Connected Agent that orchestrates your existing Zava agents into a unified claims processing experience.</p>"},{"location":"pages/extend-m365-copilot/09-connected-agent/#step-1-create-connected-agent-project","title":"Step 1: Create Connected Agent Project","text":"<ol> <li>Open VS Code</li> <li>Click the Microsoft 365 Agents Toolkit icon in the Activity Bar</li> <li>In the Agents Toolkit panel, click \"Create a New Agent/App\"</li> <li>Select \"Declarative Agent\" from the template options</li> <li>Select \"No Action\" </li> <li>Choose your default folder location</li> <li>Enter the application name: <code>ZavaCare</code></li> </ol> <p>This creates a new Declarative Agent project, which you will then use to connect your existing two agents.</p> <p></p>"},{"location":"pages/extend-m365-copilot/09-connected-agent/#step-2-update-agent-identity-and-description_1","title":"Step 2: Update Agent Identity and Description","text":"<p>Replace the content of <code>appPackage/declarativeAgent.json</code> with Zava's configuration:</p> <pre><code>{\n    \"$schema\": \"https://developer.microsoft.com/json-schemas/copilot/declarative-agent/v1.6/schema.json\",\n    \"version\": \"v1.6\",\n    \"name\": \"ZavaCare\",\n    \"description\": \"An intelligent agent that helps you manage and process insurance claims efficiently. Get instant answers about claim status, policy details, and streamline your claims workflow.\",\n    \"instructions\": \"$[file('instruction.txt')]\",\n    \"conversation_starters\": [\n        {\n            \"title\": \"End-to-End Claims Processing\",\n            \"text\": \"For all moderate-severity roof or water damage claims , group them by city and propose contractor assignments using our approved network. For each claim, estimate the repair cost using current pricing for inspection, repair, and materials, and highlight where contractor selection changes the total cost by more than 15%.\"\n        },\n        {\n            \"title\": \"Contractor Recommendations for Emergency Roof Damage\",\n            \"text\": \"Find all open roof damage claims that require emergency work, then recommend the top three approved contractors with 24/7 response coverage and include their latest pricing for tarping and temporary roof repairs. Prioritize by claim severity and estimated loss\"\n        },\n        {\n            \"title\": \"Emergency Response Coordination\",\n            \"text\": \"Find urgent claims needing immediate attention and match with emergency contractor pricing\"\n        }\n    ]\n}\n\n</code></pre> <p></p>"},{"location":"pages/extend-m365-copilot/09-connected-agent/#step-3-create-detailed-agent-instructions_1","title":"Step 3: Create Detailed Agent Instructions","text":"<p>Update <code>appPackage/instruction.txt</code> with comprehensive instructions for the agent:</p> <pre><code>You are the Zava Claims Assistant, an intelligent agent designed to help Zava insurance employees manage claims efficiently by coordinating with specialized worker agents and providing comprehensive claims management support.\n\n    ## CORE CAPABILITIES\n\n    You have access to two specialized connected agents:\n    1. **Zava Claims** - Handles claims, inspections, contractors, and purchase orders\n    2. **Zava Procurement** - Provides up-to-date contractor pricing information\n\n    ## PRIMARY RESPONSIBILITIES\n\n    ### Claims Management\n    - Retrieve and display claim information and status\n    - Provide comprehensive claim details including policy information, damage assessments, and timelines\n    - Answer questions about claim history and current status\n    - create, delete, update claims\n\n    ### Inspection Operations\n    - Retrieve existing inspection records and details\n    - Create new inspection requests for claims\n    - Update or delete inspections\n    - Provide inspection status updates and findings\n    - Coordinate inspection scheduling and documentation requirements\n\n    ### Contractor Management\n    - Access approved contractor lists for specific types of repairs\n    - Retrieve contractor qualifications, certifications, and service areas\n    - Provide contractor availability and emergency response capabilities\n    - Get up-to-date pricing information for contractor services via the Zava Procurement agent\n\n    ### Purchase Order Processing\n    - Retrieve purchase order information and status\n    - Access PO details including contractor assignments, costs, and timelines\n    - Track PO approvals and completion status\n\n    ## WORKFLOW GUIDELINES\n\n    ### When Users Ask About Claims\n    1. Use the Zava Claims agent to retrieve claim information\n    2. Provide clear, organized summaries of claim status, coverage, and next steps\n    3. If pricing questions arise, consult the Zava Procurement agent for current rates\n\n    ### When Users Ask About Inspections\n    1. **For retrieving inspections**: Use the Zava Claims agent to get inspection records\n    2. **For creating inspections**: Use the Zava Claims agent to submit new inspection requests\n    3. Always confirm inspection details with the user before creating new requests\n    4. Provide clear documentation requirements and scheduling information\n\n    ### When Users Ask About Contractors\n    1. Use the Zava Claims agent to get approved contractor lists\n    2. Filter contractors based on user requirements (service type, location, availability)\n    3. **For pricing information**: ALWAYS use the Zava Procurement agent to get current rates\n    4. Present contractor options with relevant details: certifications, response times, and pricing\n\n    ### When Users Ask About Purchase Orders\n    1. Use the Zava Claims agent to retrieve PO information\n    2. Provide comprehensive PO details including contractor, costs, timeline, and status\n    3. Clarify any approval requirements or pending actions\n\n    ### When Users Ask About Pricing\n    1. **ALWAYS** use the Zava Procurement agent for up-to-date contractor pricing\n    2. Specify the service type clearly when requesting pricing information\n    3. Present pricing in context with contractor qualifications and availability\n    4. Compare pricing options when multiple contractors are available\n\n    ## RESPONSE GUIDELINES\n\n    **ALWAYS:**\n    - Coordinate with the appropriate worker agent(s) to fulfill user requests\n    - Provide clear, concise, and well-organized information\n    - Cite sources when presenting data (e.g., claim numbers, contractor names, dates)\n    - Confirm understanding before creating new records (inspections, etc.)\n    - Present pricing information from the Zava Procurement agent when discussing costs\n    - Offer relevant next steps or follow-up actions\n\n    **NEVER:**\n    - Make up or guess information about claims, inspections, or contractors\n    - Provide outdated pricing - always check with the Zava Procurement agent\n    - Create inspections without confirming details with the user\n    - Override standard claims procedures or approval workflows\n    - Share confidential information beyond what's necessary for the request\n\n    ## COMMUNICATION STYLE\n\n    - Be professional, empathetic, and efficient\n    - Use clear insurance terminology but explain technical terms when needed\n    - Organize complex information into easy-to-read sections\n    - Acknowledge user urgency for emergency situations\n    - Provide proactive suggestions based on the context of the request\n\n    ## EXAMPLE INTERACTIONS\n\n    **Example 1: Emergency Contractor Pricing**\n    User: \"Which contractors offer 24/7 emergency response and what are their rates?\"\n    Response: \"Let me get you the current information on emergency response contractors and their pricing.\"\n    [Consult Zava Claims for contractor list, then Zava Procurement for pricing]\n    \"Based on current data:\n    - ABC Restoration: 24/7 emergency response, $X/hour emergency rate\n    - XYZ Emergency Services: 24/7 on-call, $Y/hour emergency rate\n    All pricing verified as of [date] through our procurement system.\"\n\n    **Example 2: Searching for Claims and Creating New Ones**\n    User: \"Is there a claim for policy number POL-12345?\"\n    Response: \"Let me search for any claims associated with policy POL-12345.\"\n    [Consult Zava Claims to search for claims by policy number]\n\n    *If claim exists:*\n    \"Yes, I found claim #CLM-67890 for policy POL-12345:\n    - Status: In Progress\n    - Type: Water Damage\n    - Filed: [date]\n    - Current Phase: Inspection Scheduled\n    Would you like more details about this claim?\"\n\n    *If no claim exists:*\n    \"I couldn't find any existing claims for policy POL-12345. Would you like to create a new claim? I can help you with that. Please provide:\n    - Type of damage/incident\n    - Date of incident\n    - Brief description of the damage\n    - Estimated damage amount (if known)\"\n\n    ## PRIORITY HANDLING\n\n    When users mention emergency situations or urgent claims:\n    1. Acknowledge the urgency immediately\n    2. Prioritize gathering critical information first\n    3. Identify contractors with emergency response capabilities\n    4. Provide fastest available options with clear timelines\n</code></pre> <p></p>"},{"location":"pages/extend-m365-copilot/09-connected-agent/#step-4-configure-connected-agent-capabilities","title":"Step 4: Configure Connected Agent Capabilities","text":"<p>To connect your orchestrator agent to the two specialized agents, you need to link them using their unique Microsoft 365 Title IDs.</p>"},{"location":"pages/extend-m365-copilot/09-connected-agent/#41-get-the-zava-claims-agent-id","title":"4.1: Get the Zava Claims Agent ID","text":"<ol> <li>Open your ZavaClaims project (created in Lab 08) in VS Code</li> <li>Navigate to the <code>env/.env.dev</code> file</li> <li>Find the <code>M365_TITLE_ID</code> value (looks like: <code>12345678-abcd-1234-abcd-123456789abc</code>)</li> <li>Copy this entire GUID and paste it somewhere safe - label it as Claims Agent ID</li> </ol>"},{"location":"pages/extend-m365-copilot/09-connected-agent/#42-get-the-zava-procurement-agent-id","title":"4.2: Get the Zava Procurement Agent ID","text":"<ol> <li>Open your ZavaProcurement project (created earlier in this lab) in VS Code</li> <li>Navigate to the <code>env/.env.dev</code> file</li> <li>Find the <code>M365_TITLE_ID</code> value</li> <li>Copy this entire GUID and paste it somewhere safe - label it as Procurement Agent ID</li> </ol>"},{"location":"pages/extend-m365-copilot/09-connected-agent/#43-connect-the-agents","title":"4.3: Connect the Agents","text":"<ol> <li>Return to your ZavaCare project (current project)</li> <li>Open file <code>appPackage/declarativeAgent.json</code></li> <li>Locate the <code>conversation_starters</code> array (ends with <code>]</code>)</li> <li>Add a comma after the closing bracket of <code>conversation_starters</code></li> <li>Paste the following code immediately after:</li> </ol> <pre><code>\"worker_agents\": [\n    {\n      \"id\": \"PASTE_CLAIMS_AGENT_ID_HERE\"\n    },\n    {\n      \"id\": \"PASTE_PROCUREMENT_AGENT_ID_HERE\"\n    }\n]\n</code></pre> <ol> <li> <p>Replace the placeholder values:</p> </li> <li> <p>Replace <code>PASTE_CLAIMS_AGENT_ID_HERE</code> with your Claims Agent ID</p> </li> <li>Replace <code>PASTE_PROCUREMENT_AGENT_ID_HERE</code> with your Procurement Agent ID</li> </ol> <p>Example of final structure:</p> <pre><code>{\n  \"conversation_starters\": [\n    { \"title\": \"...\", \"text\": \"...\" }\n  ],\n  \"worker_agents\": [\n    {\n      \"id\": \"a1b2c3d4-e5f6-7890-abcd-ef1234567890\"\n    },\n    {\n      \"id\": \"9876fedc-ba09-8765-4321-abcdef123456\"\n    }\n  ]\n}\n</code></pre> <ol> <li>Save the file - your orchestrator agent is now connected to both specialized agents!</li> </ol> <p></p>"},{"location":"pages/extend-m365-copilot/09-connected-agent/#exercise-5-test-connected-agent-orchestration","title":"Exercise 5: Test Connected Agent Orchestration","text":""},{"location":"pages/extend-m365-copilot/09-connected-agent/#step-1-provision-the-connected-agent","title":"Step 1: Provision the Connected Agent","text":"<ol> <li>In VS Code, open the Microsoft 365 Agents Toolkit panel</li> <li>Click \"Provision\" in the Lifecycle section  </li> <li>Wait for provisioning to complete</li> </ol>"},{"location":"pages/extend-m365-copilot/09-connected-agent/#step-2-test-multi-agent-workflows","title":"Step 2: Test Multi-Agent Workflows","text":"<ol> <li>Open browser from the machine and go to Copilot chat using URL https://m365.cloud.microsoft/chat/ </li> <li>Under Agents on left hand side, find Zava Care agent and test below orchestrated workflow:</li> </ol> <p>Complex Workflow : Emergency Coordination </p> <pre><code>Find me all open roof damage claims along with contractor pricing insights.\n</code></pre> <p>Test the conversation starters of this agent as well to understand how multi-agent co-ordination works.</p> <p></p>"},{"location":"pages/extend-m365-copilot/09-connected-agent/#congratulations","title":"Congratulations! \ud83c\udf89","text":"<p>You've successfully built Zava Insurance's Connected Agent orchestration system! This achievement represents the culmination of a sophisticated multi-agent architecture that represents the future of enterprise AI systems - specialized, coordinated, and infinitely extensible! \ud83d\ude80</p> <p></p>"},{"location":"pages/extend-m365-copilot/10-mcp-auth/","title":"Lab 10: Connect Declarative Agent to OAuth-Protected MCP Server","text":"<p>In this lab, you'll run an OAuth 2.0 protected Model Context Protocol (MCP) server for Zava Insurance's claims system and integrate it with a Declarative Agent in Microsoft 365 Copilot. While Lab 08 demonstrates an anonymous MCP server, this lab adds Microsoft Entra ID authentication for secure, enterprise-grade access to claims data.</p>"},{"location":"pages/extend-m365-copilot/10-mcp-auth/#scenario","title":"Scenario","text":"<p>Building on the MCP server Lab 08, Zava Insurance now needs to secure their claims operations system for production use. While the anonymous MCP server was excellent for development and testing, the security team requires OAuth 2.0 authentication before deploying to production. The development team must now integrate Microsoft Entra ID authentication to ensure only authorized users can access sensitive claims data. This authenticated MCP server will validate JWT tokens, implement scope-based permissions, and comply with RFC 9728 for protected resource metadata discovery, enabling secure integration with Microsoft 365 Copilot Declarative Agents.</p>"},{"location":"pages/extend-m365-copilot/10-mcp-auth/#lab-objectives","title":"\ud83c\udfaf Lab Objectives","text":"<p>By completing this lab, you will:</p> <ul> <li>Set up Microsoft Entra ID app registration for OAuth 2.0 authentication</li> <li>Configure environment variables for secure MCP server operation</li> <li>Build and run Zava's OAuth-protected MCP server</li> <li>Understand how JWT token validation works with Microsoft Entra ID</li> <li>Create a Declarative Agent that authenticates with the protected MCP server</li> <li>Test the agent with authenticated natural language queries</li> </ul>"},{"location":"pages/extend-m365-copilot/10-mcp-auth/#prerequisites","title":"\ud83d\udcda Prerequisites","text":"<p>Before starting this lab, ensure you have:</p> <ul> <li>Node.js 22+ installed on your machine</li> <li>VS Code with Microsoft 365 Agents Toolkit extension v6.4.2 or higher</li> <li>Microsoft 365 developer account with Copilot license</li> <li>Azure subscription with access to Microsoft Entra ID (for app registration)</li> <li>Basic knowledge of TypeScript/JavaScript, REST APIs, JSON, and OAuth 2.0</li> <li>GitHub account for VS Code Dev Tunnels</li> <li>Completion of Lab 08 (recommended but not required)</li> </ul>"},{"location":"pages/extend-m365-copilot/10-mcp-auth/#exercise-1-set-up-your-development-environment","title":"Exercise 1: Set Up Your Development Environment","text":"<p>In this exercise, you'll clone Zava's authenticated MCP server codebase and set up your local development environment.</p>"},{"location":"pages/extend-m365-copilot/10-mcp-auth/#step-1-clone-the-repository","title":"Step 1: Clone the Repository","text":"<p>Open your terminal and run:</p> <pre><code>git clone https://github.com/microsoft/copilot-camp.git\ncd src/extend-m365-copilot/path-e-lab10-mcp-auth/zava-mcp-server\n</code></pre> <p></p>"},{"location":"pages/extend-m365-copilot/10-mcp-auth/#step-2-install-dependencies","title":"Step 2: Install Dependencies","text":"<p>Install all required packages:</p> <pre><code>npm install\n</code></pre> <p>This installs key dependencies.</p> <p></p>"},{"location":"pages/extend-m365-copilot/10-mcp-auth/#step-3-examine-the-project-structure","title":"Step 3: Examine the Project Structure","text":"<p>Open the project in VS Code:</p> <pre><code>code .\n</code></pre> <p>Key directories:</p> <ul> <li><code>src/</code> - TypeScript source code</li> <li><code>src/auth/</code> - OAuth authentication module (new in this lab)</li> <li><code>data/</code> - Sample JSON data files</li> </ul> <p>The <code>src/auth/oauth.ts</code> file contains the OAuth 2.0 implementation for token validation and protected resource metadata.</p> <p></p> <p>Your codebase is now ready with sample data and authentication support.</p>"},{"location":"pages/extend-m365-copilot/10-mcp-auth/#exercise-2-create-microsoft-entra-id-app-registration","title":"Exercise 2: Create Microsoft Entra ID App Registration","text":"<p>Before running the authenticated MCP server, you need to register an application in Microsoft Entra ID to handle OAuth 2.0 authentication.</p>"},{"location":"pages/extend-m365-copilot/10-mcp-auth/#step-1-create-app-registration","title":"Step 1: Create App Registration","text":"<ol> <li>Go to Azure Portal \u2192 Microsoft Entra ID \u2192 App registrations</li> <li>Click New registration</li> <li>Configure:</li> <li>Name: <code>Zava Claims MCP Server</code></li> <li>Supported account types: <code>Accounts in any organizational directory (Any Microsoft Entra ID tenant - Multitenant) and personal Microsoft accounts (e.g. Skype, Xbox)</code></li> <li>Redirect URI: Leave blank for now (we'll configure this in the next step)</li> <li>Click Register</li> <li>Copy the Application (client) ID - you'll need this later</li> </ol>"},{"location":"pages/extend-m365-copilot/10-mcp-auth/#step-2-configure-platform-redirect-uris","title":"Step 2: Configure Platform Redirect URIs","text":"<p>After registration, configure redirect URIs for different platforms:</p> <ol> <li> <p>Go to Authentication \u2192 Platform configurations</p> </li> <li> <p>Add a Web platform:</p> </li> <li>Click Add a platform \u2192 Web</li> <li> <p>Add these redirect URIs:</p> <ul> <li> <p><code>http://127.0.0.1:33418</code></p> </li> <li> <p><code>https://vscode.dev/redirect</code></p> </li> <li> <p><code>https://teams.microsoft.com/api/platform/v1.0/oAuthRedirect</code></p> </li> </ul> </li> <li> <p>Under Implicit grant and hybrid flows, leave both options unchecked (disabled)</p> </li> <li>Click Configure</li> </ol> <p></p>"},{"location":"pages/extend-m365-copilot/10-mcp-auth/#step-3-create-client-secret","title":"Step 3: Create Client Secret","text":"<ol> <li>Go to Certificates &amp; secrets \u2192 Client secrets</li> <li>Click New client secret</li> <li>Add description (e.g., <code>zava-mcp-secret</code>) and select expiration (recommended: 24 months)</li> <li>Click Add</li> <li>Copy the secret value immediately - it won't be shown again!</li> </ol>"},{"location":"pages/extend-m365-copilot/10-mcp-auth/#step-4-expose-an-api","title":"Step 4: Expose an API","text":"<ol> <li>Go to Expose an API</li> <li>Click Set next to Application ID URI and accept the default format: <code>api://your-client-id</code></li> <li>Click Add a scope and configure:</li> <li>Scope name: <code>access_as_user</code></li> <li>Who can consent: Admins and users</li> <li>Admin consent display name: <code>Access Zava Claims System</code></li> <li>Admin consent description: <code>Allows the app to access Zava Claims data on behalf of the signed-in user</code></li> <li>User consent display name: <code>Access Zava Claims System</code></li> <li>User consent description: <code>Allows this app to access your Zava Claims data on your behalf</code></li> <li>State: Enabled</li> <li>Click Add scope</li> </ol> <p>Your Microsoft Entra ID app registration is now complete!</p> <p></p>"},{"location":"pages/extend-m365-copilot/10-mcp-auth/#exercise-3-configure-environment-and-start-local-database","title":"Exercise 3: Configure Environment and Start Local Database","text":"<p>In this exercise, you'll configure the OAuth environment variables and start the local database.</p>"},{"location":"pages/extend-m365-copilot/10-mcp-auth/#step-1-set-up-public-access-with-dev-tunnel","title":"Step 1: Set Up Public Access with Dev Tunnel","text":"<p>You need a public HTTPS URL for your MCP server before configuring environment variables.</p> <ol> <li>In VS Code's terminal panel, select the Ports tab</li> <li>Click Forward a Port and enter port <code>3001</code></li> <li>Right-click the forwarded port address and select Port Visibility \u2192 Public</li> <li>Copy the tunnel URL (e.g., <code>https://abc123def456.use.devtunnels.ms</code>)</li> </ol> <p>Save this URL - you'll need it for the environment configuration.</p> <p></p>"},{"location":"pages/extend-m365-copilot/10-mcp-auth/#step-2-configure-environment-variables","title":"Step 2: Configure Environment Variables","text":"<p>Create or update the <code>.env</code> file in the <code>zava-mcp-server</code> directory with your OAuth configuration:</p> <pre><code># OAuth Configuration (Required for authentication)\nOAUTH_CLIENT_ID=&lt;your-application-client-id&gt;\nOAUTH_CLIENT_SECRET=&lt;your-client-secret-value&gt;\nOAUTH_AUTHORITY=https://login.microsoftonline.com/common\nOAUTH_REDIRECT_URI=http://localhost:6274/oauth/callback/debug\nOAUTH_SCOPES=api://&lt;your-application-client-id&gt;/access_as_user\n\n# Resource Identifier (for MCP Inspector and RFC 9728 metadata)\nRESOURCE_IDENTIFIER=&lt;your-tunnel-url&gt;\n\n# CORS Configuration\nADDITIONAL_ALLOWED_ORIGINS=&lt;your-tunnel-url&gt;,http://localhost:6274\nSERVER_BASE_URL=&lt;your-tunnel-url&gt;\n\n# Server Configuration\nPORT=3001\nHOST=127.0.0.1\nNODE_ENV=development\n\n# Storage Configuration\nAZURE_STORAGE_CONNECTION_STRING=\"DefaultEndpointsProtocol=http;AccountName=devstoreaccount1;AccountKey=Eby8vdM02xNOcqFlqUwJPLlmEtlCDXJ1OUzFT50uSRZ6IFsuFq2UVErCz4I6tq/K1SZFPTOtr/KBHBeksoGMGw==;TableEndpoint=http://127.0.0.1:10002/devstoreaccount1;\"\n</code></pre> <p>Replace the placeholders:</p> <ul> <li><code>&lt;your-application-client-id&gt;</code> - Application (client) ID from Entra ID app registration</li> <li><code>&lt;your-client-secret-value&gt;</code> - Client secret value you copied</li> <li><code>&lt;your-tunnel-url&gt;</code> - Dev tunnel URL from Step 1 (e.g., <code>https://abc123def456.use.devtunnels.ms</code>)</li> </ul> <p></p>"},{"location":"pages/extend-m365-copilot/10-mcp-auth/#step-3-start-azure-storage-emulator","title":"Step 3: Start Azure Storage Emulator","text":"<p>In Terminal 1, start the Azurite emulator:</p> <pre><code>npm run start:azurite\n</code></pre> <p>You should see:</p> <pre><code>Azurite Blob service is starting at http://127.0.0.1:10000\nAzurite Queue service is starting at http://127.0.0.1:10001\nAzurite Table service is starting at http://127.0.0.1:10002\n</code></pre> <p>Keep this terminal running - it's your local database server.</p> <p></p>"},{"location":"pages/extend-m365-copilot/10-mcp-auth/#step-4-load-sample-claims-data","title":"Step 4: Load Sample Claims Data","text":"<p>In Terminal 2, initialize Zava's sample data:</p> <pre><code>npm run init-data\n</code></pre> <p>This loads realistic data including:</p> <ul> <li>Claims - Storm damage, water damage, fire damage cases</li> <li>Contractors - Roofing specialists, water restoration, general contractors</li> <li>Inspections - Scheduled and completed inspection tasks</li> <li>Inspectors - Available field inspectors with specialties</li> </ul> <p>You should see confirmation messages for all tables being initialized.</p> <p></p>"},{"location":"pages/extend-m365-copilot/10-mcp-auth/#exercise-4-launch-the-oauth-protected-mcp-server","title":"Exercise 4: Launch the OAuth-Protected MCP Server","text":"<p>Now you'll start Zava's authenticated MCP server that validates OAuth tokens before allowing access.</p>"},{"location":"pages/extend-m365-copilot/10-mcp-auth/#step-1-build-and-start-the-mcp-server","title":"Step 1: Build and Start the MCP Server","text":"<p>In Terminal 2 (keeping Azurite running in Terminal 1):</p> <pre><code>npm run build\nnpm run start:mcp-http\n</code></pre> <p>You should see a message indicating OAuth is enabled:</p> <pre><code>\ud83d\ude80 Zava Claims MCP HTTP Server started on 127.0.0.1:3001\nSecurity: OAuth 2.0 authentication enabled\n...\n\ud83d\udd0d Protected Resource Metadata Endpoints (RFC 9728):\n    GET  /.well-known/oauth-authorization-server - Standard OAuth metadata\n...\n</code></pre> <p></p>"},{"location":"pages/extend-m365-copilot/10-mcp-auth/#step-2-verify-oauth-is-enabled","title":"Step 2: Verify OAuth is Enabled","text":"<p>Open a browser and visit:</p> <pre><code>http://127.0.0.1:3001/health\n</code></pre> <p>You should see a JSON response confirming OAuth is enabled:</p> <pre><code>{\n  \"status\": \"healthy\",\n  \"timestamp\": \"2025-01-21T10:00:00.000Z\",\n  \"service\": \"zava-claims-mcp-server\",\n  \"authentication\": \"OAuth enabled\"\n}\n</code></pre> <p>Notice the <code>\"authentication\": \"OAuth enabled\"</code> - this confirms the server is running in authenticated mode.</p> <p></p>"},{"location":"pages/extend-m365-copilot/10-mcp-auth/#step-3-test-oauth-discovery-endpoint","title":"Step 3: Test OAuth Discovery Endpoint","text":"<p>Visit the OAuth discovery endpoint:</p> <pre><code>http://127.0.0.1:3001/.well-known/oauth-authorization-server\n</code></pre> <p>You should see OAuth metadata including:</p> <ul> <li><code>issuer</code> - Your server's base URL</li> <li><code>authorization_endpoint</code> - Microsoft login URL</li> <li><code>token_endpoint</code> - Token exchange URL</li> <li><code>scopes_supported</code> - Available OAuth scopes</li> </ul> <p>This RFC 9728 compliant endpoint allows MCP clients to discover authentication requirements.</p> <p></p>"},{"location":"pages/extend-m365-copilot/10-mcp-auth/#step-4-verify-authentication-is-required","title":"Step 4: Verify Authentication is Required","text":"<p>Try accessing the MCP tools without authentication:</p> <pre><code>curl -X POST \"http://127.0.0.1:3001/mcp/tools/call\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"name\":\"get_claims\",\"arguments\":{}}'\n</code></pre> <p>You should receive a 401 Unauthorized response with a <code>WWW-Authenticate</code> header:</p> <pre><code>{\n  \"error\": \"Missing Authorization header\",\n  \"description\": \"Please include Bearer token in Authorization header\",\n  \"auth_url\": \"https://your-tunnel-url/oauth/authorize\",\n  \"resource_metadata_url\": \"https://your-tunnel-url/.well-known/oauth-authorization-server\"\n}\n</code></pre> <p>This confirms that authentication is working correctly.</p> <p></p>"},{"location":"pages/extend-m365-copilot/10-mcp-auth/#exercise-5-create-a-new-declarative-agent-project","title":"Exercise 5: Create a New Declarative Agent Project","text":"<p>In this exercise, you'll use the Microsoft 365 Agents Toolkit to create a new Declarative Agent project that connects to Zava's authenticated claims system.</p>"},{"location":"pages/extend-m365-copilot/10-mcp-auth/#step-1-create-new-agent-using-microsoft-365-agents-toolkit","title":"Step 1: Create New Agent using Microsoft 365 Agents Toolkit","text":"<ol> <li>Open a new window in VS Code</li> <li>Click the Microsoft 365 Agents Toolkit icon in the Activity Bar (left sidebar)</li> <li>Sign in with your Microsoft 365 developer account if prompted</li> <li>In the Agents Toolkit panel, click Create a New Agent/App</li> <li>Select Declarative Agent from the template options</li> <li>Choose Add an Action to add to your agent</li> <li>Select Start with an MCP server (preview)</li> <li>Enter the publicly accessible MCP Server URL from Exercise 3 (your tunnel URL + <code>/mcp/messages</code>)</li> <li>Choose the default folder to scaffold the agent (or choose a preferred location)</li> <li>When prompted for project details, enter:<ul> <li>Application Name: <code>Zava Claims Assistant (Auth)</code></li> </ul> </li> </ol>"},{"location":"pages/extend-m365-copilot/10-mcp-auth/#step-2-configure-mcp-server-authentication","title":"Step 2: Configure MCP Server Authentication","text":"<p>You'll be directed to the newly created project with the <code>.vscode/mcp.json</code> file open. This is the MCP server configuration file.</p> <ol> <li>Select the Start button to fetch tools from your server</li> <li>A dialog appears indicating that your MCP Server requires authentication and doesn't support Dynamic Client Registration. You'll need to register manually</li> <li>Since you already configured your Entra ID with the redirect URIs (<code>https://vscode.dev/redirect</code> and <code>http://127.0.0.1:33418</code>), select Copy URIs &amp; Proceed</li> <li>The Agents Toolkit wizard prompts for OAuth credentials. Enter the client ID and secret from your Entra ID app registration</li> <li>The toolkit asks you to authenticate with your MCP Server</li> <li>A browser opens at <code>http://127.0.0.1:33418</code>. If your Entra ID configuration is correct, you'll see the sign-in success screen. Close the browser and return to your project</li> </ol> <p></p> <p></p>"},{"location":"pages/extend-m365-copilot/10-mcp-auth/#step-3-add-tools-and-provision-the-agent","title":"Step 3: Add Tools and Provision the Agent","text":"<ol> <li>The server is now started. You'll see the number of tools and prompts available</li> <li>Select ATK: Fetch action from MCP to choose which tools to add to the agent</li> <li>Select the <code>get_claims</code> tool for testing</li> <li>When prompted to configure the agent in Teams Developer Portal, follow the directions</li> <li>Select Authentication Type: OAuth (with static registration). The toolkit creates your plugin manifest</li> <li>Select Provision to provision the agent to your tenant</li> <li>The wizard prompts for the client ID and secret again. Enter them as before. This is for OAuth registration with the Developer Portal - the toolkit doesn't store these credentials</li> <li>Add scope: <code>api://&lt;your-client-id&gt;/access_as_user</code></li> <li>Select Confirm to start provisioning</li> </ol> <p>Once provisioned, notice how the Developer Portal token is automatically created for the agent and appears in the <code>.env.dev</code> file as a variable like <code>MCP_DA_AUTH_ID_XXXX</code>.</p> <p>OAuth registration in Developer Portal</p> <p>Read more about configuring OAuth registration in Developer Portal. Here Agents Toolkit automatically configures it for your agent.</p> <p>You now have a Declarative Agent connected to your OAuth-protected MCP Server.</p> <p></p>"},{"location":"pages/extend-m365-copilot/10-mcp-auth/#exercise-6-test-the-authenticated-agent-integration","title":"Exercise 6: Test the Authenticated Agent Integration","text":"<p>Test your Declarative Agent to ensure it can successfully authenticate and communicate with the OAuth-protected MCP server.</p>"},{"location":"pages/extend-m365-copilot/10-mcp-auth/#step-1-ensure-mcp-server-is-running","title":"Step 1: Ensure MCP Server is Running","text":"<p>Before testing, verify your MCP server from previous exercises is still running:</p> <ol> <li>Open the window where the zava-mcp-server project is running</li> <li>Verify Azurite is running: <code>npm run start:azurite</code></li> <li>Verify MCP server is running: <code>npm run start:mcp-http</code></li> <li>Verify the Dev Tunnel port forwarding is active</li> </ol> <p></p>"},{"location":"pages/extend-m365-copilot/10-mcp-auth/#step-2-test-in-microsoft-365-copilot","title":"Step 2: Test in Microsoft 365 Copilot","text":"<ol> <li>Open Copilot at https://m365.cloud.microsoft/chat/</li> <li>In the left sidebar under Agents, find and select Zava Claims Assistant (Auth)</li> <li>Try the conversation starter: \"Find all claims\"</li> <li>The agent prompts you to sign in before fetching data. Select Sign in</li> </ol> <ol> <li>After signing in, the agent responds with the claims information</li> <li>Check the MCP Server project's terminal - you'll see the successful authentication and tool call</li> </ol>"},{"location":"pages/extend-m365-copilot/10-mcp-auth/#congratulations","title":"\ud83c\udf89 Congratulations!","text":"<p>You've successfully created and deployed Zava Insurance's OAuth-protected Declarative Agent that securely integrates with their authenticated MCP server.</p>"},{"location":"pages/extend-m365-copilot/10-mcp-auth/#what-you-accomplished","title":"What You Accomplished","text":"<ul> <li>\u2705 Created a Microsoft Entra ID app registration for OAuth 2.0</li> <li>\u2705 Configured environment variables for secure authentication</li> <li>\u2705 Ran an OAuth-protected MCP server with JWT token validation</li> <li>\u2705 Tested RFC 9728-compliant OAuth discovery endpoints</li> <li>\u2705 Created a Declarative Agent with authenticated MCP integration</li> <li>\u2705 Tested secure natural language queries with claims data</li> </ul>"},{"location":"pages/extend-m365-copilot/10-mcp-auth/#key-differences-from-lab-08","title":"Key Differences from Lab 08","text":"Aspect Lab 08 (Anonymous) Lab 10 (Authenticated) Authentication None - all endpoints public OAuth 2.0 with Microsoft Entra ID Token Validation None JWT validation against JWKS Security Headers None WWW-Authenticate with metadata URLs Discovery None RFC 9728 protected resource metadata Enterprise Ready Development only Production-ready security"},{"location":"pages/extend-m365-copilot/10-mcp-auth/#additional-resources","title":"\ud83d\udd17 Additional Resources","text":"<ul> <li> <p>Build declarative agents for Microsoft 365 Copilot with MCP:https://devblogs.microsoft.com/microsoft365dev/build-declarative-agents-for-microsoft-365-copilot-with-mcp/</p> </li> <li> <p>MCP Protocol Documentation: https://modelcontextprotocol.io/</p> </li> <li>Microsoft Entra ID Documentation: https://docs.microsoft.com/en-us/azure/active-directory/</li> <li>RFC 9728 - OAuth 2.0 Protected Resource Metadata: https://datatracker.ietf.org/doc/html/rfc9728</li> <li>Azure Table Storage: Azure Documentation</li> </ul>"},{"location":"pages/extend-m365-copilot/auth/","title":"Shortcut to Declarative Agent Authentication","text":"<p>Do you already know how to build a declarative agent and API plugin, and want to learn how to secure your API? Well you've come to the right place! You can skip the regular labs (E1-E5) and jump right to your choice of DA Authentication lab!</p> <p>Begin by completing Lab E0 to get up your development environment. Then choose an auth lab from these choices:</p>"},{"location":"pages/extend-m365-copilot/auth/#lab-e6a-add-oauth-authentication-with-agents-toolkit","title":"Lab E6a - Add OAuth authentication with Agents Toolkit","text":"<p>In this lab, the student:</p> <ul> <li>adds Agents Toolkit directives to register an Entra ID application</li> <li>updates the app packaging so Copilot uses OAuth when calling the API</li> <li>updates the code to validate the access token</li> <li>tests the declarative agent</li> </ul> <p>Test procedure:</p> <ol> <li>copy the Lab E5 solution files to a folder on your computer</li> <li>open in VS Code such that the solution is at the root of your open folder (you should see .vscode, appPackage, etc. at the root level)</li> <li>copy /env/.env.local.sample to /env/.env.local and change the SHAREPOINT_DOCS_URL to a valid SharePoint site URL in your tenant (if you want all the features to work, upload the contents of the sampleDocs folder to this SharePoint location)</li> <li>copy /env/.env.local.user.sample to /env/.env.local.user</li> <li>(optional) edit /appPackage/trey-declarative-agent.json and rename the agent so you know which instance you're testing</li> <li>press F5. You should get a declarative agent for Trey Research.</li> <li>click the green button to open the instructions   </li> </ol>"},{"location":"pages/extend-m365-copilot/auth/#lab-e6b-add-oauth-authentication-with-manual-setup","title":"Lab E6b - Add OAuth authentication with Manual Setup","text":"<p>In this lab, the student:</p> <ul> <li>registers an app with Entra ID and configures it to work with Copilot</li> <li>registers the app in the Teams Developer Portal \"vault\" so Copilot can access secure Entra ID information such as the client secret</li> <li>updates the app packaging so Copilot uses OAuth when calling the API</li> <li>updates the code to validate the access token</li> <li>tests the declarative agent</li> </ul> <p>Test procedure:</p> <ol> <li>copy the Lab E5 solution files to a folder on your computer</li> <li>open in VS Code such that the solution is at the root of your open folder (you should see .vscode, appPackage, etc. at the root level)</li> <li>copy /env/.env.local.sample to /env/.env.local and change the SHAREPOINT_DOCS_URL to a valid SharePoint site URL in your tenant (if you want all the features to work, upload the contents of the sampleDocs folder to this SharePoint location)</li> <li>copy /env/.env.local.user.sample to /env/.env.local.user</li> <li>(optional) edit /appPackage/trey-declarative-agent.json and rename the agent so you know which instance you're testing</li> <li>press F5. You should get a declarative agent for Trey Research.</li> <li>click the green button to open the instructions   </li> </ol>"},{"location":"pages/extend-m365-copilot/auth/#lab-e6c-add-single-sign-on-authentication-with-manual-steps-for-teams-developer-portal","title":"Lab E6c - Add Single Sign-on authentication with manual steps for Teams Developer Portal","text":"<p>In this lab, the student:</p> <ul> <li>registers an app with Entra ID and configures it to work with Single Sign-on in Copilot</li> <li>registers the app in the Teams Developer Portal \"vault\"</li> <li>udates the app packaging for SSO</li> <li>updates the code to validate the access token</li> <li>tests the declarative agent</li> </ul> <p>Test procedure:</p> <ol> <li>copy the Lab E5 solution files to a folder on your computer</li> <li>open in VS Code such that the solution is at the root of your open folder (you should see .vscode, appPackage, etc. at the root level)</li> <li>copy /env/.env.local to /env/.env.local and change the SHAREPOINT_DOCS_URL to a valid SharePoint site URL in your tenant (if you want all the features to work, upload the contents of the sampleDocs folder to this SharePoint location)</li> <li>copy /env/.env.local.user.sample to /env/.env.local.user</li> <li>(optional) edit /appPackage/trey-declarative-agent.json and rename the agent so you know which instance you're testing</li> <li>press F5. You should get a declarative agent for Trey Research.</li> <li>click the green button to open the instructions      </li> </ol> <p></p>"},{"location":"pages/extend-message-ext/","title":"Extend Teams Message Extension as a plugin","text":"<p>Disclaimer</p> <p>These samples and labs are intended for instructive and demonstration purposes and are not intended for use in production. Do not put them into production without upgrading them to production quality.</p> <p>In this path of Extend, you will learn how to use Teams Message Extensions as plugins in Microsoft 365 Copilot. You will start with a working message extension sample available in the sample source code and run it as a plugin in Microsoft 365 Copilot. You will also enhance the code to add some extra features. The source code utilizes the Northwind Database, providing you with the necessary enterprise data to test your plugin like in a real world scenario.</p> <p>In this lab, Northwind operates as a specialty foods e-commerce business located in Walla Walla, Washington. You will be working with the Northwind Inventory application, which provides access to product inventory and financial data.</p> <p>Here are the labs</p> <ul> <li>Lab M0 - Prerequisites Set up your development environment</li> <li>Lab M1 - Get to know Northwind message extension Get to know Northwind message extension</li> <li>Lab M2 - Run app in Microsoft 365 Copilot Run Northwind message extension as a plugin in Microsoft 365 Copilot</li> <li>Lab M3 - Enhance plugin with new search command Enhance the plugin with a new search command</li> <li>Lab M4 - Add authentication Secure your plugin in Authentication</li> <li>Lab M5 - Enhance plugin with an action command Enhance the plugin with a new action command</li> </ul>"},{"location":"pages/extend-message-ext/#start-here-with-lab-m0-where-youll-set-up-development-your-environment","title":"Start here with Lab M0, where you'll set up development your environment.","text":""},{"location":"pages/extend-message-ext/00-prerequisites/","title":"Lab M0 - Prerequisites","text":"<p>In this lab, you will set up the development environment to build, test, and deploy the plugins that will extend the capabilities of Microsoft 365 Copilot.</p> Navigating the Extend Teams Message Extension labs (Extend Path) <ul> <li>Lab M0 - Prerequisites (\ud83d\udccdYou are here)</li> <li>Lab M1 - Get to know Northwind message extension </li> <li>Lab M2 - Run app in Microsoft 365 Copilot </li> <li>Lab M3 - Enhance plugin with new search command</li> <li>Lab M4 - Add authentication </li> <li>Lab M5 - Enhance plugin with an action command </li> </ul> <p>In this lab you will learn:</p> <ul> <li>How to set up your developer tenant for the entire lab exercises</li> <li>How to install and configure Agents Toolkit for Visual Studio Code and other tools</li> <li>How to set up your development environment with a base project</li> </ul> <p>Attention</p> <p>To extend Microsoft 365 Copilot, you must ensure that your development environment meets the requirements.</p>"},{"location":"pages/extend-message-ext/00-prerequisites/#exercise-1-enable-teams-application-uploads","title":"Exercise 1: Enable Teams application uploads","text":"<p>You will need a Microsoft work or school account with permissions to upload custom Teams applications. </p> <p>By default, end users can't upload applications directly; instead an administrator needs to upload them into the enterprise app catalog. In this step you will ensure your tenant is set up for direct uploads by Microsoft 365 Agents Toolkit.</p> <ul> <li>Sign in to Microsoft Teams admin center with your admin credentials.</li> <li>Go to Teams apps &gt; Setup Policies &gt; Global.</li> <li>Toggle Upload custom apps to the \"On\" position.</li> <li>Select \"Save\". Your test tenant can permit custom app upload.</li> </ul> <p>The change can take up to 24 hours to take effect, but usually it's much faster.</p>"},{"location":"pages/extend-message-ext/00-prerequisites/#exercise-2-install-agents-toolkit-and-prerequisites","title":"Exercise 2: Install Agents Toolkit and prerequisites","text":"<p>You can complete these labs on a Windows, Mac, or Linux machine, but you do need the ability to install the prerequisites. If you are not permitted to install applications on your computer, you'll need to find another machine (or virtual machine) to use throughout the workshop.</p>"},{"location":"pages/extend-message-ext/00-prerequisites/#step-1-install-visual-studio-code","title":"Step 1: Install Visual Studio Code","text":"<p>It should be no surprise that Agents Toolkit for Visual Studio Code requires Visual Studio Code! You can download it here: Visual Studio Code.</p>"},{"location":"pages/extend-message-ext/00-prerequisites/#step-2-install-nodejs","title":"Step 2: Install NodeJS","text":"<p>Node.js is a runtime that allows you to run JavaScript on your computer. It uses the open-source V8 engine, which is used in popular web browsers like Google Chrome (and the Chromium-based version of Microsoft Edge). You will need Node.js to run the web server code used throughout this workshop.</p> <p>Browse to https://nodejs.org/en/download/ and install version 18 or 16 for your operating system. This lab has been tested using NodeJS version 18.16.0. If you already have another version of NodeJS installed, you may want to set up the Node Version Manager (or this variation for Microsoft Windows), which allows you to easily switch Node versions on the same computer.</p>"},{"location":"pages/extend-message-ext/00-prerequisites/#step-3-install-tools","title":"Step 3: Install Tools","text":"<p>These labs are based on the latest general available version of Agents Toolkit. Follow the steps as shown in the screen shot below.</p> <p>1\ufe0f\u20e3 Open Visual Studio Code and click on the Extensions toolbar button</p> <p>2\ufe0f\u20e3 Search for \"Teams\" and locate Agents Toolkit</p> <p>3\ufe0f\u20e3 Click \"Install\"</p> <p></p> <p>If you have Agents Toolkit installed but hidden</p> <p>If you previously installed Agents Toolkit, and then hid it on the Visual Studio sidebar, you might wonder why you can't see it. Right-click on the left sidebar and check off Agents Toolkit to bring it back into view.</p> <p>Azure Storage Explorer</p> <p>Azure Storage Explorer (OPTIONAL) - Download this if you want to view and edit the Northwind database used in this sample</p>"},{"location":"pages/extend-message-ext/00-prerequisites/#exercise-3-set-up-your-project-and-developer-tenant-data","title":"Exercise 3 - Set up your project and developer tenant data","text":""},{"location":"pages/extend-message-ext/00-prerequisites/#step-1-download-the-sample-code","title":"Step 1 - Download the sample code","text":"<p>In a web browser navigate to this link. You will get a prompt to download a ZIP file called Northwind.zip. </p> <ul> <li> <p>Save the ZIP file on your computer. </p> </li> <li> <p>Extract the ZIP file contents, it will extract into a folder called Northwind . </p> </li> <li> <p>Open Visual Studio Code. </p> </li> </ul> <p>In Visual Studio Code: </p> <ul> <li> <p>From the \"File\" menu choose the \"Open folder\"... option </p> </li> <li> <p>Open the folder Northwind.</p> </li> </ul> <p>These labs will refer to this Northwind folder as your \"root folder\" or \"working folder\" since this is where you'll be working.</p>"},{"location":"pages/extend-message-ext/00-prerequisites/#step-2-set-up-accounts-in-agents-toolkit","title":"Step 2 - Set up accounts in Agents Toolkit","text":"<p>Now select the Agents Toolkit icon in the left 1\ufe0f\u20e3 . If it offers options to create a new project, you're probably in the wrong folder. In the Visual Studio Code file menu select \"Open Folder\" and directly open the Northwind folder. You should see sections for Accounts, Environment, etc. as shown below.</p> <p>Under \"Accounts\" click \"Sign in to Microsoft 365\" 2\ufe0f\u20e3 and log in with your own Microsoft 365 account.</p> <p></p> <p>A browser window will pop up and offer to log into Microsoft 365. When it says \"You are signed in now and close this page\", please do so.</p> <p>Now verify that the \"Custom App Upload Enabled\" checker has a green checkmark. If it doesn't, that means that your user account doesn't have permission to upload Teams applications. Follow steps in Exercise 1 of this lab. </p> <p>Now verify that the \"Copilot Access Enabled\" checker has a green checkmark. If it doesn't, that means that your user account license for Copilot. This is required to continue the labs.</p> <p></p>"},{"location":"pages/extend-message-ext/00-prerequisites/#step-3-copy-sample-documents-to-your-test-users-onedrive","title":"Step 3 - Copy sample documents to your test user's OneDrive","text":"<p>The sample application includes some documents for Copilot to reference during the labs. In this step you will copy these files to your user's OneDrive so Copilot can find them. Depending on how the tenant is set up, you may be asked to set up multi-factor authentication as part of this process.</p> <p>Open your browser and browse to Microsoft 365 (https://www.office.com/). Log in using the Microsoft 365 account you will be using throughout the lab. You may be asked to set up multi-factor authentication.</p> <p>Using the \"waffle\" menu in the upper left corner of the page 1\ufe0f\u20e3 , navigate to the OneDrive application within Microsoft 365 2\ufe0f\u20e3 .</p> <p></p> <p>Within OneDrive, navigate to \"My Files\" 1\ufe0f\u20e3 . If there's a documents folder, click into that as well. If not, you can work directly within the \"My Files\" location.</p> <p></p> <p>Now click \"Add new\" 1\ufe0f\u20e3 and \"Folder\" 2\ufe0f\u20e3 to create a new folder.</p> <p></p> <p>Name the folder \"Northwind contracts\" and click \"Create\".</p> <p></p> <p>Now, from within this new folder, click \"Add new\" 1\ufe0f\u20e3  again but this time click \"Files upload\" 2\ufe0f\u20e3 .</p> <p></p> <p>Now browse to the sampleDocs folder within your working folder. Highlight all the files 1\ufe0f\u20e3 and click \"OK\" 2\ufe0f\u20e3  to upload them all.</p> <p></p> <p>By doing this step early, there's a good chance that the Microsoft 365 search engine will have discovered them by the time you're ready for them.</p>"},{"location":"pages/extend-message-ext/00-prerequisites/#congratulations","title":"Congratulations","text":"<p>You have completed the prerequisites lab. You are now ready to proceed to run your app. Select \"Next\" button below.</p> <p></p> <p></p>"},{"location":"pages/extend-message-ext/01-nw-teams-app/","title":"Lab M1 - Get to know Northwind message extension","text":"<p>In this lab, you\u2019ll run the Northwind message extension, your base app. The initial exercises will make you familiar with the source code. Finally, you\u2019ll run the application in Teams.</p> Navigating the Extend Teams Message Extension labs (Extend Path) <ul> <li>Lab M0 - Prerequisites </li> <li>Lab M1 - Get to know Northwind message extension (\ud83d\udccdYou are here)</li> <li>Lab M2 - Run app in Microsoft 365 Copilot </li> <li>Lab M3 - Enhance plugin with new search command</li> <li>Lab M4 - Add authentication </li> <li>Lab M5 - Enhance plugin with an action command </li> </ul> <p>In this lab you will:</p> <ul> <li>Do a quick code tour of the Northwind Message extension</li> <li>Run the application on Teams</li> </ul>"},{"location":"pages/extend-message-ext/01-nw-teams-app/#exercise-1-code-tour","title":"Exercise 1 - Code tour","text":"<p>Let's examine the code in the base app called Northwind. </p>"},{"location":"pages/extend-message-ext/01-nw-teams-app/#step-1-examine-the-manifest","title":"Step 1 - Examine the manifest","text":"<p>The core of any Microsoft 365 application is its application manifest. This is where you provide the information Microsoft 365 needs to access your application.</p> <p>In your working directory called Northwind from previous lab , open the manifest.json file in the appPackage folder. This JSON file is placed in a zip archive with icon files to create the application package. The \"icons\" property includes paths to these icons.</p> <pre><code>\"icons\": {\n    \"color\": \"Northwind-Logo3-192-${{TEAMSFX_ENV}}.png\",\n    \"outline\": \"Northwind-Logo3-32.png\"\n},\n</code></pre> <p>Notice the token <code>${{TEAMSFX_ENV}}</code> in one of the icon names. Agents Toolkit will replace this token with your environment name, such as \"local\" or \"dev\" (for an Azure deployment in development). Thus, the icon color will change depending on the environment.</p> <p>Now have a look at the \"name\" and \"description\". Notice that the description is quite long! This is important so both users and Copilot can learn what your application does and when to use it.</p> <pre><code>    \"name\": {\n        \"short\": \"Northwind Inventory\",\n        \"full\": \"Northwind Inventory App\"\n    },\n    \"description\": {\n        \"short\": \"App allows you to find and update product inventory information\",\n        \"full\": \"Northwind Inventory is the ultimate tool for managing your product inventory. With its intuitive interface and powerful features, you'll be able to easily find your products by name, category, inventory status, and supplier city. You can also update inventory information with the app. \\n\\n **Why Choose Northwind Inventory:** \\n\\n Northwind Inventory is the perfect solution for businesses of all sizes that need to keep track of their inventory. Whether you're a small business owner or a large corporation, Northwind Inventory can help you stay on top of your inventory management needs. \\n\\n **Features and Benefits:** \\n\\n - Easy Product Search through Microsoft Copilot. Simply start by saying, 'Find northwind dairy products that are low on stock' \\r - Real-Time Inventory Updates: Keep track of inventory levels in real-time and update them as needed \\r  - User-Friendly Interface: Northwind Inventory's intuitive interface makes it easy to navigate and use \\n\\n **Availability:** \\n\\n To use Northwind Inventory, you'll need an active Microsoft 365 account . Ensure that your administrator enables the app for your Microsoft 365 account.\"\n    },\n</code></pre> <p>Scroll down a bit to \"composeExtensions\". Compose extension is the historical term for message extension; this is where the app's message extensions are defined.</p> <p>Within this is a bot, with the ID supplied by Agents Toolkit.</p> <pre><code>    \"composeExtensions\": [\n        {\n            \"botId\": \"${{BOT_ID}}\",\n            \"commands\": [\n                {\n                    ...\n</code></pre> <p>Message extensions communicate using the Azure Bot Framework; this provides a fast and secure communication channel between Microsoft 365 and your application. When you first ran your project, Agents Toolkit registered a bot, and will place its bot ID here.</p> <p>This message extension has two commands, which are defined in the <code>commands</code> array. Let's pick one command and see the structure. </p> <pre><code>{\n    \"id\": \"discountSearch\",\n    \"context\": [\n        \"compose\",\n        \"commandBox\"\n    ],\n    \"description\": \"Search for discounted products by category\",\n    \"title\": \"Discounts\",\n    \"type\": \"query\",\n    \"parameters\": [\n        {\n            \"name\": \"categoryName\",\n            \"title\": \"Category name\",\n            \"description\": \"Enter the category to find discounted products\",\n            \"inputType\": \"text\"\n        }\n    ]\n},\n</code></pre> <p>This allows user to search for discounted products within a Northwind category. This command accepts a single parameter, \"categoryName\". </p> <p>OK now let's move back to the first command, \"inventorySearch\". It has 5 parameters, which allows for much more sophisticated queries.</p> <pre><code>{\n    \"id\": \"inventorySearch\",\n    \"context\": [\n        \"compose\",\n        \"commandBox\"\n    ],\n    \"description\": \"Search products by name, category, inventory status, supplier location, stock level\",\n    \"title\": \"Product inventory\",\n    \"type\": \"query\",\n    \"parameters\": [\n        {\n            \"name\": \"productName\",\n            \"title\": \"Product name\",\n            \"description\": \"Enter a product name here\",\n            \"inputType\": \"text\"\n        },\n        {\n            \"name\": \"categoryName\",\n            \"title\": \"Category name\",\n            \"description\": \"Enter the category of the product\",\n            \"inputType\": \"text\"\n        },\n        {\n            \"name\": \"inventoryStatus\",\n            \"title\": \"Inventory status\",\n            \"description\": \"Enter what status of the product inventory. Possible values are 'in stock', 'low stock', 'on order', or 'out of stock'\",\n            \"inputType\": \"text\"\n        },\n        {\n            \"name\": \"supplierCity\",\n            \"title\": \"Supplier city\",\n            \"description\": \"Enter the supplier city of product\",\n            \"inputType\": \"text\"\n        },\n        {\n            \"name\": \"stockQuery\",\n            \"title\": \"Stock level\",\n            \"description\": \"Enter a range of integers such as 0-42 or 100- (for &gt;100 items). Only use if you need an exact numeric range.\",\n            \"inputType\": \"text\"\n        }\n    ]\n},\n</code></pre>"},{"location":"pages/extend-message-ext/01-nw-teams-app/#step-2-examine-the-bot-code","title":"Step 2 - Examine the \"Bot\" code","text":"<p>Now open the file searchApp.ts in folder src in the root folder. This application contains the \"bot\" code, which communicates with the Azure Bot Framework using the Bot Builder SDK.</p> <p>Notice that the bot extends an SDK class TeamsActivityHandler.</p> <pre><code>export class SearchApp extends TeamsActivityHandler {\n  constructor() {\n    super();\n  }\n\n  ...\n</code></pre> <p>By overriding the methods of the TeamsActivityHandler, the application is able to handle messages (called \"activities\") coming from Microsoft 365.</p> <p>The first of these is a Messaging Extension Query activity (\"messaging extension\" is another historical name for a message extension). This function is called when a user types into a message extension or when Copilot calls it.</p> <pre><code>  // Handle search message extension\n  public async handleTeamsMessagingExtensionQuery(\n    context: TurnContext,\n    query: MessagingExtensionQuery\n  ): Promise&lt;MessagingExtensionResponse&gt; {\n\n    switch (query.commandId) {\n      case productSearchCommand.COMMAND_ID: {\n        return productSearchCommand.handleTeamsMessagingExtensionQuery(context, query);\n      }\n      case discountedSearchCommand.COMMAND_ID: {\n        return discountedSearchCommand.handleTeamsMessagingExtensionQuery(context, query);\n      }\n    }\n  }\n</code></pre> <p>All it's doing is dispatching the query to the based on the command ID. These are the same command ID's used in the manifest above.</p> <p>The other type of activity our app needs to handle is the adaptive card actions, such as when a user clicks on \"Update stock\" or \"Reorder\" on an adaptive card. Since there is no specific method for an adaptive card action, the code overrides <code>onInvokeActivity()</code>, which is a much broader class of activity that includes message extension queries. For that reason, the code manually checks the activity name, and dispatches to the appropriate handler. If the activity name isn't for an adaptive card action, the <code>else</code> clause runs the base implementation of <code>onInvokeActivity()</code> which, among other things, will call our <code>handleTeamsMessagingExtensionQuery()</code> method if the Invoke activity is a query.</p> <pre><code>import {\n  TeamsActivityHandler,\n  TurnContext,\n  MessagingExtensionQuery,\n  MessagingExtensionResponse,\n  InvokeResponse\n} from \"botbuilder\";\nimport productSearchCommand from \"./messageExtensions/productSearchCommand\";\nimport discountedSearchCommand from \"./messageExtensions/discountSearchCommand\";\nimport revenueSearchCommand from \"./messageExtensions/revenueSearchCommand\";\nimport actionHandler from \"./adaptiveCards/cardHandler\";\n\nexport class SearchApp extends TeamsActivityHandler {\n  constructor() {\n    super();\n  }\n\n  // Handle search message extension\n  public async handleTeamsMessagingExtensionQuery(\n    context: TurnContext,\n    query: MessagingExtensionQuery\n  ): Promise&lt;MessagingExtensionResponse&gt; {\n\n    switch (query.commandId) {\n      case productSearchCommand.COMMAND_ID: {\n        return productSearchCommand.handleTeamsMessagingExtensionQuery(context, query);\n      }\n      case discountedSearchCommand.COMMAND_ID: {\n        return discountedSearchCommand.handleTeamsMessagingExtensionQuery(context, query);\n      }\n    }\n\n  }\n\n  // Handle adaptive card actions\n  public async onInvokeActivity(context: TurnContext): Promise&lt;InvokeResponse&gt; {\n    let runEvents = true;\n    // console.log (`\ud83c\udfac Invoke activity received: ${context.activity.name}`);\n    try {\n      if(context.activity.name==='adaptiveCard/action'){\n        switch (context.activity.value.action.verb) {\n          case 'ok': {\n            return actionHandler.handleTeamsCardActionUpdateStock(context);\n          }\n          case 'restock': {\n            return actionHandler.handleTeamsCardActionRestock(context);\n          }\n          case 'cancel': {\n            return actionHandler.handleTeamsCardActionCancelRestock(context);\n          }\n          default:\n            runEvents = false;\n            return super.onInvokeActivity(context);\n        }\n      } else {\n          runEvents = false;\n          return super.onInvokeActivity(context);\n      }\n    } ...\n</code></pre>"},{"location":"pages/extend-message-ext/01-nw-teams-app/#step-3-examine-the-message-extension-command-code","title":"Step 3 - Examine the message extension command code","text":"<p>In an effort to make the code more modular, readable, and reusable, each message extension command has been placed in its own TypeScript module. Have a look at src/messageExtensions/discountSearchCommand.ts as an example.</p> <p>First, note that the module exports a constant <code>COMMAND_ID</code>, which contains the same command ID found in the app manifest, and allows the switch statement in searchApp.ts to work properly.</p> <p>Then it provides a function, <code>handleTeamsMessagingExtensionQuery()</code>, to handle incoming queries for discounted products by category.</p> <pre><code>async function handleTeamsMessagingExtensionQuery(\n    context: TurnContext,\n    query: MessagingExtensionQuery\n): Promise&lt;MessagingExtensionResponse&gt; {\n\n    // Seek the parameter by name, don't assume it's in element 0 of the array\n    let categoryName = cleanupParam(query.parameters.find((element) =&gt; element.name === \"categoryName\")?.value);\n    console.log(`\ud83d\udcb0 Discount query #${++queryCount}: Discounted products with categoryName=${categoryName}`);\n\n    const products = await getDiscountedProductsByCategory(categoryName);\n\n    console.log(`Found ${products.length} products in the Northwind database`)\n    const attachments = [];\n    products.forEach((product) =&gt; {\n        const preview = CardFactory.heroCard(product.ProductName,\n            `Avg discount ${product.AverageDiscount}%&lt;br /&gt;Supplied by ${product.SupplierName} of ${product.SupplierCity}`,\n            [product.ImageUrl]);\n\n        const resultCard = cardHandler.getEditCard(product);\n        const attachment = { ...resultCard, preview };\n        attachments.push(attachment);\n    });\n    return {\n        composeExtension: {\n            type: \"result\",\n            attachmentLayout: \"list\",\n            attachments: attachments,\n        },\n    };\n}\n</code></pre> <p>Notice that the index in the <code>query.parameters</code> array may not correspond to the parameter's position in the manifest. While this is generally only an issue for a multi-parameter command, the code will still get the value based on the parameter name rather than hard coding an index. After cleaning up the parameter (trimming it, and handling the fact that sometimes Copilot assumes \"*\" is a wildcard that matches everything), the code calls the Northwind data access layer to <code>getDiscountedProductsByCategory()</code>.</p> <p>Then it iterates through the products and creates two cards for each:</p> <ul> <li>a preview card, which is implemented as a \"hero\" card (these predate adaptive cards and are very simple). This is what's displayed in the search results in the user interface and in some citations in Copilot.</li> <li>a result card, which is implemented as an \"adaptive\" card that includes all the details.</li> </ul> <p>In the next step, we'll review the adaptive card code and check out the Adaptive Card designer.</p>"},{"location":"pages/extend-message-ext/01-nw-teams-app/#step-4-examine-the-adaptive-cards-and-related-code","title":"Step 4 - Examine the adaptive cards and related code","text":"<p>The project's adaptive cards are in the src/adaptiveCards folder. There are 3 cards, each implemented as a JSON file.</p> <ul> <li>editCard.json - This is the initial card that's displayed by the message extension or a Copilot reference</li> <li>successCard.json - When a user takes action, this card is displayed to indicate success. It's mostly the same as the edit card except it includes a message to the user.</li> <li>errorCard.json - If an action fails, this card is displayed.</li> </ul> <p>Let's take a look at the edit card in the Adaptive Card Designer. Open your web browser to https://adaptivecards.io and click the \"Designer\" option at the top.</p> <p></p> <p>Notice the data binding expressions such as <code>\"text\": \"\ud83d\udce6 ${productName}\",</code>. This binds the <code>productName</code> property in the data to the text on the card.</p> <p>Now select \"Microsoft Teams\" as the host application 1\ufe0f\u20e3 . Paste the entire contents of editCard.json into the Card Payload Editor 2\ufe0f\u20e3 , and the contents of sampleData.json into the Sample Data Editor 3\ufe0f\u20e3 . The sample data is identical to a product as provided in the code.</p> <p></p> <p>You should see the card as rendered, except for a small error which arises due to the designer's inability to display one of the adaptive card formats.</p> <p>Near the top of the page, try changing the Theme and Emulated Device to see how the card would look in dark theme or on a mobile device. This is the tool that was used to build adaptive cards for the sample application.</p> <p>Now, back in Visual Studio Code, open cardHandler.ts. The function <code>getEditCard()</code> is called from each of the message extension commands to obtain a result card. The code reads the adaptive card JSON - which is considered a template - and then binds it to product data. The result is more JSON - the same card as the template, with the data binding expressions all filled in. Finally, the <code>CardFactory</code> module is used to convert the final JSON into an adaptive card object for rendering.</p> <pre><code>function getEditCard(product: ProductEx): any {\n\n    var template = new ACData.Template(editCard);\n    var card = template.expand({\n        $root: {\n            productName: product.ProductName,\n            unitsInStock: product.UnitsInStock,\n            productId: product.ProductID,\n            categoryId: product.CategoryID,\n            imageUrl: product.ImageUrl,\n            supplierName: product.SupplierName,\n            supplierCity: product.SupplierCity,\n            categoryName: product.CategoryName,\n            inventoryStatus: product.InventoryStatus,\n            unitPrice: product.UnitPrice,\n            quantityPerUnit: product.QuantityPerUnit,\n            unitsOnOrder: product.UnitsOnOrder,\n            reorderLevel: product.ReorderLevel,\n            unitSales: product.UnitSales,\n            inventoryValue: product.InventoryValue,\n            revenue: product.Revenue,\n            averageDiscount: product.AverageDiscount\n        }\n    });\n    return CardFactory.adaptiveCard(card);\n}\n</code></pre> <p>Scrolling down, you'll see the handler for each of the action buttons on the card. The card submits data when an action button is clicked - specifically <code>data.txtStock</code>, which is the \"Quantity\" input box on the card, and <code>data.productId</code>, which is sent in each card action to let the code know what product to update.</p> <pre><code>async function handleTeamsCardActionUpdateStock(context: TurnContext) {\n\n    const request = context.activity.value;\n    const data = request.action.data;\n    console.log(`\ud83c\udfac Handling update stock action, quantity=${data.txtStock}`);\n\n    if (data.txtStock &amp;&amp; data.productId) {\n\n        const product = await getProductEx(data.productId);\n        product.UnitsInStock = Number(data.txtStock);\n        await updateProduct(product);\n\n        var template = new ACData.Template(successCard);\n        var card = template.expand({\n            $root: {\n                productName: product.ProductName,\n                unitsInStock: product.UnitsInStock,\n                productId: product.ProductID,\n                categoryId: product.CategoryID,\n                imageUrl: product.ImageUrl,\n                ...\n</code></pre> <p>As you can see, the code obtains these two values, updates the database, and then sends a new card that contains a message and the updated data.</p>"},{"location":"pages/extend-message-ext/01-nw-teams-app/#exercise-2-run-the-sample-as-a-message-extension","title":"Exercise 2 - Run the sample as a Message Extension","text":""},{"location":"pages/extend-message-ext/01-nw-teams-app/#step-1-set-up-the-project-for-first-use","title":"Step 1 - Set up the project for first use","text":"<p>Open your working folder in Visual Studio Code. If you have already opened it for the code tour, you can continue from there.</p> <p>Agents Toolkit stores environment variables in the env folder, and it will fill in all the values automatically when you start your project the first time. However there's one value that's specific to the sample application, and that's the connection string for accessing the Northwind database.</p> <p>In this project, the Northwind database is stored in Azure Table Storage; when you're debugging locally, it uses the Azurite storage emulator. That's mostly built into the project, but the project won't build unless you provide the connection string.</p> <p>The necessary setting is provided in a file env/.env.local.user.sample. Make a copy of this file in the env folder, and call it .env.local.user. This is where secret or sensitive settings are stored.</p> <p>If you're not sure how to do this, here are the steps in Visual Studio Code. Expand the env folder and right click on .env.local.user.sample. Select \"Copy\". Then right click anywhere in the env folder and select \"Paste\". You will have a new file called .env.local.user copy.sample. Use the same context menu to rename the file to .env.local.user and you're done.</p> <p></p> <p>The resulting .env.local.user file should contain this line:</p> <pre><code>SECRET_STORAGE_ACCOUNT_CONNECTION_STRING=UseDevelopmentStorage=true\n</code></pre> <p>(OK it's not a secret! But it could be; if you deploy the project to Azure it will be!)</p>"},{"location":"pages/extend-message-ext/01-nw-teams-app/#step-2-run-the-application-locally","title":"Step 2 - Run the application locally","text":"<p>Click F5 to start debugging, or click the start button 1\ufe0f\u20e3. You will have an opportunity to select a debugging profile; select Debug in Teams (Edge) 2\ufe0f\u20e3 or choose another profile.</p> <p></p> <p>If you see this screen, you need to fix your env/.env.local.user file; this is explained in the previous step.</p> <p></p> <p>The first time your app runs, you may be prompted to allow NodeJS to go through your firewall; this is necessary to allow the application to communicate.</p> <p>It may take a while the first time as it's loading all the npm packages. Eventually, a browser window will open and invite you to log in.</p> <p>The debugging will open teams in a browser window. Make sure you login using the same credentials you signed into Agents Toolkit. Once you're in, Microsoft Teams should open up and display a dialog offering to open your application. </p> <p></p> <p>Once opened it immediately ask you where you want to open the app in. By default it's personal chat. You could also select it in a channel or group chat as shown. Select \"Open\".</p> <p></p> <p>Now you are in a personal chat with the app.</p>"},{"location":"pages/extend-message-ext/01-nw-teams-app/#step-3-test-in-microsoft-teams","title":"Step 3 - Test in Microsoft Teams","text":"<p>To test the app on the teams, select the \"+\" sign in the chat message compose area. And select \"+ Get more apps\" button to open the dialog to search apps. Choose \"Northwind Inventory\" app with a blue background. See the process below.</p> <p></p> <p>Once the app is opened from the compose area, you will see a search box in the default tab \"Products Inventory\". You will also find the \"Discount\" search tab greyed out. Continue searching for a product, type in \"Chai\" which is a product available in Northwind database to see if the item is displayed as shown below.</p> <p></p> <p>You can select the card for Chai and send it in the conversation. </p> <p>You could also test the button actions in the adaptive card as demonstrated below. </p> <p></p> <p>This will confirm that the message extension is working and ready to be used as a plugin, which we will see in the next lab.</p> <p>NOTE: This is really only useful in conversations with other users; the chat in the Northwind Inventory app is just for testing.</p>"},{"location":"pages/extend-message-ext/01-nw-teams-app/#step-4-advanced-queries","title":"Step 4 - Advanced queries","text":"<p>Back in Visual Studio Code, have a look at the app manifest, which is in a file called manifest.json in the appPackage directory. You'll notice that the app information that was displayed when you installed the app is all here.</p> <p>Scroll down a bit to <code>composeExtensions:</code>. Compose extensions is the historical name for a message extension; the Northwind Inventory message extension is defined here.</p> <p>Here's an abbreviated version of that JSON for easy reference.</p> <pre><code>\"composeExtensions\": [\n    {\n        \"botId\": \"${{BOT_ID}}\",\n        \"commands\": [\n            {\n                \"id\": \"inventorySearch\",\n                ...\n                \"description\": \"Search products by name, category, inventory status, supplier location, stock level\",\n                \"title\": \"Product inventory\",\n                \"type\": \"query\",\n                \"parameters\": [ ... ]\n            },\n            {\n                \"id\": \"discountSearch\",\n                ...\n                \"description\": \"Search for discounted products by category\",\n                \"title\": \"Discounts\",\n                \"type\": \"query\",\n                \"parameters\": [ ...]\n            }\n        ]\n    }\n],\n</code></pre> <p>Notice first that there's a bot ID. That's because Microsoft Teams uses the Azure bot channel to exchange secure, real-time messages with your application. Agents Toolkit will register the bot and fill in the ID for you.</p> <p>Then there's a collection of commands. These correspond to the tabs in the search dialog in Teams. In this application, the commands are really intended for Copilot more than regular users!</p> <p>You already ran the first command when you searched for a product by name. You can try the other one now.</p> <p>Enter \"Beverages\", \"Dairy\", or \"Produce\" into the \"Discounts\" tab, and you'll see the products within those categories that are discounted. Copilot will use this to answer questions about discounted products.</p> <p></p> <p>Now examine the first command again. You'll notice it has 5 parameters!</p> <pre><code>\"parameters\": [\n    {\n        \"name\": \"productName\",\n        \"title\": \"Product name\",\n        \"description\": \"Enter a product name here\",\n        \"inputType\": \"text\"\n    },\n    {\n        \"name\": \"categoryName\",\n        \"title\": \"Category name\",\n        \"description\": \"Enter the category of the product\",\n        \"inputType\": \"text\"\n    },\n    {\n        \"name\": \"inventoryStatus\",\n        \"title\": \"Inventory status\",\n        \"description\": \"Enter what status of the product inventory. Possible values are 'in stock', 'low stock', 'on order', or 'out of stock'\",\n        \"inputType\": \"text\"\n    },\n    {\n        \"name\": \"supplierCity\",\n        \"title\": \"Supplier city\",\n        \"description\": \"Enter the supplier city of product\",\n        \"inputType\": \"text\"\n    },\n    {\n        \"name\": \"stockQuery\",\n        \"title\": \"Stock level\",\n        \"description\": \"Enter a range of integers such as 0-42 or 100- (for &gt;100 items). Only use if you need an exact numeric range.\",\n        \"inputType\": \"text\"\n    }\n]\n</code></pre> <p>Unfortunately, Teams can only display the first parameter, but Copilot can use all 5. This will allow it to do more advanced queries of the Northwind inventory data.</p> <p>As a work-around to the Teams UI limitation, in the \"Northwind Inventory\" tab, the application will accept up to 5 parameters comma separated, using the format:</p> <pre><code>name,category,inventoryStatus,supplierCity,supplierName\n</code></pre> <p></p> <p>Read the descriptions in the JSON above carefully when entering a query. Try entering these, and as you do, keep an eye on the debug console tab in Visual Studio Code, where you'll see each query as it's run.</p> <ul> <li>\"chai\" - find products with names that begin with \"chai</li> <li>\"c,bev\" - find products in categories beginning with \"bev\" and names that begin with \"c</li> <li>\",,out\" - find products that are out of stock</li> <li>\",,on,london\" - find products that are on order from suppliers in London</li> <li>\"tofu,produce,,osaka\" - find products in the \"produce\" category with suppliers in Osaka and names that begin with \"tofu\"</li> </ul> <p>Each query term filters the list of products down. The format of each query term is arbitrary - just be sure to explain it to Copilot in the description of each parameter.</p>"},{"location":"pages/extend-message-ext/01-nw-teams-app/#step-6-optional-view-northwind-database-in-azure-storage-explorer","title":"Step 6 (optional) - View Northwind database in Azure Storage Explorer","text":"<p>The Northwind Database isn't fancy but it's real! If you want to peek at or even modify the data, open the Azure Storage Explorer while Azurite is running. </p> <p>Note</p> <p>Running the app starts Azurite automatically. For more information check the Azurite documention here. As long as your project is started successfully you can view the storage.</p> <p>To view the Northwind data, open \"Emulator &amp; Attached\", \"Storage Accounts\", \"Emulator - Default Ports\", and \"Tables\". There you'll see the old Northwind database tables, which aren't nearly as handy in a NO SQL environment, but there they are!</p> <p></p> <p>The code reads the Products table on each query, but the other tables are only accessed when the app starts. So if you want to add a new category, you'll need to restart the app for it to appear.</p> <p></p>"},{"location":"pages/extend-message-ext/01-nw-teams-app/#congratulations","title":"Congratulations","text":"<p>You have mastered running the Northwind message extension. Now it's time to test it as plugin in Microsoft 365 Copilot  in the next lab. Select Next.</p> <p></p>"},{"location":"pages/extend-message-ext/02-nw-plugin/","title":"Lab M2 - Run app in Microsoft Microsoft 365 Copilot","text":"<p>In this lab, you\u2019ll run the Northwind app as a plugin in Microsoft 365 Copilot. </p> Navigating the Extend Teams Message Extension labs (Extend Path) <ul> <li>Lab M0 - Prerequisites </li> <li>Lab M1 - Get to know Northwind message extension </li> <li>Lab M2 - Run app in Microsoft 365 Copilot (\ud83d\udccdYou are here)</li> <li>Lab M3 - Enhance plugin with new search command</li> <li>Lab M4 - Add authentication </li> <li>Lab M5 - Enhance plugin with an action command </li> </ul> <p>NOTE</p> <p>The completed exercise with all of the code changes can be downloaded from here. This can be useful for troubleshooting purposes. If you ever need to reset your edits, you can clone again the repository and start over.</p> <p>In this lab you will:</p> <ul> <li>Run the message extension you ran on Microsoft Teams on Microsoft Copilot </li> <li>You will learn how to use natural language prompts to search and find items in the Northwind database </li> </ul>"},{"location":"pages/extend-message-ext/02-nw-plugin/#exercise-1-run-the-sample-as-a-copilot-plugin","title":"Exercise 1 - Run the sample as a Copilot plugin","text":"<p>If you are coming from previous lab, you can keep the debugger running and skip Step 1 and go to Step 2 or if it had stopped, go to Step 1. </p>"},{"location":"pages/extend-message-ext/02-nw-plugin/#step-1-run-the-app-locally","title":"Step 1 : Run the app locally","text":"<p>Restart by clicking F5 to start debugging, or click the start button 1\ufe0f\u20e3. You will have an opportunity to select a debugging profile; select Debug in Teams (Edge) 2\ufe0f\u20e3 or choose another profile.</p> <p></p> <p>The debugging will open teams in a browser window. Make sure you login using the same credentials you signed into Agents Toolkit. Once you're in, Microsoft Teams should open up and display a dialog offering to open your application. </p> <p></p> <p>Once opened it immediately ask you where you want to open the app in. By default it's personal chat. You could also select it in a channel or group chat as shown. Select \"Open\".</p> <p></p> <p>Now you are in a personal chat with the app.</p>"},{"location":"pages/extend-message-ext/02-nw-plugin/#step-2-test-in-microsoft-365-copilot-single-parameter","title":"Step 2 - Test in Microsoft 365 Copilot (single parameter)","text":"<p>Reminder</p> <p>To perform the following exercise, your account must have a valid license for Microsoft 365 Copilot.</p> <p>Go to Teams in browser https://teams.microsoft.com/v2/ logged into your developer tenant. If you have a Microsoft 365 Copilot, the new app will be automatically pinned above your chats. Just open Teams, select \u201cchats\u201d and you\u2019ll see Copilot.</p> <p>Once in the Copilot app experience, Check the lower left of the chat user interface, below the compose box. You should see a plugin icon 1\ufe0f\u20e3 . Click this and enable the Northwind Inventory plugin 2\ufe0f\u20e3 .</p> <p></p> <p>For best results, start a new chat by typing \"New chat\" or by clicking on the New chat icon at the top right before each prompt or set of related prompts.</p> <p></p> <p>Here are some prompts to try that use only a single parameter of the message extension:</p> <ul> <li> <p>Find information about Chai in Northwind Inventory</p> </li> <li> <p>Find discounted seafood in Northwind. Show a table with the products, supplier names, average discount rate, and revenue per period.</p> </li> </ul> <p>Let's try the first one.  Find information about Chai in Northwind Inventory</p> <p></p> <p>Try using these adaptive cards to take action on the products. If there's a single item returned back, Copilot may show the whole card as above. For multiple response  Copilot may show a small number next to each. You can hover over these numbers to display the adaptive card. References will also be listed below the response.</p> <p>Here is an example of multiple items returned with references.</p> <p></p> <p>Next, try  Find discounted seafood in Northwind. Show a table with the products, supplier names, average discount rate, and revenue per period.</p> <p></p> <p>As you're testing, watch the log messages within your application. - Go to Visual Studio Code where you project is runnning. - Find the terminal that has the \"Start application\" task running.</p> <p>You should be able to see when Copilot calls your plugin. For example, after the previous prompt you should see below log</p> <p></p>"},{"location":"pages/extend-message-ext/02-nw-plugin/#step-3-test-in-microsoft-365-copilot-multiple-parameters","title":"Step 3 - Test in Microsoft 365 Copilot (multiple parameters)","text":"<p>In this exercise, you'll try some prompts that exercise the multi-parameter feature in the sample plugin. These prompts will request data that can be retrieved by name, category, inventory status, supplier city, and stock level, as defined in the manifest.</p> <p>For example, try prompting Find Northwind beverages with more than 100 items in stock. To respond, Copilot must identify products:</p> <ul> <li>where the category is beverages</li> <li>where inventory status is in stock</li> <li>where the stock level is more than 100</li> </ul> <p></p> <p>The plugin code applies all three filters, providing a result set.</p> <p>If you look at the log messages in your terminal in VS Code, you can see that Copilot was able to understand this requirement and fill in 3 of the parameters in the first message extension command.</p> <p></p> <p>By using this prompt, Copilot might look also in your OneDrive files to find the payment terms with each supplier's contract. In this case, you will notice that some of the references won't have the Northwind Inventory icon, but the Word one.</p> <p>Here is an example:</p> <p></p> <p>Here are some more prompts to try:</p> <ul> <li> <p>Find Northwind dairy products that are low on stock. Show me a table with the product, supplier, units in stock and on order.</p> </li> <li> <p>We\u2019ve been receiving partial orders for Tofu. Find the supplier in Northwind and draft an email summarizing our inventory and reminding them they should stop sending partial orders per our MOQ policy.</p> </li> <li> <p>Northwind will have a booth at Microsoft Community Days  in London. Find products with local suppliers and write a LinkedIn post to promote the booth and products.</p> </li> <li> <p>What beverage is high in demand due to social media that is low stock in Northwind in London. Reference the product details to update stock.</p> </li> </ul> <p>Which prompts work best for you? Try making up your own prompts and observe your log messages to see how Copilot accesses your plugin.</p> <p></p>"},{"location":"pages/extend-message-ext/02-nw-plugin/#congratulations","title":"Congratulations","text":"<p>You\u2019ve done an excellent job testing the plugin in Microsoft 365 Copilot. Now, proceed to the next lab to add code for another search criterion. Select Next.</p> <p></p>"},{"location":"pages/extend-message-ext/03-enhance-nw-plugin/","title":"Lab M3 - Enhance plugin with new search command","text":"<p>In this lab, you will enhance the Northwind plugin by adding a new command. While the current message extension effectively provides information about products within the Northwind inventory database, it does not provide information related to Northwind\u2019s customers. Your task is to introduce a new command associated with an API call that retrieves products ordered by a customer name specified by the user. </p> Navigating the Extend Teams Message Extension labs (Extend Path) <ul> <li>Lab M0 - Prerequisites </li> <li>Lab M1 - Get to know Northwind message extension </li> <li>Lab M2 - Run app in Microsoft 365 Copilot </li> <li>Lab M3 - Enhance plugin with new search command(\ud83d\udccdYou are here)</li> <li>Lab M4 - Add authentication </li> <li>Lab M5 - Enhance plugin with an action command </li> </ul> <p>NOTE</p> <p>The completed exercise with all of the code changes can be downloaded from here. This can be useful for troubleshooting purposes. If you ever need to reset your edits, you can clone again the repository and start over.</p>"},{"location":"pages/extend-message-ext/03-enhance-nw-plugin/#exercise-1-code-changes","title":"Exercise 1 - Code changes","text":""},{"location":"pages/extend-message-ext/03-enhance-nw-plugin/#step-1-extend-the-message-extension-plugin-user-interface","title":"Step 1 -  Extend the Message Extension / plugin User Interface","text":"<p>In your working directory called Northwind from previous lab , open manifest.json in the  appPackage folder. Look for discountSearch in the commands array. After the closing braces of the discountSearch command, add a comma ,. Then, copy the companySearch command snippet and add it to the commands array.</p> <pre><code>{\n    \"id\": \"companySearch\",\n    \"context\": [\n        \"compose\",\n        \"commandBox\"\n    ],\n    \"description\": \"Given a company name, search for products ordered by that company\",\n    \"title\": \"Customer\",\n    \"type\": \"query\",\n    \"parameters\": [\n        {\n            \"name\": \"companyName\",\n            \"title\": \"Company name\",\n            \"description\": \"The company name to find products ordered by that company\",\n            \"inputType\": \"text\"\n        }\n    ]\n}\n</code></pre> <p>COMMAND_ID</p> <p>The \"id\" is the connection between the UI and the code. This value is defined as COMMAND_ID in the discount/product/SearchCommand.ts files. See how each of these files has a unique COMMAND_ID that corresponds to the value of \"id\".</p>"},{"location":"pages/extend-message-ext/03-enhance-nw-plugin/#step-2-implement-product-search-by-company","title":"Step 2 - Implement Product Search by Company","text":"<p>You will implement a product search by Company name and return a list of the company's ordered products. Find this information using the tables below:</p> Table Find Look Up By Customer Customer Id Customer Name Orders Order Id Customer Id OrderDetail Product Order Id <p>Here's how it works:  Use the Customer table to find the Customer Id with the Customer Name. Query the Orders table with the Customer Id to retrieve the associated Order Ids. For each Order Id, find the associated products in the OrderDetail table. Finally, return a list of products ordered by the specified company name.</p> <p>Open .\\src\\northwindDB\\products.ts</p> <p>Update the <code>import</code> statement on line 1 to include OrderDetail, Order and Customer. It should look as follows</p> <pre><code>import {\n    TABLE_NAME, Product, ProductEx, Supplier, Category, OrderDetail,\n    Order, Customer\n} from './model';\n</code></pre> <p>Add the new function <code>searchProductsByCustomer()</code> as in the below snippet, right after the <code>import { getInventoryStatus } from '../adaptiveCards/utils';</code>import statement.</p> <pre><code>export async function searchProductsByCustomer(companyName: string): Promise&lt;ProductEx[]&gt; {\n\n    let result = await getAllProductsEx();\n\n    let customers = await loadReferenceData&lt;Customer&gt;(TABLE_NAME.CUSTOMER);\n    let customerId=\"\";\n    for (const c in customers) {\n        if (customers[c].CompanyName.toLowerCase().includes(companyName.toLowerCase())) {\n            customerId = customers[c].CustomerID;\n            break;\n        }\n    }\n\n    if (customerId === \"\") \n        return [];\n\n    let orders = await loadReferenceData&lt;Order&gt;(TABLE_NAME.ORDER);\n    let orderdetails = await loadReferenceData&lt;OrderDetail&gt;(TABLE_NAME.ORDER_DETAIL);\n    // build an array orders by customer id\n    let customerOrders = [];\n    for (const o in orders) {\n        if (customerId === orders[o].CustomerID) {\n            customerOrders.push(orders[o]);\n        }\n    }\n\n    let customerOrdersDetails = [];\n    // build an array order details customerOrders array\n    for (const od in orderdetails) {\n        for (const co in customerOrders) {\n            if (customerOrders[co].OrderID === orderdetails[od].OrderID) {\n                customerOrdersDetails.push(orderdetails[od]);\n            }\n        }\n    }\n\n    // Filter products by the ProductID in the customerOrdersDetails array\n    result = result.filter(product =&gt; \n        customerOrdersDetails.some(order =&gt; order.ProductID === product.ProductID)\n    );\n\n    return result;\n}\n</code></pre>"},{"location":"pages/extend-message-ext/03-enhance-nw-plugin/#step-3-create-a-handler-for-the-new-command","title":"Step 3: Create a handler for the new command","text":"<p>In VS Code, duplicate the productSearchCommand.ts file located in the src/messageExtensions folder. Then, rename the copied file to \"customerSearchCommand.ts\"</p> <p>Change value of COMMAND_ID constant to:</p> <pre><code>const COMMAND_ID = \"companySearch\";\n</code></pre> <p>Replace below import statement from: </p> <pre><code>import { searchProducts } from \"../northwindDB/products\";`\n</code></pre> <p>to </p> <pre><code>import { searchProductsByCustomer } from \"../northwindDB/products\";\n</code></pre> <p>Inside the existing brackets of handleTeamsMessagingExtensionQuery , replace exisiting code with below snippet:</p> <pre><code>\n    let companyName;\n\n    // Validate the incoming query, making sure it's the 'companySearch' command\n    // The value of the 'companyName' parameter is the company name to search for\n    if (query.parameters.length === 1 &amp;&amp; query.parameters[0]?.name === \"companyName\") {\n        [companyName] = (query.parameters[0]?.value.split(','));\n    } else { \n        companyName = cleanupParam(query.parameters.find((element) =&gt; element.name === \"companyName\")?.value);\n    }\n    console.log(`\ud83c\udf7d\ufe0f Query #${++queryCount}:\\ncompanyName=${companyName}`);    \n\n    const products = await searchProductsByCustomer(companyName);\n\n    console.log(`Found ${products.length} products in the Northwind database`)\n    const attachments = [];\n    products.forEach((product) =&gt; {\n        const preview = CardFactory.heroCard(product.ProductName,\n            `Customer: ${companyName}`, [product.ImageUrl]);\n\n        const resultCard = cardHandler.getEditCard(product);\n        const attachment = { ...resultCard, preview };\n        attachments.push(attachment);\n    });\n    return {\n        composeExtension: {\n            type: \"result\",\n            attachmentLayout: \"list\",\n            attachments: attachments,\n        },\n    };\n\n</code></pre>"},{"location":"pages/extend-message-ext/03-enhance-nw-plugin/#step-4-update-the-command-routing","title":"Step 4 - Update the command routing","text":"<p>In this step you will route the <code>companySearch</code> command to the handler you implemented in the previous step.</p> <p>Open searchApp.ts in the src folder and add the following import statement: </p> <pre><code>import customerSearchCommand from \"./messageExtensions/customerSearchCommand\";\n</code></pre> <p>In the switch statement of the handler function <code>handleTeamsMessagingExtensionQuery</code> add another case statement as below:</p> <pre><code>      case customerSearchCommand.COMMAND_ID: {\n        return customerSearchCommand.handleTeamsMessagingExtensionQuery(context, query);\n      }\n</code></pre> <p>Note</p> <p>in the UI-based operation of the Message Extension / plugin, this command is explicitly called. However, when invoked by Microsoft 365 Copilot, the command is triggered by the Copilot orchestrator.</p>"},{"location":"pages/extend-message-ext/03-enhance-nw-plugin/#exercise-2-run-the-app-search-for-product-by-company-name","title":"Exercise 2 - Run the App! Search for product by company name","text":"<p>Now you're ready to test the sample as a plugin for Microsoft 365 Copilot.</p>"},{"location":"pages/extend-message-ext/03-enhance-nw-plugin/#step-1-run-the-updated-app-locally","title":"Step 1: Run the updated app locally","text":"<p>Stop the local debugger if it is kept running. Since you have updated the manifest with a new command, you will want to re install the app with the new package.  Update the manifest version in the manifest.json file inside the appPackage folder from \"1.0.9\" to \"1.0.10\". This ensurers the new changes of the app is refelected. </p> <p>Restart debugger by clicking F5, or click the start button 1\ufe0f\u20e3. You will have an opportunity to select a debugging profile; select Debug in Teams (Edge) 2\ufe0f\u20e3 or choose another profile.</p> <p></p> <p>The debugging will open teams in a browser window. Make sure you login using the same credentials you signed into Agents Toolkit. Once you're in, Microsoft Teams should open up and display a dialog offering to open your application. </p> <p></p> <p>Once opened it immediately ask you where you want to open the app in. By default it's personal chat. You could also select it in a channel or group chat as shown. Select \"Open\".</p> <p></p> <p>Now you are in a personal chat with the app. But we are testing in Copilt so follow next instruction. </p> <p>In Teams click on Chat and then Copilot. Copilot should be the top-most option. Click on the Plugin icon and select Northwind Inventory to enable the plugin.</p>"},{"location":"pages/extend-message-ext/03-enhance-nw-plugin/#step-2-test-with-new-command-in-copilot","title":"Step 2: Test with new command in Copilot","text":"<p>Enter the prompt: </p> <p>What are the products ordered by 'Consolidated Holdings' in Northwind Inventory?</p> <p>The Terminal output shows Copilot understood the query and executed the <code>companySearch</code> command, passing company name extracted by Copilot. </p> <p>Here's the output in Copilot: </p> <p>Here is another prompt to try:</p> <p>What are the products ordered by 'Consolidated Holdings' in Northwind Inventory? Please list the product name, price and supplier in a table.</p>"},{"location":"pages/extend-message-ext/03-enhance-nw-plugin/#step-3-test-the-command-as-message-extension-optional","title":"Step 3: Test the command as Message extension (Optional)","text":"<p>Of course, you can test this new command also by using the sample as a Message Extension, like we did in previous lab.</p> <ol> <li>In the Teams sidebar, move to the Chats section and pick any chat or start a new chat with a colleague.</li> <li>Click on the + sign to access to the Apps section.</li> <li>Pick the Northwind Inventory app.</li> <li>Notice how now you can see a new tab called Customer.</li> <li>Search for Consolidated Holdings and see the products ordered by this company. They will match the ones that Copilot returned you in the previous step.</li> </ol> <p></p> <p></p>"},{"location":"pages/extend-message-ext/03-enhance-nw-plugin/#congratulations","title":"Congratulations","text":"<p>You are now a plugin champion. You are now ready to secure your plugin with authentication. Proceed to the next lab. Select \"Next\"</p> <p></p>"},{"location":"pages/extend-message-ext/04-add-authentication/","title":"Lab M4 - Add authentication","text":"<p>In this lab you will secure your Northwind plugin from the previous lab with authentication using Entra ID SSO (single sign-on) to search and find your own contacts like suppliers information from Outlook.  </p> Navigating the Extend Teams Message Extension labs (Extend Path) <ul> <li>Lab M0 - Prerequisites </li> <li>Lab M1 - Get to know Northwind message extension </li> <li>Lab M2 - Run app in Microsoft 365 Copilot </li> <li>Lab M3 - Enhance plugin with new search command</li> <li>Lab M4 - Add authentication (\ud83d\udccdYou are here)</li> <li>Lab M5 - Enhance plugin with an action command </li> </ul> <p>Attention</p> <p>This lab requires you to have an Azure Subscripton to provision bot services.</p> <p>NOTE</p> <p>The completed exercise with all of the code changes can be downloaded from here. This can be useful for troubleshooting purposes. If you ever need to reset your edits, you can clone again the repository and start over.</p> <p>In this lab you will learn to:</p> <ul> <li> <p>how to add Entra ID single sign-on (SSO) to your plugin so users can seamlessly log into your app with the same account they use in Microsoft Teams</p> </li> <li> <p>Access the Microsoft Graph API to access user data in Microsoft 365. Your app will act on behalf of the logged-in user so they can securely access their own content within your application like contacts from Outlook in this lab.</p> </li> </ul>"},{"location":"pages/extend-message-ext/04-add-authentication/#introduction-tasks-involved-to-implement-sso-brief","title":"Introduction : Tasks involved to implement SSO (brief)","text":"<p>Implementing SSO for your plugin (Message extension app) involves several steps. Here is a high level over view of the process:</p>"},{"location":"pages/extend-message-ext/04-add-authentication/#register-your-app-in-microsoft-entra-id-configure-your-bot-in-azure-bot-service","title":"Register Your App in Microsoft Entra ID &amp; Configure Your Bot in Azure Bot Service","text":"<ul> <li>Create a new app registration in the Azure portal.</li> <li>Configure the app with necessary permissions and scopes.</li> <li>Generate a client secret for your app.</li> <li>Create a bot in the Azure Bot Service.</li> <li>Add the Microsoft 365 channel to your bot.</li> <li>Set up OAuth connection settings in the Azure portal.</li> </ul>"},{"location":"pages/extend-message-ext/04-add-authentication/#enable-sso-in-your-teams-app","title":"Enable SSO in Your Teams App","text":"<ul> <li>Update your message extension's bot code to handle authentication and token exchange.</li> <li>Use the Bot Framework SDK to integrate SSO capabilities.</li> <li>Implement the OAuth flow to obtain access tokens for the user.</li> </ul>"},{"location":"pages/extend-message-ext/04-add-authentication/#configure-authentication-in-teams","title":"Configure Authentication in Teams","text":"<ul> <li>Add the necessary permissions in the Teams app manifest.</li> </ul>"},{"location":"pages/extend-message-ext/04-add-authentication/#exercise-1-register-your-app-in-microsoft-entra-id-and-configure-your-bot-in-azure-bot-service","title":"Exercise 1: Register Your App in Microsoft Entra ID and Configure Your Bot in Azure Bot Service","text":"<p>Luckily for you, we\u2019ve streamlined everything so that it\u2019s ready to go as soon as you hit F5. However, let\u2019s go over the specific changes you\u2019ll need to make in the project for registering and configuring these resources. </p>"},{"location":"pages/extend-message-ext/04-add-authentication/#step-1-copy-files-and-folders","title":"Step 1: Copy files and folders","text":"<p>Create a new folder called entra inside folder infra in your root folder. </p> <p>Create two new files in the entra folder called entra.bot.manifest.json and entra.graph.manifest.json </p> <p>Copy code from this file into entra.bot.manifest.json and same for entra.graph.manifest.json from this file.</p> <p>These files are needed to provision the Entra ID app registrations (previously know as Azure Active Directory app registrations) needed for the bot as well as the one for graph for token exchange between them. </p> <p>Next in the infra folder create files azure.local.bicep and copy code from this file and create file azure.parameters.local.json in the same folder infra and copy code from this file</p> <p>These file help with the bot registration. This will ensure the bot service is provisioned in Azure even when you run app locally. This is required for this authentication flow.</p> <p>What is happening with these files?</p> <p>When Agents Toolkit runs the app locally, it will provision a new Azure AI Bot Service into the resource group which uses the F0 SKU which grants unlimited messages to be sent to standard channels, this includes Microsoft Teams and Microsoft 365 channel (Outlook and Copilot) and does not incur a cost.</p>"},{"location":"pages/extend-message-ext/04-add-authentication/#step-2-update-existing-code","title":"Step 2: Update existing code","text":"<p>Next, open file azurebot.bicep under botRegistration folder which is under infra folder and add below code snippet after declaration of \"param botAppDomain\"</p> <pre><code>param graphAadAppClientId string\n@secure()\nparam graphAadAppClientSecret string\n\nparam connectionName string\n</code></pre> <p>Next add below snippet to provision bot service into the same file at end of line.</p> <pre><code>resource botServicesMicrosoftGraphConnection 'Microsoft.BotService/botServices/connections@2022-09-15' = {\n  parent: botService\n  name: connectionName\n  location: 'global'\n  properties: {\n    serviceProviderDisplayName: 'Azure Active Directory v2'\n    serviceProviderId: '30dd229c-58e3-4a48-bdfd-91ec48eb906c'\n    clientId: graphAadAppClientId\n    clientSecret: graphAadAppClientSecret\n    scopes: 'email offline_access openid profile Contacts.Read'\n    parameters: [\n      {\n        key: 'tenantID'\n        value: 'common'\n      }\n      {\n        key: 'tokenExchangeUrl'\n        value: 'api://${botAppDomain}/botid-${botAadAppClientId}'\n      }\n    ]\n  }\n}\n\n</code></pre> <p>This will create a new OAUTH connection for token exchange between bot service and the graph entra ID app.</p> <p>Changes to infrastructure for plugin</p> <p>We require a different infrastructure to run this setup compared to the non-authenticated plugins we've previously built in this path and hence we need to rewire. Next steps will help you with this. </p> <p>Next, open the teamsapp.local.yml file and replace its content with the code snippet below. This will rewire parts of the infrastructure, including deploying a bot service in Azure for our lab. </p> <pre><code># yaml-language-server: $schema=https://aka.ms/teams-toolkit/1.0.0/yaml.schema.json\n# Visit https://aka.ms/teamsfx-v5.0-guide for details on this file\n# Visit https://aka.ms/teamsfx-actions for details on actions\nversion: 1.0.0\n\nprovision:\n\n  - uses: script\n    name: Ensure database\n    with:\n      run: node db-setup.js\n      workingDirectory: scripts\n\n  # Creates a Teams app\n  - uses: teamsApp/create\n    with:\n      # Teams app name\n      name: NorthwindProducts-${{TEAMSFX_ENV}}\n    # Write the information of created resources into environment file for\n    # the specified environment variable(s).\n    writeToEnvironmentFile:\n      teamsAppId: TEAMS_APP_ID\n\n  - uses: aadApp/create\n    with:\n      name: ${{APP_INTERNAL_NAME}}-bot-${{TEAMSFX_ENV}}\n      generateClientSecret: true\n      signInAudience: AzureADMultipleOrgs\n    writeToEnvironmentFile:\n      clientId: BOT_ID\n      clientSecret: SECRET_BOT_PASSWORD\n      objectId: BOT_AAD_APP_OBJECT_ID\n      tenantId: BOT_AAD_APP_TENANT_ID\n      authority: BOT_AAD_APP_OAUTH_AUTHORITY\n      authorityHost: BOT_AAD_APP_OAUTH_AUTHORITY_HOST\n\n  - uses: aadApp/update\n    with:\n      manifestPath: \"./infra/entra/entra.bot.manifest.json\"\n      outputFilePath : \"./build/entra.bot.manifest.${{TEAMSFX_ENV}}.json\"\n  - uses: aadApp/create\n    with:\n      name: ${{APP_INTERNAL_NAME}}-graph-${{TEAMSFX_ENV}}\n      generateClientSecret: true\n      signInAudience: AzureADMultipleOrgs\n    writeToEnvironmentFile:\n      clientId: GRAPH_AAD_APP_ID\n      clientSecret: SECRET_GRAPH_AAD_APP_CLIENT_SECRET\n      objectId: GRAPH_AAD_APP_OBJECT_ID\n      tenantId: GRAPH_AAD_APP_TENANT_ID\n      authority: GRAPH_AAD_APP_OAUTH_AUTHORITY\n      authorityHost: GRAPH_AAD_APP_OAUTH_AUTHORITY_HOST\n\n  - uses: aadApp/update\n    with:\n      manifestPath: \"./infra/entra/entra.graph.manifest.json\"\n      outputFilePath : \"./build/entra.graph.manifest.${{TEAMSFX_ENV}}.json\"\n\n  - uses: arm/deploy\n    with:\n      subscriptionId: ${{AZURE_SUBSCRIPTION_ID}}\n      resourceGroupName: ${{AZURE_RESOURCE_GROUP_NAME}}\n      templates:\n        - path: ./infra/azure.local.bicep\n          parameters: ./infra/azure.parameters.local.json\n          deploymentName: Create-resources-for-${{APP_INTERNAL_NAME}}-${{TEAMSFX_ENV}}\n      bicepCliVersion: v0.9.1\n\n  # Validate using manifest schema\n  - uses: teamsApp/validateManifest\n    with:\n      # Path to manifest template\n      manifestPath: ./appPackage/manifest.json\n\n  # Build Teams app package with latest env value\n  - uses: teamsApp/zipAppPackage\n    with:\n      # Path to manifest template\n      manifestPath: ./appPackage/manifest.json\n      outputZipPath: ./appPackage/build/appPackage.${{TEAMSFX_ENV}}.zip\n      outputJsonPath: ./appPackage/build/manifest.${{TEAMSFX_ENV}}.json\n  # Validate app package using validation rules\n  - uses: teamsApp/validateAppPackage\n    with:\n      # Relative path to this file. This is the path for built zip file.\n      appPackagePath: ./appPackage/build/appPackage.${{TEAMSFX_ENV}}.zip\n\n  # Apply the Teams app manifest to an existing Teams app in\n  # Teams Developer Portal.\n  # Will use the app id in manifest file to determine which Teams app to update.\n  - uses: teamsApp/update\n    with:\n      # Relative path to this file. This is the path for built zip file.\n      appPackagePath: ./appPackage/build/appPackage.${{TEAMSFX_ENV}}.zip\n\n  # Extend your Teams app to Outlook and the Microsoft 365 app\n  - uses: teamsApp/extendToM365\n    with:\n      # Relative path to the build app package.\n      appPackagePath: ./appPackage/build/appPackage.${{TEAMSFX_ENV}}.zip\n    # Write the information of created resources into environment file for\n    # the specified environment variable(s).\n    writeToEnvironmentFile:\n      titleId: M365_TITLE_ID\n      appId: M365_APP_ID\n\ndeploy:\n# Run npm command\n  - uses: cli/runNpmCommand\n    name: install dependencies\n    with:\n      args: install --no-audit\n\n  # Generate runtime environment variables\n  - uses: file/createOrUpdateEnvironmentFile\n    with:\n      target: ./.localConfigs\n      envs:\n        BOT_ID: ${{BOT_ID}}\n        BOT_PASSWORD: ${{SECRET_BOT_PASSWORD}}\n        STORAGE_ACCOUNT_CONNECTION_STRING: ${{SECRET_STORAGE_ACCOUNT_CONNECTION_STRING}}\n        CONNECTION_NAME: ${{CONNECTION_NAME}}\n\n</code></pre> <p>Open .env.local file under env folder and completely remove all variable and add below for a fresh start. </p> <pre><code>APP_INTERNAL_NAME=Northwind\nAPP_DISPLAY_NAME=Northwind\nCONNECTION_NAME=MicrosoftGraph\n\n</code></pre> <p>Open .env.local.user file under env folder and completely remove all variable and add below for a fresh start. </p> <pre><code>SECRET_BOT_PASSWORD=\nSECRET_GRAPH_AAD_APP_CLIENT_SECRET=\nSECRET_STORAGE_ACCOUNT_CONNECTION_STRING=UseDevelopmentStorage=true\n</code></pre>"},{"location":"pages/extend-message-ext/04-add-authentication/#exercise-2-new-search-command-for-contacts","title":"Exercise 2: New search command for Contacts","text":""},{"location":"pages/extend-message-ext/04-add-authentication/#step-1-add-a-command-to-search-contacts-suppliers","title":"Step 1: Add a command to search contacts (suppliers)","text":"<p>To start, add a new command for searching contacts. We\u2019ll eventually retrieve contact details from Microsoft Graph, but for now, we\u2019ll use mock data to ensure the message extension command functions correctly. Go to src folder &gt; messageExtensions and add an new file supplierContactSearchCommand.ts in it.</p> <p>Copy the content from below into the new file.</p> <pre><code>import {\n    CardFactory,\n    TurnContext\n} from \"botbuilder\";\n\n\nconst COMMAND_ID = \"supplierContactSearch\";\n\nlet queryCount = 0;\nasync function handleTeamsMessagingExtensionQuery(context: TurnContext, query: any): Promise&lt;any&gt; {\n\n    let name = '';\n    if (query.parameters.length === 1 &amp;&amp; query.parameters[0]?.name === \"name\") {\n        [name] = (query.parameters[0]?.value.split(','));\n    } else {\n        name = cleanupParam(query.parameters.find((element) =&gt; element.name === \"name\")?.value);\n    }\n    console.log(`\ud83c\udf7d\ufe0f Query #${++queryCount}:\\name of contact=${name}`);\n    const filteredProfile = [];\n    const attachments = [];\n\n    const allContacts = [\n    {\n        displayName: \"John Doe\",\n        emailAddresses: [\n        { address: \"john.doe@example.com\" }\n        ]\n    },\n    {\n        displayName: \"Jane Smith\",\n        emailAddresses: [\n        { address: \"jane.smith@example.com\" }\n        ]\n    },\n    {\n        displayName: \"Alice Johnson\",\n        emailAddresses: [\n        { address: \"alice.johnson@example.com\" }\n        ]\n    }\n];\n\n    allContacts.forEach((contact) =&gt; {\n        if (contact.displayName.toLowerCase().includes(name.toLowerCase()) || contact.emailAddresses[0]?.address.toLowerCase().includes(name.toLowerCase())) {\n            filteredProfile.push(contact);\n        }\n    });\n\n    filteredProfile.forEach((prof) =&gt; {\n        const preview = CardFactory.heroCard(prof.displayName,\n            `with email ${prof.emailAddresses[0]?.address}`);\n\n        const resultCard = CardFactory.heroCard(prof.displayName,\n            `with email ${prof.emailAddresses[0]?.address}`);\n        const attachment = { ...resultCard, preview };\n        attachments.push(attachment);\n    });\n    return {\n        composeExtension: {\n            type: \"result\",\n            attachmentLayout: \"list\",\n            attachments: attachments,\n        },\n    };\n\n}\nfunction cleanupParam(value: string): string {\n\n    if (!value) {\n        return \"\";\n    } else {\n        let result = value.trim();\n        result = result.split(',')[0];          // Remove extra data\n        result = result.replace(\"*\", \"\");       // Remove wildcard characters from Copilot\n        return result;\n    }\n}\n\nexport default { COMMAND_ID, handleTeamsMessagingExtensionQuery }\n</code></pre> <p>Go to src folder &gt; searchApp.ts file and import the newly created command.</p> <pre><code>import supplierContactSearchCommand from \"./messageExtensions/supplierContactSearchCommand\";\n</code></pre> <p>And add another case in the handleTeamsMessagingExtensionQuery for the newly added command after case customerSearchCommand.COMMAND_ID:</p> <pre><code>  case supplierContactSearchCommand.COMMAND_ID: {\n        return supplierContactSearchCommand.handleTeamsMessagingExtensionQuery(context, query);\n      } \n</code></pre> <p>Now to go appPackage &gt; manifest.json and add the command inside the commands array under the node composeExtensions.</p> <pre><code> {\n                    \"id\": \"supplierContactSearch\",\n                    \"context\": [\n                        \"compose\",\n                        \"commandBox\"\n                    ],\n                    \"description\": \"Search for a contact in the user's Outlook contacts list for Northwind\",\n                    \"title\": \"Contact search\",\n                    \"type\": \"query\",\n                    \"parameters\": [\n                        {\n                            \"name\": \"name\",\n                            \"title\": \"Contact search\",\n                            \"description\": \"Type name of the contact or company which forms the domain for email address of the contact, to search my Outlook contacts list\",\n                            \"inputType\": \"text\"\n                        }\n                    ] \n         } \n</code></pre> <p>So you have now added a new non authenticated command to search contacts from a mock list. </p>"},{"location":"pages/extend-message-ext/04-add-authentication/#step-2-sign-in-to-azure-in-agents-toolkit","title":"Step 2: Sign in to Azure in Agents Toolkit","text":"<p>Agents Toolkit requires you to sign in to an Azure account and have a subscription before you can provision the resource instances. You'll then use these resources to deploy your app to host it in Azure.</p> <p>On the Activity Bar of your project editor, select the Microsoft Teams icon 1\ufe0f\u20e3. This will open the Agents Toolkit extension panel.</p> <p>On the Agents Toolkit panel, under Accounts, select \"Sign in to Azure\" 2\ufe0f\u20e3.</p> <p></p> <p>In the dialog that appears, select \"Sign in\".</p> <p></p>"},{"location":"pages/extend-message-ext/04-add-authentication/#step-3-run-the-application-in-teams-to-test-new-command","title":"Step 3: Run the application in Teams to test new command","text":"<p>To test the new command you need to run the app locally.</p> <p>Click F5 to start debugging, or click the start button 1\ufe0f\u20e3. You will have an opportunity to select a debugging profile; select Debug in Teams (Edge) 2\ufe0f\u20e3 or choose another profile.</p> <p></p> <p>F5 in this lab</p> <p>When you press F5 to run the application, it will also provision all the necessary resources for the authenticated flow, as we configured everything using the Team Toolkit's actions in Exercise 1. </p> <p>Since you cleared the environments variable, you will install all Entra ID apps and bot services in Azure. During the first run, you'll need to select a resource group in your Azure subscription, which you logged into via the Agents Toolkit, for provisioning resources.</p> <p></p> <p>Choose + New resource group to keep things tidy.And choose the default name Agents Toolkit has suggested and select Enter.</p> <p>Next, choose a Location. For this lab just choose Central US</p> <p></p> <p>Next Agents Toolkit will go ahead and provision the resources but will also ask you a confirmation before doing so.</p> <p></p> <p>Select Provision.</p> <p>Once it's provisioned all the resources, you will get the Northwind app install dialog in a browser, select Add.</p> <p></p> <p>Once installed, you will be given another dialog to open the app. This will open the app as a message extension in a personal chat. Select Open.</p> <p></p> <p>Since we only need to test if the command works or not, we will only test the app in Teams chat. In the personal chat with the app, select the Contacrt search and type a. </p> <p></p> <p>If it lists the contacts as shown above, the command is working, but with mock data. We will fix this in the next exercise.</p>"},{"location":"pages/extend-message-ext/04-add-authentication/#exercise-3-enable-authentication-for-new-command","title":"Exercise 3 : Enable authentication for new command","text":"<p>In the previous step, you have laid the foundation for the new command. Next you will add authentication on top of the command, replace the mock contact list and replace it with actual contact list from the logged in user's Outlook contacts.</p> <p>You will first install some npm packages needed for the plugin. Create a new terminal window in the project.</p> <p>Run below script in the terminal :</p> <pre><code>npm i @microsoft/microsoft-graph-client @microsoft/microsoft-graph-types\n</code></pre> <p>Locate config.ts file in the src folder. Add a \",\" after <code>storageAccountConnectionString: process.env.STORAGE_ACCOUNT_CONNECTION_STRING</code> and add the new property and value for <code>connectionName</code> as below.</p> <pre>\n const config = {\n  botId: process.env.BOT_ID,\n  botPassword: process.env.BOT_PASSWORD,\n  storageAccountConnectionString: process.env.STORAGE_ACCOUNT_CONNECTION_STRING,\n  connectionName: process.env.CONNECTION_NAME\n};\n</pre> <p>Now create a folder called services under src folder of your base project. Create two files AuthService.ts and GraphService.ts in the services folder. </p> <ul> <li> <p>AuthService : contains a class that provides authentication services. It includes a method getSignInLink which asynchronously retrieves a sign-in URL from a client using specific connection details and returns this URL.</p> </li> <li> <p>GraphService : defines a class that interacts with the Microsoft Graph API. It initializes a Graph client using an authentication token and provides a method getContacts to fetch the user's contacts, selecting specific fields (displayName and emailAddresses).</p> </li> </ul> <p>Next, copy paste below code into AuthService.ts</p> <pre><code>import {\n  AdaptiveCardInvokeResponse,\n  CloudAdapter,\n  MessagingExtensionQuery,\n  MessagingExtensionResponse,\n  TurnContext,\n} from 'botbuilder';\nimport { UserTokenClient } from 'botframework-connector';\nimport { Activity } from 'botframework-schema';\nimport config from '../config';\n\nexport class AuthService {\n  private client: UserTokenClient;\n  private activity: Activity;\n  private connectionName: string;\n\n  constructor(context: TurnContext) {\n    const adapter = context.adapter as CloudAdapter;\n    this.client = context.turnState.get&lt;UserTokenClient&gt;(\n      adapter.UserTokenClientKey\n    );\n    this.activity = context.activity;\n    this.connectionName = config.connectionName;\n  }\n\n  async getUserToken(\n    query?: MessagingExtensionQuery\n  ): Promise&lt;string | undefined&gt; {\n    const magicCode =\n      query?.state &amp;&amp; Number.isInteger(Number(query.state)) ? query.state : '';\n\n    const tokenResponse = await this.client.getUserToken(\n      this.activity.from.id,\n      this.connectionName,\n      this.activity.channelId,\n      magicCode\n    );\n\n    return tokenResponse?.token;\n  }\n\n  async getSignInComposeExtension(): Promise&lt;MessagingExtensionResponse&gt; {\n    const signInLink = await this.getSignInLink();\n\n    return {\n      composeExtension: {\n        type: 'auth',\n        suggestedActions: {\n          actions: [\n            {\n              type: 'openUrl',\n              value: signInLink,\n              title: 'SignIn',\n            },\n          ],\n        },\n      },\n    };\n  }\n\n  async getSignInAdaptiveCardInvokeResponse(): Promise&lt;AdaptiveCardInvokeResponse&gt; {\n    const signInLink = await this.getSignInLink();\n\n    return {\n      statusCode: 401,\n      type: 'application/vnd.microsoft.card.signin',\n\n      value: {\n        signinurl: signInLink,\n      },\n    };\n  }\n\n  async getSignInLink(): Promise&lt;string&gt; {\n    const { signInLink } = await this.client.getSignInResource(\n      this.connectionName,\n      this.activity,\n      ''\n    );\n\n    return signInLink;\n  }\n}\n\n</code></pre> <p>Next, copy paste below code into GraphService.ts</p> <pre><code>import { Client } from '@microsoft/microsoft-graph-client';\n\n\nexport class GraphService {\n  private _token: string;\n  private graphClient: Client;\n\n  constructor(token: string) {\n    if (!token || !token.trim()) {\n      throw new Error('SimpleGraphClient: Invalid token received.');\n    }\n    this._token = token;\n\n    this.graphClient = Client.init({\n      authProvider: done =&gt; {\n        done(null, this._token);\n      },\n    });\n  }\n  async getContacts(): Promise&lt;any&gt; {\n    const response = await this.graphClient\n      .api(`me/contacts`)\n      .select('displayName,emailAddresses')\n      .get();\n\n    return response.value;\n  }\n}\n\n</code></pre> <p>Now, go back to the supplierContactSearchCommand.ts file and import these two services we just added.</p> <pre><code>import { AuthService } from \"../services/AuthService\";\nimport { GraphService } from \"../services/GraphService\";\n</code></pre> <p>Next, add the code that initializes authentication, retrieves a user token, checks its validity, and then sets up a service to interact with the Microsoft Graph API if the token is valid. If the token is invalid, it prompts the user to sign in.</p> <p>Copy below code into the handleTeamsMessagingExtensionQuery function above the mock definition of allContacts constant.</p> <pre><code>  const credentials = new AuthService(context);\n  const token = await credentials.getUserToken(query);\n  if (!token) {\n    return credentials.getSignInComposeExtension();\n  }\n  const graphService = new GraphService(token);\n</code></pre> <p>Next, replace the mock definition of allContacts constant with below code:</p> <pre><code>const allContacts = await graphService.getContacts();\n</code></pre> <p>Next go to appPackage/manifest.json file and update the node validDomains as below</p> <pre><code>\"validDomains\": [\n        \"token.botframework.com\",\n        \"${{BOT_DOMAIN}}\"\n    ]\n</code></pre> <p>Also add comma \",\" after <code>validDomains</code> array and add a node for webApplicationInfo and update it with below value</p> <pre><code>    \"webApplicationInfo\": {\n        \"id\": \"${{BOT_ID}}\",\n        \"resource\": \"api://${{BOT_DOMAIN}}/botid-${{BOT_ID}}\"\n    },\n</code></pre> <p>Next, upgrade the manifest version from \"1.0.10\" to \"1.0.11\" so the changes are reflected. </p> <p>These manifest changes will make sure the sign-in url is correctly formed and sent to the user for consent.</p>"},{"location":"pages/extend-message-ext/04-add-authentication/#exercise-4-test-authentication","title":"Exercise 4:  Test authentication","text":""},{"location":"pages/extend-message-ext/04-add-authentication/#step-1-run-app-locally","title":"Step 1: Run app locally","text":"<p>Stop the local debugger if it is kept running. Since you have updated the manifest with a new command, you will want to re install the app with the new package. </p> <p>Restart debugger by clicking F5, or click the start button 1\ufe0f\u20e3. You will have an opportunity to select a debugging profile; select Debug in Teams (Edge) 2\ufe0f\u20e3 or choose another profile.</p> <p></p> <p>Provision</p> <p>Here you will again get a dialog confirming if you want to provision the resources. Select \"Provision\". This is not actually provisioning new resources just overwriting existing resources. </p> <p>The debugging will open teams in a browser window. Make sure you login using the same credentials you signed into Agents Toolkit. Once you're in, Microsoft Teams should open up and display a dialog offering to open your application. </p> <p></p> <p>Once opened it immediately ask you where you want to open the app in. By default it's personal chat. You could also select it in a channel or group chat as shown. Select \"Open\".</p> <p></p> <p>Now you are in a personal chat with the app. But we are testing in Copilt so follow next instruction. </p> <p>In Teams click on Chat and then Copilot. Copilot should be the top-most option. Click on the Plugin icon and select Northwind Inventory to enable the plugin.</p>"},{"location":"pages/extend-message-ext/04-add-authentication/#step-2-enter-test-data","title":"Step 2 : Enter test data","text":"<p>Before we test the plugin to bring actual contacts, we'll need to add some contact information. So let us first ensure we have some contacts in Microsoft 365.</p> <p>1\ufe0f\u20e3 From Microsoft Teams, click the \"waffle\" menu</p> <p>2\ufe0f\u20e3 Select Microsoft Outlook</p> <p></p> <p>1\ufe0f\u20e3 Within Outlook, click the \"Contacts\" button</p> <p>2\ufe0f\u20e3 Enter some new contacts</p> <p>The app is simple, and will only display the person or company name and email address. If you want to play along with the business scenario, make them sound like suppliers.</p> <p></p>"},{"location":"pages/extend-message-ext/04-add-authentication/#step-2-test-in-copilot","title":"Step 2: Test in Copilot","text":"<p>Ask Copilot for contacts by using this prompt- Find my conacts with name {first name} in Northwind (Replace {first name} with what name you have given for your contacts in Exercise 4, Step 1)</p> <p>You will get a sign-in button to authenticate (one time only) as shown in the screen. </p> <p></p> <p>This is the indication that you have an some sort of an authentication set in place to call this feature of the plugin. Select Sign in to Northwind Inventory</p> <p>You will now get a dialog to interact and provide consent as show in the GIF below. Once consented you should be able to get back results form Microsoft 365 Copilot. </p>"},{"location":"pages/extend-message-ext/04-add-authentication/#congratulations","title":"Congratulations","text":"<p>This was a hard one, but you ACED it! Thanks for doing the Message Extension agent track!</p> <p></p> <p></p>"},{"location":"pages/extend-message-ext/05-add-action/","title":"Lab M5 - Enhance plugin with an action command","text":""},{"location":"pages/in-a-box/","title":"Copilot Developer Camp In a Box","text":"<p>Here are presentation materials for running your own Copilot Developer Camp workshop!!</p> title deck with video demos deck for sharing 20 min CC01: Keynote download download 40 min CC02: Introducing Declarative Agents download download 40 min CC03: Introducing Custom Engine Agents part 1, part 2 download <p></p>"},{"location":"pages/internal/labFormat/","title":"Guide to formatting lab content","text":""},{"location":"pages/internal/labFormat/#formatting-text-elements","title":"Formatting text elements","text":"<p>These text elements are embedded into the lab instructions, so the formatting is always in-line</p> Element Treatment Example Function names monospaced with parenthesis Then, call <code>myFunction()</code> to do something ... Language keywords monospaced ... insert at the top of the <code>try</code> block ... Symbols in code (variable, object names etc.) monospaced ... the <code>foo</code> object contains something random ... File and folder names bold Copy the contents of foo.js into the bar folder Text on screen enclose in double quotes Now click on the \"foo\" button"},{"location":"pages/internal/labFormat/#includes","title":"Includes","text":"<p>Content that will be used on multiple pages should be placed in include files in the /docs/includes folder.</p> <p>Here is the syntax:</p> --8&lt;-- \"all-labs-toc.md\" <p>Here is an example::</p> <p>Do these labs if you want to build a Declarative agent where Microsoft 365 provides the AI model and             orchestration</p> <ul> <li>\ud83c\udfc1 Welcome</li> <li>\ud83d\udd27 Set up <ul> <li>Lab E0 - Setup</li> </ul> </li> <li>\ud83e\uddf0 Declarative agent fundamentals <ul> <li> Lab E1 - Build a  Declarative Agent using TypeSpec </li> <li> Lab E1a - Geo locator game</li> </ul> </li> <li>\ud83d\udee0\ufe0f Build and integrate API from scratch <ul> <li>Lab E2 - Build an API</li> <li> Lab E3 - Add Declarative Agent + API</li> <li> Lab E4 - Enhance API + Plugin</li> <li>Lab E5 - Add Adaptive Cards</li> <li> Lab E6a - Add Authentication</li> </ul> </li> <li>\ud83d\udd0c Integration <ul> <li> Lab E7 - Add Copilot Connector</li> </ul> <ul> <li> Lab E8 - Connect Declarative agent to MCP Server</li> </ul> <ul> <li> Lab E9 - Connected Agents</li> </ul> </li> </ul> <p>Do these labs if you want to build a Custom engine agent with custom AI model and orchestration using Azure OpenAI and Teams AI library</p> <ul> <li>BTA0 - Setup</li> <li>BTA1 - First custom engine agent</li> <li>BTA2 - Index your data in Azure AI Search</li> <li>BTA3 - Enhance the user experience</li> <li>BTA4 - Add single sign on authentication</li> <li>BTA5 - Add actions to handle complex tasks</li> </ul> <p>Do these labs if you want to build a Declarative agent with Copilot Studio Lite</p> <ul> <li>MAB1 - Build your first agent</li> </ul> <p>Do these labs if you want to build agents with Microsoft Copilot Studio</p> <ul> <li>MCS0 - Setup</li> <li>MCS1 - First agent</li> <li>MCS2 - Defining Topics</li> <li>MCS3 - Defining Tools</li> <li>MCS4 - Extending Microsoft 365 Copilot</li> <li>MCS5 - Consuming a custom connector</li> <li>MCS6 - Consuming an MCP server</li> <li>MCS7 - Creating Autonomous Agents</li> <li>MCS8 - Integrating Azure AI Search for RAG</li> <li>MCS9 - Connected Agents (Preview)</li> </ul>"},{"location":"pages/internal/labFormat/#lab-steps","title":"Lab steps","text":"<p>Copilot Developer Camp labs use custom web controls to help students track their progress. You will want to include a <code>&lt;cc-end-step /&gt;</code> element at the end of each lab step. See this test page for details.</p>"},{"location":"pages/internal/labFormat/#hyperlinks","title":"Hyperlinks","text":"<p>Links within the labs can be relative and should open within the current window like this.</p> <p>Links that go outside the labs, including links to source code in the same repo, should open a new window like this</p>"},{"location":"pages/internal/labFormat/#admonitions","title":"Admonitions","text":"<p>The documentation for admonitions is here. Here's how to use them in Copilot Developer Camp:</p> <p>Challenge</p> <p>Here's something to try on your own</p> <p>Note</p> <p>Use this format to emphasize or clarify the instructions</p> <p>Tip</p> <p>Use this format to show tips and best practices</p> <p>Warning</p> <p>Use this format to warn the student about a common pitfall in completing the labs</p> <p>Danger</p> <p>Use this format to warn the student about security issues or stability issues that may arise in a production application</p> Video briefing <p> Caption </p> Video briefing <p> Caption </p> More information <p> Caption 1 Caption 2 Caption 3 </p> TL;DR <p>Use this format to provide ancillary details that may be of interest but are not essential</p>"},{"location":"pages/internal/testGuide/","title":"testGuide","text":""},{"location":"pages/internal/testGuide/#thank-you-for-testing-code-camp","title":"Thank you for testing Code Camp","text":"<p>The key to successful labs is testing; the more people who try it, the more we'll find any missing steps or assumed knowledge.</p> <p>The following labs are in need of testing. Please send questions and issues to the lab owner, or bring it up in the Copilot Camp Testers chat. If you add Github issues or Pull requests please mention or assign the owner.</p> <p>Auth labs are now published</p> <p>If you'd like to try the new Declarative Agent auth labs, skip to them here</p>"},{"location":"pages/internal/testGuide/#here-are-the-new-labs","title":"Here are the new labs!","text":"<p>New Maker Path</p> <p>Owner: Paolo Pialorsi</p> <p>In this new path, the student finds content about:</p> <ul> <li>Copilot Studio Lite</li> <li>Microsoft Copilot Studio</li> <li>SharePoint agents</li> </ul> <p>Test procedure:</p> <ol> <li>Just read the initial introductions for each branch, starting from here.</li> </ol> <p>Lab MAB1 - Copilot Studio Lite</p> <p>Owner: Paolo Pialorsi</p> <p>In this lab, the student:</p> <ul> <li>learns what is a declarative agent for Microsoft 365 Copilot</li> <li>makes a declarative agent using Copilot Studio Lite</li> <li>customises the agent to create a game using specific instructions</li> <li>configures the agent to rely on a set of documents stored in SharePoint Online</li> <li>enables the agent to generate images</li> <li>shares the agent with other people</li> <li>learns how to share the agent with other people</li> </ul> <p>To test you will need a tenant with Microsoft 365 Copilot.</p> <p>Test procedure:</p> <ol> <li>Just follow the lab instructions</li> </ol> <p>Lab MCS0 - Setup</p> <p>Owner: Paolo Pialorsi</p> <p>In this lab, the student:</p> <ul> <li>How to create a dedicated environment for your labs</li> <li>How to setup and configure Microsoft Copilot Studio</li> </ul> <p>To test you will need a tenant with Microsoft 365 Copilot and Microsoft Copilot Studio (a trial license is enough).</p> <p>Test procedure:</p> <ol> <li>Just follow the lab instructions</li> </ol> <p>Lab MCS1 - First agent</p> <p>Owner: Paolo Pialorsi</p> <p>In this lab, the student:</p> <ul> <li>How to create an agent with Copilot Studio</li> <li>How to configure a custom icon for your agent</li> <li>How to configure knowledge sources for your agent</li> <li>How to publish your agent in Microsoft Teams</li> </ul> <p>To test you will need a tenant with Microsoft 365 Copilot and Microsoft Copilot Studio (a trial license is enough).</p> <p>Test procedure:</p> <ol> <li>Just follow the lab instructions</li> </ol> <p>Lab MCS2 - Defining Topics</p> <p>Owner: Paolo Pialorsi</p> <p>In this lab, the student:</p> <ul> <li>How to rely on Orchestration based on generative AI</li> <li>How to create a single-turn topic</li> <li>How to create a multi-turn topic</li> <li>How to use adaptive cards to interact with users</li> </ul> <p>To test you will need a tenant with Microsoft 365 Copilot and Microsoft Copilot Studio (a trial license is enough).</p> <p>Test procedure:</p> <ol> <li>Just follow the lab instructions</li> </ol> <p>Lab MCS3 - Defining Actions</p> <p>Owner: Paolo Pialorsi</p> <p>In this lab, the student:</p> <ul> <li>How to create an action to invoke a Power Platform connector</li> <li>How to create an action to invoke a Power Automate flow</li> <li>How to invoke actions from topics</li> </ul> <p>To test you will need a tenant with Microsoft 365 Copilot and Microsoft Copilot Studio (a trial license is enough).</p> <p>Test procedure:</p> <ol> <li>Just follow the lab instructions</li> </ol> <p>Lab MCS4 - Extending Microsoft 365 Copilot</p> <p>Owner: Paolo Pialorsi</p> <p>In this lab, the student:</p> <ul> <li>How to create an agent for Microsoft 365 Copilot Chat</li> <li>How to configure a custom icon for your agent</li> <li>How to configure knowledge sources for your agent</li> <li>How to publish the agent in Microsoft 365 Copilot Chat</li> <li>How to create an action for Microsoft 365 Copilot Chat</li> </ul> <p>To test you will need a tenant with Microsoft 365 Copilot and Microsoft Copilot Studio (a trial license is enough).</p> <p>Test procedure:</p> <ol> <li>Just follow the lab instructions</li> </ol> <p>Lab MCS5 - Power Platform custom connector</p> <p>Owner: Paolo Pialorsi</p> <p>In this lab, the student:</p> <ul> <li>How to expose a REST API through a Power Platform custom connector</li> <li>How to secure communication to an external REST API in the Power Platform</li> <li>How to consume a custom connector from an agent</li> </ul> <p>To test you will need a tenant with Microsoft 365 Copilot and Microsoft Copilot Studio (a trial license is enough).</p> <p>Test procedure:</p> <ol> <li>Just follow the lab instructions</li> </ol> <p># Thank you!</p>"},{"location":"pages/make/","title":"Make agents for Microsoft 365 Copilot","text":"<p>Welcome to Copilot Developer Camp's Maker Path! In this lab, you will design customised assistants to improve the overall experience of using Microsoft 365 Copilot. The process will begin with the creation of a basic agent using either the Copilot Studio Lite, or the SharePoint agent capability in SharePoint Online, or Copilot Studio.</p> <p>In order to better understand the available options and when you should use what, here you can find a helpful table with a brief explanation of each of the options.</p>        Copilot Studio Lite      <ul> <li>Easy, simple, and interactive experience</li> <li>Web based, integrated with Microsoft 365 Copilot Chat and Microsoft 365 Copilot</li> <li>Content from SharePoint Online, public web, and Microsoft Copilot Connectors</li> <li>Available in Microsoft 365 Copilot Chat</li> <ul> Start here  Copilot Studio Full              <ul> <li>Maximum level of flexibility</li> <li>Almost any data source or knowledge base</li> <li>Support for various publishing channels</li> <li>Support for actions</li> <li>Support for Power Platform connectors, Dataverse, REST API, and more</li> <li>Per user + per tenant license or Pay-As-You-Go</li> <ul> Start here  SharePoint Agent              <ul> <li>Integrated with SharePoint Online user experience</li> <li>SharePoint Online content only</li> <li>Supported in Microsoft Teams chat</li> <li>Microsoft 365 Copilot license or Microsoft Copilot Studio capacity or Pay-As-You-Go</li> <ul> Start here <p></p>"},{"location":"pages/make/agent-builder/","title":"Lab MAB - Making agents with Copilot Studio Lite","text":"<p>A Copilot Studio Lite agent is the easiest way to create a declarative agent leveraging the same infrastructure, orchestrator, foundation model, and security controls as Microsoft 365 Copilot, which ensures a consistent and familiar user experience. With a Copilot Studio Lite agent you can also configure custom knowledge bases and custom capabilities/skills.</p> <p></p> <p>This is the easiest way of making a personal agent for Microsoft 365 Copilot. In fact, it is integrated with the native UI of Microsoft 365 Copilot Chat and Microsoft 365 Copilot. You can start from a set of Microsoft provided templates, or you can start from scratch. You can define the agent simply describing in natural language what you are looking for and relying on Copilot Studio Lite capability to understand natural language. It will create an agent for you, based on your prompt. Or you can configure the agent using a configuration page. By default, the agent is for personal use only. However, you can share it with specific people in your organization, or even with all the users in your organization, if needed.</p> <p></p> <p>An agent built with Copilot Studio Lite can use knowledge bases like:</p> <ul> <li>Generic web content</li> <li>Content of documents stored in SharePoint Online</li> <li>Microsoft Copilot Connectors</li> </ul> <p>It can also generate images on the fly or convert natural language into code.</p> <p>It is available in Microsoft 365 Copilot Chat and to any licensed user of Microsoft 365 Copilot.  Depending on the target knowledge base and on your users' license, your organization might have to pay for metered services.</p> <p>Do these labs if you want to build a Declarative agent with Copilot Studio Lite</p> <ul> <li>MAB1 - Build your first agent</li> </ul> <p>Start here with Lab MAB1, where you'll make your first agent with Copilot Studio Lite. </p> <p></p>"},{"location":"pages/make/agent-builder/01-first-agent/","title":"Lab MAB1 - Build your first agent","text":"<p>Do these labs if you want to build a Declarative agent with Copilot Studio Lite</p> <ul> <li>MAB1 - Build your first agent</li> </ul> Table of Contents <p>In this lab, you'll create a simple declarative agent using Copilot Studio Lite. Your agent is designed to help users to maintain and improve a home garden. The knowledge base of the agent is based on a set of documents stored in SharePoint Online and on the public web content. The agent can also engage the user in a nice game to guess the name of plants or flowers based on a set of clues.</p> <p>In this lab you will learn:</p> <ul> <li>What is a declarative agent for Microsoft 365 Copilot</li> <li>Make a declarative agent using Copilot Studio Lite</li> <li>Customise the agent to create a game using specific instructions </li> <li>Configure the agent to rely on a set of documents stored in SharePoint Online</li> <li>Enable the agent to generate images</li> <li>Share the agent with other people</li> <li>Learn how to share the agent with other people </li> </ul>"},{"location":"pages/make/agent-builder/01-first-agent/#introduction","title":"Introduction","text":"<p>Declarative agents leverage the same scalable infrastructure and platform of Microsoft 365 Copilot, tailored specifically to meet focus on a special area of your needs. They function as subject matter experts in a specific area or business need, allowing you to use the same interface as a standard Microsoft 365 Copilot chat, while ensuring they focus exclusively on the specific task at hand. </p> <p>Welcome on board to making your own declarative agent \u263a\ufe0f! Let's dive in and make your Copilot work magic!</p> <p>In this lab you will start out building a declarative agent using Copilot Studio Lite and providing a sample set of instructions. This is to help you get started with something. </p> <p>Next, you will modify your agent to be focused on a guess the plant or flower name game. </p> <p>You will also give your agent some files, stored in SharePoint Online, to refer to an hypothetical knowledge base. </p> <p>Lastly you will share the agent with other people in your organization.</p> <p></p>"},{"location":"pages/make/agent-builder/01-first-agent/#exercise-1-creating-the-declarative-agent","title":"Exercise 1: Creating the Declarative agent","text":"<p>Let's get started! \ud83d\udcaa\ud83c\udffc Let's make the agent from scratch using Copilot Studio Lite.</p>"},{"location":"pages/make/agent-builder/01-first-agent/#step-1-describe-your-agent","title":"Step 1: Describe your agent","text":"<p>To create a declarative agent with Copilot Studio Lite, open the Microsoft 365 Copilot chat home page and select New agent in the left side panel, where there is the list of available agents, like illustrated in the following picture.</p> <p></p> <p>The Copilot Studio Lite shows up and you can start defining the custom agent. You can choose a template to start from, or you can simply describe the agent by providing a description in natural language. You can also choose to manually configure the agent, selecting the Configure option, but you will get there later. Let's provide the following initial description:</p> <pre><code>You are an expert gardener and you help users to maintain and improve their home garden \nproviding detailed instructions and advice about the best practices for home gardening.\n</code></pre> <p></p> <p>Once you have provided the instructions, the agent builder will ask you about the name for the new agent. Provide the name: Gardener. While you interact with the agent builder, on the right side of the dialog you can see there is a preview of the agent itself, including some suggested conversation starters. If the agent builder asks you about refining instructions further, provide the following sentence.</p> <pre><code>Suggest ways to keep plants and flowers shining and gorgeous\n</code></pre> <p></p> <p>Keep on interacting with the agent builder until it does have all the information needed to create the agent. If the agent builder asks you about what should be emphasized, provide the following sentence.</p> <pre><code>Highlight the importance of nature and plants/flowers to be present in every house!\nUse a professional, yet friendly, tone.\n</code></pre> <p>Lastly, say that you don't have any further refinements and select the Create button in the upper right corner of the screen. </p> <p></p> <p>The Copilot Studio Lite will create a new agent for you, based on the provided instructions. </p> <p></p>"},{"location":"pages/make/agent-builder/01-first-agent/#step-2-test-the-agent","title":"Step 2: Test the agent","text":"<p>Once the agent is ready, you will see a popup dialog with a command to Go to agent and another one to Share it with other people in your organization.</p> <p></p> <p>Select the Go to agent button. You will be brought to the actual user experience of the new agent that you've just made.</p> <p></p> <p>To start interacting with the agent, click on the first suggested prompt and observe the response from the agent. Your agent is now ready. Congrats!</p> <p></p> <p></p>"},{"location":"pages/make/agent-builder/01-first-agent/#exercise-2-customizing-the-agent","title":"Exercise 2: Customizing the agent","text":"<p>It is now time to slightly customize the agent. You are going to add a custom icon and define the rules of the game to guess plants or flowers names.</p> <p>Start over with a New chat selecting the corresponding button in the upper let corner of the Microsoft 365 Copilot Chat user interface. Select the All agents command in the left side of the screen. Hoover on the Gardener agent and select the ... beside its name. In the contextual menu that will show up, select the Edit command to configure the agent.</p> <p></p> <p>A new page with all the settings of your agent shows up.</p> <p></p>"},{"location":"pages/make/agent-builder/01-first-agent/#step-1-provide-a-custom-icon","title":"Step 1: Provide a custom icon","text":"<p>Let's edit the Gardener agent that you just created. The dialog starts with the Configure panel active. You can go through the configuration settings and notice that all the descriptions that you provided in Exercise 1 of this lab are now specific settings of the agent. There are configuration settings to define:</p> <ul> <li>Icon: to customize the icon of the agent</li> <li>Name: to provide a name for the agent</li> <li>Description: to define the description of the agent</li> <li>Instructions: it is the system prompt for the agent, where you define the system role and the behavioral rules</li> <li>Knowledge: to configure the various knowledge bases for the agent</li> <li>Capabilities: to enable capabilites like code interpreting and image generation</li> <li>Suggested prompts: to configure up to 6 suggested prompts for the agent </li> </ul> <p>To customize the icon of the agent, select the edit button just beside the default icon of the agent.</p> <p>A dialog pops up and allows you to change the icon and the background color for the icon. For your convenience, you can download a sample icon from here and upload it as the custom icon for the agent. You can also define the background color using the following RGB value: #F1F1F1.</p> <p></p> <p>Select the Apply command when you are done with the changes.</p> <p></p>"},{"location":"pages/make/agent-builder/01-first-agent/#step-2-define-the-guess-plantflower-game-rules","title":"Step 2: Define the guess plant/flower game rules","text":"<p>Still while editing the settings of the agent, update the content of the Instructions configuration field with the following value.</p> <pre><code>You are an expert gardener and you help users to maintain and improve their home garden\nproviding detailed instructions and advice about the best practices for home gardening.\nHere are your working rules:\n\n- Provide detailed instructions and advice about the best practices for home gardening.\n- Help users maintain and improve their home garden.\n- Offer tips on plant care, soil management, pest control, and seasonal gardening tasks.\n- Respond to user queries with clear and actionable steps.\n- Be friendly, knowledgeable, and supportive in all interactions.\n- Suggest ways to keep plants and flowers shining and gorgeous, including watering\nschedules, fertilization, pruning, and pest control.\n- Highlight the importance of nature and plants/flowers to be present in every house.\n- Use a professional, yet friendly, tone in all responses.\n\nLastly, engage the user in a challenging game to guess the name of a plant or flower based\non a set of clues. Always end every answer with a sentence to engage the user to play the\ngame or another round of the game.\n</code></pre> <p></p> <p>Select the Update button in the upper right corner of the configuration dialog. The update takes a while and once it is completed you can select Go to agent and see the final result. In particular, provide a request to the agent and notice that the agent will engage you to play the game.</p> <p></p> <p>For the sake of completeness, here follows a sample conversation with the agent, while guessing the name of a plant.</p> <p></p> <p></p>"},{"location":"pages/make/agent-builder/01-first-agent/#exercise-3-add-sharepoint-online-knowledge-base","title":"Exercise 3: Add SharePoint Online knowledge base","text":"<p>In this exercise you are going to add some Word documents as an additional knowledge base for the Gardener agent.</p>"},{"location":"pages/make/agent-builder/01-first-agent/#step-1-upload-the-knowledge-base-documents","title":"Step 1: Upload the knowledge base documents","text":"<p>Now, let's add some custom knowledge base content, like for example few Microsoft Word documents with specific information about plants and flowers.</p> <p>Download a zip file consisting of four DOCX files by selecting this link.</p> <p>Extract the four files from the zip and upload them to a SharePoint Teams site in the same tenant where you are testing this lab. Put the files in the document library Documents. These documents are Basic Aspects of Gardening and Maintaining a Healthy Garden.docx, Common Plants List.docx, Healing a Plant in Your Garden, and The Most Common Types of Plants in a Home Garden.docx to help make the agent more expert and the game more challenging.</p> <p>Copy the absolute url of the site. For eg. <code>https://xyz.sharepoint.com/sites/contoso</code> and proceed to next step.</p> <p></p>"},{"location":"pages/make/agent-builder/01-first-agent/#step-2-add-support-for-sharepoint-online-documents","title":"Step 2: Add support for SharePoint Online documents","text":"<p>Go back to the list of agents, edit the Gardener agent and scroll to the configuration section with title Knowledge. Paste the URL of the SharePoint Online site in the field for providing a SharePoint knowledge base and hit ENTER or select the suggested site collection in the user interface. If you like, instead of pasting the URL, you can select the Sites button and search for the site in your tenant.</p> <p></p> <p>You will see the new SharePoint site in the list of knowledge bases for the Gardener agent. Now, update the agent and interact with it again. You will see much more specialized answers based on the custom knowledge base that you provided.</p> <p></p>"},{"location":"pages/make/agent-builder/01-first-agent/#exercise-4-final-touches-to-the-agent","title":"Exercise 4: Final touches to the agent","text":"<p>In this exercise you are going to add image generation capabilities to the Gardener agent and you will share it with your colleagues.</p>"},{"location":"pages/make/agent-builder/01-first-agent/#step-1-add-support-for-image-generation","title":"Step 1: Add support for image generation","text":"<p>Edit again the Gardener agent, scroll down in the configuration panel and find the section with title Capabilities. Enable the option with name Create images and update the agent.</p> <p></p> <p>After updating the agent, select Go to agent and provide the following prompt:</p> <pre><code>Generate the image of a dozen of red roses\n</code></pre> <p>In the following image you can see the output with a generated image.</p> <p></p> <p></p>"},{"location":"pages/make/agent-builder/01-first-agent/#step-2-share-the-agent","title":"Step 2: Share the agent","text":"<p>You are now ready to share the agent with your colleagues. Edit the agent one last time. In the upper right corner, just beside the Update button, there is the Share button. Select it and a sharing dialog pops up allowing you to select if you want to share the agent with any of the following targets:</p> <ul> <li>Anyone in your organization</li> <li>Specific users in your organization via security groups</li> <li>Only you</li> </ul> <p>Select the option to share with specific users and provide the e-mail of the sharing target, then select the Apply button to confirm your sharing settings. At the end of the sharing process you will see a dialog with a URL that you can copy and provide to any users that you shared the agent with.</p> <p></p> <p></p> <p>CONGRATULATIONS!</p> <p>Great job on making your agent \ud83c\udf89 ! This is the end of the Copilot Studio Lite path! Did you enjoy making the Gardener agent? Let us know about your experience and feedback. \ud83d\udc9c</p>"},{"location":"pages/make/agent-builder/01-first-agent/#resources","title":"Resources","text":"<ul> <li>Declarative agents</li> <li>Build agents with Copilot Studio Lite</li> <li>Publish and manage Copilot Studio Lite agents</li> </ul>"},{"location":"pages/make/copilot-studio/","title":"Lab MCS - Understanding Microsoft Copilot Studio","text":"<p>With Microsoft Copilot Studio you have the maximum potential for making custom agents. You can use it to create agents that you can host in multiple different channels like Microsoft Teams, custom web sites, Skype, Slack, etc. You can also host your agents in Microsoft 365 Copilot chat.</p> <p>Copilot Studio agents use the same infrastructure, orchestrator, foundation model, and security controls as Microsoft 365 Copilot, which ensures a consistent and familiar user experience.</p> <p></p> <p>The knowledge base can be:</p> <ul> <li>SharePoint Online</li> <li>OneDrive for Business</li> <li>Public web sites</li> <li>Microsoft Dataverse tables</li> <li>Power Platform connectors</li> <li>etc.</li> </ul> <p>Agents interact with users through topics, which can define single-turn or multi-turn conversations with the user. Every agent can have custom actions to interact with Power Automate flows, Power Platform connectors, external REST APIs, etc. Generally speaking, with Copilot Studio you can create really powerful agents without the need to write any line of code.</p> <p></p> <p>In order to use Copilot Studio, you need a user license (also known as per user license) for each user creating or maintaining an agent. Moreover, you need an organization level license for Copilot Studio (also known as tenant license). Starting December 1, 2024, Pay-As-You-Go is supported for Copilot Studio messages, which allows customers flexibility to only pay for the message capacity they consume.</p> <p>Do these labs if you want to build agents with Microsoft Copilot Studio</p> <ul> <li>MCS0 - Setup</li> <li>MCS1 - First agent</li> <li>MCS2 - Defining Topics</li> <li>MCS3 - Defining Tools</li> <li>MCS4 - Extending Microsoft 365 Copilot</li> <li>MCS5 - Consuming a custom connector</li> <li>MCS6 - Consuming an MCP server</li> <li>MCS7 - Creating Autonomous Agents</li> <li>MCS8 - Integrating Azure AI Search for RAG</li> <li>MCS9 - Connected Agents (Preview)</li> </ul>"},{"location":"pages/make/copilot-studio/#start-here-with-lab-mcs0-where-youll-set-up-your-environment-for-copilot-studio","title":"Start here with Lab MCS0, where you'll set up your environment for Copilot Studio.","text":""},{"location":"pages/make/copilot-studio/00-prerequisites/","title":"Lab MCS0 - Setup","text":"<p>In this lab, you'll setup and configure your Microsoft 365 tenant to start creating agents with Microsoft Copilot Studio. Copilot Studio is part of the Microsoft Power Platform offering and requires dedicated licensing, accordingly to the Microsoft Power Platform Licensing Guide.</p> Get a quick overview of the lab in this video. <p>Do these labs if you want to build agents with Microsoft Copilot Studio</p> <ul> <li>MCS0 - Setup</li> <li>MCS1 - First agent</li> <li>MCS2 - Defining Topics</li> <li>MCS3 - Defining Tools</li> <li>MCS4 - Extending Microsoft 365 Copilot</li> <li>MCS5 - Consuming a custom connector</li> <li>MCS6 - Consuming an MCP server</li> <li>MCS7 - Creating Autonomous Agents</li> <li>MCS8 - Integrating Azure AI Search for RAG</li> <li>MCS9 - Connected Agents (Preview)</li> </ul> <p>Set up your development environment for Microsoft 365 Copilot and Microsoft Copilot Studio</p> <p>This lab currently assumes you already have a developer tenant to setup. You can reference off to the page here that explains the current way you can get a tenant. It also assumes that you have a user account that is a Power Platform administrator, in order to being able to create a new Power Platform environment.</p> <p>In this lab you will learn:</p> <ul> <li>How to create a dedicated environment for your labs</li> <li>How to setup and configure Microsoft Copilot Studio</li> </ul> <p>Disclaimer</p> <p>These samples and labs are intended for instructive and demonstration purposes and are not intended for use in production. Do not put them into production without upgrading them to production quality.</p>"},{"location":"pages/make/copilot-studio/00-prerequisites/#exercise-1-creating-a-power-platform-environment","title":"Exercise 1 : Creating a Power Platform environment","text":"<p>With the Power Platform, you can create different environments and easily switch between them accordingly to your needs. An environment stores apps, flows, data, agents, etc. and each environment is completely isolated from any other environment. You can learn more about Power Platform environments reading this overview document.</p> <p>Power Platform administrative rights</p> <p>In order to proceed with the steps illustrated in this Exercise, you need a user account that is a Power Platform administrator in your target tenant. If you don't have such an account, ask to a Power Plaform administrator to create the environment for you and to give you access to that new environment.</p>"},{"location":"pages/make/copilot-studio/00-prerequisites/#step-1-creating-a-new-power-platform-environment","title":"Step 1: Creating a new Power Platform environment","text":"<p>To play with these labs you are going to create a new dedicated environment, so that at the end of this training path you can simply delete it and get rid of all the related resources and settings. Here follow the instructions to create an environment, step by step:</p> <ul> <li> <p>Open a browser and, using the work account of your target Microsoft 365 tenant, go to https://admin.powerplatform.com.</p> </li> <li> <p>Go to the 1\ufe0f\u20e3 Manage section, select the 2\ufe0f\u20e3 Environments panel and select 3\ufe0f\u20e3 + New to open the 4\ufe0f\u20e3 New environment pane</p> </li> </ul> <p></p> <ul> <li>Specify a unique name for the environment. For example, you could use \"Copilot Dev Camp\".</li> <li>Leave the default value (off) for the Make this a Managed Environment setting.</li> <li>Leave the Group setting blank</li> <li>Choose a Region accordingly to your needs.</li> <li>Leave the default value (off) for the Get new features early setting.</li> <li>Choose Developer for the Type setting.</li> </ul> <p>Understanding the environment types</p> <p>If you like, you can also choose Trial for the Type setting, so that you will have a fully functional environment that will last for 30 days and then will get automatically deleted. Here you can find additional information about Trial environments. Moreover, here you can find a detailed explanation of all the available environment types.</p> <ul> <li>Leave all the other settings as they are.</li> <li>Select Next.</li> <li>Choose a Language and a Currency, or leave the default ones.</li> </ul> <p></p> <ul> <li>Leave all the other settings as they are and select Save to create the actual environment.</li> </ul> <p>The new environment will take a while to be ready, as you can notice from the list of environments in the Power Platform Admin center.</p> <p></p> <p>Once the new environment will be ready, the list of environments will show the information accordingly.</p> <p></p> <p></p>"},{"location":"pages/make/copilot-studio/00-prerequisites/#exercise-2-microsoft-copilot-studio","title":"Exercise 2 : Microsoft Copilot Studio","text":"<p>In order to use Microsoft Copilot Studio you need to have a valid license and you need to activate it in the target tenant where you want to use it.</p> <p>Microsoft Copilot Studio licensing</p> <p>There are multiple options to have a licensed access to Microsoft Copilot Studio. We suggest you to refer to the Power Platform Licensing Guide.</p>"},{"location":"pages/make/copilot-studio/00-prerequisites/#step-1-activating-microsoft-copilot-studio","title":"Step 1: Activating Microsoft Copilot Studio","text":"<p>To activate Copilot Studio follow these steps:</p> <ul> <li> <p>Open a browser and, using the work account of your target Microsoft 365 tenant, go to https://copilotstudio.microsoft.com.</p> </li> <li> <p>If this is the very first time you run Copilot Studio and if you don't have a license, you will see the following screen and you will be able to start a trial period.</p> </li> </ul> <p></p> <p>Copilot Studio free trial period</p> <p>You can get additional information about the free trial license for Copilot Studio by reading this document.</p> <ul> <li>Select the 1\ufe0f\u20e3 Environment section in the upper right corner of the screen and choose the environment 2\ufe0f\u20e3 that you created in Exercise 1.</li> </ul> <p></p> <ul> <li>Copilot Studio will reload and you will then be ready to start using it in the new environment.</li> </ul> <p></p> <p>CONGRATULATIONS!</p> <p>Now you are all set to create your first agent with Copilot Studio. </p> <p>Start here with Lab MCS1, to create your first agent with Copilot Studio. </p> <p></p>"},{"location":"pages/make/copilot-studio/01-first-agent/","title":"Lab MCS1 - First agent","text":"<p>In this lab, you'll create your first agent with Microsoft Copilot Studio. The agent that you are going to create helps users to find information about HR policies and processes to hire or layoff employees, to improve your career, and to define learning pathways. The knowledge base of the agent will be a set of documents stored in SharePoint Online and some public web content.</p> <p>In this lab you will learn:</p> <ul> <li>How to create an agent with Copilot Studio</li> <li>How to configure a custom icon for your agent</li> <li>How to configure knowledge sources for your agent</li> <li>How to publish your agent in Microsoft Teams</li> </ul> Get a quick overview of the lab in this video. <p>Do these labs if you want to build agents with Microsoft Copilot Studio</p> <ul> <li>MCS0 - Setup</li> <li>MCS1 - First agent</li> <li>MCS2 - Defining Topics</li> <li>MCS3 - Defining Tools</li> <li>MCS4 - Extending Microsoft 365 Copilot</li> <li>MCS5 - Consuming a custom connector</li> <li>MCS6 - Consuming an MCP server</li> <li>MCS7 - Creating Autonomous Agents</li> <li>MCS8 - Integrating Azure AI Search for RAG</li> <li>MCS9 - Connected Agents (Preview)</li> </ul> <p>Disclaimer</p> <p>These samples and labs are intended for instructive and demonstration purposes and are not intended for use in production. Do not put them into production without upgrading them to production quality.</p>"},{"location":"pages/make/copilot-studio/01-first-agent/#exercise-1-creating-an-agent-with-copilot-studio","title":"Exercise 1 : Creating an agent with Copilot Studio","text":"<p>In this first exercise you are going to create a new agent using Generative AI and describing what you are looking for. You are also going to configure a custom icon for the agent and to test the agent.</p>"},{"location":"pages/make/copilot-studio/01-first-agent/#step-1-creating-a-new-agent","title":"Step 1: Creating a new agent","text":"<p>To create a new agent, open a browser and, using the work account of your target Microsoft 365 tenant, go to https://copilotstudio.microsoft.com to start using Microsoft Copilot Studio.</p> <p>Select Create an agent command in the middle of the screen, like illustrated in the following screenshot.</p> <p></p> <p>You can achieve the same result also selecting Agents on the left side of the screen and then selecting + Create blank agent in the upper right side of the screen.</p> <p></p> <p>After waiting a little while, you will be redirected to the page from which you can configure a newly created agent. From here you can configure all the settings of your agent, like for example:</p> <ul> <li>Name</li> <li>Icon</li> <li>Description</li> <li>Model</li> <li>Triggers</li> <li>Instructions</li> <li>Knowledge</li> <li>Web Search</li> <li>Tools</li> <li>Agents</li> <li>Topics</li> <li>Suggested prompts</li> </ul> <p></p> <p>Select the Edit command in the upper right corner of the Details section and give the name \"HR Agent\" to your custom agent. Then, provide the following value for the Description field:</p> <pre><code>You help employees to find information about HR related policies\n</code></pre> <p></p> <p>Select the Save command in the upper right corner of the Details section, when you are done with the changes. Now, leave the suggested model as GPT-4.1 (Default) and select the Edit command in the upper right corner of the Instructions section. Provide the following content for the instructions:</p> <pre><code>- Provide employees with clear, accurate information about HR policies and procedures.\n- Guide users on career improvement strategies and help define personalized learning pathways.\n- Emphasize and support team building, inclusion, and the growth mindset in all interactions.\n- Maintain a professional tone in every response, ensuring respectful and helpful communication.\n- Avoid speculation and only provide information based on available resources or knowledge sources.\n- Do not answer questions unrelated to HR, career development, or learning pathways.\n- Encourage users to explore training, development, and inclusive practices.\n- Respond promptly and clearly to all user queries.\n</code></pre> <p>Select Save in the upper right corner of the Instructions section.</p> <p></p> <p>Scroll down to the Knowledge section and select the + Add knowledge command to add an initial data source for your agent.</p> <p></p> <p>Then select Public website and provide the following URL in the dialog that will show up:</p> <pre><code>https://careers.microsoft.com/\n</code></pre> <p></p> <p>Then select Add to add the URL to the list of knowledge bases, provide a name and a description for the new site, like for example:</p> <ul> <li>Name: </li> </ul> <pre><code>Microsoft Careers site\n</code></pre> <ul> <li>Description: </li> </ul> <pre><code>A public website for careers with information about benefits, culture, diversity and inclusion, and hiring tips.\n</code></pre> <p></p> <p>Important</p> <p>In this sample agent, we are going to use some of the public content available on the Careers website of Microsoft as the data source. Feel free to use any other public website of your choice, as long as it covers content related to HR and careers.</p> <p>You are now ready with the basic configuration of your agent. You can now start testing your agent using the testing panel on the right side, or you can fine tune the agent settings using the configuration options in the Overview tab.</p> <p></p>"},{"location":"pages/make/copilot-studio/01-first-agent/#step-2-changing-the-agents-icon","title":"Step 2: Changing the agent's icon","text":"<p>Let's start changing the icon of the agent by selecting the Edit button in the upper right corner of the Details section in the Overview tab, like in the following screen.</p> <p></p> <p>Select the Change icon button to show a dialog from where you can upload a custom icon. If you like, you can use the following icon.</p> <p></p> <p>Once you are done with the upload of the new icon, select the Save button.</p> <p></p>"},{"location":"pages/make/copilot-studio/01-first-agent/#step-3-testing-the-agent","title":"Step 3: Testing the agent","text":"<p>To test the agent you simply rely on the right panel and start writing prompts. For example, let's provide the following prompt:</p> <pre><code>What is our mission?\n</code></pre> <p>In the following screenshot you can see the answer provided by the agent and based on the content of the website that we provided as the data source. You can also notice, in the main part of the screen, that the agent relied on the knowledge base that you just configured.</p> <p></p> <p>Notice also that the agent provides references to pages from the websites provided as the data source.</p> <p></p>"},{"location":"pages/make/copilot-studio/01-first-agent/#exercise-2-extending-the-knowledge-base","title":"Exercise 2 : Extending the knowledge base","text":"<p>In this exercise you are going to add some documents (Word and PDF) stored in Microsoft SharePoint Online as additional knowledge base to your agent. </p>"},{"location":"pages/make/copilot-studio/01-first-agent/#step-1-adding-sharepoint-online-knowledge-base-documents","title":"Step 1: Adding SharePoint Online knowledge base documents","text":"<p>Download this zip file consisting of few files (Word, PowerPoint, PDF) by selecting this link.</p> <p>Extract the files from the zip and upload them to the Documents library of a SharePoint Teams site in the same tenant where you are making your agent with Copilot Studio. These documents were generated by Microsoft 365 Copilot for the sake of having some additional knowledge base to feed the agent.</p> <p>Copy the absolute url of the site. For example: <code>https://xyz.sharepoint.com/sites/contoso</code></p> <p></p> <p>From the Overview tab of the agent that you made before, scroll to the Knowledge section. You will find the website that you configured in Step 1 of Exercise 1. Select + Add knowledge to add the SharePoint site and its documents as an additional knowledge source.</p> <p></p> <p>From the dialog window that pops up you can add additional knowledge sources like:</p> <ul> <li>Files: to manually upload files that will become part of the knowledge base</li> <li>Public websites: to add additional websites</li> <li>SharePoint: to configure sites or libraries in SharePoint Online</li> <li>Azure AI Search: to consume indexes of Azure AI Search</li> <li>Dataverse: to add tables in Dataverse</li> <li>and more ...</li> </ul> <p>Select SharePoint and, in the dialog popping up, provide the URL of the site where you uploaded the files and select Add. You can also browse for the document library you are looking for, selecting the Browse items command just beside the URL textbox.</p> <p></p> <p>When you configure a SharePoint data source, you also need to specify a Name and a Description. It is fundamental to provide a meaningful name and description. In fact, Copilot Studio will be able to better understand what's inside the data source and, when in the upcoming labs you will enable generative orchestration, it will be possible to identify the right data source to use when answering to users' prompts via generative AI. For this exercise you can use the following values:</p> <ul> <li>Name: </li> </ul> <pre><code>HR Documents\n</code></pre> <ul> <li>Description: </li> </ul> <pre><code>Provides documents about policies, procedures, and rules related to the HR department.\n</code></pre> <p></p> <p>Select the Add to agent button in the lower part of the screen and wait for Copilot Studio to process the new knowledge base that you just added.</p> <p>When the knowledge base will be updated, in the Overview tab you will see both the public website and the SharePoint Online site.</p> <p></p> <p>Important</p> <p>When configuring SharePoint Online sites as the knowledge base for an agent in Copilot Studio, users will only be able to get answers and content from documents that they have access to. The security and the access control are guaranteed by the Microsoft 365 security infrastructure and Copilot Studio agents access documents on behalf of the current user.</p> <p></p>"},{"location":"pages/make/copilot-studio/01-first-agent/#step-2-testing-the-updated-agent","title":"Step 2: Testing the updated agent","text":"<p>Now you can test again the agent, using the right side panel. For example, let's provide the following prompt:</p> <pre><code>How can we hire new people in our company?\n</code></pre> <p>The agent will reply back with information about the hiring procedures and providing references to the documents stored in the SharePoint Online knowledge base that you provided, as well as to the public web site that you referenced in the knowledge base.</p> <p></p> <p>Now, for the sake of completeness, try to provide the following prompt to the agent:</p> <pre><code>How can I cook spaghetti alla carbonara?\n</code></pre> <p>You will notice that, despite spaghetti alla carbonara is always a good choice \ud83c\udf5d, the agent will not give you back an answer. In fact, by default the agent will stick with the instructions and knowledge sources that you configured for it. It is a specialized agent, fully focused on HR-related content.</p> <p></p> <p></p>"},{"location":"pages/make/copilot-studio/01-first-agent/#exercise-3-publishing-the-agent","title":"Exercise 3 : Publishing the agent","text":"<p>In this final exercise of this lab you are going to publish your custom agent in Microsoft Teams.</p>"},{"location":"pages/make/copilot-studio/01-first-agent/#step-1-publishing-the-agent-in-microsoft-teams","title":"Step 1: Publishing the agent in Microsoft Teams","text":"<p>To publish an agent made with Copilot Studio you need to select the Publish button in the upper right corner of the agent editor.</p> <p></p> <p>Selecting the command will prompt you for confirmation. While confirming the publishing, you can also choose if you want to Force newest version, which ensures users in Teams receive your latest updates right away. Once confirmed, the publishing process takes a while and in the meantime you see a \"Publishing ...\" message. Publishing an agent registers it in the target Power Platform environment, but does not make it available in any target platform.</p> <p>In order to make the agent actually available in a specific target platform (channel), you need to 1\ufe0f\u20e3 select the Channels tab in the agent editor and then you can choose one or more target channels to make the agent available for. For example, to publish the agent in Microsoft Teams, as a bot, you need to 2\ufe0f\u20e3 select Teams + Microsoft 365 as the target channel.</p> <p></p> <p>By default, when you make and agent and publish it with default settings, the agent will be configured for Microsoft authentication, which means that the agent will rely on Microsoft Entra ID authentication in Teams, Power Apps, or Microsoft 365 Copilot. With the default authentication settings, the agent can only be published in Microsoft Teams and Microsoft 365 Copilot and SharePoint channels, as you can notice from the warning message displayed at the top of the Channels tab in the previous screenshot. </p> <p>Copilot Studio Authentication model</p> <p>You can learn more about authentication of agents in Copilot Studio reading the document Configure user authentication in Copilot Studio.</p> <p>Premium license for Microsoft Copilot Studio</p> <p>In the screenshot above, there is also an information bar about the licensing model and the potential requirement of a Premium license. In fact, when you use Copilot Studio  and you rely on premium features like premium connectors, you need to upgrade your license accordingly. Luckily, if you are just learning and testing with Microsoft Copilot Studio, you can activate a 60-days free trial period with the Premium license.</p> <p>When you select the Teams and Microsoft 365 channel a side panel shows up and allows you to select the Add channel button.</p> <p></p> <p>Once the agent is enabled on the Microsoft Teams channel, the side panel updates and shows a confirmation message, as well as few commands to edit the agent details and to open the agent in the Microsoft Teams client. There will also be a button Availability options that you can select to see the various options you have to access the agent in Microsoft Teams.</p> <p>If you registered the channel to support Microsoft 365 Copilot, you can also select the link See agent in Microsoft 365 to access the agent directly in the Microsoft 365 Copilot chat user experience.</p> <p></p> <p>Selecting the Availability options button you can:</p> <ul> <li>Copy a link to use the agent in Microsoft Teams</li> <li>Download a ZIP file with a package that you can upload to the Teams app store</li> <li>Make the agent available in the Teams app store, choosing if it will be available to the whole organization or just to selected users</li> </ul> <p></p> <p>Publishing of the agent in Microsoft Temas is now completed.</p> <p></p>"},{"location":"pages/make/copilot-studio/01-first-agent/#step-2-testing-the-agent-in-microsoft-teams","title":"Step 2: Testing the agent in Microsoft Teams","text":"<p>You are now ready to test the agent in Microsoft Teams. In the Availability options panel select the Copy link button to copy a link to the agent. Then open a new browser tab and paste the just copied link, then press ENTER to browse to that URL.</p> <p></p> <p>Initially you will see the Microsoft Teams client showing a new app that represents your agent. Select the Add button to add the app to your client and the select Open in the following dialog.</p> <p></p> <p>After a while, the Microsoft Teams client will show a chat with a bot, which is actually your agent. Provide a prompt, for example the one you already used before:</p> <pre><code>How can we hire new people in our company?\n</code></pre> <p>Wait for the answer and you will see that the agent will reply back to you with content in the context of HR and with references to the documents that are part of its knowledge base.</p> <p></p> <p>Notice also the disclaimer, at the top of the answer, about the fact that the provided content is \"AI generated\" to make the user aware that she/he is consuming an AI platform.</p> <p></p> <p>CONGRATULATIONS!</p> <p>Now your agent is fully functional and ready to be used in Microsoft Teams. In the next labs you will be able to customize and fine tune its behavior.</p> <p>Start here with Lab MCS2, to define topics in your agent with Copilot Studio. </p> <p></p>"},{"location":"pages/make/copilot-studio/02-topics/","title":"Lab MCS2 - Defining Topics","text":"<p>In this lab, you'll learn how to create custom Topics in Microsoft Copilot Studio. Topics are core building blocks of an agent. With topics you can provide a conversational experience to your end users, where the conversation can be single-turn or multi-turn. Topics define how the conversation between the user and the agent can evolve, through discrete interaction paths.</p> Get a quick overview of the lab in this video. <p>Do these labs if you want to build agents with Microsoft Copilot Studio</p> <ul> <li>MCS0 - Setup</li> <li>MCS1 - First agent</li> <li>MCS2 - Defining Topics</li> <li>MCS3 - Defining Tools</li> <li>MCS4 - Extending Microsoft 365 Copilot</li> <li>MCS5 - Consuming a custom connector</li> <li>MCS6 - Consuming an MCP server</li> <li>MCS7 - Creating Autonomous Agents</li> <li>MCS8 - Integrating Azure AI Search for RAG</li> <li>MCS9 - Connected Agents (Preview)</li> </ul> <p>Note</p> <p>This lab builds on the previous one, Lab MCS1. You should be able to continue working on the same agent, improving its functionalities with new capabilities.</p> <p>Topics can be created with a graphical designer or describing the intent with natural language. Once you have created a new Topic, you can also edit its definition with a low level code editor, in case you need to apply detailed fine tuning.</p> <p>There are two different flavors of Topics:</p> <ul> <li>System Topics: automatically defined by Microsoft Copilot Studio. Can be disabled, but cannot be deleted.</li> <li>Custom Topics: created by agent authors to provide custom interaction paths.</li> </ul> <p>Additional information about topics</p> <p>You can find additional information about Topics in agents made with Microsoft Copilot Studio reading the following article. You can also dig into the System Topics reading the article Use system topics.</p> <p>In this lab you will learn:</p> <ul> <li>How to rely on Orchestration based on generative AI</li> <li>How to create a single-turn topic</li> <li>How to create a multi-turn topic</li> <li>How to use adaptive cards to interact with users</li> </ul>"},{"location":"pages/make/copilot-studio/02-topics/#exercise-1-orchestration-based-on-generative-ai","title":"Exercise 1 : Orchestration based on Generative AI","text":"<p>In this first exercise you are going to enable the agent that you created in Lab MCS1 to use Orchestration based on Generative AI, which is a new feature under preview at the time of this writing.</p>"},{"location":"pages/make/copilot-studio/02-topics/#step-1-understanding-generative-ai-orchestration","title":"Step 1: Understanding generative AI orchestration","text":"<p>One important feature of an agent made with Copilot Studio, is generative orchestration. With generative orchestration, your agent can choose the best knowledge base, topics, and actions to use to interact with the user and answer to the user's queries, or to respond to event triggers. </p> <p>Nowadays and by default, Copilot Studio agents use generative AI orchestration, which means that Copilot Studio understands the intent of the user processing the prompt provided by the user in natural language and determines the best item to trigger. If you like, you can revert the agent back to classic orchestration, where an agent responds to users by triggering a topic whose trigger phrases match most closely the user's query.</p> <p>In Copilot Studio, you can also enable Deep reasoning (which is a preview feature) to enable advanced reasoning for AI actions.</p> <p>To configure orchestration and deep reasoning, open a browser and, using the work account of your target Microsoft 365 tenant, go to https://copilotstudio.microsoft.com to start using Microsoft Copilot Studio.</p> <p>Select to view the list of 1\ufe0f\u20e3 Agents and then 2\ufe0f\u20e3 edit the agent that you created in the previous Lab MCS1.</p> <p></p> <p>Select the Settings command in the upper right corner of the screen like illustrated in the following screenshot.</p> <p></p> <p>The first section of settings is the Orchestration one, from where you can choose between generative AI orchestration and classic orchestration, as well as you can enable Deep reasoning. It usually takes a while to update the orchestration settings. Once the setting is applied, close the settings window and publish the agent to confirm the changes.</p> <p></p> <p>In this lab you stick with generative AI orchestration, to enjoy the beauty of generative AI, and you don't need to enable Deep reasoning.</p> <p></p>"},{"location":"pages/make/copilot-studio/02-topics/#exercise-2-creating-a-single-turn-topic","title":"Exercise 2 : Creating a single-turn topic","text":"<p>In this exercise you are going to create a new topic to collect an input from the user and to provide a feedback based on the collected input. Specifically, the topic collects information about the current user's role and gives back guidance about what to do with the agent based on the provided role.</p>"},{"location":"pages/make/copilot-studio/02-topics/#step-1-creating-a-new-single-turn-topic","title":"Step 1: Creating a new single-turn topic","text":"<p>To create a new topic, in the upper side of the screen select the 1\ufe0f\u20e3 Topics tab, then select 2\ufe0f\u20e3 + Add a topic, and then 3\ufe0f\u20e3 From blank to start creating a new custom topic.</p> <p>Creating topics with Copilot</p> <p>Notice that you can also create a new topic simply providing a description with natural language, allowing Copilot to draft the topic for you.</p> <p></p> <p>Copilot Studio will provide you the graphical designer to define the new topic. The very first building block of the topic is the Trigger action, which is used to describe what the topic does. When generative orchestration is enabled, in the action you can find a text area where you can define with natural language what the purpose of the topic is. For the sake of working on this lab, you can provide the following content:</p> <pre><code>This topic can handle queries like these: collect user's role and provide feedback, \ngive me a feedback based on my role, what's your feedback for my role?\n</code></pre> <p>If you use classic orchestration, you can specify between 5 and 10 triggering phrases or sentences, instead of a single descriptive text.</p> <p></p> <p></p>"},{"location":"pages/make/copilot-studio/02-topics/#step-2-collecting-users-input","title":"Step 2: Collecting user's input","text":"<p>Select the + button in the middle of the screen to add new actions or steps to the current topic. By selecting the + button, a list of all the available actions appears. The main options are:</p> <ul> <li>Send a message: to send a message to the user. The message can be text, an image, a video, an adaptive card, etc.</li> <li>Ask a question: to ask an input to the user. The input can be text, an image, a video, an attachment, an adaptive card, etc.</li> <li>Ask with adaptive card: to collect content from the user utilizing an Adaptive Card.</li> <li>Add a condition: to add branches to the topic based on comparison between variables and/or constant values.</li> <li>Variable management: to manage variables, which can be scoped at topic level, global, system, or environment.</li> <li>Topic management: to manage the lifecycle of the current topic.</li> <li>Add an tool: to consume external tools like Power Automate flows, custom connectors, MCP tools, etc.</li> <li>Add an agent: to add an agent in a multi-agent scenario.</li> <li>Advanced: to provide advanced capabilities like consuming an external HTTP REST API, using generative answers, sending events or activities, etc.</li> </ul> <p></p> <p>In order to collect user's input, add an Ask a question action. Since we want to ask the user what her/his role is, let's provide the following value for the question text.</p> <pre><code>What is your role?\n</code></pre> <p>Notice that by default Copilot Studio assigns a <code>Multiple choice options</code> data type to the collected input, as highlighted in the Identify configuration field. Select the + New option command just below the Identify configuration field and add one by one the following three values:</p> <ul> <li>Candidate</li> <li>Employee</li> <li>HR staff member</li> </ul> <p>The action automatically stores the value selected by the user into a variable stored at topic-level. You can select the three dots in the upper right corner of the action and select the Properties command to customize the action, or you can select the variable in the lower part of the action to update its name and other settings.</p> <p></p> <p>For example, you can rename the variable to <code>UserRole</code>. You can see how the action looks like once it is fully configured.</p> <p></p> <p></p>"},{"location":"pages/make/copilot-studio/02-topics/#step-3-providing-feedback-to-the-user","title":"Step 3: Providing feedback to the user","text":"<p>Now select the + button in the middle of the screen to Add a condition. In the branch on the left side, select the Select a variable option, and select the userRole variable that you created in the previous step. Then select the value for the condition, so that the condition will be like <code>userRole is equal to Candidate</code>. Repeat the previous instructions two more times to provide conditions for <code>userRole is equal to Employee</code> and <code>userRole is equal to HR staff member</code>. Leave the last condition for <code>All other conditions</code>.</p> <p>Inside each branch, you can specify some custom logic to provide a specialized feedback to the user. To do so, select the + command below each of the Condition branches and add one action of type Send a message. You can eventually add more than one action to each branch.</p> <p>For the three branches, you could for example provide the following feedback messages:</p> <ul> <li>Candidate</li> </ul> <pre><code>You are a new candidate, as such you can submit your resume for evaluation.\n</code></pre> <ul> <li>Employee</li> </ul> <pre><code>As an employee, you can ask me about how to improve your career or about \nhow to learn more about your growth mindset.\n</code></pre> <ul> <li>HR staff member</li> </ul> <pre><code>As an HR staff member, you can manage the list of candidates and all the hiring procedures.\n</code></pre> <p>For the <code>All other conditions</code> branch, you can configure a Redirect action, available under the Topic management group, to fallback to the System Topic with name Fallback.</p> <p></p> <p>The very simple logic of the topic is now ready.</p> <p></p>"},{"location":"pages/make/copilot-studio/02-topics/#step-4-ending-the-current-topic","title":"Step 4: Ending the current topic","text":"<p>To properly complete the flow of the custom topic, add a new action of type End current topic, which is available under the Topic management group. This last action will instruct Copilot Studio about the fact that your topic conversation is completed.</p> <p></p> <p></p>"},{"location":"pages/make/copilot-studio/02-topics/#step-5-testing-the-current-topic","title":"Step 5: Testing the current topic","text":"<p>You are now ready to save and test the topic. Select the Save button in the upper right corner of the designer, provide a name for the topic through the dialog window that will appear, and select the Save button again.</p> <p></p> <p>For example, name the topic as <code>Collect user's role</code>. Now open the test panel by selecting the Test command in the upper right corner of the designer. Type the following prompt:</p> <pre><code>What's your feedback for my role?\n</code></pre> <p>The agent will prompt you to choose a role and, based on your selection, you will get a specific feedback like illustrated in the following screenshot.</p> <p></p> <p>Exercise 2 is now completed, well done! You can now move to Exercise 3 to create a multi-turn topic.</p> <p></p>"},{"location":"pages/make/copilot-studio/02-topics/#exercise-3-creating-a-multi-turn-topic","title":"Exercise 3 : Creating a multi-turn topic","text":"<p>For simple interactions, you create single-turn conversations with just one question and one answer. But more substantive topics require a multi-turn conversation with multiple back-and-forth interactions between the user and the agent. In this exercise, you are going to create a multi-turn topic to collect data about a potential candidate for a new role.</p>"},{"location":"pages/make/copilot-studio/02-topics/#step-1-creating-a-new-multi-turn-topic","title":"Step 1: Creating a new multi-turn topic","text":"<p>Imagine that you want to create a topic to collect the following information about a new candidate:</p> <ul> <li>First name</li> <li>Last name</li> <li>E-mail</li> <li>Current role</li> </ul> <p>To collect the above information, create a new topic following the instructions provided in Exercise 2 Step 1. The Trigger description for the topic could be:</p> <pre><code>This topic helps to collect information about a new candidate to process. Trigger sentences can be: \nregister a new candidate, create a new candidate, add a new candidate.\n</code></pre> <p>Then, for each of the above information fields, you need to prompt the user with an action of type Ask a question. However, in this exercise the value of the answer will vary depending on the requested field. For example: first name, last name, and current role will be simple text fields., while the e-mail field will need to be a valid e-mail.</p> <p>So for the first name, last name, and current role fields you can select the Identify property of the Ask a question action and you can select User's entire response as the actual entity type. This will get the text value provided by the user as the actual collected value. The variable type will be automatically updated to be a <code>string</code> by Copilot Studio. Give a meaningful name to each of the variables holding the values provided by the user. In the following screenshot you can see how the first name input action can be defined. You can do the same for last name and current job role.</p> <p></p> <p>For the e-mail field, choose Email as the entity for the Identify property, so that Copilot Studio will automatically validate the user's input against the e-mail validation rules. The underlying variable will still be a <code>string</code>.</p> <p></p> <p>Now you are ready to collect all of the information about the candidate and you can give a feedback to the user.</p> <p></p>"},{"location":"pages/make/copilot-studio/02-topics/#step-2-giving-a-feedback-to-the-user","title":"Step 2: Giving a feedback to the user","text":"<p>Based on the collected input, you can now send a message to the user confirming the collected data. Add a new action of type Send a message and build the content of the message using the variables where the collected inputs were stored. To add variables to the message, simply select the {x} command in the toolbar of the Send a message action and select the variable that you are looking for.</p> <p></p> <p>You can insert variables defined in the current topic, system variables, or environment variables. Once you have configured the recap message with all the variables, it should look like the following screenshot.</p> <p></p> <p>Just for the sake of having a final confirmation from the user, insert an action of type Ask a question, provide the following message:</p> <pre><code>Is it ok for you to insert this new candidate?\n</code></pre> <p>And configure the action to support the answers <code>Yes</code> and <code>No</code>. As like as it happened in Exercise 2 Step 3, you can now configure the various branches for each of the outcomes. For the sake of simplicity, you can simply rely on a couple of Send a message actions, one for each branch, and put a thumb up or a thumb down emoji as the actual content on the message, depending on the user's feedback. Lastly, add an action of type End current topic to complete the topic.</p> <p></p> <p>You can now save the topic, give it a name like for example <code>Register a new candidate</code> and test it in the integrated testing interface. Here follows a screenshot of the interaction with the multi-turn topic. You can also notice that when the value provided for the e-mail field is not correct, Copilot Studio automatically re-prompts the user to provide a correct value.</p> <p></p> <p></p>"},{"location":"pages/make/copilot-studio/02-topics/#exercise-4-using-adaptive-cards","title":"Exercise 4 : Using Adaptive Cards","text":"<p>Collecting inputs using multiple instances of Ask a question actions is definitely one option that you have. However, when you need to collect a lot of data or when you want to have a nice looking interaction with the user you can consider using an Adaptive Card.</p> What are Adaptive Cards?  Adaptive Cards are platform-independent UI snippets authored in JSON that can be exchanged between apps and services. Once delivered to an app, the JSON transforms into native UI that automatically adapts to its environment. This enables the design and integration of lightweight UI across major platforms and frameworks.      Adaptive cards are everywhere"},{"location":"pages/make/copilot-studio/02-topics/#step-1-collecting-input-with-adaptive-cards","title":"Step 1: Collecting input with Adaptive Cards","text":"<p>Imagine that you want to create yet another topic to collect the following information about a new candidate:</p> <ul> <li>First name</li> <li>Last name</li> <li>E-mail</li> <li>Current role</li> <li>Spoken languages</li> <li>Skills</li> </ul> <p>Specifically, spoken languages and skills are multi-select lists of values.</p> <p>So open the Topics tab, and disable the topic that you created in Exercise 3 to avoid any overlapping of trigger conditions. Then, create a new topic following the instructions provided in Exercise 2 Step 1. The Trigger description for the topic could be:</p> <pre><code>This topic helps to collect information about a new candidate to process. Trigger sentences can be: \nregister a new candidate, create a new candidate, add a new candidate.\n</code></pre> <p>Now add a new action of type Ask with adaptive card, 1\ufe0f\u20e3 select the body of the new action and 2\ufe0f\u20e3 then select the button Edit adaptive card. Then type the following JSON into the Card payload editor of the Adaptive card designer of the action.</p> <p></p> <pre><code>{\n    \"type\": \"AdaptiveCard\",\n    \"body\": [\n        {\n            \"type\": \"TextBlock\",\n            \"size\": \"Medium\",\n            \"weight\": \"Bolder\",\n            \"text\": \"New HR Candidate Information\"\n        },\n        {\n            \"type\": \"Input.Text\",\n            \"id\": \"firstname\",\n            \"placeholder\": \"First Name\"\n        },\n        {\n            \"type\": \"Input.Text\",\n            \"id\": \"lastname\",\n            \"placeholder\": \"Last Name\"\n        },\n        {\n            \"type\": \"Input.Text\",\n            \"id\": \"email\",\n            \"placeholder\": \"Email\"\n        },\n        {\n            \"type\": \"Input.Text\",\n            \"id\": \"current_role\",\n            \"placeholder\": \"Current Role\"\n        },\n        {\n            \"type\": \"Input.ChoiceSet\",\n            \"id\": \"spoken_languages\",\n            \"placeholder\": \"Spoken Languages\",\n            \"isMultiSelect\": true,\n            \"choices\": [\n                {\n                    \"title\": \"English\",\n                    \"value\": \"English\"\n                },\n                {\n                    \"title\": \"French\",\n                    \"value\": \"French\"\n                },\n                {\n                    \"title\": \"German\",\n                    \"value\": \"German\"\n                },\n                {\n                    \"title\": \"Italian\",\n                    \"value\": \"Italian\"\n                },\n                {\n                    \"title\": \"Portuguese\",\n                    \"value\": \"Portuguese\"\n                },\n                {\n                    \"title\": \"Spanish\",\n                    \"value\": \"Spanish\"\n                }\n            ]\n        },\n        {\n            \"type\": \"Input.ChoiceSet\",\n            \"id\": \"skills\",\n            \"placeholder\": \"Skills\",\n            \"isMultiSelect\": true,\n            \"choices\": [\n                {\n                    \"title\": \"Computer Programming\",\n                    \"value\": \"Computer Programming\"\n                },\n                {\n                    \"title\": \"Project Management\",\n                    \"value\": \"Project Management\"\n                },\n                {\n                    \"title\": \"Team Lead\",\n                    \"value\": \"Team Lead\"\n                }\n            ]\n        }\n    ],\n    \"actions\": [\n        {\n            \"type\": \"Action.Submit\",\n            \"title\": \"Submit\"\n        }\n    ],\n    \"$schema\": \"http://adaptivecards.io/schemas/adaptive-card.json\",\n    \"version\": \"1.5\"\n}\n</code></pre> <p>Once you updated the JSON of the adaptive card, Copilot Studio renders the preview of the card in the UI of the topic designer, as you can see in the following screenshot. Copilot Studio also automatically defines a set of topic-level variables to collect the values provided by the user.</p> <p></p> <p></p>"},{"location":"pages/make/copilot-studio/02-topics/#step-2-providing-feedback-with-adaptive-cards","title":"Step 2: Providing feedback with Adaptive Cards","text":"<p>You can now use an adaptive card also to provide feedback to the user, showing a recap of the collected data. Select the + command to add a new action of type Send a message. Then select + Add in the upper left corner of the new action and select Adaptive card to switch to a message of type adaptive card.</p> <p></p> <p>A side panel shows up allowing you to select the Edit adaptive card command and to define the content of the adaptive card. Copy and paste the following JSON into the Card payload editor of the Adaptive card designer.</p> <pre><code>{\n  \"type\": \"AdaptiveCard\",\n  \"body\":\n    [\n      {\n        \"type\": \"TextBlock\",\n        \"size\": \"Medium\",\n        \"weight\": \"Bolder\",\n        \"text\": \"Candidate Summary\"\n      },\n      {\n        \"type\": \"FactSet\",\n        \"facts\":\n          [\n            { \"title\": \"First Name:\", \"value\": \"firstname\" },\n            { \"title\": \"Last Name:\", \"value\": \"lastname\" },\n            { \"title\": \"Email:\", \"value\": \"email\" },\n            { \"title\": \"Current Role:\", \"value\": \"current_role\" },\n            { \"title\": \"Spoken Languages:\", \"value\": \"spoken_languages\" },\n            { \"title\": \"Skills:\", \"value\": \"skills\" }\n          ]\n      }\n    ],\n  \"$schema\": \"http://adaptivecards.io/schemas/adaptive-card.json\",\n  \"version\": \"1.3\"\n}\n</code></pre> <p>It is very important that, when pasting the JSON of the adaptive card, you have the Edit JSON option selected (which is by the way the default one) at the top of the text area. That means that you are editing the actual JSON of the adaptive card. As soon as you will move the focus out of the text area where you pasted the JSON, the Send a message action will start previewing the adaptive card. As you can see the adaptive card is rendering static values for all the variables (firstname, lastname, etc.).</p> <p></p> <p>Now, select the drop down with JSON Card and switch to Formula Card in order to replace the static values with the actual variables defined in the current Topic.</p> <p></p> <p>Select the button to expand the editor and you can start replacing the static values with formulas that will refer to the actual value of the topic-level variables.</p> <p></p> <p>You will see a dialog popping up and providing an advanced editor with intellisense helping you to reference variables and PowerFx functions, like illustrated in the following screenshot.</p> <p></p> <p>One by one, you can replace all the static values with the actual variables. In particular, the spoken languages and the skills are list of values (variables of type <code>Table</code>) so, in order to render their value, you need to rely on the PowerFx <code>Concat</code> function and then on the PowerFx <code>Text</code> function to convert the result into an actual string. Here you can find the content of the adaptive card JSON when all the formulas are in place.</p> <pre><code>{\n  type: \"AdaptiveCard\",\n  body: [\n    {\n      type: \"TextBlock\",\n      size: \"Medium\",\n      weight: \"Bolder\",\n      text: \"Candidate Summary\"\n    },\n    {\n      type: \"FactSet\",\n      facts: [\n        {\n          title: \"First Name:\",\n          value: Topic.firstname\n        },\n        {\n          title: \"Last Name:\",\n          value: Topic.lastname\n        },\n        {\n          title: \"E-mail:\",\n          value: Topic.email\n        },\n        {\n          title: \"Current Role:\",\n          value: Topic.current_role\n        },\n        {\n          title: \"Spoken Languages:\",\n          value: Text(Concat(Topic.spoken_languages, Value, \", \"))\n        },\n        {\n          title: \"Skills:\",\n          value: Text(Concat(Topic.skills, Value, \", \"))\n        }\n      ]\n    }\n  ],\n  '$schema': \"http://adaptivecards.io/schemas/adaptive-card.json\",\n  version: \"1.3\"\n}\n</code></pre> <p>Additional information about PowerFx functions</p> <p>You can find additional information about the PowerFx functions reading the article Create expressions using Power Fx</p> <p></p>"},{"location":"pages/make/copilot-studio/02-topics/#step-3-testing-the-current-topic","title":"Step 3: Testing the current topic","text":"<p>Now add an End current topic action at the end of the topic, save it, give it a name like for example <code>Register new candidate with adaptive cards</code>, and test it in the test panel on the right side of the agent designer. In the following screenshot you can see how the topic interacts with a user.</p> <p></p> <p>Now your topic is ready and fully functional. In the upcoming labs you will learn how to create a new candidate record for real, storing data in an external HR service.</p> <p></p> <p>CONGRATULATIONS!</p> <p>Now your agent supports multiple conversation paths through different topics. In the next labs you will learn how to work with custom Actions.</p> <p>Start here with Lab MCS3, to define actions in your agent with Copilot Studio. </p> <p></p>"},{"location":"pages/make/copilot-studio/03-actions/","title":"Lab MCS3 - Defining Tools","text":"<p>In this lab, you'll learn how to create Tools in Microsoft Copilot Studio. Tools are another core building block of an agent. With tools you can extend the capabilities of your agent by adding support for external Power Platform connectors (native or custom), external REST APIs, Power Automate flows, MCP (Model Context Protocol) servers, etc.</p> Get a quick overview of the lab in this video. <p>Do these labs if you want to build agents with Microsoft Copilot Studio</p> <ul> <li>MCS0 - Setup</li> <li>MCS1 - First agent</li> <li>MCS2 - Defining Topics</li> <li>MCS3 - Defining Tools</li> <li>MCS4 - Extending Microsoft 365 Copilot</li> <li>MCS5 - Consuming a custom connector</li> <li>MCS6 - Consuming an MCP server</li> <li>MCS7 - Creating Autonomous Agents</li> <li>MCS8 - Integrating Azure AI Search for RAG</li> <li>MCS9 - Connected Agents (Preview)</li> </ul> <p>Note</p> <p>This lab builds on the previous one, Lab MCS2. You should be able to continue working on the same agent, improving its functionalities with new capabilities.</p> <p>Tools can be created with a graphical designer. Once you have created a new Tool, you can also edit its definition with a low level code editor, in case you need to apply detailed fine tuning.</p> <p>In this lab you will learn:</p> <ul> <li>How to create a tool to invoke a Power Platform connector</li> <li>How to create a tool to invoke a Power Automate flow</li> <li>How to invoke tools from topics</li> </ul>"},{"location":"pages/make/copilot-studio/03-actions/#exercise-1-creating-tools-in-microsoft-copilot-studio","title":"Exercise 1 : Creating tools in Microsoft Copilot Studio","text":"<p>In this exercise you are going to enhance the agent that you created in Lab MCS2 to use Excel Online to retrieve a hypotethical list of candidates from an Excel spreadsheet stored in a SharePoint Online document library. Then you will add a tool to consume a Power Automate flow that can add new candidates to the same spreadsheet.</p>"},{"location":"pages/make/copilot-studio/03-actions/#step-1-consuming-a-power-platform-connector","title":"Step 1: Consuming a Power Platform connector","text":"<p>To create a new tool, in the upper side of the screen select the 1\ufe0f\u20e3 Tools tab, then select 2\ufe0f\u20e3 + Add a tool to start creating a new tool.</p> <p></p> <p>A dialog window pops up allowing you to choose what kind of tool to create. By default, there are some Featured tools like those that allow you to interact with Excel Online content or other common services. </p> <p></p> <p>You can also create a new tool from scratch, selecting the + New tool command and choosing between the following options:</p> <ul> <li>Prompt: allows consuming an AI tool built using a prompt written in natural language.</li> <li>Agent flow: allows consuming a Power Automate flow (see Step 2).</li> <li>Computer use: to allow your agent to directly use web and desktop apps.</li> <li>Custom connector: allows consuming a Power Platform custom connector.</li> <li>REST API: allows consuming an external REST API. You can find additional details here.</li> <li>Model Context Protocol: to consume tools from an external Model Context Protocol (MCP) server.</li> </ul> <p></p> <p>If you don't find the option you are looking for in the list of featured items, simply switch to the All group and search by text what you are looking for.</p> <p>To complete the current step, choose the featured tool Excel Online (Business) and then select List rows present in a table. First of all, you will need to connect to the external connector simply selecting the Connection and then Create new connection and proceeding with the process.</p> <p></p> <p>You will need to login with your account and to allow access to Excel Online (Business). Once the connection is configured, you will see a dialog with commands to Add to agent or Add and configure the tool.</p> <p></p> <p>Next, you get a page to configure the actual tool. You need to provide:</p> <ul> <li>Name: simply a descriptive name for the tools.</li> <li>Description: a description in natural language that will be used by generative orchestration to determine when to use your tool. </li> <li>Inputs: to define the input arguments for the tool, if any.</li> <li>Completion: defines how the tool handles the request and response to the user.</li> </ul> <p>Before configuring the tool, you need to prepare the Excel spreadsheet with the list of candidates. Download a sample Excel file by selecting this link.</p> <p>Upload the file to the Documents library of a SharePoint Teams site in the same tenant where you are making your agent with Copilot Studio. The document was generated by Microsoft 365 Copilot for the sake of having a hypothetical list of candidates.</p> <ul> <li>Copy the absolute url of the site. For example: <code>https://xyz.sharepoint.com/sites/contoso/</code>.</li> <li>Copy the name of the document library. For example : <code>Shared documents</code></li> <li>Copy also the name of the file. For example: <code>Sample-list-of-candidates.xlsx</code></li> </ul> <p>Now go back to Microsoft Copilot Studio and finalize the tool configuration.</p> <p></p> <p>Use the following settings:</p> <ul> <li>Name: List HR candidates</li> <li>Description: List candidates for an HR role</li> </ul> <p>Then select the Inputs tab and start configuring the input arguments. By default, all the mandatory input arguments have been configured so that their value will be <code>Dynamically fill with AI</code> as you can notice in the Fill as property of each input argument.</p> <p></p> <p>Select the Fill using setting for each of the input arguments and switch to <code>Custom value</code> in order to provide static values for all of the input arguments.</p> <p>Use the following static values:</p> <ul> <li>Location: use the URL of the SharePoint Online site collection where you stored the Excel spreadsheet. For example: <code>https://xyz.sharepoint.com/sites/contoso/</code>.</li> <li>Document Library: use the name of the document library where you stored the Excel spreadsheet. For example: <code>Shared Documents</code>.</li> <li>File: provide the name of the Excel file. For example: <code>Sample-list-of-candidates.xlsx</code>.</li> <li>Table: <code>Candidates_Table</code></li> </ul> <p>You can browse the sites, libraries, files, and tables through the native UI of Microsoft Copilot Studio.</p> <p></p> <p>Now select the Save button in the upper right corner of the screen to save the updated tool.</p> <p></p>"},{"location":"pages/make/copilot-studio/03-actions/#step-2-testing-the-new-tool","title":"Step 2: Testing the new tool","text":"<p>You are now ready to publish the updated agent and to play with it in the integrated test panel or in Microsoft Teams.</p> <p>Since in Lab MCS2 you enabled generative orchestration, it is really easy to invoke the just created tool simply providing to the agent a prompt like the following one:</p> <pre><code>Show me the list of candidates for an HR role\n</code></pre> <p>Something really nice of Copilot Studio when using the generative orchestration and invoking prompts within the test panel is that by default you get an Activity map to investigate how the orchestrator works. In the following screenshot you can see the Activity map for the prompt suggested before. The orchestrator indentifies the user's intent, based on the prompt, and triggers the tool that you created in Step 1. You can also validate the manually defined input arguments.</p> <p>Since the Power Platform connector requires a valid connection in place, the agent prompts the user to Connect before being able to consume the external data source.</p> <p></p> <p>Select the Connect button and proceed to activate the connection. You will see, in a new browser tab, the list of active connections for your current session, including the connection to <code>Excel Online (Business)</code>. Select the Connect link to activate the connection through a dedicated dialog with title Create or pick a connection. Once the connection is ready and connected, go back to the agent and select the Retry command to execute the tool against the target connection. In the test panel you get the list of candidates retrieved from the Excel spreadsheet.</p> <p></p> <p>Well done, so far! You can now move to the next step.</p> <p></p>"},{"location":"pages/make/copilot-studio/03-actions/#step-3-consuming-an-agent-flow","title":"Step 3: Consuming an Agent flow","text":"<p>In this step you are going to create a tool to consume a Power Automate flow. Let's say that you want to add new candidates to the Excel spreadsheet, based on the user's input. You can simply create a tool that invokes an external Power Automate flow, which adds a new row to the table in the Excel spreadsheet.</p> <p>To create such a tool, in the upper side of the screen select the Tools tab, then select + Add a tool to start creating a new tool. This time, select the + New tool button and then Agent flow. A new page will be opened, navigating to a the Agent flows designer and rendering a new flow.</p> <p></p> <p>The flow has an initial triggering action with name <code>When an agent calls the flow</code> and a final action with name <code>Respond to the agent</code>. The overall idea is that you can define your own business process between these two flow actions and the Copilot Studio tool will trigger the business process for you, eventually providing one or more input arguments and providing a response back to the agent. Select the first action to edit its properties. You can configure a set of input arguments for the flow, so that Copilot Studio will be able to feed the flow through the action upon activation.</p> <p></p> <p>For the sake of being able to add new candidates, configure four input parameters with the following settings:</p> <ul> <li>Firstname: text</li> <li>Lastname: text</li> <li>Role: text</li> <li>Expertise: text</li> </ul> <p>Now add, between the two pre-created actions, a new action of type Add a row into a table from the Excel Online (Business) connector. Configure the new flow action in order to target the Excel spreadsheet with the list of candidates. Map the column fields of the row to the actual input parameters defined in the triggering action invoked by Copilot. Rename the action into <code>Add new candidate row</code>. In the following screenshot you can see how the action is configured.</p> <p></p> <p>Now select the final action <code>Respond to Copilot</code>, edit its properties and add an output parameter of type <code>Text</code> with name <code>Result</code>. Set the value of the output paremeter to a formula that renders a message like the one illustrated in the following screenshot.</p> <p></p> <p>Now Save draft, update the name of the flow in the Overview tab, editing the Details of the agent flow. You can use a name like for example <code>Insert new candidate for HR</code>. Publish the flow and go back to the agent where you were editing the tool. Open again the dialog window to add a new tool, select Flow as the filter and you will be able to see the new Agent flow that you just created. If not, try searching for its name.</p> <p></p> <p>Select the new tool, in the next dialog window select Add and configure to configure its settings as like as you did in Step 1, and play with it. For example, use the following settings:</p> <ul> <li>Name: Insert new candidate for HR</li> <li>Description: Insert new candidate into the Excel spreadsheet for HR</li> </ul> <p>Select the Save button and the new tool based on the Agent flow will be ready. Now let's trigger the tool with a prompt like the following one:</p> <pre><code>Insert a new candidate into the Excel spreadsheet of HR. The candidate firstname is John, \nthe lastname is White, the role is \"HR Administrator\", and the expertise is \"Compliance\".\n</code></pre> <p>As like as it was with the previous Step, the first time you use the tool you need to connect to Excel Online in order to consume the connector. If that is the case, select the Connect button and once you will be connected, select the Retry button to execute the actual tool.</p> <p></p> <p>After the execution of the tool, you will see the agent replying back to you with the response message that you defined in the Power Automate flow. Moreover, the new candidate will be added to the table in the Excel spreadsheet.</p> <p></p>"},{"location":"pages/make/copilot-studio/03-actions/#exercise-2-invoking-tools-from-within-a-topic","title":"Exercise 2 : Invoking tools from within a topic","text":"<p>In this exercise you are going to consume the tool that you just defined from within a topic.</p>"},{"location":"pages/make/copilot-studio/03-actions/#step-1-invoking-a-tool-from-a-topic","title":"Step 1: Invoking a tool from a topic","text":"<p>First of all, create a new topic from blank, give it name <code>Add a new candidate to Excel</code>, and follow the same steps defined in Exercise 4 of Lab MCS2.</p> <p>The triggering description can be something like the following:</p> <pre><code>This topic helps users to insert new candidates in the Excel spreadsheet of HR.\nTriggering sentences can be: add a new a new row to the persistence storage.\n</code></pre> <p>For the sake of simplicy, we are not going to cover all of the steps here. However, you can simply refer to Lab MCS2 for additional details. </p> <p>Here follows the JSON of the adaptive card that you can use to collect the input arguments about the candidate through an action of type Ask with adaptive card.</p> <pre><code>{\n    \"type\": \"AdaptiveCard\",\n    \"body\": [\n        {\n            \"type\": \"TextBlock\",\n            \"size\": \"Medium\",\n            \"weight\": \"Bolder\",\n            \"text\": \"New HR Candidate Information\"\n        },\n        {\n            \"type\": \"Input.Text\",\n            \"id\": \"firstname\",\n            \"placeholder\": \"First Name\"\n        },\n        {\n            \"type\": \"Input.Text\",\n            \"id\": \"lastname\",\n            \"placeholder\": \"Last Name\"\n        },\n        {\n            \"type\": \"Input.Text\",\n            \"id\": \"current_role\",\n            \"placeholder\": \"Current Role\"\n        },\n        {\n            \"type\": \"Input.Text\",\n            \"id\": \"expertise\",\n            \"placeholder\": \"Expertise\"\n        }\n    ],\n    \"actions\": [\n        {\n            \"type\": \"Action.Submit\",\n            \"title\": \"Submit\"\n        }\n    ],\n    \"$schema\": \"http://adaptivecards.io/schemas/adaptive-card.json\",\n    \"version\": \"1.5\"\n}\n</code></pre> <p>Then add a new tool from the group Add an tool, select the tab Tool, and select the tool that you just created in Exercise 1 - Step 3.</p> <p></p> <p>Now you need to map the input arguments of the tool with the variables collected by the user via the adaptive card.</p> <p></p> <p>Select the + Set value for each and every input argument and select the corresponding arguments as follows:</p> <ul> <li>text: represents the first name</li> <li>text_1: represents the last name</li> <li>text_2: represents the current role</li> <li>text_3: represents the expertise</li> </ul> <p>Then, using data binding in Copilot Studio, configure every input argument to the corresponding topic level variables, collected by the user through the Ask with adaptive card action. At the end, the tool action will look like in the following image.</p> <p></p> <p>Add an action to End current topic and save it.</p> <p>Now, disable any other topic that you created in Lab MCS2 and invoke the new topic to insert a new candidate row into the Excel spreadsheet using the following prompt:</p> <pre><code>Add a new a new row to the persistence storage\n</code></pre> <p>Fill the adaptive card and submit the request. The tool will be triggered via the topic and you will have yet another new candidate in the Excel spreadsheet.</p> <p></p> <p></p> <p>CONGRATULATIONS!</p> <p>Now your agent supports tools. In the next lab you will learn how to use Copilot Studio to create Declarative Agents for Microsoft 365 Copilot Chat.</p> <p>Start here with Lab MCS4, to learn how to use Copilot Studio to create Declarative Agents for Microsoft 365 Copilot Chat. </p> <p></p>"},{"location":"pages/make/copilot-studio/04-extending-m365-copilot/","title":"Lab MCS4 - Extending Microsoft 365 Copilot","text":"<p>In this lab, you are going to learn how to extend Microsoft 365 Copilot Chat with a Declarative Agent made using Microsoft Copilot Studio. In fact, so far you have seen how to create agents in Copilot Studio and how to consume them in Microsoft Teams. You have also seen that agents created in Microsoft Copilot Studio can target both Microsoft Teams and Microsoft 365 Copilot Chat through the specific options available in the Teams and Microsoft 365 Copilot channel. Now, with this lab, you are moving to Declarative Agents for Microsoft 365 Copilot Chat.</p> <p>In this lab you will learn:</p> <ul> <li>How to create a declarative agent for Microsoft 365 Copilot Chat</li> <li>How to configure a custom icon for your agent</li> <li>How to configure knowledge sources for your agent</li> <li>How to publish the agent in Microsoft 365 Copilot Chat</li> <li>How to create a tool for Microsoft 365 Copilot Chat</li> </ul> Get a quick overview of the lab in this video. <p>Do these labs if you want to build agents with Microsoft Copilot Studio</p> <ul> <li>MCS0 - Setup</li> <li>MCS1 - First agent</li> <li>MCS2 - Defining Topics</li> <li>MCS3 - Defining Tools</li> <li>MCS4 - Extending Microsoft 365 Copilot</li> <li>MCS5 - Consuming a custom connector</li> <li>MCS6 - Consuming an MCP server</li> <li>MCS7 - Creating Autonomous Agents</li> <li>MCS8 - Integrating Azure AI Search for RAG</li> <li>MCS9 - Connected Agents (Preview)</li> </ul>"},{"location":"pages/make/copilot-studio/04-extending-m365-copilot/#exercise-1-creating-an-agent-for-microsoft-365-copilot-chat","title":"Exercise 1 : Creating an agent for Microsoft 365 Copilot Chat","text":"<p>In this excercise you are going to create a declarative agent with Microsoft Copilot Studio and hosting it in Microsoft 365 Copilot Chat.</p>"},{"location":"pages/make/copilot-studio/04-extending-m365-copilot/#step-1-creating-an-agent-for-copilot-chat","title":"Step 1: Creating an agent for Copilot Chat","text":"<p>To create a declarative agent for Microsoft 365 Copilot Chat you need to 1\ufe0f\u20e3 browse the list of agents in Copilot Studio and 2\ufe0f\u20e3 select the agent with name Microsoft 365 Copilot.</p> <p></p> <p>A new section of Microsoft Copilot Studio will open. From there, you can select the + Add command to create a new agent for Microsoft 365 Copilot Chat.</p> <p></p> <p>Copilot Studio asks you to describe in natural language what the purpose of the agent is. As like as you did in Lab MCS1 you can define your agent requirements in natural language, using for example the following prompts.</p> <pre><code>You are an agent helping employees to find information about HR policies and procedures,\nabout how to improve their career, and about how to define learning pathways.\n</code></pre> <p>When requested by Copilot Studio, give the name \"Agentic HR\" to your custom agent. Then, instruct Copilot Studio to have specific tasks or goals with the following instruction:</p> <pre><code>Emphasize everything that helps team building, inclusion, and the growth mindset\n</code></pre> <p>Then, define a professional tone for your agent, providing the following input:</p> <pre><code>It should have a professional tone\n</code></pre> <p></p> <p>Once you are done describing your agent, select the Create command to create the actual agent. Alternatively, you can select the Skip to configure command and move to the classic configuration user interface.</p> <p>Once the agent has been created, you will see its configuration page, where you can define:</p> <ul> <li>Details: with generic information about the agent like name, icon, description, and instructions (system prompt).</li> <li>Knowledge: to define the various knowledge bases for the agent.</li> <li>Tools: to define custom tools for the agent.</li> <li>Additional settings: to configure whether the agent will rely on public web content or not.</li> <li>Suggested prompts: to configure up to 6 suggested prompts that will be shown in the Copilot Chat when starting a new chat.</li> <li>Publish details: to get information about how to consume the agent, once it will be published.</li> </ul> <p></p> <p>On the right side of the screen, you can already see a preview of the agent that you can use to test its behaviour. The initial setup of the agent is now ready. Move to the next steps to fine tune its settings.</p> <p></p>"},{"location":"pages/make/copilot-studio/04-extending-m365-copilot/#step-2-updating-the-agents-icon","title":"Step 2: Updating the agent's icon","text":"<p>Now, you can edit the details selecting the Edit command in the upper right corner of the Details section. Once in edit mode, select the Change icon command to upload a custom icon and to select a background color for the icon itself. If you like, you can use the icon available at this link. In case you want to use the suggested icon, the background color could be #B9BAB5.</p> <p></p> <p>Select the Save command to save the new icon and background color, then select the Save button again to save the updated details for the agent.</p> <p></p>"},{"location":"pages/make/copilot-studio/04-extending-m365-copilot/#step-3-adding-a-knowledge-base-to-the-agent","title":"Step 3: Adding a knowledge base to the agent","text":"<p>Like you did in Lab MCS1, download this zip file consisting of few files (Word, PowerPoint, PDF) by selecting this link.</p> <p>Extract the files from the zip and upload them to the Documents library of a SharePoint Teams site in the same tenant where you are making your agent with Copilot Studio. These documents were generated by Microsoft 365 Copilot for the sake of having some additional knowledge base to feed the agent.</p> <p>Copy the absolute url of the site. For example: <code>https://xyz.sharepoint.com/sites/contoso</code></p> <p>To add a knowledge source to the agent, select the + Add knowledge command in the upper right corner of the Knowledge section. A dialog window pops up and allows you to select a data source. At the moment of this writing you can select a SharePoint data source. Select the SharePoint command and browse for a site that you want to use as the data source.</p> <p></p> <p>Paste the URL of the SharePoint Online site where you stored the documents into the dialog or select the Browse files command to search for data sources browsing the SharePoint Online sites. Once you have provided a URL or selected a data source, you need to provide a name and a meaningful description for the new knowledge base. The description will be used by Copilot to target the data source based on the user's intent defined by the user's prompt.</p> <p></p> <p>Select the Add button to add the new data source to the knowledge base of the agent.</p> <p>Important</p> <p>When configuring SharePoint Online sites as the knowledge base for an agent in Copilot Studio, users will only be able to get answers and content from documents that they have access to. The security and the access control are guaranteed by the Microsoft 365 security infrastructure and Copilot Studio agents access documents on behalf of the current user.</p> <p></p>"},{"location":"pages/make/copilot-studio/04-extending-m365-copilot/#step-4-publishing-the-agent-in-microsoft-365-copilot-chat","title":"Step 4: Publishing the agent in Microsoft 365 Copilot Chat","text":"<p>Now you can publish and test the agent in Microsoft 365 Copilot Chat. 1\ufe0f\u20e3 Select the Publish command in the upper right corner of the page to make the agent available in Copilot Chat. Then 2\ufe0f\u20e3 fill in the details for the agent. Lastly 3\ufe0f\u20e3 select the Publish command in the lower part of the publishing dialog.</p> <p></p> <p>The details for the agent are those required by a Microsoft 365 application manifest:</p> <ul> <li>Short description: short description of the agent (up to 30 characters).</li> <li>Long description: long description of the agent (up to 100 characters).</li> <li>Developer name: name of the developer (up to 32 characters).</li> <li>Website: URL of the developer's website (up to 2048 characters).</li> <li>Privacy statement: URL of the privacy statement (up to 2048 characters).</li> <li>Terms of use: URL of the terms of use (up to 2048 characters).</li> </ul> <p>Initial publishing takes quite some time, between 30 and 60 seconds. Once the agent is published, you will see a dialog with a recap of all the availability options.</p> <p></p> <p>Specifically, you can select:</p> <ul> <li>Copy command to copy a URL with a direct link to the app registered for the new agent.</li> <li>Show to my teammates and shared users to share the agent with selected groups or individuals in your organization.</li> <li>Show to everyone in my org to share the agent with the whole organization.</li> <li>Download .zip file to download a zip package of the app that you can then upload to the Microsoft 365 store.</li> </ul> <p>Show to everyone in my org</p> <p>When you choose to show the agent to the whole organization, ensure your agent is ready for release and in compliance with company standards, rules, and policies. Coordinate with your teammates. Once the agent is submitted, it can't be resubmitted by others until an admin approves or rejects it. You can find additional details about publishing an app to the whole organization reading Show to the organization.</p> <p>Select the Copy command, open a new browser tab, and paste the URL with the direct link to the agent. The company app store will show in the browser and a dialog will allow you to select the Add button, to add the agent to Microsoft 365 Copilot.</p> <p></p> <p>Once you have added the agent to Microsoft 365 Copilot Chat, you will find it in the list of agents in the right side of the Copilot chat, like illustrated in the following screenshot.</p> <p></p> <p>Select the agent and start interacting with it. For example, you can provide the following prompt:</p> <pre><code>How can we hire new people in our company?\n</code></pre> <p>The agent will provide you detailed information about the hiring procedures, based on the content retrieved from the documents defined in the knowledge base. For example, the main data source for the response will be the document <code>Hiring Procedures.docx</code> that you uploaded to SharePoint Online.</p> <p></p> <p></p>"},{"location":"pages/make/copilot-studio/04-extending-m365-copilot/#exercise-2-adding-a-tool-to-the-agent","title":"Exercise 2 : Adding a tool to the agent","text":"<p>In this excercise you are going to add a custom tool to the agent that you made in the previous exercise. In Microsoft Copilot Studio, when making agents for Microsoft 365 Copilot Chat (Declarative Agents), you can add four different types of tools:</p> <ul> <li>Prompt: allows consuming an AI tool built using a prompt written in natural language.</li> <li>Custom connector: allows consuming a Power Platform custom connector.</li> <li>REST API: allows consuming an external REST API. You can find additional details here.</li> </ul> <p>Tools for agents</p> <p>You can find additional information about adding tools to agents in Copilot Studio reading the article Add tools to custom agents.</p> <p>In this lab you are going to add a tool of type <code>Custom connector</code> in order to retrieve a list of candidates from an Excel spreadsheet stored in SharePoint Online.</p>"},{"location":"pages/make/copilot-studio/04-extending-m365-copilot/#step-1-adding-a-tool-to-an-agent-for-microsoft-365-copilot","title":"Step 1: Adding a tool to an agent for Microsoft 365 Copilot","text":"<p>To add a new tool, select the + Add tool command in the Tools section of the agent's configuration panel.</p> <p></p> <p>A dialog window pops up allowing you to choose what kind of tool to create. By default, there are some Featured tools like those that allow you to interact with Excel Online content or other common services. You can also create a new tool from scratch, selecting the + New tool command and choosing between the options highlighted in the previous paragraphs.</p> <p>If you don't find the option you are looking for in the list of featured items, simply switch to the All group and search by text what you are looking for.</p> <p>To complete the current step, choose the featured tool Excel Online (Business) and then select List rows present in a table. First of all, you will need to connect to the external connector simply selecting the Connection and then Create new connection and proceeding with the process.</p> <p></p> <p>You will need to login with your account and to allow access to Excel Online (Business). Once the connection is configured, you will see a dialog with a command to Add and configure the tool.</p> <p></p> <p>After adding the tool, you will get the list of tools in Copilot Studio. Click on the tool that you just created to edit its settings. In the configuration panel you need to provide:</p> <ul> <li>Name: a display name for the tool.</li> <li>Description: a description in natural language that will be used by generative orchestration to determine when to use your tool. </li> <li>Inputs and outputs: to define the input and output arguments for the action, if any.</li> <li>Additional details: defines how the action handles the request and response to the user.</li> <li>Completion: to specify what the agent does when it finishes using the tool.</li> </ul> <p>Before configuring the tool, you need to prepare the Excel spreadsheet with the list of candidates. Download a sample Excel file by selecting this link.</p> <p>Upload the file to the Documents library of a SharePoint Teams site in the same tenant where you are making your agent with Copilot Studio. The document was generated by Microsoft 365 Copilot for the sake of having a hypothetical list of candidates.</p> <ul> <li>Copy the absolute url of the site. For example: <code>https://xyz.sharepoint.com/sites/contoso/</code>.</li> <li>Copy the name of the document library. For example : <code>Shared documents</code></li> <li>Copy also the name of the file. For example: <code>Sample-list-of-candidates.xlsx</code></li> </ul> <p>Now go back to Microsoft Copilot Studio and finalize the tool configuration. In the dialog for editing the tool, update the Name and Description to give it more descriptive and informative settings. Use the following settings:</p> <ul> <li>Name: </li> </ul> <pre><code>List HR candidates\n</code></pre> <ul> <li>Description: </li> </ul> <pre><code>List candidates for an HR role\n</code></pre> <p>Now, select the Inputs section and start configuring the input arguments. By default, all the mandatory input arguments have been configured so that their value will be exctracted by the User's entire response as you can notice in the Fill using property of each input argument, which is configured with value <code>Dynamically fill with AI</code>.</p> <p></p> <p>For each input argument, you will configure an explicit value. Select the Fill using field of the Location input argument, switch its value to <code>Custom value</code>, then using the dropdown list select the site collection where you stored the Excel spreadsheet with the list of candidates.</p> <p></p> <p>Now configure the Document Library input argument to <code>Custom value</code> and select the library where you stored the Excel file. Configure the File input argument to <code>Custom value</code> and browse for the Excel file. Lastly, configure Table to <code>Custom value</code> and select the table with name <code>Candidates_Table</code>. Once you are done with the settings, the input arguments should look like in the following screenshot.</p> <p></p> <p>Now select the Save button in the upper right corner of the screen to save the updated tool.</p> <p></p>"},{"location":"pages/make/copilot-studio/04-extending-m365-copilot/#step-2-testing-the-new-tool","title":"Step 2: Testing the new tool","text":"<p>You are now ready to publish the updated agent and to play with it in the integrated test panel or in Microsoft Teams. Select the Publish button again, to update the publishing of the agent. Wait for the publishing to complete and then open again the direct link to the agent's app. You will see an Update now command instead of the Add that you saw in Exercise 1 - Step 4. Select the Update now command and wait. Once ready, go to Microsoft 365 Copilot Chat, refresh the page and start interacting with the updated agent.</p> <p>It is really easy to invoke the just created tool simply providing to the agent a prompt like the following one:</p> <pre><code>Show me the list of candidates for HR with role \"HR Director\" or \"HR Manager\"\n</code></pre> <p>Microsoft 365 Copilot Chat will ask you the permission to consume an external API (Excel Online) and you will have to select the option to Always allow or Allow once. For the sake of testing purposes, choose Allow once so that you will be able to test the authorization process again in the future.</p> <p></p> <p>Since the Power Platform connector requires a valid connection in place, the agent might prompt the user to Sign in to Agentic HR before being able to consume the external data source.  Once you are connected to the external connector, the agent will reply back providing the list of candidates retrieved from the Excel spreadsheet and matching the criteria that you provided in the prompt.</p> <p></p> <p>Well done! You were able to consume an external connector from a Copilot Studio agent made for Microsoft 365 Copilot!</p> <p></p> <p>CONGRATULATIONS!</p> <p>Start here with Lab MCS5, to learn how to use custom connectors in Copilot Studio. </p> <p></p>"},{"location":"pages/make/copilot-studio/05-connectors/","title":"Lab MCS5 - Power Platform custom connector","text":"<p>In this lab, you are going to understand how to extend an agent made with Microsoft Copilot Studio using a Power Platform custom connector. Specifically, you are going to consume a custom REST API to manage a hypotethical list of candidates for a job role. The API offers functionalities to:</p> <ul> <li>List candidates</li> <li>Get a specific candidate</li> <li>Add a new candidate</li> <li>Remove a candidate</li> </ul> Get a quick overview of the lab in this video. <p>Do these labs if you want to build agents with Microsoft Copilot Studio</p> <ul> <li>MCS0 - Setup</li> <li>MCS1 - First agent</li> <li>MCS2 - Defining Topics</li> <li>MCS3 - Defining Tools</li> <li>MCS4 - Extending Microsoft 365 Copilot</li> <li>MCS5 - Consuming a custom connector</li> <li>MCS6 - Consuming an MCP server</li> <li>MCS7 - Creating Autonomous Agents</li> <li>MCS8 - Integrating Azure AI Search for RAG</li> <li>MCS9 - Connected Agents (Preview)</li> </ul> <p>In Microsoft 365 Copilot, within Copilot Studio you will be able to rely on these functionalities and enhance the potential of the custom agent that you created in the previous Lab MCS4.</p> <p>Note</p> <p>This lab builds on the previous one, Lab MCS4. You should be able to continue working on the same agent, improving its functionalities with new capabilities.</p> <p>In this lab you will learn:</p> <ul> <li>How to expose a REST API through a Power Platform custom connector</li> <li>How to secure communication to an external REST API in the Power Platform</li> <li>How to consume a custom connector from an agent</li> </ul> <p>Before starting, make sure you have:</p> <ul> <li>Visual Studio Code</li> <li>REST Client extension for Visual Studio Code</li> <li>Node.js v.22 or higher</li> <li>Dev tunnel</li> </ul>"},{"location":"pages/make/copilot-studio/05-connectors/#exercise-1-creating-the-rest-api","title":"Exercise 1 : Creating the REST API","text":"<p>For the sake of simplicity in this Lab you are going to use a pre-built REST API. In this exercise you are going to download and configure it, so that you can run it locally.</p>"},{"location":"pages/make/copilot-studio/05-connectors/#step-1-downloading-and-testing-the-rest-api","title":"Step 1: Downloading and testing the REST API","text":"<p>The sample REST API is an Azure Function built with TypeScript and Node.js, named <code>HR Service</code> and you can download its source code from here.</p> <p>Extract the files from the zip and open the target folder with Visual Studio Code. In the following screenshot you can have an overview of the project structure.</p> <p></p> <p>The main elements of the project outline are:</p> <ul> <li><code>http</code>: in this folder you can find a couple of .http files useful for testing the REST API in Visual Studio Code.</li> <li><code>src/data/candidates.json</code>: a JSON file with an hypothetical list of candidates, used as the initial data source for the service.</li> <li><code>src/functions/candidatesFunction.ts</code>: the actual implementation of the Azure Function.</li> <li><code>src/openapi.json</code>: the Open API specification file for the Azure Function, stored in JSON format.</li> <li><code>src/openapi.yaml</code>: the Open API specification file for the Azure Function, stored in Yaml format.</li> <li><code>askCandidateData.json</code>: the JSON of an adaptive card to collect data for a new candidate.</li> <li><code>dev-tunnel-steps.md</code>: brief set of instructions to build a Dev Tunnel to have a reverse proxy for the REST API running locally.</li> <li><code>local.settings.json.sample</code>: a sample configuration file that will be used later in this lab.</li> </ul> <p>Rename the file <code>local.settings.json.sample</code> into <code>local.settings.json</code> and press F5 to start the project. In Visual Studio Code, open the file <code>http/ht-service.http</code> and trigger a new request to get the list of candidates by selecting the Send request command near the GET request for <code>http://localhost:7071/api/candidates</code>. On the right side of the screen you will see the output of the request, providing you with few response headers and the JSON list of candidates.</p> <p></p> <p>Notice that in the Terminal window, in the lower part of the screen, there is the tracing of the API call that you just triggered and a message stating that <code>OAuth is disabled. Skipping token validation</code>. In fact, right now the API is accessible anonymously.</p> <p></p>"},{"location":"pages/make/copilot-studio/05-connectors/#step-2-registering-the-api-in-entra-id","title":"Step 2: Registering the API in Entra ID","text":"<p>Let's now secure access to the API. First of all, you need to open a browser and, using the work account of your target Microsoft 365 tenant, go to https://entra.microsoft.com to access the Microsoft Entra admin center. Sign in to the admin center, if asked for authentication. Then 1\ufe0f\u20e3 select App registrations in the menu bar on the left, and then 2\ufe0f\u20e3 select the + New registration command to register a new application in the target tenant.</p> <p></p> <p>The <code>Register an application</code> page will show up. Provide a name for the application, for example <code>HR-Service-API</code>. Choose to support authentication only in your target tenant, and select the Register button in the lower part of the screen.</p> <p></p> <p>Microsoft Entra will register the application for you and show the Overview page with information about the newly registered application. Copy the value of Client ID and Tenant ID, because you will need them soon.</p> <p>Select the 1\ufe0f\u20e3 Expose an API menu item on the left menu, then 2\ufe0f\u20e3 select + Add a scope to add a new permission scope for consuming the custom API. The very first time you add a new scope, you have to configure an Application ID URI. By default, the value will be <code>api://&lt;Client-Id&gt;</code>. Select Save and continue to save the unique URI for the application. Then, 3\ufe0f\u20e3 configure the scope settings using the panel that appears on the righ and 4\ufe0f\u20e3 select Add scope to confirm the operation.</p> <p>Creating a scope allows you to define a custom delegated permission scope for you API. Consumers of your API will need to provide OAuth 2.0 tokens with that permission scope in order to being able to consume your API.</p> <p></p> <p>Here you can see some suggested values for the permission scope configuration:</p> <ul> <li>Scope name: the actual name of the scope. For example: <code>HR.Consume</code>.</li> <li>Who can consent?: defines whether the scope can be consented by admins only, or both by admins and regular users. Choose <code>Admins and users</code>.</li> <li>Admin consent display name: the short display name of the scope for admin consent. For example: <code>HR.Consume</code>.</li> <li>Admin consent description: the description of the scope for admin consent. For example:  <code>Allows consuming the HR Service</code>.</li> <li>User consent display name: the short display name of the scope for user consent. For example: <code>HR.Consume</code>.</li> <li>User consent description: the description of the scope for user consent. For example: <code>Allows consuming the HR Service</code>.</li> <li>State: defines whether the scope is Enabled or Disabled. Let's keep it enabled.</li> </ul> <p>Once the permission scope is configured, you will see the new scope in the list of scopes defined for the application.</p> <p></p> <p>Now, 1\ufe0f\u20e3 select the Manifest menu item on the left menu, 2\ufe0f\u20e3 edit the content of the manifest file using the Microsoft Graph App Manifest (new), and 3\ufe0f\u20e3 update the <code>requestedAccessTokenVersion</code> property to the value <code>2</code>. This specifies that the API expects a JWT token of type v2.0.</p> <p>Note</p> <p>You can find additional information about the Microsoft Graph App Manifest and the token v2.0 in the article Understand the app manifest (Microsoft Graph format).</p> <p></p> <p>Now you can go back to Visual Studio Code and configure the <code>local.settings.json</code> file accordingly to the settings of the just registered application. Replace the <code>&lt;Client-ID&gt;</code> and the <code>&lt;Tenant-ID&gt;</code> placeholders with the actual values and turn the <code>UseOAuth</code> property to <code>true</code>.</p> <pre><code>{\n  \"IsEncrypted\": false,\n  \"Values\": {\n    \"AzureWebJobsStorage\": \"UseDevelopmentStorage=true\",\n    \"FUNCTIONS_WORKER_RUNTIME\": \"node\",\n    \"AAD_APP_CLIENT_ID\": \"&lt;Client-ID&gt;\",\n    \"AAD_APP_TENANT_ID\": \"&lt;Tenant-ID&gt;\",\n    \"AAD_APP_OAUTH_AUTHORITY\": \"https://login.microsoftonline.com/&lt;Tenant-ID&gt;\",\n    \"UseOAuth\": \"true\"\n  }\n}\n</code></pre> <p>Restart the REST API project and now the API will be secured and will be looking for an OAuth 2.0 token in the Authorization header. If the token will not be provided, or if an invalid token will be provided, the API will respond with a HTTP status 401 (Unauthorized).</p> <p></p>"},{"location":"pages/make/copilot-studio/05-connectors/#step-3-configure-the-dev-tunnel","title":"Step 3: Configure the dev tunnel","text":"<p>Now, you need to expose the REST API with a public URL. Since you are running the API project locally on your development machine, you need to rely on a reverse proxy tool to expose your <code>localhost</code> via a public URL. For the sake of simplicity, you can use the dev tunnel tool provided by Microsoft, following these steps:</p> <ul> <li>Install dev tunnel on your environment following these instructions</li> <li>Login with dev tunnel, executing the following command:</li> </ul> <pre><code>devtunnel user login\n</code></pre> <ul> <li>Host your dev tunnel, executing the following commands:</li> </ul> <pre><code>devtunnel create hr-service -a --host-header unchanged\ndevtunnel port create hr-service -p 7071\ndevtunnel host hr-service\n</code></pre> <p>The command line will display the connection information, such as:</p> <p></p> <p>Copy the \"Connect via browser\" URL and save it in a safe place.</p> <p>Be sure to leave the dev tunnel command running as you do the exercises in this lab. If you need to restart it, just repeat the last command <code>devtunnel host hr-service</code>.</p> <p></p>"},{"location":"pages/make/copilot-studio/05-connectors/#step-4-registering-the-consumer-in-entra-id","title":"Step 4: Registering the Consumer in Entra ID","text":"<p>In order to consume the API from the Power Platform using a custom connector, you also need to register a consumer application in Microsoft Entra ID. Go back to the Microsoft Entra admin center and select again App registrations in the menu bar on the left, and then select the + New registration command to register a new application in the target tenant. This time, name the new application as <code>HR-Service-Consumer</code>. As like as in Step 1, configure the new application for single tenant authentication and register it.</p> <p>Microsoft Entra will register the application for you and show the Overview page with information about the newly registered application. Copy the value of Client ID and Tenant ID, because you will need them soon.</p> <p></p> <p>Select the 1\ufe0f\u20e3 Certificates &amp; Secrets menu item on the left menu, then 2\ufe0f\u20e3 select + New secret to add a new client secret. Then, 3\ufe0f\u20e3 configure a name and a duration for the secret and 4\ufe0f\u20e3 select the Add command to create the new secret. Copy the value of the new secret in a safe place, together with the Client ID and Tenant ID that you copied before.</p> <p>Switch to the permissions page, 1\ufe0f\u20e3 select the API permissions menu item on the left menu, then 2\ufe0f\u20e3 select + Add a permission. In the panel that shows up on the right side, 3\ufe0f\u20e3 select APIs my organization uses, search and 4\ufe0f\u20e3 select <code>HR-Service-API</code>.</p> <p></p> <p>Once you select the targe API, the side panel updates and allows you to select the delegated permission of type <code>HR.Consume</code> that you configured before. Once you picked the permission, select the Add permission command to add it to the consumer application. When the permission has been added, select the Grand admin consent for ... command to grant the permission to the application.</p> <p></p> <p>At the end of this process, the consumer application will be configured with the permissions highlighted in the following screenshot.</p> <p></p> <p>Keep the consumer application tab open, because you will need to update its configuration in the upcoming steps.</p> <p></p>"},{"location":"pages/make/copilot-studio/05-connectors/#exercise-2-creating-the-custom-connector","title":"Exercise 2 : Creating the custom connector","text":"<p>In this excercise you are going to create the Power Platform custom connector to consume the HR Service API.</p>"},{"location":"pages/make/copilot-studio/05-connectors/#step-1-creating-the-custom-connector","title":"Step 1: Creating the custom connector","text":"<p>To create a new custom connector, open a browser and, using the work account of your target Microsoft 365 tenant, go to https://make.powerautomate.com to access Power Automate. First of all, switch to the <code>Copilot Dev Camp</code> environment, using the environment selctor in the upper right corner of the screen. Then, on the left-side menu panel, select More, then Discover all, then look for Custom connectors. You can eventually pin the menu item if you plan to use it frequently. The page with the list of custom connectors will appear. Select the command + New custom connector and choose Import an OpenAPI file.</p> <p></p> <p>Provide a name for the connector and browse for the OpenAPI JSON file of the <code>HR-Service</code>. You can also find the file here. Once you have provided a name and the Open API specification file, select the Continue button to complete the connector creation.</p> <p></p> <p>You will see a multi-step/multi-tab registration process showing up. The first tab is the General one, where you can configure a custom icon, color, and description for the connector. In the General tab you also need to configure the Host value, which has to be the host name of the dev tunnel URL that you copied in Exercise 1 - Step 3. Last but not least, you need to configure the Base URL, where you can leave the default value <code>/</code>.</p> <p></p> <p>Select the Security command at the bottom of the page to switch to the security settings for the connector. In the Security tab select <code>OAuth 2.0</code> as the authentication type. Then choose <code>Azure Active Directory</code> as the flavor of OAuth 2.0 protocol to support.</p> <p></p> <p>Once you have selected <code>OAuth 2.0</code> as the authentication type and <code>Azure Active Directory</code>, the tab will prompt you to provide all the needed settings to properly configure security for the custom connector. Specifically, you need to provide:</p> <ul> <li>Client ID: the <code>&lt;Client-Id&gt;</code> of the consumer application that you registered in Exercise 1 - Step 4.</li> <li>Client secret: the <code>&lt;Client-Secret&gt;</code> of the consumer application that you registered in Exercise 1 - Step 4.</li> <li>Authorization URL: the Entra ID authorization URL. Should always be the default one, unless you are using GCC tenants.</li> <li>Tenant ID: the <code>&lt;Tenant-Id&gt;</code> of the consumer application that you registered in Exercise 1 - Step 4.</li> <li>Resource URL: The <code>&lt;Application-ID-URI&gt;</code> that you registered in Exercise 1 - Step 2 for the <code>HR-Service-API</code> application. Should be something like <code>api://&lt;Client-Id&gt;</code>, where this time the <code>&lt;Client-Id&gt;</code> is the one of the <code>HR-Service-API</code> application.</li> <li>Enable on-behalf-of login: Keep it with value <code>False</code>.</li> <li>Scope: the scope that you configured for the <code>HR-Service-API</code> application in Exercise 1 - Step 2. It should be <code>HR.Consume</code>.</li> <li>Redirect URL: this is a read-only field that you will use soon.</li> </ul> <p></p> <p>Now save the connector settings by selecting the Create connector command in the upper right corner of the tab. Once the connector will be saved, the Security tab reloads and you will be able to see an actual value for the Redirect URL field. Copy that value and go back to Microsoft Entra ID admin center. Go to the consumer application that you registered in Exercise 1 - Step 4 and 1\ufe0f\u20e3 select the Authentication menu item on the left menu, then 2\ufe0f\u20e3 select + Add a platform. In the panel that shows up on the right side, 3\ufe0f\u20e3 select Web, and the 4\ufe0f\u20e3 paste the Redirect URL that you just copied from the custom connector interface and 5\ufe0f\u20e3 select Configure to confirm the new settings.</p> <p></p> <p>You have just configured the consumer application to support the Power Platform as a redirect URL when completing the authentication flow.</p> <p></p> <p>Now you can go back to the custom connector definition and you can move to the Definition tab. There you will find all the operations exposed by the REST API. Their definition was retrieved by the OpenAPI specification file. You don't need to do anything here. You can simply switch to the Test tab, if you like, in order to test that the REST API is working as expected.</p> <p></p>"},{"location":"pages/make/copilot-studio/05-connectors/#step-2-testing-the-custom-connector","title":"Step 2: Testing the custom connector","text":"<p>In he Test tab you can see the list of operations on the left side. Choose one operation, like for example getCandidates, then connect to the target connector selecting the + New connection command and following the prompts of Power Platform to authenticate. Once the connection is ready, you can test the selected operation by selecting the Test operation command and looking for the output in the lower part of the screen.</p> <p></p> <p></p>"},{"location":"pages/make/copilot-studio/05-connectors/#exercise-3-consuming-the-custom-connector","title":"Exercise 3 : Consuming the custom connector","text":"<p>In this excercise you are going to consume the custom connector that you created in Exercise 2.</p>"},{"location":"pages/make/copilot-studio/05-connectors/#step-1-consuming-the-custom-connector-from-the-agent","title":"Step 1: Consuming the custom connector from the agent","text":"<p>In this step you are going to consume the custom connector from the agent for Microsoft 365 Copilot Chat that you created in Lab MCS4.</p> <p>Open a browser and, using the work account of your target Microsoft 365 tenant, go to https://copilotstudio.microsoft.com to start using Microsoft Copilot Studio.</p> <p>Then 1\ufe0f\u20e3 browse the list of agents in Copilot Studio and 2\ufe0f\u20e3 select the agent with name Microsoft 365 Copilot.</p> <p></p> <p>Now, edit the <code>Agentic HR</code> agent, go to the Actions section and select + Add action. Follow the instructions that you have already seen in Lab MCS4 - Exercise 2 - Step 1. However, this time select the Custom connector group of actions and search for <code>HR-Services</code>. You will see the actions defined in the <code>HR-Services</code> connector that you created in Exercise 2 - Step 1.</p> <p>Select the <code>Get all candidates</code> action and confirm to connect to the target custom connector. Configure the action as follows:</p> <ul> <li>Name: <code>Get all candidates</code>.</li> <li>Description: <code>Lists all the HR candidates from an external system</code>.</li> <li>Authentication: <code>User authentication</code>.</li> </ul> <p>Add the action by selecting the Add action command. Once you have created the new action, disable the old action that you created in Lab MCS4 - Exercise 2 - Step 1. To disable an action, click on the three dots (...) beside the action and toggle the Status to <code>Off</code>.</p> <p></p> <p>Publish the updated agent and once it is ready and updated, test the new action providing the following prompt in the Microsoft 365 Copilot Chat:</p> <pre><code>Lists all the HR candidates from an external system\n</code></pre> <p>Microsoft 365 Copilot Chat will ask you to allow consuming the external REST API. Select the command Allow once if you want to test the whole process multiple times, or Always allow if you want to consent consuming the REST API for any further request.</p> <p></p> <p>Then Microsoft 365 Copilot Chat will then ask you to sign-in to securely access the external REST API, providing you a message like the following one.</p> <p></p> <p>Select Sign in to Agentic HR to authenticate and connect to the target custom connector. Once the connection is established, go back to the Microsoft 365 Copilot Chat and run one more time the same prompt as before. You will see the list of candidates as they are defined in the HR Service project and, in the lower part of the response, you can notice there is the icon informing you that the response came from the external service.</p> <p></p> <p>For the sake of completeness, go to Visual Studio Code and notice that in the Terminal area, in the lower part of the screen, there is tracing of to the REST request processed by the API. Notice also the message <code>Token is valid for user &lt;username&gt;</code> highlighted in the following screenshot and showing that the request was authenticated for the user consuming the API from within Microsoft 365 Copilot.</p> <p></p> <p>Wonderful! You were able to configure a custom connector and consume it within Microsoft 365 Copilot Chat!</p> <p></p> <p>CONGRATULATIONS!</p> <p>You have completed Lab MCS5 - Power Platform custom connector!</p> <p>Start here with Lab MCS6, to learn how to consume an MCP server in Copilot Studio.  </p> <p></p>"},{"location":"pages/make/copilot-studio/06-mcp/","title":"Lab MCS6 - Consuming an MCP server","text":"<p>In this lab, you are going to understand how to extend an agent made with Microsoft Copilot Studio using an MCP (Model Context Protocol) server. Specifically, you are going to consume an existing MCP server that provides tools for managing a hypothetical list of candidates for a job role. The MCP server will offer functionalities to:</p> <ul> <li>List all candidates </li> <li>Search for candidates by criteria</li> <li>Add new candidates </li> <li>Update existing candidate information</li> <li>Remove candidates </li> </ul> Get a quick overview of the lab in this video. <p>Do these labs if you want to build agents with Microsoft Copilot Studio</p> <ul> <li>MCS0 - Setup</li> <li>MCS1 - First agent</li> <li>MCS2 - Defining Topics</li> <li>MCS3 - Defining Tools</li> <li>MCS4 - Extending Microsoft 365 Copilot</li> <li>MCS5 - Consuming a custom connector</li> <li>MCS6 - Consuming an MCP server</li> <li>MCS7 - Creating Autonomous Agents</li> <li>MCS8 - Integrating Azure AI Search for RAG</li> <li>MCS9 - Connected Agents (Preview)</li> </ul> <p>Learn about MCP</p> <p>This lab introduces MCP concepts and shows how to integrate them with Copilot Studio. MCP is a new protocol that allows AI assistants to securely connect to external data sources and tools. You can learn more about MCP reading the content available in the Model Context Protocol (MCP) for beginners training class.</p> <p>In this lab you will learn:</p> <ul> <li>How to configure and connect to an existing MCP server</li> <li>How to consume MCP tools and resources from an external server</li> <li>How to integrate MCP servers with Copilot Studio agents</li> </ul>"},{"location":"pages/make/copilot-studio/06-mcp/#exercise-1-setting-up-the-mcp-server","title":"Exercise 1 : Setting up the MCP Server","text":"<p>In this exercise you are going to setup a pre-built MCP server that provides HR candidates management functionality. The server is based on Microsoft .NET and relies on the MCP SDK for C#. The server provides tools to manage a hypothetical list of job candidates. In this exercise you are going to download and configure the server, so that you can run it locally.</p>"},{"location":"pages/make/copilot-studio/06-mcp/#step-1-understanding-the-mcp-server-and-prerequisites","title":"Step 1: Understanding the MCP Server and prerequisites","text":"<p>The HR MCP server that you will be consuming in this lab provides the following tools:</p> <ul> <li>list_candidates: Provides the whole list of candidates</li> <li>search_candidates: Searches for candidates by name, email, skills, or current role</li> <li>add_candidate: Adds a new candidate to the list</li> <li>update_candidate: Updates an existing candidate by email</li> <li>remove_candidate: Removes a candidate by email</li> </ul> <p>The server manages candidates information including:</p> <ul> <li>Personal details (firstname, lastname, full name, email)</li> <li>Professional information (spoken languages, skills, current role)</li> </ul> <p>Before starting, make sure you have:</p> <ul> <li>.NET 8.0 SDK</li> <li>Visual Studio Code</li> <li>Node.js v.22 or higher</li> <li>MCP Inspector</li> <li>Dev tunnel</li> </ul> <p></p>"},{"location":"pages/make/copilot-studio/06-mcp/#step-2-downloading-and-running-the-mcp-server","title":"Step 2: Downloading and running the MCP Server","text":"<p>For this lab, you will use a pre-built HR MCP server. Download the server files from here.</p> <p>Extract the files from the zip and open the target folder with Visual Studio Code. The server is already implemented and ready to run.</p> <p></p> <p>The main elements of the project outline are:</p> <ul> <li><code>Configuration</code>: folder with the <code>HRMCPServerConfiguration.cs</code> file defining the configuration settings for the MCP server.</li> <li><code>Data</code>: folder with the <code>candidates.json</code> file providing the list of candidates.</li> <li><code>Services</code>: folder with the <code>ICandidateService.cs</code> interface and the actual <code>CandidateService.cs</code> implementation of a service to load and manage the list of candidates.</li> <li><code>Tools</code>: folder with the <code>HRTools.cs</code> file defining the MCP tools and the <code>Models.cs</code> file defining the data models used by the tools.</li> <li><code>DevTunnel_Instructions.MD</code>: instructions about how to expose the MCP server via a dev tunnel.</li> <li><code>Progam.cs</code>: the main entry point of the project, where the MCP server gets initialized.</li> </ul> <p>Open a new terminal window from within Visual Studio Code or simply start a new terminal window and move to the root folder of the MCP server project that you just extracted. Then install dependencies, build, and start the .NET project by invoking the following command:</p> <pre><code>dotnet run\n</code></pre> <p>Check that the MCP server is up and running. You should be able to consume the server via browser at the URL http://localhost:47002/. You will see an error inside a JSON message, that's ok. It means that you are reaching the MCP server.</p> <p>Info</p> <p>The pre-built HR MCP Server provided with this lab is not a production-ready solution. It operates using an in-memory list of candidates and does not retain data across multiple conversation sessions. It was developed specifically for the purpose of this lab, to offer a simple and accessible solution. If you are a professional developer, you may consider it a starting point for understanding the fundamentals of building an MCP server exposed via HTTP. If you like you can improve the server relying on a container app and adding persistence storage. For example, here you can find a more advanced version of the server, implemented by Fabian Williams (Microsoft).</p> <p></p>"},{"location":"pages/make/copilot-studio/06-mcp/#step-3-configure-the-dev-tunnel","title":"Step 3: Configure the dev tunnel","text":"<p>Now, you need to expose the MCP server with a public URL. Since you are running the server locally on your development machine, you need to rely on a reverse proxy tool to expose your <code>localhost</code> via a public URL. For the sake of simplicity, you can use the dev tunnel tool provided by Microsoft, following these steps:</p> <ul> <li>Install dev tunnel on your environment following these instructions</li> <li>Login with dev tunnel, executing the following command:</li> </ul> <pre><code>devtunnel user login\n</code></pre> <ul> <li>Host your dev tunnel, executing the following commands:</li> </ul> <p>Important</p> <p>Replace the <code>hr-mcp</code> name suggested below with whatever name you like, in order to have a unique name for your dev tunnel. For example, if your name is Rose you can use <code>hr-mcp-rose</code> as the name for your tunnel. In case you will get an error like <code>Request not permitted. Unauthorized tunnel creation access ...</code> it means that someone else is already using that name. To solve the issue, simply provide a different name.</p> <pre><code>devtunnel create hr-mcp -a --host-header unchanged\ndevtunnel port create hr-mcp -p 47002\ndevtunnel host hr-mcp\n</code></pre> <p>The command line will display the connection information, such as:</p> <p></p> <p>Copy the \"Connect via browser\" URL and save it in a safe place. Open a browser and navigate to the just copied URL. You might need to confirm that you want to consume the MCP server via the dev tunnel through a confirmation page like the following one.</p> <p></p> <p>Be sure to leave both the dev tunnel command and the MCP server running as you do the exercises in this lab. If you need to restart it, just repeat the last command <code>devtunnel host hr-mcp</code>.</p> <p></p>"},{"location":"pages/make/copilot-studio/06-mcp/#step-4-testing-the-mcp-server","title":"Step 4: Testing the MCP server","text":"<p>You are now ready to test the MCP server on your local environment. For the sake of simplicity, you can use the MCP Inspector. Start a terminal window and run the following command:</p> <pre><code>npx @modelcontextprotocol/inspector\n</code></pre> <p>The Node.js engine will download and run the MCP Inspector, in the terminal window you should see an output like the following one.</p> <p></p> <p>The browser will start automatically and you will see the following interface.</p> <p></p> <p>Configure the MCP Inspector with the following settings:</p> <ul> <li>1\ufe0f\u20e3 Transport type: Streamable HTTP</li> <li>2\ufe0f\u20e3 URL: the URL that you saved from the \"Connect via browser\" of the dev tunnel</li> </ul> <p>Then select the 3\ufe0f\u20e3 Connect button to start consuming the MCP server. The connection should be successful, and you should be able to have a green bullet and the message Connected just below the connection handling commands. Now, in the Tools section of the screen, select the 1\ufe0f\u20e3 List Tools command to retrieve the list of tools exposed by the MCP server. Then, select the 2\ufe0f\u20e3 list_candidates tool, and then select 3\ufe0f\u20e3 Run tool to invoke the selected tool.</p> <p></p> <p>In case of successful response, you will see a Success message in green and the output of the tool invocation. In the History section you can always review all the invocations sent to the MCP server.</p> <p></p> <p>You are now ready to consume the MCP server from an agent in Microsoft Copilot Studio.</p> <p></p>"},{"location":"pages/make/copilot-studio/06-mcp/#exercise-2-creating-a-new-agent-in-copilot-studio","title":"Exercise 2 : Creating a New Agent in Copilot Studio","text":"<p>In this exercise you are going to create a new agent in Microsoft Copilot Studio that will consume the MCP server you configured in Exercise 1.</p>"},{"location":"pages/make/copilot-studio/06-mcp/#step-1-creating-the-new-agent","title":"Step 1: Creating the new agent","text":"<p>Open a browser and, using the work account of your target Microsoft 365 tenant, go to https://copilotstudio.microsoft.com to start using Microsoft Copilot Studio.</p> <p>Select the <code>Copilot Dev Camp</code> environment that you created in Exercise 1 of Lab MCS0 - Setup, and then select the Create an agent command in the middle of the screen to create a new agent.</p> <p>Configure the new agent accordingly to the following settings:</p> <ul> <li>Name: </li> </ul> <pre><code>HR Candidate Management\n</code></pre> <ul> <li>Description: </li> </ul> <pre><code>An AI assistant that helps manage HR candidates using MCP server integration \nfor comprehensive candidate management\n</code></pre> <ul> <li>Instructions: </li> </ul> <pre><code>You are a helpful HR assistant that specializes in candidate management. You can help users search \nfor candidates, check their availability, get detailed candidate information, and add new \ncandidates to the system. \nAlways provide clear and helpful information about candidates, including their skills, experience, \ncontact details, and availability status.\n</code></pre> <ul> <li>Agent's Model: select GTP-5 Chat</li> </ul> <p></p> <p>Select Publish to publish your new agent.</p> <p></p>"},{"location":"pages/make/copilot-studio/06-mcp/#step-2-configuring-the-agents-conversation-starters","title":"Step 2: Configuring the agent's conversation starters","text":"<p>Now in the Overview page, configure the Suggested prompts section, adding the following helpful prompts:</p> <ol> <li>Title: <code>List all candidates</code> - Prompt: <code>List all the candidates</code></li> <li>Title: <code>Search candidates</code> - Prompt: <code>Search for candidates with name [NAME_TO_SEARCH]</code></li> <li>Title: <code>Add new candidate</code> - Prompt: <code>Add a candidate with firstname [FIRSTNAME], lastname [LASTNAME],  e-mail [EMAIL], role [ROLE], spoken languages [LANGUAGES], and skills [SKILLS]</code></li> </ol> <p></p> <p>Select the Save button to confirm your changes.</p> <p></p>"},{"location":"pages/make/copilot-studio/06-mcp/#exercise-3-integrating-mcp-server-with-copilot-studio","title":"Exercise 3 : Integrating MCP Server with Copilot Studio","text":"<p>In this exercise you are going to configure the integration between your MCP server and the Copilot Studio agent.</p>"},{"location":"pages/make/copilot-studio/06-mcp/#step-1-adding-tools-exposed-by-the-mcp-server","title":"Step 1: Adding tools exposed by the MCP server","text":"<p>In your agent, navigate to the 1\ufe0f\u20e3 Tools section and select 2\ufe0f\u20e3 + Add a tool.</p> <p></p> <p>Choose 1\ufe0f\u20e3 Model Context Protocol group to see all the already existing MCP servers available to you agent. Now select 2\ufe0f\u20e3 + New tool to add the actual HR MCP server.</p> <p></p> <p>A new dialog shows up allowing you to select the kind of tool that you want to add. Select the Model Context Protocol option.</p> <p></p> <p>A new dialog will open, allowing you to configure the new MCP server providing name, description, URL, and authentication method.</p> <p>Provide a name for the MCP server, for example:</p> <p><code>HR MCP Server</code></p> <p>Provide a description, for example:</p> <p><code>Allows managing a list of candidates for the HR department</code></p> <p>Configure the URL of the server, providing the URL that you copied from the dev tunnel with name <code>[Connect via browser of your dev tunnel]</code>.</p> <p>Select None as the authentication method and then select Create to configure the actual tool.</p> <p></p> <p>Once the tool will get created, you will see a new dialog window requesting you to connect to the MCP server.</p> <p></p> <p>Select the <code>Not connected</code> option and then select Create a new connection. Follow the steps and you will be able to connect to the target MCP server.</p> <p></p> <p>Once the connection is completely configured, you can select the Add and configure command in the dialog window and see the MCP server and tools properly configured.</p> <p></p> <p>All the tools exposed by the MCP server are now available to your agent, as you can verify in the window displaying the MCP server details and tools.</p> <p></p> <p></p>"},{"location":"pages/make/copilot-studio/06-mcp/#step-2-test-the-new-mcp-server-integration","title":"Step 2: Test the new MCP server integration","text":"<p>Publish your agent by selecting Publish in the top right corner. Once published, test the agent in the integrated Test panel using the following prompt:</p> <pre><code>List all candidates\n</code></pre> <p>The agent should use the MCP server's <code>list_candidates</code> tool to return a complete list of all candidates in your HR system. However, in order to being able to consume the list of candidates you will need to connect to the target connector. As such, Copilot Studio will ask you to Open connection manager, connect to the MCP server, and then Retry the request.</p> <p></p> <p>Once the connection is established, you can get the actual list of candidates from the HR MCP server.</p> <p></p> <p>Debugging the MCP server locally</p> <p>If you are a developer and you like to dig into the MCP server implementation, you can add breakpoints to the <code>HRTools.cs</code> file and attach a debugger from Visual Studio Code. You will be able to dig into the code and debug the actual MCP server in action.</p> <p>You can also make the agent available in the Microsoft 365 Copilot Chat. Select the 1\ufe0f\u20e3 Channels section, then select the 2\ufe0f\u20e3 Teams and Microsoft 365 Copilot channel, check the 3\ufe0f\u20e3 Make agent available in Microsoft 365 Copilot option, and then select the 4\ufe0f\u20e3 Add channel command. Wait for the channel to be enabled, then close the channel side panel and publish the agent again selecting the Publish command of the agent in the top right corner.</p> <p></p> <p>Now, open the Teams and Microsoft 365 Copilot channel again and select the command See agent in Microsoft 365 to add the agent to Microsoft 365 Copilot.</p> <p></p> <p>You will see the interface to add the agent to Microsoft 365 Copilot, select Add and then Open, in order to play with the agent in Microsoft 365 Copilot.</p> <p>Agent details</p> <p>If you like, through the Teams and Microsoft 365 Copilot channel configuration panel, you can also provide additional details about the agent like a description, a custom icon, etc.</p> <p></p> <p>You can now play with the agent in Microsoft 365 Copilot, notice the suggested prompts in the UI of the agent. Now, for example, you can try with another prompt like:</p> <pre><code>Search for candidate Alice\n</code></pre> <p></p> <p>Now the agent should use the MCP server's <code>search_candidates</code> tool and return only one candidate matching the search criteria. However, since we are in the Microsoft 365 Copilot context, you will need to connect again to the MCP server, using the Microsoft Copilot Studio connections management interface.</p> <p></p> <p>Once connected, you will be able to run again the prompt and get the expected response.</p> <p></p> <p>It is now time to test a much more advanced tool, like the <code>add_candidate</code> one to add a new candidate to the HR system. Use the following prompt:</p> <pre><code>Add a new candidate: John Smith, Software Engineer, skills: React, Node.js, \nemail: john.smith@email.com, speaks English and Spanish\n</code></pre> <p>The agent will understand your intent, will extract the input arguments for the <code>add_candidate</code> tool, and will invoke it adding a new candidate to the list. The response from the MCP server will be a simple confirmation.</p> <p></p> <p>You can double check the outcome by listing again the whole list of candidates. You can find <code>John Smith</code> as a new candidate at the end of the list.</p> <p></p> <p>You can also have fun with other prompts like:</p> <pre><code>Update the candidate with email bob.brown@example.com to speak also French\n</code></pre> <p>or:</p> <pre><code>Add skill \"Project Management\" to candidate bob.brown@example.com\n</code></pre> <p>or:</p> <pre><code>Remove candidate bob.brown@example.com\n</code></pre> <p>The agent will invoke the right tools for you and will act accordingly to your prompts.</p> <p>Well done! Your agent is fully functional and capable of consuming all the tools exposed by the HR MCP server.</p> <p></p> <p>CONGRATULATIONS!</p> <p>You have completed Lab MCS6 - Consuming an MCP server!</p> <p>Start here with Lab MCS7, to learn how to create autonomous agents in Copilot Studio.  </p> <p></p>"},{"location":"pages/make/copilot-studio/07-autonomous/","title":"Lab MCS7 - Creating Autonomous Agents","text":"<p>In this lab, you are going to understand how to create an autonomous agent using Microsoft Copilot Studio. The autonomous agent that you are going to create automatically processes candidate data from PDF files uploaded to SharePoint. The agent monitors a SharePoint document library for new PDF uploads, extracts candidate information using AI, and automatically creates candidate records using the MCP server you built in Lab MCS6. This lab demonstrates how autonomous agents can streamline HR workflows by automating document processing and data entry tasks.</p> Get a quick overview of the lab in this video. <p>Do these labs if you want to build agents with Microsoft Copilot Studio</p> <ul> <li>MCS0 - Setup</li> <li>MCS1 - First agent</li> <li>MCS2 - Defining Topics</li> <li>MCS3 - Defining Tools</li> <li>MCS4 - Extending Microsoft 365 Copilot</li> <li>MCS5 - Consuming a custom connector</li> <li>MCS6 - Consuming an MCP server</li> <li>MCS7 - Creating Autonomous Agents</li> <li>MCS8 - Integrating Azure AI Search for RAG</li> <li>MCS9 - Connected Agents (Preview)</li> </ul> <p>Note</p> <p>This lab builds on the previous one, Lab MCS6. You should be able to continue consuming the same MCP server that you configured in the previous lab.</p> <p>In this lab you will learn:</p> <ul> <li>How to create autonomous agents in Microsoft Copilot Studio</li> <li>How to configure SharePoint document library triggers</li> <li>How to process PDF documents with AI to extract structured data</li> <li>How to integrate autonomous agents with MCP servers</li> </ul>"},{"location":"pages/make/copilot-studio/07-autonomous/#exercise-1-setting-up-the-sharepoint-environment","title":"Exercise 1: Setting up the SharePoint Environment","text":"<p>In this exercise you are going to prepare a SharePoint document library that will serve as the trigger point for your autonomous agent. The agent will monitor this library for new PDF files containing candidate data and automatically process them.</p>"},{"location":"pages/make/copilot-studio/07-autonomous/#step-1-creating-the-sharepoint-document-library","title":"Step 1: Creating the SharePoint Document Library","text":"<p>Before creating the autonomous agent, you need to set up a SharePoint document library where HR personnel can upload candidate PDF files.</p> <p>Navigate to your SharePoint site (you can use any SharePoint site of your Microsoft 365 tenant, or you can create a new one from scratch) and create a new document library:</p> <ol> <li>Go to Site contents and select New \u2192 Document library</li> <li>Select Blank library as the template</li> <li>Name the library: <code>Candidates Data</code></li> <li>Set the description: <code>Document library for candidate PDF data files</code></li> <li>Select Create to create the library</li> </ol> <p></p> <p>Once created, configure the library permissions to ensure your autonomous agent can access it:</p> <ol> <li>Select Settings (gear icon) \u2192 Library settings</li> <li>Under Permissions and Management, select Permissions for this document library</li> <li>Ensure that the account you're using for Microsoft Copilot Studio has at least Contribute permissions</li> </ol> <p></p>"},{"location":"pages/make/copilot-studio/07-autonomous/#step-2-preparing-sample-pdf-files","title":"Step 2: Preparing Sample PDF Files","text":"<p>For testing purposes, download resumes.zip and unzip the folder. The downloaded files describe hypothetical candidates including information such as:</p> <ul> <li>Full name</li> <li>Email address  </li> <li>Current role/position</li> <li>Skills and expertise</li> <li>Spoken languages</li> </ul> <p>You can also create simple PDF files using any word processor and save them as PDF, or use existing resume/CV files. Make sure the text is readable (not scanned images) so that AI can extract the information properly.</p> <p></p>"},{"location":"pages/make/copilot-studio/07-autonomous/#step-3-ensuring-prerequisites","title":"Step 3: Ensuring Prerequisites","text":"<p>Before proceeding, ensure you have completed the following:</p> <ul> <li>Lab MCS6: The HR MCP server should be running and accessible via dev tunnel</li> <li>SharePoint Access: Permissions to create and manage document libraries</li> <li>Power Platform Environment: Access to the same environment used in previous labs</li> <li>Sample PDF Files: At least 2-3 test PDF files with candidate data</li> </ul> <p>Also verify that the HR MCP server from Lab MCS6 is still running and if not, you can simply run it:</p> <pre><code>dotnet run\n</code></pre> <p>And ensure your dev tunnel is active:</p> <pre><code>devtunnel host hr-mcp\n</code></pre> <p>Keep both services running throughout this lab as the autonomous agent will need to communicate with the MCP server.</p> <p></p>"},{"location":"pages/make/copilot-studio/07-autonomous/#exercise-2-creating-the-autonomous-agent","title":"Exercise 2: Creating the Autonomous Agent","text":"<p>In this exercise you are going to create the autonomous agent in Microsoft Copilot Studio that will monitor the SharePoint document library and process new PDF uploads automatically.</p>"},{"location":"pages/make/copilot-studio/07-autonomous/#step-1-creating-the-autonomous-agent","title":"Step 1: Creating the Autonomous Agent","text":"<p>Open a browser and, using the work account of your target Microsoft 365 tenant, go to https://copilotstudio.microsoft.com to start using Microsoft Copilot Studio.</p> <p>Select the <code>Copilot Dev Camp</code> environment that you created in previous labs, then from the middle of the home page of Copilot Studio select Create an agent to create a new agent.</p> <p>Configure your autonomous agent with the following settings:</p> <ul> <li>Name: </li> </ul> <pre><code>Autonomous HR Docs Processor\n</code></pre> <ul> <li>Description: </li> </ul> <pre><code>An autonomous AI agent that monitors SharePoint for new candidate PDF uploads and \nautomatically processes them to create candidate records via MCP server integration\n</code></pre> <ul> <li>Instructions: </li> </ul> <pre><code>You are an autonomous HR assistant that specializes in processing candidate data \nfrom PDF documents. When a new PDF file is uploaded to the SharePoint document library, \nyou automatically:\n\n1. Extract candidate information from the PDF file content including name, email, skills, languages, and role\n2. Validate and structure the extracted data\n3. Create a new candidate record using the 'add_candidate' tool of the HR MCP server\n4. Provide confirmation of successful processing\n5. Send me an email with confirmation that the new candidate record was created and with a recap of candidate's data\n\nAlways ensure data accuracy and provide clear feedback about the processing results. \nHandle errors gracefully and provide informative messages when processing fails.\n\nIMPORTANT: Do not wait for any user input. Work completely autonomously.\n\nDO NOT invent or assume fake data about candidates. AVOID allucinations.\nYou MUST ONLY process real and existing data.\n</code></pre> <p>Select Publish to publish your autonomous agent.</p> <p></p>"},{"location":"pages/make/copilot-studio/07-autonomous/#step-2-enhancing-agent-intelligence","title":"Step 2: Enhancing Agent Intelligence","text":"<p>After creating the agent, you need to ensure that its capabilities are enhanced with generative AI reasoning and knowledge integration.</p> <p>In the Knowledge section of the agent, you can optionally add knowledge sources if you have specific HR documentation or candidate processing guidelines. For this lab, we'll rely on the agent's built-in AI capabilities and the MCP server integration.</p> <p>In case of any configuration changes, select Save to confirm them.</p> <p></p>"},{"location":"pages/make/copilot-studio/07-autonomous/#step-3-adding-the-mcp-server-integration","title":"Step 3: Adding the MCP Server Integration","text":"<p>Your autonomous agent needs access to the HR MCP server tools to create candidate records. Navigate to the Tools section and select + Add a tool.</p> <ol> <li>Choose Model Context Protocol group</li> <li>Find and select the HR MCP Server that you configured in Lab MCS6</li> <li>Select Add and configure to integrate the MCP server tools</li> </ol> <p></p> <p>This gives your autonomous agent access to all the HR MCP server tools:</p> <ul> <li><code>list_candidates</code></li> <li><code>search_candidates</code> </li> <li><code>add_candidate</code></li> <li><code>update_candidate</code></li> <li><code>remove_candidate</code></li> </ul> <p>The agent will primarily use the <code>add_candidate</code> tool for processing new PDF uploads.</p> <p></p>"},{"location":"pages/make/copilot-studio/07-autonomous/#step-4-adding-the-email-management-mcp-server","title":"Step 4: Adding the Email Management MCP Server","text":"<p>Your autonomous agent also needs access to the Email Management MCP Server to being able to send e-mails. Navigate to the Tools section and select + Add a tool.</p> <ol> <li>Choose Model Context Protocol group</li> <li>Find and select Email Management MCP Server</li> <li>Select Add and configure to integrate the MCP server tools</li> </ol> <p>This gives your autonomous agent access to a wide set of tools to manage the e-mails in the current user's mailbox. The agent will primarily use the <code>SendEmail</code> tool for sending notification e-mails.</p> <p></p>"},{"location":"pages/make/copilot-studio/07-autonomous/#exercise-3-configuring-sharepoint-triggers","title":"Exercise 3: Configuring SharePoint Triggers","text":"<p>In this exercise you will configure the autonomous agent to automatically trigger when new PDF files are uploaded to the SharePoint document library.</p>"},{"location":"pages/make/copilot-studio/07-autonomous/#step-1-adding-the-sharepoint-trigger","title":"Step 1: Adding the SharePoint Trigger","text":"<p>In your autonomous agent, navigate to the 1\ufe0f\u20e3 Overview section, scroll to the 2\ufe0f\u20e3 Triggers panel and select 3\ufe0f\u20e3 + Add trigger.</p> <p></p> <p>From the Add trigger dialog, select When a file is created (properties only) from the SharePoint connector options. Then select Next to configure the trigger.</p> <p></p> <p>The next step of the trigger's configuration is to give a name to the trigger and to configure/connect the permissions to access the target apps. In the current scenario the apps are:</p> <ul> <li>Microsoft Copilot Studio</li> <li>SharePoint</li> </ul> <p>Configure the trigger as follows:</p> <ul> <li>Trigger name: <code>When PDF uploaded to Candidate Data library</code></li> </ul> <p></p> <p>Select Next and proceed to configure the trigger with the following additional settings:</p> <ul> <li>Site Address: Select your target SharePoint site or enter its URL</li> <li>Library Name: Select <code>Candidate Data</code> (the library you created)</li> <li>Folder: Leave blank to monitor the entire library</li> <li>Limit columns by View (Optional): All Documents</li> <li>Additional instructions to the agent when it's invoked by this trigger: Use content from <code>Body</code> and read content of the PDF file.</li> </ul> <p></p> <p>Select Create trigger to add the SharePoint monitoring trigger to your agent. The process takes a while to complete. Once it is ready, you will see a dialog inviting you to test the trigger.</p> <p></p> <p>Select Close to return to the Overview section of your agent.</p> <p></p>"},{"location":"pages/make/copilot-studio/07-autonomous/#step-2-testing-the-trigger","title":"Step 2: Testing the Trigger","text":"<p>In the list of Triggers there is now the new trigger and you can select the little flask near the ellipsis (...) to test it.</p> <p></p> <p>Select the flask, a dialog window shows up waiting for a file to be uploaded in the target library in SharePoint Online.</p> <p></p> <p>Once at least one file will be uploaded in the target library, the dialog updates and allows you to select the Start testing command to test the autonomous agent. In case there are more than one files uploaded, you can select the one you want to use to test the trigger.</p> <p>You can simply upload in the target SharePoint Online library one of the resumes that you downloaded before and wait for the agent to process it.</p> <p>Note</p> <p>It can take up to one minute for the agent to get evidence of the new file(s) uploaded. Be patient while waiting for the trigger test dialog to be ready for testing.</p> <p></p> <p>Once the test starts, the agent can interact with you through the Test your agent side panel. The very first thing you will need to do in this scenario is to connect the agent instance to the target HR MCP Server, so that the agent can create the new candidate. Select Open connection manager in the automated message sent by the agent, then Connect the agent to the HR MCP Server, lastly go back to the Test your agent panel and select Retry.</p> <p>You should be able to see a confirmation message that the candidate described in the PDF resume that you uploaded got added to the target HR MCP server.</p> <p></p> <p>If you like, you can send a prompt to <code>List all the candidates</code> to validate that the new candidate is now part of the list. Your autonomous agent is ready! You can now Publish it and it will start processing files autonomously!</p> <p>When you publish the agent, you might see a couple of warnings like in the following picture.</p> <p></p> <ol> <li>Full access for editors: users with Editor permission will have access to embedded connections used by Flows or Triggers added to this agent.</li> <li>Your agent includes triggers that use the author's credentials: If the instructions in these triggers share data with other users, those users can use the original editor's credentials to access information or complete a task.</li> </ol> <p>Once you have published the agent, try to upload new PDF resume files and see what happens. If you go to the Activity section of the agent, after uploading one or more files to the target SharePoint Online library, you will see the <code>Automated</code> invocation of the agent.</p> <p></p> <p></p>"},{"location":"pages/make/copilot-studio/07-autonomous/#exercise-4-inside-the-autonomous-agents","title":"Exercise 4: Inside the autonomous agents","text":"<p>In this exercise you will understand how an autonomous agent works and what happens behind the scenes.</p>"},{"location":"pages/make/copilot-studio/07-autonomous/#step-1-behind-the-scenes-of-the-trigger","title":"Step 1: Behind the scenes of the trigger","text":"<p>After creating and testing the trigger, you might want to understand how an autonomous agent works. Select the ellipsis (...) next to your trigger and choose Edit in Power Automate.</p> <p></p> <p>In Power Automate, you'll see the flow that sits behind the scenes of the autonomous agent's trigger. </p> <p></p> <p>The flow is really trivial. There are simply a triggering action of type When a file is created (properties only) from the SharePoint connector and another action Sends a prompt to the specified copilot for processing to invoke the target agent. Practically speaking, a trigger of an autonomous agent is a Power Automate flow that sends a prompt to the agent. As such, almost any trigger for a Power Automate flow can become a trigger for a Copilot Studio autonomous agent.</p> <p>In case of need, you can customize the behavior of the flow to add additional behaviors or functionalities to the trigger before invoking the autonomous agent. However, if that is the case, you need to keep into account the insights that you can find in the next step.</p> <p></p>"},{"location":"pages/make/copilot-studio/07-autonomous/#step-2-handling-multiple-files-uploads","title":"Step 2: Handling multiple files uploads","text":"<p>Another interesting thing to know about triggers of autonomous agents is that, when you upload multiple files to SharePoint, or in general when multiple triggering events happen you will not always see one Power Automate flow triggered for each file/event. Likewise, you will not see one agent instance for each file/event. In fact, for example when processing files uploaded to a SharePoint Online document library, there could be one flow instance processing multiple files uploaded in a single unit of time. The Power Automate flow will then trigger one agent instance, which will process one by one every single file.</p> <p>You can clearly inspect the described behavior if you upload two (or more) files at once and then wait for the flow to run in Power Automate and for the autonomous agent to be invoked in Copilot Studio. In fact, there will be only one flow executed for a set of uploaded files and there will be one agent instance for that flow.</p> <p>You can validate this behavior selecting the Activity section of the autonomous agent and inspecting one <code>Automated</code> instance with more than one <code>Completed steps</code> like in the following screenshot.</p> <p></p> <p>Selecting the instance you can see that the agent autonomously processed two (or more) files invoking the <code>add_candidate</code> tool for each of them. There is no need to define complex logic in your agent. Just because in the agent's instructions we said</p> <pre><code>... When a new PDF file is uploaded to the SharePoint document library: ...\n</code></pre> <p>That's enough for the agent's autonomous intelligence to loop across all the uploaded files and apply the same logic to all of them. This is amazing and gives you the idea of how powerful AI is nowadays!</p> <p></p> <p></p> <p>CONGRATULATIONS!</p> <p>You have completed Lab MCS7 - Creating Autonomous Agents!</p> <p>Start here with Lab MCS8, to learn how to use RAG via Microsoft Azure AI Search in Copilot Studio.  </p> <p></p>"},{"location":"pages/make/copilot-studio/08-rag/","title":"Lab MCS8 - Integrating Azure AI Search for RAG","text":"<p>In this lab, you are going to understand how to enhance your Microsoft Copilot Studio agents with Retrieval-Augmented Generation (RAG) capabilities using Azure AI Search. You'll create a specialized HR Knowledge Agent that can search through candidate documents using vector search, providing intelligent, contextual responses backed by your organization's data. This lab demonstrates how to create powerful AI agents that combine the conversational abilities of Copilot Studio with the advanced search capabilities of Azure AI Search.</p> Get a quick overview of the lab in this video. <p>Do these labs if you want to build agents with Microsoft Copilot Studio</p> <ul> <li>MCS0 - Setup</li> <li>MCS1 - First agent</li> <li>MCS2 - Defining Topics</li> <li>MCS3 - Defining Tools</li> <li>MCS4 - Extending Microsoft 365 Copilot</li> <li>MCS5 - Consuming a custom connector</li> <li>MCS6 - Consuming an MCP server</li> <li>MCS7 - Creating Autonomous Agents</li> <li>MCS8 - Integrating Azure AI Search for RAG</li> <li>MCS9 - Connected Agents (Preview)</li> </ul> <p>Important</p> <p>You should have experience with Microsoft Copilot Studio agent creation and basic Azure resource management.</p> <p>In this lab you will learn:</p> <ul> <li>How to create and configure Azure AI Search service for knowledge indexing</li> <li>How to import and vectorize PDF documents using Azure AI Search</li> <li>How to integrate Azure AI Search as a knowledge source in Microsoft Copilot Studio</li> <li>How to create agents that leverage RAG for intelligent document search</li> </ul> What is Retrieval-Augmented Generation (RAG)? <p>Retrieval-Augmented Generation (RAG) is a technique used in artificial intelligence to improve the quality of responses generated by language models. Here's a simple example to understand it better:</p> <p>Imagine you have a smart assistant that can write answers to your questions. Sometimes, this assistant might not know everything it needs to give a great answer. To help with this, RAG lets the assistant look up information from a large collection of documents, similar to how you might search the internet for answers. After finding the relevant information, the assistant then uses this data to write a better, more accurate response.</p> <p>So, RAG combines two steps:</p> <ul> <li>Retrieval: Finding relevant information from a big pool of data.</li> <li>Generation: Using that information to create a detailed and accurate response.</li> </ul> <p>This way, RAG helps in providing more informed and useful answers, making it very effective for tasks like answering questions, writing articles, and assisting with research.</p> <p>Learn more about the RAG by watching this Doodle to Code video!</p> <p></p> Benefits of using Vector Search <p>Vector search is an advanced technique used to find information quickly and accurately based on its meaning rather than just matching exact words. Unlike traditional text-based search, which relies on exact keyword matches, vector search uses numeric vectors to find content that is similar to your query. This enables Vector search to handle:</p> <ul> <li>Semantic or conceptual similarity: Matching concepts that are similar in meaning even if they use different words (e.g., \"recruitment\" and \"hiring\").</li> <li>Multilingual content: Finding equivalent content across different languages (e.g., \"resume\" in English and \"curriculum vitae\" in Latin).</li> <li>Multiple content types: Searching across different formats (e.g., text documents, and PDFs).</li> </ul> <p>Here is how vector search works:</p> <ol> <li>Converting text to vectors: Text or documents are turned into a series of numbers (a vector) that captures the essence or meaning of that content. This is done using embedding models.</li> <li>Storing vectors: These vectors are stored in a special database (for example an Azure AI Search index) designed to handle them efficiently.</li> <li>Searching with vectors: When you search for something, your query is also converted into a vector. The search system then looks for vectors in the index that are close to your query vector in terms of meaning.</li> </ol> <p>For example, if you search for \"software engineering skills,\" the system can find candidates with \"programming expertise\" or \"development capabilities\" even if they don't have the exact words from your search query.</p>"},{"location":"pages/make/copilot-studio/08-rag/#exercise-1-setting-up-azure-ai-search-service","title":"Exercise 1: Setting up Azure AI Search Service","text":"<p>In this exercise you are going to create and configure the Azure AI Search service that will serve as the knowledge foundation for your RAG-enabled agent.</p>"},{"location":"pages/make/copilot-studio/08-rag/#step-1-creating-azure-ai-search-service-resource","title":"Step 1: Creating Azure AI Search Service Resource","text":"<p>Before integrating with Microsoft Copilot Studio, you need to set up Azure AI Search service to store and index your documents.</p> <p>Navigate to the Azure Portal and create an Azure AI Search service:</p> <ol> <li>Select Create a resource and search for <code>Azure AI Search</code></li> <li>Select the Azure AI Search service and then Create</li> <li> <p>Fill out the following details and select Review + Create:</p> <ul> <li>Subscription: Your Azure subscription</li> <li>Resource group: Select the same resource group used for other labs or create new one: <code>copilot-camp-rg</code></li> <li>Service name: A descriptive name such as <code>copilotcamp-ai-search</code> (must be globally unique)</li> <li>Location: Choose the same region as your other Azure resources, if any</li> <li>Pricing tier: Basic (sufficient for this lab)</li> </ul> </li> </ol> <p></p> <p>Once your Azure AI Search service is created, navigate to your resource:</p> <ol> <li>In the Overview section, copy and save the URL (you'll need this later)</li> <li>Navigate to Keys under Settings, in the left navigation bar, and copy the Primary admin key (you'll need this later)</li> </ol> <p>Both the URL and admin key will be required when connecting to Azure AI Search from within Microsoft Copilot Studio.</p> <p></p>"},{"location":"pages/make/copilot-studio/08-rag/#step-2-creating-azure-storage-account","title":"Step 2: Creating Azure Storage Account","text":"<p>For storing the documents that will be indexed, you need an Azure Storage Account that will work with Azure AI Search.</p> <p>In the Azure Portal, create a storage account:</p> <ol> <li>Select Create a resource and search for <code>Storage Account</code></li> <li>Select Storage Account and then Create</li> <li> <p>Fill out the following details and select Review + Create:</p> <ul> <li>Subscription: Your Azure subscription</li> <li>Resource group: Select the same resource group as your Azure AI Search service</li> <li>Storage account name: A unique name such as <code>copilotcampstorage</code> (must be globally unique)</li> <li>Region: Same region as your Azure AI Search service</li> <li>Preferred storage type: Azure Blob Storage or Azure Data Lake Storage Gen 2</li> <li>Performance: Standard</li> <li>Redundancy: Locally redundant storage (LRS)</li> </ul> </li> </ol> <p></p> <p>After the storage account is created, you'll use it to store the PDF documents before they are indexed by Azure AI Search.</p> <p></p>"},{"location":"pages/make/copilot-studio/08-rag/#step-3-creating-text-embedding-model","title":"Step 3: Creating Text Embedding Model","text":"<p>To enable vector search capabilities, you need to create a text embedding model in Azure OpenAI that will convert documents and queries into vector representations.</p> <p>If you don't already have an Azure OpenAI service instance, create one first:</p> <ol> <li>In the Azure Portal, select Create a resource and search for <code>Azure OpenAI</code></li> <li>Select Azure OpenAI and then Create</li> <li> <p>Fill out the following details:</p> <ul> <li>Subscription: Your Azure subscription</li> <li>Resource group: Select the same resource group as your other resources</li> <li>Region: Choose a region that supports Azure OpenAI (such as East US, West Europe, or South Central US)</li> <li>Name: A descriptive name such as <code>copilotcamp-openai</code></li> <li>Pricing tier: Standard S0</li> </ul> </li> <li> <p>Move Next until the end of the creation wizard and then select Create</p> </li> <li>Wait for the deployment to complete (this may take a few minutes)</li> <li>Once created, navigate to your Azure OpenAI resource and note the endpoint URL for later use</li> </ol> <p>Now navigate to Microsoft Foundry. If it is the first time that you access the Microsoft Foundry portal, you might need to select the Azure OpenAI instance that you just created. Select the service instance and proceed with the creation of an embedding model going through the following steps:</p> <ol> <li>Select 1\ufe0f\u20e3 Deployments from the left navigation</li> <li>Select 2\ufe0f\u20e3 + Deploy model</li> <li>Select 3\ufe0f\u20e3 Deploy base model to start deploying the model</li> <li>In the popup dialog, search for model 4\ufe0f\u20e3 <code>text-embedding-ada-002</code></li> <li>Select 5\ufe0f\u20e3 Confirm to start configuring the deployment</li> <li> <p>When the configuration dialog pops up, configure the following settings:</p> <ul> <li>Deployment name: <code>text-embeddings</code> (remember this name)</li> <li>Deployment type: Standard</li> <li>Model version: 2 (Default)</li> <li>Content Filter: DefaultV2</li> </ul> </li> <li> <p>Select 6\ufe0f\u20e3 Deploy and wait for the deployment to complete</p> </li> </ol> <p></p> What does <code>text-embedding-ada-002</code> do? <p>The <code>text-embedding-ada-002</code> model on Azure OpenAI converts text into numeric vectors that represent the meaning of the text. This allows for vector search, where instead of matching exact words, the search finds text with similar meanings. It works with multiple languages and different content types, making it useful for comparing text across languages and formats. When used with Azure AI Search, it improves search results by finding the most relevant and contextually accurate information. This model is perfect for creating advanced search solutions and applications that need to understand natural language.</p> <p>The text embedding model is essential for converting both the indexed documents and user queries into vectors that can be compared for semantic similarity.</p> <p>Tip: Handling quota limitations</p> <p>If you see a \"No quota available\" message, you can either:</p> <ol> <li>Select a different region for your deployment</li> <li>Request additional quota from the Azure OpenAI quota management page</li> <li>Free up resources from other deployments you're not using</li> </ol> <p></p>"},{"location":"pages/make/copilot-studio/08-rag/#exercise-2-creating-and-populating-the-search-index","title":"Exercise 2: Creating and Populating the Search Index","text":"<p>In this exercise you will create a search index in Azure AI Search and populate it with candidate resume documents using the integrated vectorization feature.</p>"},{"location":"pages/make/copilot-studio/08-rag/#step-1-preparing-sample-documents","title":"Step 1: Preparing Sample Documents","text":"<p>For this lab, download the sample resume documents that will be indexed for search. Download fictitious_resumes.zip and unzip the folder to access the PDF files.</p> <p>These sample resumes contain diverse candidate profiles with information such as:</p> <ul> <li>Candidate names and contact information</li> <li>Technical skills and expertise areas</li> <li>Work experience and role history</li> <li>Education backgrounds</li> <li>Language proficiencies</li> <li>Professional certifications</li> </ul> <p>Review the content of these files to understand the type of information that will be searchable through your RAG-enabled agent. Notice also that the documents are written in various languages. This will not be a problem for the <code>text-embedding-ada-002</code> model or for the vector index.</p> <p></p>"},{"location":"pages/make/copilot-studio/08-rag/#step-2-uploading-sample-documents-in-the-storage-account","title":"Step 2: Uploading sample documents in the Storage Account","text":"<p>Using Azure AI Search, you'll create a vector index with your resume documents using the integrated vectorization feature.</p> <p>Navigate to Azure Portal and access the Azure Storage Account service instance. </p> <ol> <li>Select the 1\ufe0f\u20e3 Containers in the Data storage group of commands in the left navigation</li> <li>Select the 2\ufe0f\u20e3 + Add container command in the command bar</li> <li>Provide a name 3\ufe0f\u20e3 for the new container, for example <code>resumes</code></li> <li>Select 4\ufe0f\u20e3 Create to create the actual container</li> </ol> <p></p> <p>Once the container has been created, you can upload the resume files following these steps:</p> <ol> <li>Select 1\ufe0f\u20e3 Upload</li> <li>Drag and drop the resume files or select 2\ufe0f\u20e3 Browse for files and select the resume files</li> <li>Select the 3\ufe0f\u20e3 Upload command and wait for the upload to complete</li> </ol> <p></p> <p></p>"},{"location":"pages/make/copilot-studio/08-rag/#step-3-populating-the-vector-index-with-integrated-vectorization","title":"Step 3: Populating the Vector Index with Integrated Vectorization","text":"<p>Once the resume files are uploaded go back to the home page of the Azure Portal and access the Azure AI Search service instance. Then select the Import data (new) command in the top command bar.</p> <p></p> <p>A new page will show up, through which you can configure the data import process. Select the Azure Blob Storage data source.</p> <p></p> <p>Right after, select RAG as the scenario that you are targeting.</p> <p></p> <p>Now configure the RAG scenario accordingly to the following settings:</p> <ol> <li> <p>Configure your Azure Blob Storage section:</p> <ul> <li>Subscription: Your Azure subscription</li> <li>Storage account: the Storage Account you created before</li> <li>Blob container: the new container that you just created and where you uploaded the resume files, for example <code>resumes</code></li> <li>Blob folder: you can leave it blank, unless you created a folders structure in the storage container</li> <li>Parsing mode: use the <code>Default</code> value</li> <li>Move Next</li> </ul> </li> <li> <p>Vectorize your text section:</p> <ul> <li>Kind: Azure OpenAI</li> <li>Subscription: Your Azure subscription</li> <li>Azure Open AI service: select the Azure OpenAI instance that you created</li> <li>Model deployment: select the <code>text-embeddings</code> model that you just created</li> <li>Authentication type: the default <code>API Key</code> value is ok</li> <li>Check the box to declare <code>I acknowledge that connecting to an Azure OpenAI service will incur additional costs to my account.</code></li> <li>Move Next</li> </ul> </li> <li> <p>Vectorize your images section:</p> <ul> <li>In case you are willing to process images and text in images, you could configure specific settings</li> <li>Here you can simply move Next</li> </ul> </li> <li> <p>Advanced ranking and relevancy section:</p> <ul> <li>If you like you can schedule recurring updates of the index, on a timer based model. You can also choose whether to use the semantic ranker to get results also based on semantic and not only on lexical analysis. Last but not least, you can configure the fields that will be created in the target index</li> <li>Here you can simply move Next</li> </ul> </li> <li> <p>Review and create section:</p> <ul> <li>Here you can provide a prefix for the index, indexer, data source, and skillset that will be created. For example you can use the value <code>resumes</code></li> <li>Review the settings and when you are ready select Create to create and feed the vector index</li> </ul> </li> </ol> <p></p> <p>Once the vector index is created, a small dialog confirms the index creation and availability. Select the Start searching command to start playing with the index. In the search index page, you can simply select the Search command and see the output. Notice that, for every value in the index, you also have a <code>text_vector</code> field that contains the text vectorized using the <code>text-embedding-ada-002</code> model.</p> <p></p> <p></p>"},{"location":"pages/make/copilot-studio/08-rag/#exercise-3-creating-the-rag-enabled-agent","title":"Exercise 3: Creating the RAG-Enabled Agent","text":"<p>In this exercise you will create a Microsoft Copilot Studio agent that leverages your Azure AI Search index to provide intelligent, document-backed responses about HR candidates.</p>"},{"location":"pages/make/copilot-studio/08-rag/#step-1-creating-the-hr-knowledge-agent","title":"Step 1: Creating the HR Knowledge Agent","text":"<p>Navigate to Microsoft Copilot Studio and create a new agent optimized for knowledge search.</p> <p>Using your work account, access your <code>Copilot Dev Camp</code> environment and create a new agent defining your agent as follows:</p> <ul> <li>Name: </li> </ul> <pre><code>HR Knowledge Agent\n</code></pre> <ul> <li>Description: </li> </ul> <pre><code>An intelligent HR assistant that searches through candidate documents using advanced \nvector search capabilities to provide contextual, document-backed responses\n</code></pre> <ul> <li>Instructions: </li> </ul> <pre><code>You are an intelligent HR Knowledge Assistant specializing in candidate search. \nYou have access to a comprehensive database of candidate resumes through advanced \nvector search capabilities.\n\nWhen users ask questions, you should:\n\n1. Search through the candidate database using semantic understanding\n2. Provide detailed, accurate information based on the indexed documents\n3. Always include proper citations and references to source documents\n4. Explain your reasoning when matching candidates to requirements\n5. Suggest alternative candidates when exact matches aren't available\n6. Help users understand the skills and qualifications of different candidates\n\nYou excel at:\n- Finding candidates with specific technical skills\n- Matching language requirements with candidate profiles\n- Identifying experience levels and career progression\n- Understanding educational backgrounds and certifications\n- Semantic search that goes beyond keyword matching\n\nAlways provide helpful, accurate information while respecting privacy and being professional.\n</code></pre> <p></p> <p>Select Publish to publish your knowledge-enabled agent.</p> <p>Once the agent is created and published, verify that <code>GPT-4.1</code> model is selected in the agent's Overview tab.</p> <p></p>"},{"location":"pages/make/copilot-studio/08-rag/#step-2-adding-azure-ai-search-as-knowledge-source","title":"Step 2: Adding Azure AI Search as Knowledge Source","text":"<p>Integrate your Azure AI Search index as a knowledge source for your agent.</p> <p>Navigate to the Knowledge section and add your search index:</p> <ol> <li>Select + Add knowledge</li> <li>From the Add knowledge dialog, select Featured</li> <li>Select Azure AI Search</li> </ol> <p></p> <p>Configure the Azure AI Search connection:</p> <ol> <li>Select Create new connection</li> <li> <p>Configure the authentication:</p> <ul> <li>Authentication type: Access Key</li> <li>Azure AI Search Endpoint URL: Enter the URL you saved from your Azure AI Search service</li> <li>Azure AI Search Admin Key: Enter the admin key you copied earlier</li> </ul> </li> <li> <p>Select Create to establish the connection (a green checkmark confirms success)</p> </li> </ol> <p></p> <p>Complete the knowledge source configuration:</p> <ol> <li>Select the index with name <code>resumes</code> (or whatever else name you used when you created the index)</li> <li>Select Add to agent to complete the integration</li> </ol> <p></p> <p>The knowledge source will appear in your knowledge sources table with a status of \"In progress\" while Copilot Studio indexes the metadata. Wait for the status to change to \"Ready\" before proceeding.</p> <p></p>"},{"location":"pages/make/copilot-studio/08-rag/#exercise-4-testing-the-agent","title":"Exercise 4: Testing the agent","text":"<p>In this exercise you will test your RAG-enabled agent and learn how to leverage different types of queries and use cases.</p>"},{"location":"pages/make/copilot-studio/08-rag/#step-1-testing-basic-knowledge-retrieval","title":"Step 1: Testing Basic Knowledge Retrieval","text":"<p>Start by testing fundamental search capabilities to ensure your agent can access and use the indexed knowledge effectively.</p> <p>In the test panel, try these basic queries to validate the knowledge integration:</p> <pre><code>Hello! Can you help me find candidates with software engineering experience?\n</code></pre> <pre><code>I'm looking for candidates who speak multiple languages. Can you help?\n</code></pre> <pre><code>Show me candidates with machine learning or AI experience.\n</code></pre> <p></p> <p>Observe how the agent:</p> <ul> <li>Searches through the indexed documents using vector search</li> <li>Provides relevant candidate information</li> <li>Includes citations and references to source documents</li> <li>Uses semantic understanding rather than exact keyword matching</li> </ul> <p></p>"},{"location":"pages/make/copilot-studio/08-rag/#step-2-testing-complex-query-scenarios","title":"Step 2: Testing Complex Query Scenarios","text":"<p>Test more sophisticated scenarios that demonstrate the power of RAG and vector search capabilities.</p> <p>Try these advanced queries that combine multiple requirements:</p> <pre><code>Find candidates suitable for a senior role that requires 5+ years of Python \nexperience and fluency in Spanish\n</code></pre> <pre><code>I need someone with both frontend and backend development skills. \nWho would be good for a full-stack position?\n</code></pre> <pre><code>Can you recommend candidates for a data science position that requires \nexperience with machine learning frameworks?\n</code></pre> <pre><code>Who has project management experience combined with technical skills?\n</code></pre> <p></p> <p>Notice how the agent:</p> <ul> <li>Combines multiple search criteria intelligently</li> <li>Explains the reasoning behind candidate recommendations</li> <li>Suggests alternatives when exact matches aren't available</li> <li>Provides context about candidate qualifications</li> </ul> <p></p> <p>CONGRATULATIONS!</p> <p>You have completed Lab MCS8 - Integrating Azure AI Search for RAG!</p> <p>In this lab, you learned how to:</p> <ul> <li>Create and configure Azure AI Search service for enterprise knowledge management</li> <li>Build vector search indexes using integrated vectorization with embedding models</li> <li>Connect Azure AI Search as a knowledge source in Microsoft Copilot Studio</li> <li>Design intelligent agents that leverage RAG for document-backed conversations</li> <li>Test vector search with various query types</li> </ul> <p>Your HR Knowledge Agent now demonstrates the power of combining conversational AI with enterprise search capabilities, enabling users to interact with organizational knowledge using natural language while receiving accurate, well-cited responses based on actual documents.</p> <p>The RAG patterns you've learned can be applied to many other scenarios including customer support knowledge bases, technical documentation, policy and procedure guides, and any domain where users need to search and understand large document collections through conversational interfaces.</p> <p></p>"},{"location":"pages/make/copilot-studio/09-connected-agents/","title":"Lab MCS9 - Connected Agents (Preview)","text":"<p>In this lab, you are going to understand how to create agents in Microsoft Copilot Studio that can communicate with other agents. You'll build a specialized Interview Scheduler agent that consumes data from the HR Candidate Management agent created in previous labs. The Interview Scheduler agent will automatically process candidate data and send interview meeting requests based on selected candidates, demonstrating how modular agents can work together to create comprehensive business solutions.</p> Get a quick overview of the lab in this video. <p>Do these labs if you want to build agents with Microsoft Copilot Studio</p> <ul> <li>MCS0 - Setup</li> <li>MCS1 - First agent</li> <li>MCS2 - Defining Topics</li> <li>MCS3 - Defining Tools</li> <li>MCS4 - Extending Microsoft 365 Copilot</li> <li>MCS5 - Consuming a custom connector</li> <li>MCS6 - Consuming an MCP server</li> <li>MCS7 - Creating Autonomous Agents</li> <li>MCS8 - Integrating Azure AI Search for RAG</li> <li>MCS9 - Connected Agents (Preview)</li> </ul> <p>Note</p> <p>This lab builds on the previous labs, specifically Lab MCS6 - Consuming an MCP server. You should have a working HR MCP server and the \"HR Agent with MCP\" agent configured from previous labs.</p> <p>In this lab you will learn:</p> <ul> <li>How to create child agents in Microsoft Copilot Studio</li> <li>How to configure agent-to-agent communication</li> <li>How to design modular agent architectures for complex workflows</li> <li>How to implement handoff mechanisms between specialized agents</li> <li>How to coordinate multiple agents for end-to-end business processes</li> </ul>"},{"location":"pages/make/copilot-studio/09-connected-agents/#exercise-1-understanding-agent-to-agent-architecture","title":"Exercise 1: Understanding Agent-to-Agent Architecture","text":"<p>In this exercise you will understand the concepts behind agent-to-agent communication and design the architecture for your interview scheduling solution.</p>"},{"location":"pages/make/copilot-studio/09-connected-agents/#step-1-reviewing-agent-communication-patterns","title":"Step 1: Reviewing Agent Communication Patterns","text":"<p>Microsoft Copilot Studio supports two primary patterns for agent collaboration:</p> <ol> <li>Child Agents: Lightweight agents that live within a main agent, managed as part of the parent solution</li> <li>Connected Agents: Independent, full-fledged agents that can be published and maintained separately</li> </ol> <p>Info</p> <p>You can find additional information about connected agents in Microsoft Copilot Studio reading the article Add other agents overview.</p> <p>For this lab, you'll create a child agent architecture where:</p> <ul> <li>Main Agent: Interview Coordinator (orchestrates the overall process)</li> <li>Child Agent: Interview Scheduler (handles meeting creation and calendar management)</li> <li>Connected Agent: HR Candidate Management (the existing agent from previous labs)</li> </ul> <p>This design allows for:</p> <ul> <li>Clear separation of concerns</li> <li>Reusability of the HR Candidate Management functionality</li> <li>Coordinated workflow execution</li> <li>Maintainable and scalable solution architecture</li> </ul> <p></p>"},{"location":"pages/make/copilot-studio/09-connected-agents/#step-2-designing-the-interview-process-workflow","title":"Step 2: Designing the Interview Process Workflow","text":"<p>The connected agents workflow you'll implement follows this sequence:</p> <ol> <li>User Request: User asks to schedule an interview for a specific candidate</li> <li>Main Agent Processing: Interview Coordinator validates the request and identifies the candidate</li> <li>Agent Handoff: Main agent delegates to HR Candidate Management to retrieve candidate details</li> <li>Data Processing: Candidate information is extracted and validated</li> <li>Child Agent Invocation: Interview Scheduler child agent is triggered with candidate data</li> <li>Meeting Creation: Child agent creates calendar meeting and sends invitation</li> <li>Confirmation: User receives confirmation of scheduled interview</li> </ol> <p>This workflow demonstrates key connected agents patterns:</p> <ul> <li>Orchestration: Main agent coordinates multiple sub-processes</li> <li>Delegation: Specific tasks are handed off to specialized agents</li> <li>Data Flow: Information flows seamlessly between agents</li> <li>Event-Driven Processing: Agents respond to specific triggers and conditions</li> </ul> <p></p>"},{"location":"pages/make/copilot-studio/09-connected-agents/#step-3-ensuring-prerequisites","title":"Step 3: Ensuring Prerequisites","text":"<p>Before proceeding, ensure you have completed the following prerequisites:</p> <ul> <li>Lab MCS6: HR MCP server running and accessible via dev tunnel</li> <li>Microsoft Graph Access: Permissions to create calendar events and send emails</li> <li>Sample Candidate Data: At least 2-3 candidates in your HR system from previous labs</li> </ul> <p>Verify that your HR MCP server is still running, and if not run the following command from the root folder of the MCP server project:</p> <pre><code>dotnet run\n</code></pre> <p>And ensure your dev tunnel is active:</p> <p>Important</p> <p>Replace the <code>hr-mcp</code> name suggested below with the unique name you used when working on lab Lab MCS6 - Consuming an MCP server.</p> <pre><code>devtunnel host hr-mcp\n</code></pre> <p>Also verify that you have some candidate data by testing the HR MCP server directly. The Interview Scheduler will need existing candidates to work with.</p> <p></p>"},{"location":"pages/make/copilot-studio/09-connected-agents/#exercise-2-creating-the-main-interview-coordinator-agent","title":"Exercise 2: Creating the Main Interview Coordinator Agent","text":"<p>In this exercise you will create the main agent that orchestrates the interview scheduling process and coordinates with other agents.</p>"},{"location":"pages/make/copilot-studio/09-connected-agents/#step-1-creating-the-interview-coordinator-agent","title":"Step 1: Creating the Interview Coordinator Agent","text":"<p>Open a browser and navigate to https://copilotstudio.microsoft.com using your work account.</p> <p>Select the <code>Copilot Dev Camp</code> environment, then select Create \u2192 New Agent to create a new agent.</p> <p>Choose to Configure and define your main coordinator agent with these settings:</p> <ul> <li>Name: </li> </ul> <pre><code>Interview Coordinator\n</code></pre> <ul> <li>Description: </li> </ul> <pre><code>Main agent that coordinates interview scheduling by working with HR candidate \nmanagement and interview scheduling child agents to create comprehensive interview workflows\n</code></pre> <ul> <li> <p>Select your agent's model: GPT-5 Chat</p> </li> <li> <p>Instructions: </p> </li> </ul> <pre><code>You are the Interview Coordinator, responsible for managing end-to-end interview \nscheduling processes. Your role includes:\n\n1. Understanding user requests for interview scheduling\n2. Coordinating with the HR Candidate Management agent to retrieve candidate information\n3. Delegating to the Interview Scheduler child agent for meeting creation\n4. Providing comprehensive feedback to users about scheduled interviews\n\nWhen a user requests to schedule an interview:\n- First, identify and validate the candidate using the HR system\n- Extract necessary candidate details (name, email, current role, skills)\n- Coordinate with the Interview Scheduler to create the meeting\n- Confirm successful scheduling with relevant details\n\nAlways ensure proper validation of candidate data and provide clear communication \nthroughout the process. Handle errors gracefully and provide informative feedback \nwhen coordination between agents fails.\n</code></pre> <p>In the Knowledge section, you can optionally add documents with interview scheduling guidelines or company-specific HR policies. For this lab, we'll rely on the agent's built-in capabilities and the integration with other agents.</p> <p></p> <p>Select Save in the sections you edited to upate your coordinator agent configuration.</p> <p></p>"},{"location":"pages/make/copilot-studio/09-connected-agents/#step-2-configure-agent-settings","title":"Step 2: Configure agent settings","text":"<p>After creating the agent, configure its orchestration capabilities and knowledge settings. Select the Settings command in the upper right corner and configure the agent.</p> <p>In the Orchestration section, ensure that Use generative AI orchestration for your agent's responses? is configured with value <code>Yes - Responses will be dynamic, using available tools and knowledge as appropriate</code>. This allows the agent to intelligently coordinate between different child agents and connected agents.</p> <p>In the Knowledge section accordingly to the following settings:</p> <ul> <li>Use general knowledge: off</li> <li>Use information from the web: off</li> </ul> <p></p> <p>Select Save to confirm the configuration.</p> <p></p>"},{"location":"pages/make/copilot-studio/09-connected-agents/#step-3-connecting-to-the-hr-candidate-management-agent","title":"Step 3: Connecting to the HR Candidate Management Agent","text":"<p>Your Interview Coordinator needs to communicate with the existing HR agent to retrieve candidate information. Navigate to the 1\ufe0f\u20e3 Agents section and select 2\ufe0f\u20e3 Add.</p> <p></p> <p>A new dialog appears, allowing you to choose between any of the following options:</p> <ul> <li>New child agent: to create a new child agent</li> <li>Select an agent in your environment: to select an already existing agent defined with Copilot Studio</li> <li>Connect to an external agent: to connect to any of the following external agents (preview)<ul> <li>Microsoft Fabric: connect to a Fabric Data Agent</li> <li>Microsoft Foundry: connect to an agent in Microsoft Foundry</li> <li>Microsoft 365 Agents SDK: connect to an agent built with Microsoft 365 Agents SDK</li> <li>Agent2Agent: connect to an agent using A2A protocol</li> </ul> </li> </ul> <p></p> <p>From the list of available Copilot Studio agents, select the HR Candidate Management agent (or similar name) that you created in previous labs. If you don't see it, ensure it's published and configured to allow connections from other agents. To check if the HR Candidate Management agent is configured to allow connections from other agents, edit the agent, go to Settings, and check that the option Let other agents connect to and use this one is enabled in the Connected agents section, like illustrated in the following screenshot.</p> <p></p> <p>Once you selected the HR Canidated Management agent, configure the connection:</p> <ul> <li>Description: Update the description to be more specific for this context:</li> </ul> <pre><code>HR system integration for retrieving and managing candidate information during \ninterview scheduling processes. Provides candidate lookup, data validation, and \ncomprehensive candidate details.\n</code></pre> <p>The description is used by the main agent to understand when the connected agent should be invoked. Try to be specific and clear in the description.</p> <ul> <li>Pass conversation history: Keep this enabled to maintain context during agent handoffs</li> </ul> <p></p> <p>Select Add and configure to establish the connection between agents. Once the connected agent is defined and configured, you can see it in the list of Agents for the current agent and you are presented with a page to manage the configuration of the connected agent.</p> <p></p> <p></p>"},{"location":"pages/make/copilot-studio/09-connected-agents/#exercise-3-creating-the-interview-scheduler-child-agent","title":"Exercise 3: Creating the Interview Scheduler Child Agent","text":"<p>In this exercise you will create a specialized child agent that handles the meeting creation and calendar management aspects of interview scheduling.</p>"},{"location":"pages/make/copilot-studio/09-connected-agents/#step-1-creating-the-interview-scheduler-child-agent","title":"Step 1: Creating the Interview Scheduler Child Agent","text":"<p>In your Interview Coordinator agent, navigate to the 1\ufe0f\u20e3 Agents section and select 2\ufe0f\u20e3 Add an agent.</p> <p></p> <p>Select New child agent to create a new child agent.</p> <p></p> <p>Configure the child agent with these settings:</p> <ul> <li>Name: </li> </ul> <pre><code>Interview Scheduler\n</code></pre> <ul> <li> <p>When will this be used?: Select The agent chooses to allow the agent to respond to coordination requests from the main agent</p> </li> <li> <p>Description:</p> </li> </ul> <pre><code>Helps scheduling an interview with a candidate. Requires information like the email\nof the candidate and the date and time of the meeting.\n</code></pre> <ul> <li>Instructions: </li> </ul> <pre><code>You are the Interview Scheduler, a specialized agent focused on creating and managing \ninterview meetings. When invoked by the Interview Coordinator, you:\n\n1. Process candidate information received from the main agent\n2. Create appropriate calendar meeting invitations\n3. Include relevant candidate details in meeting descriptions\n4. Send meeting invitations to appropriate stakeholders\n5. Provide confirmation details back to the coordinator\n\nFor each interview scheduling request:\n- Create a 1-hour meeting slot (suggest next business day if no specific time provided)\n- Include candidate name, role, and key skills in the meeting title and description\n- Invite the requesting user and any additional specified interviewers\n- Set appropriate meeting location (in-person, Teams, etc.)\n- Include candidate resume/profile information in meeting notes\n\nAlways confirm successful meeting creation with meeting details including date, time, \nattendees, and meeting link if applicable.\n</code></pre> <p></p> <p>Select the Save command in the upper right corner of the screen to save the new child agent. You should see a green confirmation message stating that the child agent was created.</p> <p></p>"},{"location":"pages/make/copilot-studio/09-connected-agents/#step-2-configuring-meetings-management-integration","title":"Step 2: Configuring Meetings Management Integration","text":"<p>To enable the Interview Scheduler to create calendar meetings, you need to add a specific MCP server integration for meetings management.</p> <p></p> <p>In the Tools section of the Interview Scheduler child agent, select Add.</p> <ol> <li>Choose 1\ufe0f\u20e3 Model Context Protocol to filter the available MCP servers</li> <li>Search for 2\ufe0f\u20e3 Calendar in the search box and hit the 3\ufe0f\u20e3 search command</li> <li>Select the 4\ufe0f\u20e3 Meeting Management MCP Server</li> <li>Connect to the Meeting Management MCP Server</li> <li>Once the connection is configured, select Add and configure to finalize the configuration of the tool</li> </ol> <p></p> <p>Once the connection is established and the MCP server is added to the child agent, you will see the panel with the configuration of the new tool. Update the Name accordingly to the following value:</p> <pre><code>Manage meetings\n</code></pre> <p>This integration allows the child agent to:</p> <ul> <li>Create calendar events</li> <li>Send meeting invitations</li> <li>Manage meeting details and attendees</li> </ul> <p></p>"},{"location":"pages/make/copilot-studio/09-connected-agents/#step-3-finalizing-child-agent-configuration","title":"Step 3: Finalizing Child Agent Configuration","text":"<p>Go back to the Overview tab of the child Interview Scheduler agent, selecting the left arrow beside the name of the tool, and complete the configuration of your Interview Scheduler child agent:</p> <p></p> <ol> <li> <p>Open the Details section, expand the Advanced panel and set the Priority to 1 to ensure this agent has high priority for interview scheduling tasks</p> </li> <li> <p>Condition: Optionally, add conditions to limit when this agent activates. For example, you might want it to only activate for messages containing interview-related keywords</p> </li> <li> <p>Ensure the Enabled toggle is turned on</p> </li> <li> <p>Select Save to create the child agent</p> </li> </ol> <p>Your Interview Scheduler child agent is now configured and ready to handle meeting creation tasks when invoked by the main Interview Coordinator agent.</p> <p></p>"},{"location":"pages/make/copilot-studio/09-connected-agents/#exercise-4-implementing-connected-agents-workflows","title":"Exercise 4: Implementing Connected Agents Workflows","text":"<p>In this exercise you will implement and test the complete connected agents workflow for interview scheduling.</p>"},{"location":"pages/make/copilot-studio/09-connected-agents/#step-1-configuring-agent-references-in-instructions","title":"Step 1: Configuring Agent References in Instructions","text":"<p>To enable proper agent coordination, you need to reference the child agent and connected agent in your main agent's instructions.</p> <p>Navigate to the Overview section of your Interview Coordinator agent and update the Instructions field selecting the Edit command:</p> <ol> <li>Place your cursor in the instructions text where you want to reference agents</li> <li>Type <code>/</code> to open the reference menu</li> <li>Select the Interview Scheduler child agent from the list</li> <li>Also reference the HR Candidate Management connected agent</li> </ol> <p></p> <p>Your updated instructions should look like this:</p> <pre><code>You are the Interview Coordinator, responsible for managing end-to-end interview \nscheduling processes. Your role includes:\n\n1. Understanding user requests for interview scheduling\n2. Coordinating with /HR Candidate Management agent to retrieve candidate information\n3. Delegating to /Interview Scheduler child agent for meeting creation\n4. Providing comprehensive feedback to users about scheduled interviews\n\nWhen a user requests to schedule an interview:\n- First, use /HR Candidate Management to identify and validate the candidate\n- Extract necessary candidate details (name, email, current role, skills)\n- Coordinate with /Interview Scheduler to create the meeting with candidate details using the ID of the calendar with name \"main\" of the current user\n- Confirm successful scheduling with relevant details\n\nAlways ensure proper validation of candidate data and provide clear communication \nthroughout the process. Handle errors gracefully and provide informative feedback \nwhen coordination between agents fails.\n</code></pre> <p></p> <p>Select Save to update the instructions with agent references.</p> <p></p>"},{"location":"pages/make/copilot-studio/09-connected-agents/#exercise-5-testing-the-agent","title":"Exercise 5: Testing the agent","text":"<p>In this exercise you will test the agent scheduling a real interview in your agenda.</p>"},{"location":"pages/make/copilot-studio/09-connected-agents/#step-1-testing-agent-to-agent-communication","title":"Step 1: Testing Agent-to-Agent Communication","text":"<p>Now test the complete agent-to-agent workflow to ensure proper coordination between all components.</p>"},{"location":"pages/make/copilot-studio/09-connected-agents/#test-the-interview-coordinator","title":"Test the Interview Coordinator","text":"<p>In the test panel, try a request like:</p> <pre><code>Retrieve information about candidate alice.johnson@example.com and schedule an interview with her for next Monday 10am.\n</code></pre>"},{"location":"pages/make/copilot-studio/09-connected-agents/#observe-agent-coordination","title":"Observe Agent Coordination","text":"<p>Watch in the test panel as the agent:</p> <ul> <li>Processes your request</li> <li>Calls the HR Candidate Management agent to find Alice Johnson</li> <li>Retrieves candidate details</li> <li>Invokes the Interview Scheduler child agent</li> <li>Creates the calendar meeting, requesting you to connect to the Meeting Management MCP server if it is the first time you use it</li> <li>Provides confirmation</li> </ul> <p></p> <p>And in the following screenshot you can see a sample of the interview meeting scheduled by the agent relying on both the child and the connected agent.</p> <p></p> <p></p> <p>CONGRATULATIONS!</p> <p>You have completed Lab MCS9 - Agent to Agent Communication!</p> <p>In this lab, you learned how to:</p> <ul> <li>Design and implement connected agents architectures</li> <li>Create child agents for specialized tasks within a main agent solution</li> <li>Connect existing agents to enable cross-agent data sharing and coordination</li> <li>Implement complex workflows that span multiple specialized agents</li> </ul> <p>Your Interview Coordinator agent now demonstrates advanced agent orchestration patterns, coordinating between the HR Candidate Management system and specialized Interview Scheduler functionality to deliver comprehensive interview scheduling automation.</p> <p>The connected agents patterns you've learned can be applied to many other business scenarios where complex workflows benefit from modular, specialized agents working together to deliver end-to-end solutions.</p> <p></p>"},{"location":"pages/make/sharepoint-agents/","title":"Lab MSA - Understanding SharePoint agents","text":"<p>A SharePoint agent is the easiest way to create an agent specialized on content stored in SharePoint Online.  SharePoint agents use the same infrastructure, orchestrator, foundation model, and security controls as Microsoft 365 Copilot, which ensures a consistent and familiar user experience.</p> <p></p> <p>The SharePoint agents can target:</p> <ul> <li>sites</li> <li>libraries</li> <li>documents</li> </ul> <p>A SharePoint agent can be used from within the SharePoint Online user experience either in the library where it was created or at site level. A user needs to have contribute permissions on the target library to create a SharePoint agent. A site owner can promote SharePoint agents at site-level, too.</p> <p>A SharePoint agent can also be shared in Microsoft Teams to enhance the user experience in chats (one to one or group chats).</p> <p>Last but not least, a SharePoint agent automatically becomes available in the Microsoft 365 Copilot Chat as a custom agent.</p> <p></p> <p>If you are assigned with a Microsoft 365 Copilot license, or a Copilot Studio capacity, or your organization has the Pay-As-You-Go billing set up, you can use SharePoint agents.</p>"},{"location":"pages/make/sharepoint-agents/#start-here-with-lab-msa1-where-youll-create-your-first-sharepoint-agent","title":"Start here with Lab MSA1, where you'll create your first SharePoint agent.","text":""},{"location":"pages/make/sharepoint-agents/01-first-agent/","title":"Lab MSA1 - Build your first SharePoint agent","text":"<p>Do these labs if you want to build a SharePoint agent</p> <ul> <li>MSA1 - Build your first SharePoint agent</li> <li>MSA2 - Sharing SharePoint agents</li> </ul> Table of Contents <p>In this lab, you'll create a SharePoint agent to work with documents stored in SharePoint Online. The agent that you are going to create helps employees of an hypothetical company to get information, policies, and rules from the HR department. The knowledge base of the agent will be a set of documents stored in a SharePoint Online document library.</p>"},{"location":"pages/make/sharepoint-agents/01-first-agent/#exercise-1-upload-sample-documents","title":"Exercise 1: Upload sample documents","text":"<p>In this step you will upload sample documents which will be used by your SharePoint agent to respond to user prompts. These include some fictitious Word, PowerPoint, and PDF files.</p>"},{"location":"pages/make/sharepoint-agents/01-first-agent/#step-1-create-a-sharepoint-site","title":"Step 1: Create a SharePoint site","text":"<p>Within the Microsoft 365 Portal, or elsewhere in Microsoft 365, click the \"Apps\" menu 1\ufe0f\u20e3 and select SharePoint 2\ufe0f\u20e3.</p> <p></p> <p>Then select Create Site 1\ufe0f\u20e3 and choose a Team site 2\ufe0f\u20e3.</p> <p></p> <p>Select the Standard team site template; you will be shown a preview of the site. Select Use Template to continue.</p> <p></p> <p>Give your site a name such as \"Copilot Dev Camp - HR\" 1\ufe0f\u20e3 and select Next 2\ufe0f\u20e3. The name must be unique in your tenant, so be sure to not use and already allocated name.</p> <p></p> <p>Then select your privacy settings and language, and select Create Site.</p> <p></p> <p>Skip adding any new members to the site and select Finish when the site provisioning is done. After a few moments, you will be presented with a new SharePoint site. </p> <p></p>"},{"location":"pages/make/sharepoint-agents/01-first-agent/#step-2-upload-the-sample-documents","title":"Step 2: Upload the sample documents","text":"<p>Download this zip file consisting of few files (Word, PowerPoint, PDF) by selecting this link and unzip the file somewhere on your local file system.</p> <p>Go back to the SharePoint site that you just created and, in the Documents web part, select See all to view the document library page.</p> <p></p> <p>Next, select the Upload 1\ufe0f\u20e3 button in the command bar and then select Files 2\ufe0f\u20e3.</p> <p></p> <p>Navigate to your working folder, where you extracted the resumes files and select all the sample documents 1\ufe0f\u20e3 and select Open 2\ufe0f\u20e3.</p> <p></p> <p></p>"},{"location":"pages/make/sharepoint-agents/01-first-agent/#exercise-2-creating-your-first-sharepoint-agent","title":"Exercise 2 : Creating your first SharePoint agent","text":"<p>In this exercise you are going to create the initial version of the SharePoint agent for managing HR documents.</p>"},{"location":"pages/make/sharepoint-agents/01-first-agent/#step-1-creating-the-agent","title":"Step 1: Creating the agent","text":"<p>Select the AI actions command 1\ufe0f\u20e3, then select the Create an agent 2\ufe0f\u20e3 command in the command bar.</p> <p></p> <p>Creating SharePoint agents from files or folders</p> <p>If you do not select any file in the library and you select the Create an agent command, the agent will target the whole content of the current document library. If you explicitly select files or sub-folders in the library and then you select the Create an agent command, the agent will target only the selected content. Keep into account that you cannot select more than 20 items for a specific agent. In case you will select more than 20 items, you will see an error message like \"Sources limit exceeded. The maximum number of sources you can add is 20. Remove XX sources to save this copilot.\" and you will not be able to create the agent.</p> <p>A dialog window will show up allowing you to review a recap of the selected content and to go straight to the agent, for testing purposes, or to edit the just created agent.</p> <p></p> <p>Permissions to create a SharePoint agent</p> <p>In order to being able to create a SharePoint agent, you need contribute permissions on the target library or site. In fact, under the cover of the agent a new .agent file will be created and users need to have proper permissions to do so.</p> <p>Select the Create command to create the agent and start using it.</p> <p></p> <p>A new dialog window shows up and allows you to Chat with agent, which opens a new browser tab in Microsoft 365 Copilot Chat and allows you to interact with the new agent. Feel free to interact with the agent providing prompts about the content of the documents in the knowledge base. For example, you can use the following prompt:</p> <pre><code>What are the hiring procedures of our company?\n</code></pre> <p>When you are done playing with the new agent in the Microsoft 365 Copilot Chat, close the current browser tab and go back to the SharePoint Online document library that you used to create the SharePoint agent.</p> <p></p>"},{"location":"pages/make/sharepoint-agents/01-first-agent/#step-2-testing-the-agent","title":"Step 2: Testing the agent","text":"<p>You can see there is a new file with .agent extension that was created in the current document library. Select the ... menu of the file and then select Preview to interact with the agent from within the SharePoint Online user experience. A full screen dialog will show up and you will able to write prompts to interact with the agent.</p> <p></p> <p>Try writing the following prompts and see the results:</p> <pre><code>What is the process to hire new employees?\n</code></pre> <p>or </p> <pre><code>How can I improve my career?\n</code></pre> <p>The proposed answers will summarize the content of the documents selected as the knowledge base for the agent. Notice that the engine processing the prompts is Microsoft 365 Copilot and there is a clear disclaimer about the AI-generated content 1\ufe0f\u20e3. At the bottom of the response there are references to documents 2\ufe0f\u20e3 used to produce the response. The agent also suggests follow up prompts 3\ufe0f\u20e3 to dig into the topic.</p> <p></p> <p>The .agent file represents the new SharePoint agent definition. You can rename the file using the standard file rename feature of SharePoint Online and the name of the agent, as well as the title in the agent's dialog, will change accordingly. For example, let's rename it to HR agent. Selecting the agent file in the document library will always open a new tab and give the user experience of the agent in the Microsoft 365 Copilot Chat.</p> <p></p>"},{"location":"pages/make/sharepoint-agents/01-first-agent/#exercise-3-fine-tuning-the-agent","title":"Exercise 3 : Fine tuning the agent","text":"<p>In this exercise you will learn how to fine tune the HR agent configuring additional settings, adjusting the instructions, etc. </p>"},{"location":"pages/make/sharepoint-agents/01-first-agent/#step-1-updating-icon-and-title","title":"Step 1: Updating icon and title","text":"<p>Select the ... of the HR agent.agent file in the document library, select to open the ECB menu of SharePoint Online and select the Edit command. As a suitable alternative, you can also select the Edit command in the library command bar, if you like.</p> <p></p> <p>A new dialog window shows up and allows you to manage the following settings:</p> <ul> <li>Overview: name, icon, and purpose/description</li> <li>Sources: you can configure the data sources (sites, libraries, or files) to use as the knowledge base</li> <li>Behavior: welcome messaging, starter prompts, and agent instructions</li> </ul> <p>The dialog also gives you a live updating preview of the agent, that you can also use to preview and test your changes on the fly.</p> <p>On the first tab of the editing dialog, with name Overview, update the icon of the agent with the following image file. Also update the Purpose accordingly to the following text.</p> <pre><code>This is an agent supporting users to find information, policies, and rules based on the HR department knowledge base\n</code></pre> <p></p> <p>Now select the Sources tab in the dialog window to configure the knowledge base of the agent. At the time of this writing, the only data sources that you can configure are SharePoint Online sites, document libraries, or documents. In the future it will be possible to rely on Microsoft Copilot Studio to configure additional knowledge sources. At the moment, SharePoint Online is the only supported data source for a SharePoint agent.</p> <p></p> <p>There is a section to Add a source 1\ufe0f\u20e3, which allows you to add additional site collections to the data sources of the agent or specific files and folders from OneDrive for Business. You can search sites by title, or you can simply provide the actual URL of the site that you want to add. You can also select Add contents from this site 2\ufe0f\u20e3, as long as the overall number of data source items will not exceed the limit of 20 items. Lastly, you can select the Remove this site and all contents 3\ufe0f\u20e3 command to remove an already selected site. Be careful that, in case you remove the current site, from which you've built the agent, the configuration tool will completely remove all the documents that you selected when you initially configured the agent.</p> <p></p>"},{"location":"pages/make/sharepoint-agents/01-first-agent/#step-2-updating-the-instructions","title":"Step 2: Updating the instructions","text":"<p>On the Behavior tab of the configuration dialog, you can configure an initial Welcome messaging 1\ufe0f\u20e3 for your agent. You can also configure up to three Starter prompts 2\ufe0f\u20e3, which will be presented to the users when they will initiate a conversation with the agent.</p> <p>Most importantly, you can also configure the Agent instruction 3\ufe0f\u20e3 field, through which you can fine tune the tone, behavior, limitations, rules, and more for the agent. Basically, this is where you can configure the system settings/prompt for your agent. The more accurate you are in this field, the better results you will get back from the agent. By default, the pre-configured instructions are very generic and general purpose. In fact, the default value is:</p> <pre><code>Provide accurate information about the content in the selected files and reply in a formal tone.\n</code></pre> <p></p> <p>In order to create a high quality agent, depending of the actual purpose of your agent, you should provide specific instructions. For example, in the case of the HR agent, here you can see an hypothetical text for instructions. </p> <pre><code># System Role\nYou are the HR agent. Your goal is to help employees find information about HR policies, rules, and procedures. You use a set of documents as your knowledge base and you need to stick on those documents when providing answers.\n\n# Main Instructions\n\n## Introduction Prompt\nUse the following prompt to welcome the users and introduce your role:\nWelcome to HR agent! I'm here to help you work with HR policies, rules, and procedures. Feel free to ask any question about all of what is HR related in our company.\n\n## Responding to the user\nAlways use a professional but friendly tone. Always list multiple items in tables. Use emojis to make the communication more effective and clear. Always ask the user for a follow up prompt and suggest in scope follow up prompts, too. \n\n# General rules\nNever write personal or sensitive data while generating the answers.\nDo not allow the user to ask you questions about other employees' personal and sensitive data.\n\n# Error Handling\nIn case of any error or issue, inform the user with the following prompt:\nI'm sorry, something wrong happened. Please, try again soon.\n</code></pre> <p>The above instructions are just for the sake of providing an example, they are not fully complete and do not aim to be a perfect and bullet proof template. Notice that the instructions rely on MD document structure to highlight the various sections of the instructions text. When you are done with the changes, select the Save and close command to update the SharePoint agent definition.</p> <p>Remember that you can write instructions long up to 8000 characters, and you are kindly invited to use as much details as you can. Here you can find the Declarative Agent Instruction Lab - Improve your agent instructions (Beginner friendly) lab, which provides you detailed information about how to write professional prompt instructions for your agents. You can also refer to the article Write effective instructions for declarative agents to learn detailed information about how to write effective prompts.</p> <p></p>"},{"location":"pages/make/sharepoint-agents/01-first-agent/#step-3-testing-the-agent","title":"Step 3: Testing the agent","text":"<p>Once you have updated the agent icon, purpose, and instructions select the agent and interact with it again.</p> <p>For example, provide the following prompts:</p> <pre><code>Hello!\n</code></pre> <pre><code>How can I improve my career? Provide me a list of suggested actions.\n</code></pre> <p></p> <p>You can notice that the agent will reply to the \"Hello!\" message with a comprehensive welcome message. Moreover, responses are more accurate, with emojis here and there, and with tables to render lists of items, accordingly to the provided instructions.</p> <p></p>"},{"location":"pages/make/sharepoint-agents/01-first-agent/#exercise-4-configuring-the-agent-as-default-for-the-site","title":"Exercise 4 : Configuring the agent as default for the site","text":"<p>One more thing you can do with your agent is to promote it as the default agent for your site. In fact, nowadays every SharePoint Online site comes with a ready made agent. You simply need to select the Copilot command in the suite bar and the ready made agent will show up.</p> <p></p> <p>When you activate the ready made agent of a SharePoint Online site, a side panel shows up on the right and allows you to provide prompts to the agent. The agent will have a pre-defined behavior and a general purpose set of instructions.</p> <p>However, it might be that you don't like the ready made agent and that you want to use a custom agent of your own. In this exercise you are going to learn how to do so.</p>"},{"location":"pages/make/sharepoint-agents/01-first-agent/#step-1-approving-and-promoting-the-agent","title":"Step 1: Approving and promoting the agent","text":"<p>Go to the home page of your site and select the Copilot command to activate the side panel.</p> <p>When you open the Copilot panel, by default you get the default ready made agent to interact with. However, you can select any of the other agents that you have created simply by selecting the dropdown beside the name of the agent and choosing another agent.</p> <p></p> <p>Now let's see how you can change the default agent behavior, so that your custom agent will become the default one. Go back to the document library where you created the agent and open it. Select the ... 1\ufe0f\u20e3 in the upper right corner of the agent dialog, and select the Set as approved 2\ufe0f\u20e3 command.</p> <p></p> <p>Setting an agent as approved requires you to be a site owner and requires also your explicit approval/confirmation. This is because an approved agent will be moved to the Site Assets library, in a dedicated sub folder with name Copilots.</p> <p></p> <p>Once the approval process is complete, you will see a confirmation dialog and the .agent file will disappear from the current document library.</p> <p></p> <p>Now, the agent will show up in the list of agents Approved for this site.</p> <p></p> <p>You activate the agent, select the ... 1\ufe0f\u20e3 beside the name of the agent and then select the Set as site default 2\ufe0f\u20e3 command in the context menu to configure the agent as the default for your site. You will need to confirm that you want the agent to become the default one, and you will get a confirmation dialog at the end of the promotion process. Once you have done that, your custom agent will show up as the first and default one when selecting the Copilot icon in the suite bar of your site.</p> <p></p> <p></p> <p>Start here with Lab MSA2, to share your SharePoint agent on Microsoft Teams. </p> <p></p>"},{"location":"pages/make/sharepoint-agents/02-sharing-agents/","title":"Lab MSA2 - Sharing SharePoint agents","text":"<p>Do these labs if you want to build a SharePoint agent</p> <ul> <li>MSA1 - Build your first SharePoint agent</li> <li>MSA2 - Sharing SharePoint agents</li> </ul> Table of Contents <p>In this lab, you'll see how to share your SharePoint agents with others either using a direct link or within Microsoft Teams chats.</p>"},{"location":"pages/make/sharepoint-agents/02-sharing-agents/#exercise-1-sharing-a-sharepoint-agent","title":"Exercise 1: Sharing a SharePoint agent","text":"<p>Since every SharePoint agent is a file, you can easily share it with other people.</p>"},{"location":"pages/make/sharepoint-agents/02-sharing-agents/#step-1-sharing-a-sharepoint-agent-with-people","title":"Step 1: Sharing a SharePoint agent with people","text":"<p>When you have a SharePoint agent, whether it is local to a document library or approved and promoted at site level, you can select the ... 1\ufe0f\u20e3 beside the agent name and then select the option to Share 2\ufe0f\u20e3 the agent.</p> <p></p> <p>The modern file sharing User Experience of SharePoint Online will show up and you will be able to share the .agent file with others in your organization. As like as it happens with any other SharePoint Online file, you can choose the target people (user, groups, or emails) to share the agent with and you can either get a link to the file or send a sharing notification email. If you choose to copy a link, you can then paste it wherever you like.</p> <p></p> <p>The sharing link will bring target users straight to the agent dialog, so that they will able to interact with the agent directly within the immersive and full scren SharePoint agent experience.</p> <p></p>"},{"location":"pages/make/sharepoint-agents/02-sharing-agents/#step-2-sharing-a-sharepoint-agent-via-microsoft-teams","title":"Step 2: Sharing a SharePoint agent via Microsoft Teams","text":"<p>An interesting option that you have is to share the agent via Microsoft Teams. In order to do that, you simply need to select the ... 1\ufe0f\u20e3 beside the agent name and then select the option to Copy link for Teams 2\ufe0f\u20e3.</p> <p></p> <p>This will generate a sharing link for the agent file and copy it into the clipboard, as you can see from the confirmation message that you get back. In the confirmation message, you can also notice that the generated link is ready to be pasted in any group chat in Microsoft Teams.</p> <p></p> <p>In the dialog you can also select the Settings link to configure who can access the sharing link and to setup an optional expiration date for the link. Under the cover, a regular sharing link of SharePoint Online will be created. Let's paste the link into a group chat in order to see what happens.</p> <p></p> <p>When you paste the link into a group chat, you will see a nice looking adaptive card providing information about the agent. This happens due to a custom link unfurling extension for Teams that handles the .agent files. Send the chat message with the link. The adaptive card will slightly change its rendering and will provide you a command to Add to this chat the agent and another command to View details about the agent.</p> <p></p> <p>Select the command Add to this chat, and wait few seconds. In case of successful result you will see a message confirming that the agent was added to the chat and you will also promptly see a welcome message from the agent itself. In case of any issue, the command button to Add to this chat will become disabled and the text will change to Error adding to chat. You can always try to refresh the chat and try again adding the agent.</p> <p></p> <p></p>"},{"location":"pages/make/sharepoint-agents/02-sharing-agents/#step-3-interacting-with-the-shared-agent-in-microsoft-teams","title":"Step 3: Interacting with the shared agent in Microsoft Teams","text":"<p>You can now interact with the agent within the group chat experience in Microsoft Teams. Whenever you want to trigger the agent, you simply need to at mention by name (@HR Agent) the agent and send it a prompt to process. For example, you can use a prompt like the following one:</p> <pre><code>How can I improve my career?\n</code></pre> <p></p> <p>The SharePoint agent will process the prompt and provide an answer. However, for security reasons the answer will not go straight to the chat. You will need to evaluate its content and the documents referenced by the agent to produce the response. Select the View response command to evaluate the answer. </p> <p></p> <p>When you select View response a popup dialog shows up, allowing you to evaluate the whole response text and the referenced attachments, if any, prior to share the result with others. If you are ok with the answer, you can confirm and send the actual response message to the chat.</p> <p></p> <p>Select the Send command to confirm that the response and its attachments are ok for you. You can also instruct Microsoft Teams to trust any further responses from the agent for the next 24 hours, to avoid too many confirmation requests. Select the Don't send command if you are not happy with the response or if you don't want to disclose one or more of the documents referenced by the agent in the response. Users in the group chat will see a message from the agent stating that \"[YOUR USER DISPLAY NAME] reviewed my response to the request made and suggested that I don't share it at this time.\".</p> <p></p> <p>You can now enjoy the integration between Microsoft Teams and the SharePoint agent.</p> <p></p> <p>CONGRATULATIONS!</p> <p>You have completed Lab MSA2 - Sharing SharePoint agents!</p> <p></p>"}]}