{"config":{"lang":["en","ja"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":"<p>Copilot Developer Camp is a self-paced learning resource, designed to help you build agents for Microsoft 365 Copilot. It provides practical guidance and real-world examples to support your development journey.</p>"},{"location":"#building-agents-for-microsoft-365","title":"Building Agents for Microsoft 365","text":"<p>Agents for Microsoft 365 are conversational AI-powered assistants designed to help users automate tasks, answer questions, and streamline workflows across Microsoft 365 apps and services. Agents can be used in various scenarios, such as customer support, IT helpdesk, HR support, and more.</p> <p></p> <p>An agent for Microsoft 365 is typically made up of these components\u2014foundational model,  an orchestrator, which is running that taps into that knowledge, skills, and autonomous processes that it has those capabilities to do, and it may or may not have a user interface. \u200b</p> <p>You can either extend Microsoft 365 Copilot by using the same infrastructure, orchestrator, foundation model, and security controls as Microsoft 365 Copilot, which ensures a consistent and familiar user experience.</p> <p>Or you can pick your own foundation model, orchestrator, and responsible AI controls.</p>"},{"location":"#where-should-i-start-to-build-agents","title":"\ud83e\uddea Where should I start to build agents?","text":"<p>There are three major pathways with several labs. If you want a no-code/low-code approach, choose the Maker path (\"MAB\", \"MSA\", or \"MCS\" lab). If you want to extend Microsoft 365 Copilot, choose the Extend path (\"E\" lab). If you want to build a completely custom agent using Azure AI Foundry or any AI of your choice, choose the Build path (\"BMA\" lab).</p> <p></p>        Make agents      <p>Make your agents with no-code or low-code with Copilot Studio or SharePoint Online. (\"MAB\", \"MSA\", and \"MCS\" lab)</p> Get Started        Extend M365 Copilot      <p>Build a Declarative agent where Microsoft 365 provides the AI model and orchestration. (\"E\" lab)</p> Get Started        Build your own agent      <p>Build a custom engine agent with custom AI model and orchestration using Azure OpenAI. (\"BMA\" lab)</p> Get Started Overview of Copilot Dev Camp"},{"location":"#whats-new","title":"\ud83c\udd95 What's New?","text":"<p>Updated in June 2025</p> <p>We\u2019re excited to introduce four new hands-on labs designed to help you build powerful Copilot experiences. </p> <ul> <li> <p>Build with Microsoft 365 Agents SDK: Leverage the full capabilities of the Microsoft 365 Agents SDK to create production-ready Copilot agents that integrate with real business data. \ud83d\udd17 Start this lab</p> </li> <li> <p>Build Copilot Agents Using TypeSpec: Use TypeSpec to define your agent and capabilities declaratively. Ideal for developers looking to build Copilot agents that connect to API services with seamless orchestration. \ud83d\udd17 Start this lab</p> </li> <li> <p>Agent Instructions Guide for Beginners: New to Copilot? This lab walks you through the process of writing effective natural language instructions and testing your Copilot agent in a guided environment. \ud83d\udd17 Start this lab</p> </li> <li> <p>SharePoint agents: Learn how to create SharePoint agents starting from the basics, how to fine tune their settings, and how to share them with people or in Microsoft Teams group chats. \ud83d\udd17 Start this lab</p> </li> </ul>"},{"location":"#more","title":"\ud83e\uddd1\u200d\ud83d\udcbb More","text":"Learn more      <p>Learn more from various resources</p> <ul> <li>Microsoft Learn</li> <li>Video tutorials</li> </ul>        Connect with us      <p>Join the conversation on GitHub Discussion!</p>"},{"location":"#copilot-camp-in-a-box","title":"\ud83c\udf81 Copilot Camp in a Box","text":"<p>Got the labs working? Ready to share your knowledge? Why not run your own Copilot Camp workshop using our\u00a0Copilot Camp in a Box\u00a0resources! We've got you covered with presentation materials that even include embedded demos.</p>"},{"location":"#issues","title":"\ud83d\ude91 Issues","text":"<p>We really appreciate your feedback! Please use the issues list to share your comments and issues, or if you're in Microsoft let us know in the \"Copilot Developer Camp Early Testers\" chat in Microsoft Teams. Thanks!</p>"},{"location":"#code-of-conduct","title":"\ud83d\udcdc Code of Conduct","text":"<p>This project has adopted the Microsoft Open Source Code of Conduct.</p> <p>Resources:</p> <ul> <li>Microsoft Open Source Code of Conduct</li> <li>Microsoft Code of Conduct FAQ</li> <li>Contact opencode@microsoft.com with questions or concerns</li> </ul> <p></p> <p>\u2b50\ufe0f Star our repo</p>"},{"location":"awards/","title":"Awards","text":""},{"location":"awards/#copilot-developer-camp-awards","title":"Copilot Developer Camp Awards","text":"<p>We are excited to announce a thrilling initiative that will challenge you to showcase your knowledge and skills in Microsoft 365 Copilot extensibility. This is your chance to dive deep into the world of Copilot, explore its capabilities, and demonstrate your expertise.</p>"},{"location":"awards/#why-participate","title":"Why participate?","text":"<ul> <li>Learn and Grow: This initiative is a fantastic opportunity to expand your understanding of Microsoft 365 Copilot extensibility.</li> <li>Earn Badges: Show off your achievements with exclusive badges awarded based on your performance.</li> <li>Community Recognition: Stand out in the community and get recognized for your contributions and knowledge.</li> </ul>"},{"location":"awards/#how-to-participate","title":"How to participate?","text":"<ul> <li>Register: Sign up for the Microsoft 365 &amp; Power Platform Community Recognition Program through this form. If you already claimed badges through the Microsoft 365 &amp; Power Platform Community Recognition Program, you don't need to sign up again.</li> <li>Complete a Copilot Developer Camp pathway: Complete all the labs of any of the learning pathways (Maker Path, Extend, and Build) of Copilot Developer Camp to claim a blue-belt badge!</li> </ul> <ul> <li>Complete all the pathways: Complete all the labs of all of the learning pathways of Copilot Developer Camp to get a black-belt badge and to become a Path Master!</li> </ul> <ul> <li>Submit a community sample: Once you have earned the black-belt badge, submit one or more Microsoft 365 Copilot extensibility samples to the Sample Solution Gallery and prove to yourself and to the whole community what you have learned! You will get a red-belt badge and become a Sample Sensei!</li> </ul>"},{"location":"awards/#timeline-and-limits","title":"Timeline and Limits","text":"<ul> <li>Initiative Starts: March 25, 2025</li> <li>Initiative Ends: May 31, 2025</li> <li>Limits: only the first 200 community members will earn badges</li> </ul> <p>Every single week, during Microsoft 365 &amp; Power Platform Community calls, we will announce community members awarded with one or more badges. Challenge yourself and be among the first 200 community members to earn badges and seize this unique opportunity!</p> <p>Don't miss out on this exciting opportunity to earn recognition in the community. Whether you're a seasoned expert or just starting out, this initiative is designed for everyone. So, gear up, get ready, and let's see how much you know about Microsoft 365 Copilot extensibility!</p> <p>Happy learning and good luck!</p> <p></p>"},{"location":"mslearn/","title":"Microsoft Learn \ud83d\udcd6","text":""},{"location":"mslearn/#copilot-extensibility-official-documentation","title":"Copilot Extensibility official documentation","text":"<p>Discover Microsoft Learn content to extend Copilot all in one place with the Official Collection: Microsoft 365 Copilot extensibility available at the link https://aka.ms/extend-microsoft365-copilot</p>"},{"location":"mslearn/#mcp-server","title":"MCP Server","text":"<p>If you use coding agents like GitHub Copilot and enhance the experience with Microsoft Learn content, connect the MCP server with your client!</p> <p>Set up with the endpoint manually, <code>https://learn.microsoft.com/api/mcp</code>, or go to MCP Servers for agent mode and simply click Microsoft Docs button on to install it on Visual Studio Code!</p> <p></p>"},{"location":"register/","title":"Registration","text":""},{"location":"resources/","title":"Resources","text":""},{"location":"resources/#videos-and-resources","title":"Videos and Resources","text":"Watch Microsoft 365 Copilot: Developer Camp On-demand! \ud83c\udf89 <p> Let's Start with a Game! Developer's Guide to Building Copilot Agents Introducing Declarative Agents The Future of Declarative Agents Extending Declarative Agents A Conversation with the Leaders Behind the Developer Tools Introducing Custom Engine Agents Unlock the Power of Custom Engine Agents </p> Learn about Microsoft 365 Copilot 'Wave 2' <p> Microsoft 365 Copilot Wave 2 announcement with Satya Nadella and Jared Spataro </p> Video briefing: Building Agents for Microsoft 365 Copilot <p> Understanding the Copilot Dev Camp pathways Building Copilot agents with code (Overview) Introducing Custom engine agents Introducing Declarative agents Building API Plugins for Declarative agents </p> <p>Declarative Agent Auth</p> <p>If you already know how to build a declarative agent with an API plugin and want to learn how to secure your API, you can skip directly to the authentication labs; details are here</p> <p>New schema</p> <p>If you began the \"Extend\" labs prior to October 27, 2024, you are probably still using the developer preview schema and should upgrade to the v1.19 schema at this time. Detailed instructions are here. The solution files were updated on October 27, so if you started with those you can disregard this notice.</p>"},{"location":"resources/#more-videos","title":"More videos \ud83d\udcfa","text":"<p>Here are some relevant videos from the Microsoft 365 Developer Channel. Please subscribe to keep up with all our latest videos on Microsoft 365 development!</p> Learn AI concepts with Doodle to Code! <p> What is Generative AI? What is Retrieval Augmented Generation (RAG)? Create an AI Powered Chatbot in Microsoft Teams with Teams AI Library Bring your AI App to Microsoft Teams from Azure AI Foundry </p> Microsoft Mechanics <p> Microsoft 365 Copilot - New agent and extensibility options for developers AI apps - Control Safety, Privacy &amp; Security - with Mark Russinovich How Microsoft 365 Copilot works Microsoft 365 Copilot Wave Two updates - Pages, Excel, OneDrive, and agents </p> Microsoft 365 Developer Essentials <p> Adaptive cards are everywhere Where is the Microsoft 365 API? </p> More on building Custom engine agents <p> Chat over your data with Azure OpenAI and Teams AI Library </p>"},{"location":"resources/#join-the-conversation","title":"Join the Conversation! \ud83d\udcac","text":"Welcome to the Copilot Developer Camp Discussions! \ud83e\udd17 <p>Introduce yourself and tell us about your experience with Copilot Developer Camp \ud83c\udfd5\ufe0f.</p> \ud83c\udf89 New Feature X: Ideas and Feedback <p>We\u2019re exploring some cool updates! Share your thoughts on Feature X and let\u2019s brainstorm together!</p> \ud83d\ude80 Troubleshooting Guide: Share Your Tips <p>Got any tips for solving common setup issues? Drop your wisdom and help the community thrive!</p> \u2728 Explore More Discussions"},{"location":"resources/#microsoft-learn","title":"Microsoft Learn \ud83d\udcd6","text":"<p>Discover Microsoft Learn content here.</p>"},{"location":"resources/#issues","title":"Issues","text":"<p>We really appreciate your feedback! Please use the issues list to share your comments and issues, or if you're in Microsoft let us know in the \"Copilot Developer Camp Early Testers\" chat in Microsoft Teams. Thanks!</p>"},{"location":"resources/#code-of-conduct","title":"Code of Conduct","text":"<p>This project has adopted the Microsoft Open Source Code of Conduct.</p> <p>Resources:</p> <ul> <li>Microsoft Open Source Code of Conduct</li> <li>Microsoft Code of Conduct FAQ</li> <li>Contact opencode@microsoft.com with questions or concerns</li> </ul> <p></p>"},{"location":"demo-assets/","title":"Index","text":"<p>The following sample images are hosted in the github pages for use by code samples such as the Trey Research API Plugin. Portraits were generated using Microsoft Copilot.</p>"},{"location":"demo-assets/#consultant-pictures","title":"Consultant pictures","text":"<p> Avery Howard</p> <p> Dominique Dutertre</p> <p> Robin Zupanc</p> <p> Sanjay Puranik</p> <p> Lois Wyn</p> <p> The Unknown Consultant</p> <p> Spare 1</p> <p> Spare 2</p> <p> Spare 3</p>"},{"location":"demo-assets/#maps","title":"Maps","text":"<p> Adatum Corporation</p> <p> Alpine Ski House</p> <p> Bellows College</p> <p> Consolidated Messenger</p> <p> Contoso Pharmaceuticals</p> <p> Humongous Insurance</p> <p> Lamna Healthcare Company</p> <p> Relecloud</p> <p> Southridge Video</p> <p> Woodgrove Bank</p>"},{"location":"includes/all-labs-toc/","title":"All labs toc","text":"<p>Do these labs if you want to build a Declarative agent where Microsoft 365 provides the AI model and             orchestration</p> <ul> <li>\ud83c\udfc1 Welcome</li> <li>\ud83d\udd27 Set up <ul> <li>Lab E0 - Setup</li> </ul> </li> <li>\ud83e\uddf0 Declarative agent fundamentals <ul> <li> Lab E1 - Build a Detailed Declarative Agent </li> <li> Lab E1a - Geo locator game</li> </ul> </li> <li>\ud83d\udee0\ufe0f Build and integrate API from scratch <ul> <li>Lab E2 - Build an API</li> <li> Lab E3 - Add Declarative Agent + API</li> <li> Lab E4 - Enhance API + Plugin</li> <li>Lab E5 - Add Adaptive Cards</li> </ul> </li> <li>\ud83d\udd10 Authentication <ul> <li> Lab E6a - Toolkit</li> <li> Lab E6b - Manual</li> <li> Lab E6c - SSO</li> </ul> </li> <li>\ud83d\udd0c Integration <ul> <li> Lab EB - Add Graph Connector</li> </ul> </li> </ul> <p>Do these labs if you want to build a Custom engine agent with custom AI model and orchestration using Azure OpenAI and Teams AI library</p> <ul> <li>BTA0 - Setup</li> <li>BTA1 - First custom engine agent</li> <li>BTA2 - Index your data in Azure AI Search</li> <li>BTA3 - Enhance the user experience</li> <li>BTA4 - Add single sign on authentication</li> <li>BTA5 - Add actions to handle complex tasks</li> </ul> <p>Do these labs if you want to build a Declarative agent with Copilot Studio Lite</p> <ul> <li>MAB1 - Build your first agent</li> </ul> <p>Do these labs if you want to build agents with Microsoft Copilot Studio</p> <ul> <li>MCS0 - Setup</li> <li>MCS1 - First agent</li> <li>MCS2 - Defining Topics</li> <li>MCS3 - Defining Tools</li> <li>MCS4 - Extending Microsoft 365 Copilot</li> <li>MCS5 - Consuming a custom connector</li> <li>MCS6 - Consuming an MCP server</li> <li>MCS7 - Creating Autonomous Agents</li> <li>MCS8 - Integrating Azure AI Search for RAG</li> </ul>"},{"location":"includes/b-congratulations/","title":"B congratulations","text":"<p>CONGRATULATIONS!</p>"},{"location":"includes/b-labs-branches/","title":"B labs branches","text":"Build with Microsoft 365 Agents SDK              <ul> <li>C# based exercise using Visual Studio 2022 and the Microsoft 365 Agents Toolkit</li> <li>Integrates custom orchestration with Semantic Kernel and Generative AI models</li> <li>Compatible with Microsoft Teams and Microsoft 365 Copilot Chat</li> <li>Supports external channels, including web and other endpoints</li> </ul> Start here"},{"location":"includes/b-labs-prelude/","title":"B labs prelude","text":"<p>Do these labs if you want to build a Custom engine agent with custom AI model and orchestration using Azure OpenAI and Teams AI library</p> <ul> <li>BTA0 - Setup</li> <li>BTA1 - First custom engine agent</li> <li>BTA2 - Index your data in Azure AI Search</li> <li>BTA3 - Enhance the user experience</li> <li>BTA4 - Add single sign on authentication</li> <li>BTA5 - Add actions to handle complex tasks</li> </ul>"},{"location":"includes/b-labs-toc/","title":"B labs toc","text":"<p>Do these labs if you want to build a Custom engine agent with custom AI model and orchestration using Azure OpenAI and Teams AI library</p> <ul> <li>BTA0 - Setup</li> <li>BTA1 - First custom engine agent</li> <li>BTA2 - Index your data in Azure AI Search</li> <li>BTA3 - Enhance the user experience</li> <li>BTA4 - Add single sign on authentication</li> <li>BTA5 - Add actions to handle complex tasks</li> </ul>"},{"location":"includes/discussions/","title":"Discussions","text":"Welcome to the Copilot Developer Camp Discussions! \ud83e\udd17 <p>Introduce yourself and tell us about your experience with Copilot Developer Camp \ud83c\udfd5\ufe0f.</p> \ud83c\udf89 New Feature X: Ideas and Feedback <p>We\u2019re exploring some cool updates! Share your thoughts on Feature X and let\u2019s brainstorm together!</p> \ud83d\ude80 Troubleshooting Guide: Share Your Tips <p>Got any tips for solving common setup issues? Drop your wisdom and help the community thrive!</p> \u2728 Explore More Discussions"},{"location":"includes/e-congratulations/","title":"E congratulations","text":"<p>CONGRATULATIONS!</p>"},{"location":"includes/e-labs-prelude/","title":"E labs prelude","text":"<p>Do these labs if you want to build a Declarative agent where Microsoft 365 provides the AI model and             orchestration</p> <ul> <li>\ud83c\udfc1 Welcome</li> <li>\ud83d\udd27 Set up <ul> <li>Lab E0 - Setup</li> </ul> </li> <li>\ud83e\uddf0 Declarative agent fundamentals <ul> <li> Lab E1 - Build a Detailed Declarative Agent </li> <li> Lab E1a - Geo locator game</li> </ul> </li> <li>\ud83d\udee0\ufe0f Build and integrate API from scratch <ul> <li>Lab E2 - Build an API</li> <li> Lab E3 - Add Declarative Agent + API</li> <li> Lab E4 - Enhance API + Plugin</li> <li>Lab E5 - Add Adaptive Cards</li> </ul> </li> <li>\ud83d\udd10 Authentication <ul> <li> Lab E6a - Toolkit</li> <li> Lab E6b - Manual</li> <li> Lab E6c - SSO</li> </ul> </li> <li>\ud83d\udd0c Integration <ul> <li> Lab EB - Add Graph Connector</li> </ul> </li> </ul>"},{"location":"includes/e-labs-toc/","title":"E labs toc","text":"<p>Do these labs if you want to build a Declarative agent where Microsoft 365 provides the AI model and             orchestration</p> <ul> <li>\ud83c\udfc1 Welcome</li> <li>\ud83d\udd27 Set up <ul> <li>Lab E0 - Setup</li> </ul> </li> <li>\ud83e\uddf0 Declarative agent fundamentals <ul> <li> Lab E1 - Build a Detailed Declarative Agent </li> <li> Lab E1a - Geo locator game</li> </ul> </li> <li>\ud83d\udee0\ufe0f Build and integrate API from scratch <ul> <li>Lab E2 - Build an API</li> <li> Lab E3 - Add Declarative Agent + API</li> <li> Lab E4 - Enhance API + Plugin</li> <li>Lab E5 - Add Adaptive Cards</li> </ul> </li> <li>\ud83d\udd10 Authentication <ul> <li> Lab E6a - Toolkit</li> <li> Lab E6b - Manual</li> <li> Lab E6c - SSO</li> </ul> </li> <li>\ud83d\udd0c Integration <ul> <li> Lab EB - Add Graph Connector</li> </ul> </li> </ul>"},{"location":"includes/m-labs-branches/","title":"M labs branches","text":"Copilot Studio Lite      <ul> <li>Easy, simple, and interactive experience</li> <li>Web based, integrated with Microsoft 365 Copilot Chat and Microsoft 365 Copilot</li> <li>Content from SharePoint Online, public web, and Microsoft Copilot Connectors</li> <li>Available in Microsoft 365 Copilot Chat</li> <ul> Start here  Copilot Studio Full              <ul> <li>Maximum level of flexibility</li> <li>Almost any data source or knowledge base</li> <li>Support for various publishing channels</li> <li>Support for actions</li> <li>Support for Power Platform connectors, Dataverse, REST API, and more</li> <li>Per user + per tenant license or Pay-As-You-Go</li> <ul> Start here  SharePoint Agent              <ul> <li>Integrated with SharePoint Online user experience</li> <li>SharePoint Online content only</li> <li>Supported in Microsoft Teams chat</li> <li>Microsoft 365 Copilot license or Microsoft Copilot Studio capacity or Pay-As-You-Go</li> <ul> Start here"},{"location":"includes/m-path-links/","title":"M path links","text":"<ul> <li>Lab M0 - Prerequisites READY FOR TESTING</li> <li>Lab M1 - Get to know Northwind message extension READY FOR TESTING</li> <li>Lab M2 - Run app in Microsoft 365 Copilot READY FOR TESTINGSOON</li> <li>Lab M3 - Enhance plugin with new search command READY FOR TESTING</li> <li>Lab M4 - Add authentication READY FOR TESTING</li> <li>Lab M5 - Enhance plugin with an action command COMING SOON</li> </ul>"},{"location":"includes/mab-congratulations/","title":"Mab congratulations","text":"<p>CONGRATULATIONS!</p>"},{"location":"includes/mab-labs-prelude/","title":"Mab labs prelude","text":"<p>Do these labs if you want to build a Declarative agent with Copilot Studio Lite</p> <ul> <li>MAB1 - Build your first agent</li> </ul> Table of Contents"},{"location":"includes/mab-labs-toc/","title":"Mab labs toc","text":"<p>Do these labs if you want to build a Declarative agent with Copilot Studio Lite</p> <ul> <li>MAB1 - Build your first agent</li> </ul>"},{"location":"includes/main-links/","title":"Main links","text":"Make agents      <p>Make your agents with no-code or low-code with Copilot Studio or SharePoint Online. (\"MAB\", \"MSA\", and \"MCS\" lab)</p> Get Started        Extend M365 Copilot      <p>Build a Declarative agent where Microsoft 365 provides the AI model and orchestration. (\"E\" lab)</p> Get Started        Build your own agent      <p>Build a custom engine agent with custom AI model and orchestration using Azure OpenAI. (\"BMA\" lab)</p> Get Started"},{"location":"includes/mcs-congratulations/","title":"Mcs congratulations","text":"<p>CONGRATULATIONS!</p>"},{"location":"includes/mcs-labs-prelude/","title":"Mcs labs prelude","text":"<p>Do these labs if you want to build agents with Microsoft Copilot Studio</p> <ul> <li>MCS0 - Setup</li> <li>MCS1 - First agent</li> <li>MCS2 - Defining Topics</li> <li>MCS3 - Defining Tools</li> <li>MCS4 - Extending Microsoft 365 Copilot</li> <li>MCS5 - Consuming a custom connector</li> <li>MCS6 - Consuming an MCP server</li> <li>MCS7 - Creating Autonomous Agents</li> <li>MCS8 - Integrating Azure AI Search for RAG</li> </ul>"},{"location":"includes/mcs-labs-toc/","title":"Mcs labs toc","text":"<p>Do these labs if you want to build agents with Microsoft Copilot Studio</p> <ul> <li>MCS0 - Setup</li> <li>MCS1 - First agent</li> <li>MCS2 - Defining Topics</li> <li>MCS3 - Defining Tools</li> <li>MCS4 - Extending Microsoft 365 Copilot</li> <li>MCS5 - Consuming a custom connector</li> <li>MCS6 - Consuming an MCP server</li> <li>MCS7 - Creating Autonomous Agents</li> <li>MCS8 - Integrating Azure AI Search for RAG</li> </ul>"},{"location":"includes/more-links/","title":"More links","text":"Learn more      <p>Learn more from various resources</p> <ul> <li>Microsoft Learn</li> <li>Video tutorials</li> </ul>        Connect with us      <p>Join the conversation on GitHub Discussion!</p>"},{"location":"includes/msa-congratulations/","title":"Msa congratulations","text":"<p>CONGRATULATIONS!</p>"},{"location":"includes/msa-labs-prelude/","title":"Msa labs prelude","text":"<p>Do these labs if you want to build a SharePoint agent</p> <ul> <li>MSA1 - Build your first SharePoint agent</li> <li>MSA2 - Sharing SharePoint agents</li> </ul> Table of Contents"},{"location":"includes/msa-labs-toc/","title":"Msa labs toc","text":"<p>Do these labs if you want to build a SharePoint agent</p> <ul> <li>MSA1 - Build your first SharePoint agent</li> <li>MSA2 - Sharing SharePoint agents</li> </ul>"},{"location":"includes/starrepo/","title":"Starrepo","text":"<p>\u2b50\ufe0f Star our repo</p>"},{"location":"includes/ja/all-labs-toc/","title":"All labs toc","text":"<p>Microsoft 365 \u304c AI \u30e2\u30c7\u30eb\u3068\u30aa\u30fc\u30b1\u30b9\u30c8\u30ec\u30fc\u30b7\u30e7\u30f3\u3092\u63d0\u4f9b\u3059\u308b\u5ba3\u8a00\u578b\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3092\u69cb\u7bc9\u3057\u305f\u3044\u5834\u5408\u306f\u3001\u3053\u308c\u3089\u306e\u30e9\u30dc\u3092\u5b9f\u65bd\u3057\u3066\u304f\u3060\u3055\u3044\u3002</p> <ul> <li>\ud83c\udfc1 \u306f\u3058\u3081\u306b</li> <li>\ud83d\udd27 \u30bb\u30c3\u30c8\u30a2\u30c3\u30d7 <ul> <li>\u30e9\u30dc E0 - \u30bb\u30c3\u30c8\u30a2\u30c3\u30d7</li> </ul> </li> <li>\ud83e\uddf0 \u5ba3\u8a00\u578b\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u306e\u57fa\u790e <ul> <li>\u30e9\u30dc E1 - \u8a73\u7d30\u306a\u5ba3\u8a00\u578b\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3092\u69cb\u7bc9\u3059\u308b </li> <li>\u30e9\u30dc E1a - Geo \u30ed\u30b1\u30fc\u30bf\u30fc\u30b2\u30fc\u30e0</li> </ul> </li> <li>\ud83d\udee0\ufe0f API \u3092\u30bc\u30ed\u304b\u3089\u69cb\u7bc9\u3057\u3066\u7d71\u5408\u3059\u308b <ul> <li>\u30e9\u30dc E2 - API \u3092\u69cb\u7bc9\u3059\u308b</li> <li>\u30e9\u30dc E3 - \u5ba3\u8a00\u578b\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8 + API \u3092\u8ffd\u52a0\u3059\u308b</li> <li>\u30e9\u30dc E4 - API + \u30d7\u30e9\u30b0\u30a4\u30f3\u3092\u5f37\u5316\u3059\u308b</li> <li>\u30e9\u30dc E5 - Adaptive Card \u3092\u8ffd\u52a0\u3059\u308b</li> </ul> </li> <li>\ud83d\udd10 \u8a8d\u8a3c <ul> <li>\u30e9\u30dc E6a - Toolkit</li> <li>\u30e9\u30dc E6b - \u624b\u52d5</li> <li>\u30e9\u30dc E6c - SSO</li> </ul> </li> <li>\ud83d\udd0c \u7d71\u5408 <ul> <li>\u30e9\u30dc EB - Graph Connector \u3092\u8ffd\u52a0\u3059\u308b</li> </ul> </li> </ul> <p>Azure OpenAI \u3068 Teams AI library \u3092\u4f7f\u7528\u3057\u3066\u30ab\u30b9\u30bf\u30e0 AI \u30e2\u30c7\u30eb\u3068\u30aa\u30fc\u30b1\u30b9\u30c8\u30ec\u30fc\u30b7\u30e7\u30f3\u3092\u5099\u3048\u305f Custom \u30a8\u30f3\u30b8\u30f3 \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3092\u69cb\u7bc9\u3057\u305f\u3044\u5834\u5408\u306f\u3001\u3053\u308c\u3089\u306e \u30e9\u30dc \u3092\u5b9f\u65bd\u3057\u3066\u304f\u3060\u3055\u3044</p> <ul> <li>BTA0 - \u30bb\u30c3\u30c8\u30a2\u30c3\u30d7</li> <li>BTA1 - \u306f\u3058\u3081\u3066\u306e Custom \u30a8\u30f3\u30b8\u30f3 \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8</li> <li>BTA2 - \u30c7\u30fc\u30bf\u3092 Azure AI Search \u3067\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u5316\u3059\u308b</li> <li>BTA3 - \u30e6\u30fc\u30b6\u30fc \u30a8\u30af\u30b9\u30da\u30ea\u30a8\u30f3\u30b9\u3092\u5f37\u5316\u3059\u308b</li> <li>BTA4 - \u30b7\u30f3\u30b0\u30eb \u30b5\u30a4\u30f3\u30aa\u30f3\u8a8d\u8a3c\u3092\u8ffd\u52a0\u3059\u308b</li> <li>BTA5 - \u8907\u96d1\u306a\u30bf\u30b9\u30af\u3092\u51e6\u7406\u3059\u308b\u30a2\u30af\u30b7\u30e7\u30f3\u3092\u8ffd\u52a0\u3059\u308b</li> </ul> <p>Copilot Studio Lite \u3067\u5ba3\u8a00\u578b\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3092\u69cb\u7bc9\u3057\u305f\u3044\u5834\u5408\u306f\u3001\u6b21\u306e\u30e9\u30dc\u3092\u5b9f\u65bd\u3057\u3066\u304f\u3060\u3055\u3044\u3002</p> <ul> <li>MAB1 - \u6700\u521d\u306e\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3092\u69cb\u7bc9\u3059\u308b</li> </ul> <p>Microsoft Copilot Studio \u3067 \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3092\u69cb\u7bc9\u3057\u305f\u3044\u5834\u5408\u306f\u3001\u3053\u308c\u3089\u306e \u30e9\u30dc \u3092\u5b9f\u65bd\u3057\u3066\u304f\u3060\u3055\u3044</p> <ul> <li>MCS0 - \u30bb\u30c3\u30c8\u30a2\u30c3\u30d7</li> <li>MCS1 - \u6700\u521d\u306e \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8</li> <li>MCS2 - \u30c8\u30d4\u30c3\u30af\u306e\u5b9a\u7fa9</li> <li>MCS3 - \u30c4\u30fc\u30eb\u306e\u5b9a\u7fa9</li> <li>MCS4 - Microsoft 365 Copilot \u3092\u62e1\u5f35\u3059\u308b</li> <li>MCS5 - \u30ab\u30b9\u30bf\u30e0 \u30b3\u30cd\u30af\u30bf\u306e\u5229\u7528</li> <li>MCS6 - MCP \u30b5\u30fc\u30d0\u30fc\u306e\u5229\u7528</li> <li>MCS7 - \u81ea\u5f8b\u578b \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u306e\u4f5c\u6210</li> <li>MCS8 - RAG \u306e\u305f\u3081\u306e Azure AI Search \u7d71\u5408</li> </ul>"},{"location":"includes/ja/b-congratulations/","title":"B congratulations","text":"<p>\u304a\u3081\u3067\u3068\u3046\u3054\u3056\u3044\u307e\u3059\uff01</p>"},{"location":"includes/ja/b-labs-branches/","title":"B labs branches","text":"Microsoft 365 \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8 SDK \u3092\u4f7f\u3063\u305f\u958b\u767a              <ul> <li>Visual Studio 2022 \u3068 Microsoft 365 \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8 Toolkit \u3092\u4f7f\u7528\u3057\u305f C# \u30d9\u30fc\u30b9\u306e\u6f14\u7fd2</li> <li>Semantic Kernel \u3068\u751f\u6210 AI \u30e2\u30c7\u30eb\u306b\u3088\u308b\u30ab\u30b9\u30bf\u30e0\u30aa\u30fc\u30b1\u30b9\u30c8\u30ec\u30fc\u30b7\u30e7\u30f3\u3092\u7d71\u5408</li> <li>Microsoft Teams \u3068 Microsoft 365 Copilot Chat \u306b\u5bfe\u5fdc</li> <li>Web \u3092\u542b\u3080\u5916\u90e8\u30c1\u30e3\u30cd\u30eb\u304a\u3088\u3073\u305d\u306e\u4ed6\u306e\u30a8\u30f3\u30c9\u30dd\u30a4\u30f3\u30c8\u3092\u30b5\u30dd\u30fc\u30c8</li> </ul> \u3053\u3053\u304b\u3089\u958b\u59cb"},{"location":"includes/ja/b-labs-prelude/","title":"B labs prelude","text":"<p>Azure OpenAI \u3068 Teams AI library \u3092\u4f7f\u7528\u3057\u3066\u30ab\u30b9\u30bf\u30e0 AI \u30e2\u30c7\u30eb\u3068\u30aa\u30fc\u30b1\u30b9\u30c8\u30ec\u30fc\u30b7\u30e7\u30f3\u3092\u5099\u3048\u305f Custom \u30a8\u30f3\u30b8\u30f3 \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3092\u69cb\u7bc9\u3057\u305f\u3044\u5834\u5408\u306f\u3001\u3053\u308c\u3089\u306e \u30e9\u30dc \u3092\u5b9f\u65bd\u3057\u3066\u304f\u3060\u3055\u3044</p> <ul> <li>BTA0 - \u30bb\u30c3\u30c8\u30a2\u30c3\u30d7</li> <li>BTA1 - \u306f\u3058\u3081\u3066\u306e Custom \u30a8\u30f3\u30b8\u30f3 \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8</li> <li>BTA2 - \u30c7\u30fc\u30bf\u3092 Azure AI Search \u3067\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u5316\u3059\u308b</li> <li>BTA3 - \u30e6\u30fc\u30b6\u30fc \u30a8\u30af\u30b9\u30da\u30ea\u30a8\u30f3\u30b9\u3092\u5f37\u5316\u3059\u308b</li> <li>BTA4 - \u30b7\u30f3\u30b0\u30eb \u30b5\u30a4\u30f3\u30aa\u30f3\u8a8d\u8a3c\u3092\u8ffd\u52a0\u3059\u308b</li> <li>BTA5 - \u8907\u96d1\u306a\u30bf\u30b9\u30af\u3092\u51e6\u7406\u3059\u308b\u30a2\u30af\u30b7\u30e7\u30f3\u3092\u8ffd\u52a0\u3059\u308b</li> </ul>"},{"location":"includes/ja/b-labs-toc/","title":"B labs toc","text":"<p>Azure OpenAI \u3068 Teams AI library \u3092\u4f7f\u7528\u3057\u3066\u30ab\u30b9\u30bf\u30e0 AI \u30e2\u30c7\u30eb\u3068\u30aa\u30fc\u30b1\u30b9\u30c8\u30ec\u30fc\u30b7\u30e7\u30f3\u3092\u5099\u3048\u305f Custom \u30a8\u30f3\u30b8\u30f3 \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3092\u69cb\u7bc9\u3057\u305f\u3044\u5834\u5408\u306f\u3001\u3053\u308c\u3089\u306e \u30e9\u30dc \u3092\u5b9f\u65bd\u3057\u3066\u304f\u3060\u3055\u3044</p> <ul> <li>BTA0 - \u30bb\u30c3\u30c8\u30a2\u30c3\u30d7</li> <li>BTA1 - \u306f\u3058\u3081\u3066\u306e Custom \u30a8\u30f3\u30b8\u30f3 \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8</li> <li>BTA2 - \u30c7\u30fc\u30bf\u3092 Azure AI Search \u3067\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u5316\u3059\u308b</li> <li>BTA3 - \u30e6\u30fc\u30b6\u30fc \u30a8\u30af\u30b9\u30da\u30ea\u30a8\u30f3\u30b9\u3092\u5f37\u5316\u3059\u308b</li> <li>BTA4 - \u30b7\u30f3\u30b0\u30eb \u30b5\u30a4\u30f3\u30aa\u30f3\u8a8d\u8a3c\u3092\u8ffd\u52a0\u3059\u308b</li> <li>BTA5 - \u8907\u96d1\u306a\u30bf\u30b9\u30af\u3092\u51e6\u7406\u3059\u308b\u30a2\u30af\u30b7\u30e7\u30f3\u3092\u8ffd\u52a0\u3059\u308b</li> </ul>"},{"location":"includes/ja/discussions/","title":"Discussions","text":"Copilot Developer Camp \u306e\u30c7\u30a3\u30b9\u30ab\u30c3\u30b7\u30e7\u30f3\u3078\u3088\u3046\u3053\u305d\uff01 \ud83e\udd17 <p>\u81ea\u5df1\u7d39\u4ecb\u3092\u3057\u3066\u3001Copilot Developer Camp \u3067\u306e\u3054\u7d4c\u9a13\u3092\u304a\u805e\u304b\u305b\u304f\u3060\u3055\u3044 \ud83c\udfd5\ufe0f\u3002</p> \ud83c\udf89 \u65b0\u6a5f\u80fd Feature X\uff1a\u30a2\u30a4\u30c7\u30a2\u3068\u30d5\u30a3\u30fc\u30c9\u30d0\u30c3\u30af <p>\u3044\u304f\u3064\u304b\u306e\u30af\u30fc\u30eb\u306a\u30a2\u30c3\u30d7\u30c7\u30fc\u30c8\u3092\u691c\u8a0e\u4e2d\u3067\u3059\uff01 Feature X \u306b\u3064\u3044\u3066\u306e\u3054\u610f\u898b\u3092\u5171\u6709\u3057\u3001\u4e00\u7dd2\u306b\u30d6\u30ec\u30a4\u30f3\u30b9\u30c8\u30fc\u30df\u30f3\u30b0\u3057\u307e\u3057\u3087\u3046\uff01</p> \ud83d\ude80 \u30c8\u30e9\u30d6\u30eb\u30b7\u30e5\u30fc\u30c6\u30a3\u30f3\u30b0\u30ac\u30a4\u30c9\uff1a\u30d2\u30f3\u30c8\u3092\u5171\u6709\u3057\u307e\u3057\u3087\u3046 <p>\u3088\u304f\u3042\u308b\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7\u306e\u554f\u984c\u3092\u89e3\u6c7a\u3059\u308b\u30b3\u30c4\u306f\u3042\u308a\u307e\u3059\u304b\uff1f \u3042\u306a\u305f\u306e\u77e5\u8b58\u3092\u5171\u6709\u3057\u3066\u3001\u30b3\u30df\u30e5\u30cb\u30c6\u30a3\u3092\u76db\u308a\u4e0a\u3052\u307e\u3057\u3087\u3046\uff01</p> \u2728 \u3055\u3089\u306b\u30c7\u30a3\u30b9\u30ab\u30c3\u30b7\u30e7\u30f3\u3092\u898b\u308b"},{"location":"includes/ja/e-congratulations/","title":"E congratulations","text":"<p>\u304a\u3081\u3067\u3068\u3046\u3054\u3056\u3044\u307e\u3059\uff01</p>"},{"location":"includes/ja/e-labs-prelude/","title":"E labs prelude","text":"<p>Microsoft 365 \u304c AI \u30e2\u30c7\u30eb\u3068\u30aa\u30fc\u30b1\u30b9\u30c8\u30ec\u30fc\u30b7\u30e7\u30f3\u3092\u63d0\u4f9b\u3059\u308b\u5ba3\u8a00\u578b\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3092\u69cb\u7bc9\u3057\u305f\u3044\u5834\u5408\u306f\u3001\u3053\u308c\u3089\u306e\u30e9\u30dc\u3092\u5b9f\u65bd\u3057\u3066\u304f\u3060\u3055\u3044\u3002</p> <ul> <li>\ud83c\udfc1 \u306f\u3058\u3081\u306b</li> <li>\ud83d\udd27 \u30bb\u30c3\u30c8\u30a2\u30c3\u30d7 <ul> <li>\u30e9\u30dc E0 - \u30bb\u30c3\u30c8\u30a2\u30c3\u30d7</li> </ul> </li> <li>\ud83e\uddf0 \u5ba3\u8a00\u578b\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u306e\u57fa\u790e <ul> <li>\u30e9\u30dc E1 - \u8a73\u7d30\u306a\u5ba3\u8a00\u578b\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3092\u69cb\u7bc9\u3059\u308b </li> <li>\u30e9\u30dc E1a - Geo \u30ed\u30b1\u30fc\u30bf\u30fc\u30b2\u30fc\u30e0</li> </ul> </li> <li>\ud83d\udee0\ufe0f API \u3092\u30bc\u30ed\u304b\u3089\u69cb\u7bc9\u3057\u3066\u7d71\u5408\u3059\u308b <ul> <li>\u30e9\u30dc E2 - API \u3092\u69cb\u7bc9\u3059\u308b</li> <li>\u30e9\u30dc E3 - \u5ba3\u8a00\u578b\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8 + API \u3092\u8ffd\u52a0\u3059\u308b</li> <li>\u30e9\u30dc E4 - API + \u30d7\u30e9\u30b0\u30a4\u30f3\u3092\u5f37\u5316\u3059\u308b</li> <li>\u30e9\u30dc E5 - Adaptive Card \u3092\u8ffd\u52a0\u3059\u308b</li> </ul> </li> <li>\ud83d\udd10 \u8a8d\u8a3c <ul> <li>\u30e9\u30dc E6a - Toolkit</li> <li>\u30e9\u30dc E6b - \u624b\u52d5</li> <li>\u30e9\u30dc E6c - SSO</li> </ul> </li> <li>\ud83d\udd0c \u7d71\u5408 <ul> <li>\u30e9\u30dc EB - Graph Connector \u3092\u8ffd\u52a0\u3059\u308b</li> </ul> </li> </ul>"},{"location":"includes/ja/e-labs-toc/","title":"E labs toc","text":"<p>Microsoft 365 \u304c AI \u30e2\u30c7\u30eb\u3068\u30aa\u30fc\u30b1\u30b9\u30c8\u30ec\u30fc\u30b7\u30e7\u30f3\u3092\u63d0\u4f9b\u3059\u308b\u5ba3\u8a00\u578b\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3092\u69cb\u7bc9\u3057\u305f\u3044\u5834\u5408\u306f\u3001\u3053\u308c\u3089\u306e\u30e9\u30dc\u3092\u5b9f\u65bd\u3057\u3066\u304f\u3060\u3055\u3044\u3002</p> <ul> <li>\ud83c\udfc1 \u306f\u3058\u3081\u306b</li> <li>\ud83d\udd27 \u30bb\u30c3\u30c8\u30a2\u30c3\u30d7 <ul> <li>\u30e9\u30dc E0 - \u30bb\u30c3\u30c8\u30a2\u30c3\u30d7</li> </ul> </li> <li>\ud83e\uddf0 \u5ba3\u8a00\u578b\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u306e\u57fa\u790e <ul> <li>\u30e9\u30dc E1 - \u8a73\u7d30\u306a\u5ba3\u8a00\u578b\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3092\u69cb\u7bc9\u3059\u308b </li> <li>\u30e9\u30dc E1a - Geo \u30ed\u30b1\u30fc\u30bf\u30fc\u30b2\u30fc\u30e0</li> </ul> </li> <li>\ud83d\udee0\ufe0f API \u3092\u30bc\u30ed\u304b\u3089\u69cb\u7bc9\u3057\u3066\u7d71\u5408\u3059\u308b <ul> <li>\u30e9\u30dc E2 - API \u3092\u69cb\u7bc9\u3059\u308b</li> <li>\u30e9\u30dc E3 - \u5ba3\u8a00\u578b\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8 + API \u3092\u8ffd\u52a0\u3059\u308b</li> <li>\u30e9\u30dc E4 - API + \u30d7\u30e9\u30b0\u30a4\u30f3\u3092\u5f37\u5316\u3059\u308b</li> <li>\u30e9\u30dc E5 - Adaptive Card \u3092\u8ffd\u52a0\u3059\u308b</li> </ul> </li> <li>\ud83d\udd10 \u8a8d\u8a3c <ul> <li>\u30e9\u30dc E6a - Toolkit</li> <li>\u30e9\u30dc E6b - \u624b\u52d5</li> <li>\u30e9\u30dc E6c - SSO</li> </ul> </li> <li>\ud83d\udd0c \u7d71\u5408 <ul> <li>\u30e9\u30dc EB - Graph Connector \u3092\u8ffd\u52a0\u3059\u308b</li> </ul> </li> </ul>"},{"location":"includes/ja/m-labs-branches/","title":"M labs branches","text":"Copilot Studio Lite      <ul> <li>\u7c21\u5358\u3067\u30b7\u30f3\u30d7\u30eb\u3001\u304b\u3064\u30a4\u30f3\u30bf\u30e9\u30af\u30c6\u30a3\u30d6\u306a\u64cd\u4f5c\u6027</li> <li>Web \u30d9\u30fc\u30b9\u3067\u3001Microsoft 365 Copilot Chat \u3068 Microsoft 365 Copilot \u306b\u7d71\u5408</li> <li>SharePoint Online\u3001\u30d1\u30d6\u30ea\u30c3\u30af Web\u3001\u304a\u3088\u3073 Microsoft Copilot Connectors \u304b\u3089\u306e\u30b3\u30f3\u30c6\u30f3\u30c4</li> <li>Microsoft 365 Copilot Chat \u3067\u5229\u7528\u53ef\u80fd</li> <ul> \u3053\u3053\u304b\u3089\u958b\u59cb  Microsoft Copilot Studio              <ul> <li>\u6700\u5927\u9650\u306e\u67d4\u8edf\u6027</li> <li>\u307b\u307c\u3059\u3079\u3066\u306e\u30c7\u30fc\u30bf \u30bd\u30fc\u30b9\u307e\u305f\u306f\u30ca\u30ec\u30c3\u30b8 \u30d9\u30fc\u30b9\u306b\u5bfe\u5fdc</li> <li>\u3055\u307e\u3056\u307e\u306a\u516c\u958b\u30c1\u30e3\u30cd\u30eb\u3092\u30b5\u30dd\u30fc\u30c8</li> <li>\u30a2\u30af\u30b7\u30e7\u30f3\u3092\u30b5\u30dd\u30fc\u30c8</li> <li>Power Platform \u30b3\u30cd\u30af\u30bf\u30fc\u3001Dataverse\u3001REST API \u306a\u3069\u3092\u30b5\u30dd\u30fc\u30c8</li> <li>\u30e6\u30fc\u30b6\u30fc\u5358\u4f4d + \u30c6\u30ca\u30f3\u30c8\u5358\u4f4d\u306e\u30e9\u30a4\u30bb\u30f3\u30b9\u3001\u307e\u305f\u306f\u5f93\u91cf\u8ab2\u91d1 (Pay-As-You-Go)</li> <ul> \u3053\u3053\u304b\u3089\u958b\u59cb  SharePoint \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8              <ul> <li>SharePoint Online \u306e\u30e6\u30fc\u30b6\u30fc \u30a8\u30af\u30b9\u30da\u30ea\u30a8\u30f3\u30b9\u306b\u7d71\u5408</li> <li>SharePoint Online \u306e\u30b3\u30f3\u30c6\u30f3\u30c4\u306e\u307f</li> <li>Microsoft Teams \u306e\u30c1\u30e3\u30c3\u30c8\u3067\u30b5\u30dd\u30fc\u30c8</li> <li>Microsoft 365 Copilot \u30e9\u30a4\u30bb\u30f3\u30b9\u3001Microsoft Copilot Studio \u30ad\u30e3\u30d1\u30b7\u30c6\u30a3\u3001\u307e\u305f\u306f\u5f93\u91cf\u8ab2\u91d1 (Pay-As-You-Go)</li> <ul> \u3053\u3053\u304b\u3089\u958b\u59cb"},{"location":"includes/ja/m-path-links/","title":"M path links","text":"<ul> <li>\u30e9\u30dc M0 - \u524d\u63d0\u6761\u4ef6 READY FOR TESTING</li> <li>\u30e9\u30dc M1 - Northwind \u30e1\u30c3\u30bb\u30fc\u30b8\u62e1\u5f35\u6a5f\u80fd\u3092\u7406\u89e3\u3059\u308b READY FOR TESTING</li> <li>\u30e9\u30dc M2 - Microsoft 365 Copilot \u3067\u30a2\u30d7\u30ea\u3092\u5b9f\u884c\u3059\u308b READY FOR TESTINGSOON</li> <li>\u30e9\u30dc M3 - \u65b0\u3057\u3044\u691c\u7d22\u30b3\u30de\u30f3\u30c9\u3067\u30d7\u30e9\u30b0\u30a4\u30f3\u3092\u5f37\u5316\u3059\u308b READY FOR TESTING</li> <li>\u30e9\u30dc M4 - \u8a8d\u8a3c\u3092\u8ffd\u52a0\u3059\u308b READY FOR TESTING</li> <li>\u30e9\u30dc M5 - \u30a2\u30af\u30b7\u30e7\u30f3 \u30b3\u30de\u30f3\u30c9\u3067\u30d7\u30e9\u30b0\u30a4\u30f3\u3092\u5f37\u5316\u3059\u308b COMING SOON</li> </ul>"},{"location":"includes/ja/mab-congratulations/","title":"Mab congratulations","text":"<p>\u304a\u3081\u3067\u3068\u3046\u3054\u3056\u3044\u307e\u3059\uff01</p>"},{"location":"includes/ja/mab-labs-prelude/","title":"Mab labs prelude","text":"<p>Copilot Studio Lite \u3067\u5ba3\u8a00\u578b\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3092\u69cb\u7bc9\u3057\u305f\u3044\u5834\u5408\u306f\u3001\u6b21\u306e\u30e9\u30dc\u3092\u5b9f\u65bd\u3057\u3066\u304f\u3060\u3055\u3044\u3002</p> <ul> <li>MAB1 - \u6700\u521d\u306e\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3092\u69cb\u7bc9\u3059\u308b</li> </ul> \u76ee\u6b21"},{"location":"includes/ja/mab-labs-toc/","title":"Mab labs toc","text":"<p>Copilot Studio Lite \u3067\u5ba3\u8a00\u578b\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3092\u69cb\u7bc9\u3057\u305f\u3044\u5834\u5408\u306f\u3001\u6b21\u306e\u30e9\u30dc\u3092\u5b9f\u65bd\u3057\u3066\u304f\u3060\u3055\u3044\u3002</p> <ul> <li>MAB1 - \u6700\u521d\u306e\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3092\u69cb\u7bc9\u3059\u308b</li> </ul>"},{"location":"includes/ja/main-links/","title":"Main links","text":"\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u306e\u4f5c\u6210      <p>Copilot Studio \u307e\u305f\u306f SharePoint Online \u3092\u4f7f\u7528\u3057\u3001\u30ce\u30fc\u30b3\u30fc\u30c9\u307e\u305f\u306f\u30ed\u30fc\u30b3\u30fc\u30c9\u3067\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3092\u4f5c\u6210\u3057\u307e\u3059\uff08\u300cMAB\u300d\u300cMSA\u300d\u300cMCS\u300d\u30e9\u30dc\uff09\u3002</p> \u958b\u59cb\u3059\u308b        M365 Copilot \u306e\u62e1\u5f35      <p>Microsoft 365 \u304c AI \u30e2\u30c7\u30eb\u3068\u30aa\u30fc\u30b1\u30b9\u30c8\u30ec\u30fc\u30b7\u30e7\u30f3\u3092\u63d0\u4f9b\u3059\u308b Declarative \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3092\u69cb\u7bc9\u3057\u307e\u3059\uff08\u300cE\u300d\u30e9\u30dc\uff09\u3002</p> \u958b\u59cb\u3059\u308b        \u72ec\u81ea\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u306e\u69cb\u7bc9      <p>Azure OpenAI \u3092\u4f7f\u7528\u3057\u3066\u3001\u30ab\u30b9\u30bf\u30e0 AI \u30e2\u30c7\u30eb\u3068\u30aa\u30fc\u30b1\u30b9\u30c8\u30ec\u30fc\u30b7\u30e7\u30f3\u3067\u30ab\u30b9\u30bf\u30e0 \u30a8\u30f3\u30b8\u30f3\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3092\u69cb\u7bc9\u3057\u307e\u3059\uff08\u300cBMA\u300d\u30e9\u30dc\uff09\u3002</p> \u958b\u59cb\u3059\u308b"},{"location":"includes/ja/mcs-congratulations/","title":"Mcs congratulations","text":"<p>\u304a\u3081\u3067\u3068\u3046\u3054\u3056\u3044\u307e\u3059\uff01</p>"},{"location":"includes/ja/mcs-labs-prelude/","title":"Mcs labs prelude","text":"<p>Microsoft Copilot Studio \u3067 \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3092\u69cb\u7bc9\u3057\u305f\u3044\u5834\u5408\u306f\u3001\u3053\u308c\u3089\u306e \u30e9\u30dc \u3092\u5b9f\u65bd\u3057\u3066\u304f\u3060\u3055\u3044</p> <ul> <li>MCS0 - \u30bb\u30c3\u30c8\u30a2\u30c3\u30d7</li> <li>MCS1 - \u6700\u521d\u306e \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8</li> <li>MCS2 - \u30c8\u30d4\u30c3\u30af\u306e\u5b9a\u7fa9</li> <li>MCS3 - \u30c4\u30fc\u30eb\u306e\u5b9a\u7fa9</li> <li>MCS4 - Microsoft 365 Copilot \u3092\u62e1\u5f35\u3059\u308b</li> <li>MCS5 - \u30ab\u30b9\u30bf\u30e0 \u30b3\u30cd\u30af\u30bf\u306e\u5229\u7528</li> <li>MCS6 - MCP \u30b5\u30fc\u30d0\u30fc\u306e\u5229\u7528</li> <li>MCS7 - \u81ea\u5f8b\u578b \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u306e\u4f5c\u6210</li> <li>MCS8 - RAG \u306e\u305f\u3081\u306e Azure AI Search \u7d71\u5408</li> </ul>"},{"location":"includes/ja/mcs-labs-toc/","title":"Mcs labs toc","text":"<p>Microsoft Copilot Studio \u3067 \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3092\u69cb\u7bc9\u3057\u305f\u3044\u5834\u5408\u306f\u3001\u3053\u308c\u3089\u306e \u30e9\u30dc \u3092\u5b9f\u65bd\u3057\u3066\u304f\u3060\u3055\u3044</p> <ul> <li>MCS0 - \u30bb\u30c3\u30c8\u30a2\u30c3\u30d7</li> <li>MCS1 - \u6700\u521d\u306e \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8</li> <li>MCS2 - \u30c8\u30d4\u30c3\u30af\u306e\u5b9a\u7fa9</li> <li>MCS3 - \u30c4\u30fc\u30eb\u306e\u5b9a\u7fa9</li> <li>MCS4 - Microsoft 365 Copilot \u3092\u62e1\u5f35\u3059\u308b</li> <li>MCS5 - \u30ab\u30b9\u30bf\u30e0 \u30b3\u30cd\u30af\u30bf\u306e\u5229\u7528</li> <li>MCS6 - MCP \u30b5\u30fc\u30d0\u30fc\u306e\u5229\u7528</li> <li>MCS7 - \u81ea\u5f8b\u578b \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u306e\u4f5c\u6210</li> <li>MCS8 - RAG \u306e\u305f\u3081\u306e Azure AI Search \u7d71\u5408</li> </ul>"},{"location":"includes/ja/more-links/","title":"More links","text":"\u8a73\u7d30\u60c5\u5831      <p>\u3055\u307e\u3056\u307e\u306a\u30ea\u30bd\u30fc\u30b9\u304b\u3089\u8a73\u7d30\u3092\u5b66\u3073\u307e\u3057\u3087\u3046\u3002</p> <ul> <li>Microsoft Learn</li> <li>\u30d3\u30c7\u30aa \u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb</li> </ul>        \u30b3\u30df\u30e5\u30cb\u30c6\u30a3\u3068\u3064\u306a\u304c\u308b      <p>GitHub Discussion \u3067\u306e\u4f1a\u8a71\u306b\u53c2\u52a0\u3057\u307e\u3057\u3087\u3046!</p>"},{"location":"includes/ja/msa-congratulations/","title":"Msa congratulations","text":"<p>\u304a\u3081\u3067\u3068\u3046\u3054\u3056\u3044\u307e\u3059!</p>"},{"location":"includes/ja/msa-labs-prelude/","title":"Msa labs prelude","text":"<p>SharePoint \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8 \u3092\u69cb\u7bc9\u3057\u305f\u3044\u5834\u5408\u306f\u3001\u6b21\u306e \u30e9\u30dc \u3092\u5b9f\u65bd\u3057\u3066\u304f\u3060\u3055\u3044\u3002</p> <ul> <li>MSA1 - \u521d\u3081\u3066\u306e SharePoint \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8 \u3092\u69cb\u7bc9\u3059\u308b</li> <li>MSA2 - SharePoint \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8 \u3092\u5171\u6709\u3059\u308b</li> </ul> \u76ee\u6b21"},{"location":"includes/ja/msa-labs-toc/","title":"Msa labs toc","text":"<p>SharePoint \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8 \u3092\u69cb\u7bc9\u3057\u305f\u3044\u5834\u5408\u306f\u3001\u6b21\u306e \u30e9\u30dc \u3092\u5b9f\u65bd\u3057\u3066\u304f\u3060\u3055\u3044\u3002</p> <ul> <li>MSA1 - \u521d\u3081\u3066\u306e SharePoint \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8 \u3092\u69cb\u7bc9\u3059\u308b</li> <li>MSA2 - SharePoint \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8 \u3092\u5171\u6709\u3059\u308b</li> </ul>"},{"location":"includes/ja/starrepo/","title":"Starrepo","text":"<p>\u2b50\ufe0f \u30ea\u30dd\u30b8\u30c8\u30ea\u306b\u30b9\u30bf\u30fc\u3092\u4ed8\u3051\u308b</p>"},{"location":"javascripts/card-usage/","title":"Card Component Demo","text":"<p>This page demonstrates how to use the <code>cc-card</code> web component.</p>"},{"location":"javascripts/card-usage/#individual-cards","title":"Individual Cards","text":""},{"location":"javascripts/card-usage/#basic-card","title":"Basic Card","text":"<pre><code>&lt;cc-card \n    title=\"Getting Started\" \n    description=\"Learn the basics of AI prompting and get started with your first copilot instructions.\"\n    href=\"/pages/copilot-instructions/getting-started\"&gt;\n&lt;/cc-card&gt;\n</code></pre>"},{"location":"javascripts/card-usage/#card-with-image","title":"Card with Image","text":"<pre><code>&lt;cc-card \n    title=\"Advanced Techniques\" \n    description=\"Master advanced prompting techniques and learn to create sophisticated AI agents.\"\n    href=\"/pages/copilot-instructions/advanced\"\n    image=\"/assets/images/advanced-techniques.png\"&gt;\n&lt;/cc-card&gt;\n</code></pre>"},{"location":"javascripts/card-usage/#card-with-external-link","title":"Card with External Link","text":"<pre><code>&lt;cc-card \n    title=\"GitHub Repository\" \n    description=\"Explore the source code and contribute to the Copilot Camp project.\"\n    href=\"https://github.com/microsoft/copilot-camp\"\n    target=\"_blank\"&gt;\n&lt;/cc-card&gt;\n</code></pre>"},{"location":"javascripts/card-usage/#card-grid","title":"Card Grid","text":"<p>Use the <code>cc-card-grid</code> component to create a responsive grid of cards:</p> <pre><code>&lt;cc-card-grid columns=\"3\" gap=\"1.5rem\"&gt;\n    &lt;cc-card \n        title=\"Fundamentals\" \n        description=\"Start with the basics of AI prompting.\"\n        href=\"/fundamentals\"&gt;\n    &lt;/cc-card&gt;\n    &lt;cc-card \n        title=\"Best Practices\" \n        description=\"Learn industry best practices for AI development.\"\n        href=\"/best-practices\"&gt;\n    &lt;/cc-card&gt;\n    &lt;cc-card \n        title=\"Advanced Topics\" \n        description=\"Dive deep into advanced AI concepts.\"\n        href=\"/advanced\"&gt;\n    &lt;/cc-card&gt;\n&lt;/cc-card-grid&gt;\n</code></pre> <p> </p>"},{"location":"javascripts/card-usage/#auto-fit-grid","title":"Auto-fit Grid","text":"<p>The grid automatically adjusts to fit the available space:</p> <pre><code>&lt;cc-card-grid gap=\"1rem\"&gt;\n    &lt;cc-card title=\"Card 1\" description=\"This is the first card\" href=\"#1\"&gt;&lt;/cc-card&gt;\n    &lt;cc-card title=\"Card 2\" description=\"This is the second card\" href=\"#2\"&gt;&lt;/cc-card&gt;\n    &lt;cc-card title=\"Card 3\" description=\"This is the third card\" href=\"#3\"&gt;&lt;/cc-card&gt;\n    &lt;cc-card title=\"Card 4\" description=\"This is the fourth card\" href=\"#4\"&gt;&lt;/cc-card&gt;\n    &lt;cc-card title=\"Card 5\" description=\"This is the fifth card\" href=\"#5\"&gt;&lt;/cc-card&gt;\n&lt;/cc-card-grid&gt;\n</code></pre> <p> </p>"},{"location":"javascripts/card-usage/#component-attributes","title":"Component Attributes","text":""},{"location":"javascripts/card-usage/#cc-card","title":"cc-card","text":"Attribute Type Description Default <code>title</code> string The card title \"Card Title\" <code>description</code> string The card description \"Card description\" <code>href</code> string The link destination \"#\" <code>image</code> string Optional image URL none <code>target</code> string Link target (_blank, _self, etc.) \"_self\" <code>class</code> string Additional CSS classes \"\""},{"location":"javascripts/card-usage/#cc-card-grid","title":"cc-card-grid","text":"Attribute Type Description Default <code>columns</code> number Number of columns auto-fit <code>gap</code> string Grid gap (CSS units) \"1rem\""},{"location":"javascripts/card-usage/#javascript-api","title":"JavaScript API","text":"<p>You can also update cards dynamically:</p> <pre><code>// Get a card element\nconst card = document.querySelector('cc-card');\n\n// Update its properties\ncard.updateCard({\n    title: 'New Title',\n    description: 'New description',\n    href: '/new-url',\n    image: '/new-image.png'\n});\n</code></pre>"},{"location":"javascripts/card-usage/#features","title":"Features","text":"<ul> <li>Responsive: Cards automatically adjust to different screen sizes</li> <li>Accessible: Full keyboard navigation and screen reader support</li> <li>Customizable: Support for images, external links, and custom styling</li> <li>Interactive: Hover effects and visual feedback</li> <li>Grid Layout: Flexible grid system for organizing multiple cards</li> <li>Dark Mode: Automatic dark mode support</li> </ul>"},{"location":"pages/test/","title":"Lab T1 - Test Bob's new Web Controls","text":"<p>In this lab, you, the Copilot Developer Camp content developer, will learn how to use custom web controls to provide an enhanced user experience.</p> <p>Where did I leave off?</p> <p></p> <p>Table of Contents</p> <p></p>"},{"location":"pages/test/#exercise-1-learn-the-controls","title":"Exercise 1: Learn the controls","text":"<p>In this exercise, you'll learn how to use the <code>&lt;cc-end-step&gt;</code> web control, which allows users to log their process at the end of each step.</p>"},{"location":"pages/test/#step-1-write-the-markup","title":"Step 1: Write the markup","text":"<p>Each step must begin with a 3rd level header (\"###\") that includes the name of the step. Then insert the <code>&lt;cc-end-step&gt;</code> control at the end of the step.</p> <p>For example,</p> <pre><code>### Step 1: Write the markup\n\n... (all the instructions go here)\n\n&lt;cc-end-step lab=\"t1\" exercise=\"1\" step=\"1\" /&gt;\n</code></pre> <p>The control needs your lab, exercise, and step so it can store the checkbox state uniquely across page refreshes.</p> <p>For a Table of Contents, use</p> <pre><code>!!! abstract \"Table of Contents\"\n    &lt;cc-table-of-contents /&gt;\n</code></pre> <p>To show the most recent step completed use</p> <pre><code>!!! abstract \"Where did I leave off?\"\n    &lt;cc-last-completed-step /&gt;\n</code></pre> <p>Notice the checkbox at the bottom of each step. When users check it, several things happen:</p> <ul> <li>A check mark is added to the step heading</li> <li>A check mark is added to the step in the Table of Contents</li> <li>The \"where did I leave off\" message at the top of the lab, if present, is updated</li> <li>An encouraging message is added below the checkbox</li> <li>Telemetry logs the completion (anonymously)</li> </ul> <p>Try it out now!</p> <p></p>"},{"location":"pages/test/#step-2-make-sure-your-h2-and-h3-elements-are-in-order","title":"Step 2: Make sure your h2 and h3 elements are in order","text":"<p>The controls are poking around in the DOM, and they depend on you having:</p> <ul> <li>an h2 (##) for each exercise beginning with the word \"Exercise\"</li> <li>an h3 (###) for each step </li> <li>at least one step in each exercise</li> <li>the last thing in the step is the <code>&lt;cc-end-step /&gt;</code></li> </ul> <p></p>"},{"location":"pages/test/#step-3-test-the-links","title":"Step 3: Test the links","text":"<p>Now, with some checkboxes checked, notice that the \"Where did I leave off\" message is now a hyperlink that brings you directly to the end of the last step that you completed.</p> <p>The links in the Table of Contents, on the other hand, bring you to the beginning of each step.</p> <p></p>"},{"location":"pages/test/#step-4-how-does-it-work","title":"Step 4: How does it work?","text":"<p>These are written using standard web components. Checkbox state is kept in local storage so it will persist across lab sessions so long as the user returns with the same browser and profile, the checkboxes will be as they left them. If you're curious, here is the code.</p> <p></p>"},{"location":"pages/test/#exercise-2-give-feedback","title":"Exercise 2: Give feedback","text":""},{"location":"pages/test/#step-1-do-you-like-it","title":"Step 1: Do you like it?","text":"<p>Is it useful? Whow could it be improved?</p> <p></p>"},{"location":"pages/test/#step-2-long-steps-are-no-problem","title":"Step 2: Long steps are no problem","text":"<p>In the initial implementation a single checkbox was placed in the heading for each step. If a step is really long like this one, people might not scroll back up to the top to check it off. So I moved the checkboxes to the bottom. Please scroll past all the fake Latin and check it out!</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nam quis nulla elit. Sed tortor turpis, mollis non pretium a, consectetur at augue. Fusce eu mi in sem imperdiet accumsan. Phasellus ullamcorper magna vel tincidunt dapibus. Pellentesque congue commodo finibus. Morbi scelerisque porta velit dictum tincidunt. Suspendisse potenti. Ut a mi suscipit, varius tellus id, luctus nisi. Aenean nec magna vel tortor fermentum laoreet. Praesent mattis hendrerit arcu nec rutrum. Maecenas sit amet sagittis ex, id interdum eros. Donec euismod a nisi nec efficitur. Cras sit amet massa elementum augue efficitur maximus non sed neque. Maecenas sit amet fringilla risus. Pellentesque habitant morbi tristique senectus et netus et malesuada fames ac turpis egestas.</p> <p>Ut ultrices sem dui, eu posuere orci fermentum commodo. Nam elementum ac est sit amet feugiat. Integer eget erat pharetra, tempus sem vel, consectetur arcu. Etiam vulputate porta tellus ac viverra. Mauris id aliquam mauris, sit amet rutrum lacus. Vivamus tincidunt in massa vitae varius. Donec luctus nunc eget sodales ultricies. Curabitur molestie, urna ac sodales efficitur, ipsum odio condimentum nisl, quis imperdiet erat velit ut orci. Nunc fermentum mi nec sapien pellentesque iaculis.</p> <p>Praesent iaculis feugiat justo, at rutrum turpis venenatis eu. Phasellus tempus tincidunt purus, non semper nisi gravida id. Quisque tempor urna vitae malesuada ultrices. Nulla elit ipsum, rhoncus tempor ligula vel, aliquam commodo diam. Maecenas tristique ullamcorper blandit. Vivamus in congue tortor, rhoncus faucibus nisl. Curabitur non est justo. Fusce vitae tincidunt purus. Duis malesuada leo tellus, nec faucibus neque vehicula at. Morbi nisl risus, congue a finibus in, venenatis eget augue. Nulla tempor eu nibh id imperdiet. Maecenas scelerisque posuere nibh in dapibus. Maecenas aliquam ornare magna sed pulvinar. Aenean vel placerat elit. Nunc faucibus imperdiet fringilla. In sit amet ipsum lectus.</p> <p>Morbi in congue sem. Duis suscipit enim eu erat congue, a dapibus tortor fringilla. Cras at purus gravida leo condimentum molestie id ut sapien. Morbi in eros a magna finibus efficitur quis ac lacus. Curabitur vitae elit et felis iaculis convallis a quis sem. Vivamus sit amet sollicitudin metus, ut pulvinar ex. Nunc justo lacus, eleifend ac semper quis, condimentum a quam. Nunc sagittis urna erat, nec rhoncus urna pulvinar id. Integer fermentum fermentum sollicitudin. Mauris et vestibulum massa, at eleifend tortor. Nulla vehicula eu odio ut semper. Cras et nibh lacus. Duis in magna sit amet nunc finibus faucibus vel ut eros. Cras ullamcorper efficitur velit eu fermentum.</p> <p>Proin eget vulputate lectus. Vestibulum sit amet bibendum nisl, vel interdum odio. Sed sed odio lectus. Ut et magna vitae risus imperdiet posuere. Phasellus enim velit, tempor sed consectetur in, cursus id velit. Vestibulum sed lobortis purus. Sed libero nisi, vulputate sed nulla in, fermentum imperdiet odio. Vestibulum pellentesque blandit congue. In venenatis euismod tortor, nec sagittis ante placerat eget. Sed at nunc nunc. Curabitur consequat elit ut hendrerit vestibulum. Ut maximus laoreet condimentum. Suspendisse eget sem neque. Cras in lorem facilisis, rutrum quam vel, dictum justo.</p> <p>Integer interdum mollis nulla at blandit. Interdum et malesuada fames ac ante ipsum primis in faucibus. Vivamus aliquam commodo aliquam. Maecenas rhoncus nisl vel purus sodales, id vestibulum eros viverra. Donec vehicula semper urna. In auctor consectetur libero quis eleifend. Etiam a tellus sed metus suscipit blandit non at neque. Suspendisse placerat semper est eu commodo. Nam nunc augue, cursus nec commodo in, elementum at lacus. Duis est arcu, cursus ac rhoncus sed, hendrerit in odio. Duis congue nisi faucibus ipsum convallis, eu dapibus ante rhoncus. Suspendisse eu eros et ligula ultrices tincidunt.</p> <p>Sed blandit, felis vel auctor pharetra, nibh tellus mollis nisi, ac feugiat nisl nunc et urna. Nunc magna tortor, lobortis eu congue eget, pulvinar sit amet dolor. Sed nec mattis ante. Maecenas convallis tristique lacinia. Suspendisse non tellus quis lorem sodales finibus. Curabitur rutrum vel odio at viverra. Morbi maximus nibh sit amet nisl pellentesque bibendum. Pellentesque ultricies ex ante, at hendrerit magna posuere sed.</p> <p>Proin luctus faucibus posuere. In malesuada hendrerit arcu, et mattis ante maximus ac. Phasellus dictum nibh ac neque rutrum ultrices. Nullam sed aliquam enim. Nullam nisl erat, interdum a porta eget, congue in nisl. Nullam ligula elit, ornare eget nisl eu, aliquet semper metus. Mauris pulvinar justo sem. Fusce nec ullamcorper urna. Cras eget metus eget lectus volutpat aliquet non pharetra massa. In vitae nisi arcu.</p> <p>Sed sit amet convallis massa, vehicula auctor justo. Aliquam ultricies porttitor nulla eu lobortis. Vestibulum viverra, risus nec dapibus venenatis, eros neque bibendum augue, sit amet faucibus arcu mauris eget quam. Quisque sed mollis tellus, ac tempus elit. Sed orci lorem, tincidunt vitae egestas iaculis, finibus non sem. Curabitur quis semper est, sed tempus risus. Duis dictum lorem vulputate felis convallis, commodo sagittis diam condimentum. Curabitur vitae erat nibh. Mauris vulputate maximus libero id dignissim. Quisque viverra ante tellus, id sollicitudin elit interdum quis.</p> <p>Nunc massa velit, gravida a nunc in, efficitur viverra sapien. Sed viverra ullamcorper hendrerit. Quisque cursus felis tortor, ut facilisis lectus volutpat vel. Sed scelerisque auctor tempor. Duis ante diam, pretium vitae rhoncus id, mollis vitae lorem. Mauris pretium lorem sem, sit amet iaculis sem ullamcorper ac. Fusce vel arcu aliquet, vulputate leo at, aliquet massa. Ut at imperdiet eros. Mauris gravida mi rutrum mi egestas, sit amet varius tellus pellentesque. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Integer varius nunc in arcu posuere, suscipit fringilla erat commodo. Aenean vitae nisi non felis semper commodo. Donec eget neque ornare, lobortis augue nec, pharetra est. Sed accumsan semper diam, eget pharetra mauris feugiat id. Pellentesque ac velit vitae purus sollicitudin dapibus. Mauris posuere interdum nisi sed pellentesque.</p> <p></p>"},{"location":"pages/test/#step-3-thank-you","title":"Step 3: Thank you!","text":"<p>Thanks for testing the Copilot Developer Camp web controls!</p> <p></p>"},{"location":"pages/updating-the-schema/","title":"Updating the Manifest schema","text":"<p>If you began any of the \"Extend\" path labs prior to October 27, 2024, you may be using a developer preview schema. A new, supported schema, v1.19, is now available and all preview applications need to update. The new schema also reflects the new Copilot agent naming.</p> <p>To update your project, open the appPackage/manifest.json file.</p> <p>First, replace the first two lines with these:</p> <pre><code>  \"$schema\": \"https://developer.microsoft.com/json-schemas/teams/v1.19/MicrosoftTeams.schema.json\",\n  \"manifestVersion\": \"1.19\",\n</code></pre> <p>If you see a <code>packageName</code> property like this one in your manifest.json file, remove it as it is no longer necessary or supported.</p> <pre><code>  \"packageName\": \"com.microsoft.teams.extension\",\n</code></pre> <p>Then replace the <code>copilotExtensions</code> property with this:</p> <pre><code>  \"copilotAgents\": {\n    \"declarativeAgents\": [\n      {\n        \"id\": \"treygenie\",\n        \"file\": \"trey-declarative-agent.json\"\n      }\n    ]   \n  }, \n</code></pre> <p>Finally, rename trey-declarative-copilot.json to trey-declarative-agent.json to match the lab instructions.</p>"},{"location":"pages/beyond-agents/","title":"Introduction","text":""},{"location":"pages/beyond-agents/#get-started","title":"Get started","text":"<p>Dive into the world of AI concepts and techniques to broaden your understanding beyond agent development.</p> <p> </p>"},{"location":"pages/beyond-agents/#featured-agent-prompts","title":"Featured agent prompts","text":""},{"location":"pages/beyond-agents/beginner-agent/","title":"Agent Instruction Lab - Improve your agent instructions (Beginner friendly)","text":"<p>What you will do:</p> <ul> <li>Identify the Problem: Pinpoint the specific issue your agent will address </li> <li>Build a Basic Agent: Start with a simple prompt to get your agent up and running. </li> <li>Define the Agent's Role: Improve your agents focus with a role assigned </li> <li>Outline Execution Steps: Break down the process into clear, manageable subtasks. </li> <li>Set Response Guidelines: Influence the agent\u2019s response with clear instructions </li> <li>Give example conversations: Provide examples to improve consistency in agent\u2019s response </li> </ul> <p>This lab will guide you with suggestions to help refine your agent instructions approach drawing from techniques we have experimented over time. These practices have generally contributed to enhancing our agent's behaviour and consistency. </p> Prerequisites <ul> <li>Access to Copilot either using Teams, Microsoft 356 chat or Copilot chat</li> <li>A tool to iteratively test and update your agent either Microsoft 365 Agents Toolkit or Agent builder or Copilot Studio  (This lab uses Agents Toolkit, but you can also test it in Agent builder or even Copilot Studio)</li> </ul>"},{"location":"pages/beyond-agents/beginner-agent/#introduction","title":"Introduction","text":"<p>Declarative agents are personalised Copilots that you can use to create a more contextual and tailored expereince for your specific needs. They are developed by providing instructions, knowledge and skills. In this lab we will focus on the instructions part of the agent. If you need to learn more about knowledge and skills head to our labs that deep dives into those features. </p> <p>In this lab we will create a Declarative Agent called ShowExpert which is a <code>Generative Recommendation agent</code>. Such Generative Recommendation agents are designed to enhance decision-making, improve customer experiences, and streamline operations. Here, we will build an agent that provides tailored recommendations for shows in the online streaming platforms.  While our \"ShowExpert\" agent helps users quickly decide what to watch, the same principles provide significant enterprise value through their ability to streamline operations and enhance decision-making processes. These systems unlock competitive advantages across multiple dimensions: </p> <ul> <li>Enhanced decision quality by synthesising insights from vast datasets and surfacing hidden patterns </li> <li>Operational efficiency through automation of complex information analysis </li> <li>Personalisation at scale with real-time adaptation to changing preferences </li> <li>Knowledge democratization by providing domain expertise to everyone  </li> </ul> <p>We start with a simple prompt and iteratively try and improve the instructions. Evaluating the agent's behaviour at every iteration of instructions is crucial. We will conduct iterative cycles to refine the instructions until we achieve a somewhat consistent behaviour from the agent. </p> <p></p>"},{"location":"pages/beyond-agents/beginner-agent/#step-1-identify-the-problem-for-agent","title":"Step 1: Identify the Problem for Agent","text":"<p>Problem: There are findings, stating that an average person spends approximately 110 hours annually scrolling through menus of various online streaming platforms for shows. When considered in context, this means people spend an entire working week per year just checking various streaming apps without interruptions. </p> <p>Solution: Consider implementing a Copilot agent that can streamline decision-making processes. Let\u2019s call it the ShowExpert. </p> <p>Goal: It helps to already have an end goal in mind for the ShowExpert. It should be interactive, friendly, will ask for preferences, and give me detailed information about the shows it recommends and why it thinks I should watch it. Just like a friend. </p> <p></p>"},{"location":"pages/beyond-agents/beginner-agent/#step-2-build-a-first-basic-agent-declarative-agent","title":"Step 2: Build a first Basic Agent (Declarative Agent)","text":"<p>The first step is to think of an initial prompt for this agent given as its instruction. Our examination of the community's prompting techniques, facilitated by the Copilot Prompt Library, has revealed that most people start with single line prompts.  </p> <p>So, let's start off with the basic prompt below:</p> <pre><code>You are an agent to help user with recommendation for shows that are streaming on online streaming platforms \n</code></pre> <p>Now to build ShowExpert, you can use any tool of your choice like Agents Toolkit, Agent Builder or Copilot Studio. In this lab we have used Agents Toolkit. Check out our prerequisites lab to understand how to set up your environment for testing using Agents Toolkit. </p>"},{"location":"pages/beyond-agents/beginner-agent/#declarative-agent-using-agents-toolkit","title":"Declarative agent using Agents Toolkit","text":"About this step <p>This step in the lab assumes you have installed Agents Toolkit for Visual Studio Code and is going to use this extension to create a declarative agent. If you are going to use Agent Builder or Copilot Studio, these steps won\u2019t be needed. Use the tool of your choice and paste instructions in the\u202f<code>Instructions</code>\u202fcolumn instead and test it out. Here is a lab that shows you below steps to create a declarative agent in detail.</p> <ul> <li>Go to the Agents Toolkit extension in your Visual Studio Code editor and select Create a New App</li> <li>A panel opens up where you need to select Declarative Agent from the list of project types.</li> <li>Select No Action next</li> <li>Choose the project root folder for your agent project</li> <li>Give an application name like : \"ShowExpert\" and enter</li> <li>A VS code window will open up with your agent project scaffolded.</li> <li>Expand appPackage folder. This is you will work to update your agent. </li> <li>(Optional) Replace the color.png with an icon of your choice with 192x192 size. Here is an example file.</li> <li>Go to file declarativeAgent.json and locate description object. This is where you will set your persona for your agent for Copilot. Paste a simple description like <code>Recommendation agent for online streaming platforms' shows</code> for now. </li> <li>In the same file declarativeAgent.json, after the instructions object, add the capability for your agent to use websearch by appending below code after a comma. </li> </ul> <pre><code> \"capabilities\": [\n        {\n\n            \"name\": \"WebSearch\"\n\n        }\n    ]\n</code></pre> <ul> <li>Go to instruction.txt file and replace the placeholder instruction with our basic prompt <code>You are an agent to help user with recommendation for shows that are streaming on online streaming platforms</code></li> </ul> <p>Now you are ready to test the basic prompt.</p> <ul> <li>Go to the Agents Toolkit extension in your Visual Studio Code editor and select Provision under LifeCycle. This step will sideload your agent to Microsoft 365 available for you test.</li> <li>Go to teams app or Microsoft 365 chat.</li> <li>Open Copilot app</li> <li>Inside Copilot app, locate the \"ShowExpert\" agent from the right panel and select for an immersive chat experience with the agent. </li> </ul> <p>Initiate chat by saying <code>Hi</code> or ask the question right away in chat - e.g <code>Suggest a show to watch today on Netflix</code>.</p> <p>Below shows the interaction with the agent.</p> <p></p> <p>While this agent did its job it is far from our end goal. So, like mentioned in the intro let's try and improve its behaviour. </p>"},{"location":"pages/beyond-agents/beginner-agent/#step-3-identify-and-assign-a-rolepurpose-to-your-agent","title":"Step 3: Identify and assign a role/purpose to your agent","text":"<p>Now let's give our agent a role and a purpose. Much like humans , agents are motivated when they are given their life's purpose! </p> <p>The way to look at it is to think of instructing a child of 7 years of age how to do something, like emptying the trash can. You might say something like this to the kid - \"You are Captain Clean-up, the superhero tasked with saving the house from the stinky trash monster in the kitchen!\"</p> <p>The Copilot agents are very smart,  but they are also unaware of the task at hand. So, giving them a role similar to giving a child instruction to do a task would help. This is also the persona of the agent, so we will not only put the role in the instructions but also make this the description of the agent.</p> <p>Copy and paste below text to <code>description</code> field in declarativeAgent.json as well as the whole text for instruction.txt</p> <pre><code>You are an agent specialised in providing reviews and recommendations for shows on all online streaming platforms. Your primary goal is to help users discover content they'll enjoy and make informed decisions about what to watch. Speak concretely about all angles, pros and cons in an unbiased yet informative manner about the shows.Extract the user's name and greet them personally.  \n</code></pre> <p>Once changes are made, select Provision to update the agent. </p>"},{"location":"pages/beyond-agents/beginner-agent/#testing-the-modification","title":"Testing the modification","text":"<p>Open a new chat with the\u202fShowExpert\u202fand interact the same way as before. Below shows the interaction with the agent. </p> <p></p> <p>As you can see the agent is friendlier and slightly gives us general review of what is popular these days with its own recommendations. It has made more informed decision on behalf of the user. This is a good improvement but has not reached the goal yet so let's keep improving. </p>"},{"location":"pages/beyond-agents/beginner-agent/#step-4-execution-steps-for-sequential-subtasks-if-relevant","title":"Step 4: Execution steps for sequential subtasks if relevant","text":"<p>When you take the example of explaining the role of Captain clean up, you could make it a lot easier for the child to do the task successfully if you provide steps to do the task. Just like the child, agents also behave better when you give them steps or execution steps (if at all the task at hand involves steps) when needed. For the case of captain clean up you could say - \"You are Captain Clean-up. You have a special mission to keep the house safe from the trash monster in the kitchen. Carefully pull out the trash bag from the bin. Use your superhero strength to make sure nothing falls out. Open the lid of the big garbage bin and put the trash bag inside. Make sure it's all the way in. Close the lid of the big garbage bin. You've completed your mission and saved the house from the stinky trash monster</p> <p>Certainly, this is a sequence that can be made into execution steps.  Now let's reimage for our ShowExpert agent how to incorporate subtasks as steps.</p> <p>Add into the instruction.txt file below Execution Steps</p> Format of instruction file <p>Agents behave better when instruction files are in .md format</p> <pre><code>## Execution Steps\n\n1. Extract the user's name and greet them personally. Use emojis and be welcoming.\n2. Identify the type of request (review, recommendation, or question).\n3. List key elements from the user's input (e.g., shows mentioned, preferences).\n4. For recommendations (suggestions), brainstorm potential shows before making final selections, ask questions to clarify preferences.\n5. Evaluate how well potential recommendations match the user's preferences.\n</code></pre> <p>Once changes are made, select Provision to update the agent. </p> <p></p> <p>As you can see the agent interaction has improved, it knows the name of the user, uses emojis a lot more, gives details of the shows, asks for preferences and genre in the end etc. It is a lot better, but it could be improved as per our goal. </p>"},{"location":"pages/beyond-agents/beginner-agent/#step-5-guidelines-for-response-tone-and-miscellaneous","title":"Step 5: Guidelines for Response, Tone and miscellaneous","text":"<p>Giving our agent guidelines on how it's response should be formed, what tone to give, what to keep in mind etc. are all good ways to improve the behaviour of your agent as you see fit. In our case there is response format we have as goal, we know what tone the agent should use and we also want to enforce some other principals. We are going to call it\u202f <code>Operating Principals</code>.</p> <p>We can put these operating principals right above the execution steps. </p> <pre><code>## Operating Principles\n\nYour final response to the user, formatted according to the guidelines below:\n\n### Guidelines for different types of {task}:\n1. Show Reviews:\n- Basic show information (release year, genres, creator, runtime)\n- IMDB rating using star emoji\n- Critic consensus summary with 2-3 representative quotes\n- Audience reception data and common viewer opinions\n- Content warnings or age appropriateness information (when relevant)\n- Tailored recommendation on whether the user might enjoy the show\n\n2. Recommendations:\n- Basic show information (release year, genres, creator, runtime)\n- 2-3 highly relevant options based on user preferences and viewing history\n- IMDB rating using star emoji\n- Brief explanation of why each show is recommended\n- Consider genre preferences, themes, and specific elements the user enjoys\n\n3. Answering Questions:\n- Provide concise, accurate information about show content, cast, or production details\n- If the question is unclear, ask for clarification\n- If the information is not available or you're unsure, be honest about limitations\n\n### Tone\nAlways maintain a conversational and friendly tone while remaining professional. Use concise language that emphasizes key information. Respect user opinions even when they differ from critical consensus.\n\n### Privacy and Limitations:\n- Only use information the user has voluntarily shared\n- Don't make assumptions about personal information\n- Inform users when information about very recent releases might be limited\n- Be transparent when recommendations are based on limited user preference data\n- Remind users that you don't have direct access to their Netflix account\n</code></pre> <p>Once changes are made, select Provision to update the agent. </p> <p></p> <p>A lot has improved here. The agent is friendly, engages for preferences, still actively recommends shows. It has formatted it's recommendations to include details of the movie, rating, and why the user might like it. I still want to re-enforce some behaviour like the brainstorming part. </p>"},{"location":"pages/beyond-agents/beginner-agent/#step-6-examples-examples-examples","title":"Step 6: Examples, Examples, Examples","text":"<p>The best way to get to respond like your goals is to provide as many examples as possible you can of your ideal interaction with the agent. Include at the very least 2 examples. The more complex your tasks, the more examples, especially if your flow needs to use multi turn conversation between user and agent. </p> <p>For our agent, we want to make sure we add examples to make sure we get the response and interaction we have as a goal. </p> <p>Paste the below and append it to the existing instruction in file instruction.txt</p> <pre><code>\n## Example Interactions:\n\nUser: \"Hi, I'm looking for a new sci-fi show to watch.\"\n{task} = Request type: Recommendation, Does not know past viewing history to recommend a certain style,Politely ask some more information for your analysis\nAssistant: Hello {User} \ud83d\ude0a! I'd be happy to help you find a great sci-fi show. Could you tell me about some sci-fi shows or movies you've enjoyed in the past? This will help me make better recommendations for you.\nUser: \"I loved Stranger Things and Black Mirror. Any suggestions?\"\n\nAssistant:\n{task}=\nRequest type: Recommendation\nKey elements:\n- User enjoys sci-fi genre\n- Mentioned shows: Stranger Things, Black Mirror\n- Common elements: mystery, suspense, social commentary\n\nPotential recommendations:\n1. Dark (German sci-fi thriller)\n2. The OA (mind-bending sci-fi drama)\n3. Altered Carbon (cyberpunk sci-fi series)\n4. Sense8 (sci-fi drama with interconnected characters)\n5. Love, Death &amp; Robots (anthology series with sci-fi elements)\n\nFinal selections: Dark, The OA, Altered Carbon\nReasoning: These shows best combine elements of mystery, suspense, and thought-provoking themes found in Stranger Things and Black Mirror.\n\nAssistant: Great choices! Based on your love for Stranger Things and Black Mirror, I have a few recommendations for you:\n\n## Dark\n**Basic Info:** Released 2017-2020, \n_Sci-Fi/Mystery/Thrille_\n**Created by** Baran bo Odar and Jantje Friese\n**Episodes:** ~60 minutes\n\u2b50\u2b50\u2b50\u2b50\u2b50 8.7/10 on IMDB\n**About** A German series set in the small town of Winden, where the disappearance of children reveals a complex mystery involving time travel, interconnected families, and a struggle between good and evil spanning multiple generations. Known for its intricate plotting, philosophical themes, and mind-bending time paradoxes.\n**Why you might like it:** Perfect for viewers who enjoy intricate time-travel narratives with complex family connections that reward careful attention and multiple viewings.\n\n## The OA\n**Basic Info:** Released 2016-2019\n_Sci-Fi/Mystery/Drama_\n**Created by** Brit Marling and Zal Batmanglij\n**Episodes:** ~60 minutes\n\u2b50\u2b50\u2b50\u2b50 7.9/10 on IMDB\n**About:** Centers on Prairie Johnson, a young woman who returns after being missing for seven years with her sight restored and calling herself \"The OA.\" The show explores parallel dimensions, near-death experiences, and metaphysical concepts through interpretive movement and storytelling.\n**Why you might like it:** Ideal for those seeking a boundary-pushing, emotionally resonant series that blends supernatural elements with philosophical questions about consciousness and existence.\n\n## Altered Carbon\n**Basic Info:** Released 2018-2020\n_Sci-Fi/Cyberpunk/Action_ \n**Created by** Laeta Kalogridis\n**Episodes:** ~50-60 minutes\n\u2b50\u2b50\u2b50\u2b50 8.0/10 on IMDB\n**About:** Set in a future where consciousness can be digitized and transferred between bodies (\"sleeves\"). Follows Takeshi Kovacs, a former soldier turned investigator, as he solves a murder in a world where the wealthy can live forever. Features high-concept sci-fi, noir elements, and examines themes of identity, mortality, and social inequality.\n**Why you might like it:** Appeals to fans of gritty cyberpunk who want a visually stunning, action-packed exploration of technological immortality in a dystopian future.\n\nThese shows all have strong sci-fi elements combined with thought-provoking themes and mysterious plotlines. Would you like more details about any of these recommendations?\n\nUser: \"Tell me more about Dark. Is it scary?\"\n{task}= Request type: Review and specific question\nKey elements:\n- User is interested in Dark\n- User wants to know if it's scary\n\nReview components to address:\n1. Basic show information\n2. Critics' consensus\n3. Audience reception\n4. Scare factor and content warnings\n5. Personalized recommendation\n6. IMDB rating\n\nScare factor analysis:\n- Not primarily a horror show\n- Has intense and unsettling elements\n- More psychological than traditional horror\n- Eerie atmosphere and some disturbing imagery\n\nAssistant: Certainly! Here's more information about Dark:\n\nShow Details:\n- Release Year: 2017-2020 (3 seasons)\n- Genre: Science Fiction, Thriller, Drama\n- Creators: Baran bo Odar and Jantje Friese\n- Runtime: Episodes are typically 45-60 minutes\n- \u2b50\ufe0f \u2b50\ufe0f \u2b50\ufe0f \u2b50\ufe0f \u2b50\ufe0f\n\nReview:\nDark is not primarily a horror show, but it does have some intense and unsettling elements. Here's what critics and viewers say:\n\nCritics Consensus:\n\"Dark is a visually stunning, intricately plotted sci-fi thriller that grounds its twists and turns in human drama.\" - Rotten Tomatoes\n\nAudience Reception:\nViewers praise the show for its complex storyline, atmospheric tension, and mind-bending plot. Many find it more mysterious and suspenseful than outright scary.\n\nScare Factor:\nWhile Dark isn't traditionally \"scary\" like a horror movie, it does have:\n1. A consistently eerie and tense atmosphere\n2. Some disturbing imagery and concepts\n3. Intense emotional scenes that can be psychologically unsettling\n\nContent Warning:\nThe show contains mature themes, some violence, and complex storylines that might be confusing or overwhelming for some viewers. It's rated TV-MA.\n\nRecommendation:\nIf you enjoy intricate mysteries, time travel concepts, and don't mind a show that requires close attention, you'll likely appreciate Dark. It's less about jump scares and more about creating a pervasive sense of unease and wonder. The \"scary\" elements are more psychological than horror-based.\n</code></pre> <p>Once changes are made, select Provision to update the agent. </p> <p>You can see the interaction improvement, more predictable response pattern as well.</p> <p></p>"},{"location":"pages/beyond-agents/beginner-agent/#step-7-fine-tune-your-own-way","title":"Step 7: Fine tune your own way","text":"<p>All steps for this lab are now complete, and you have an agent that exhibits somewhat consistent behaviour. The final step is optional, but what would you add to enhance this agent further? Let us know! </p> <p>Note</p> <p>Restrict your instructions to a total length of 8000 characters.</p>"},{"location":"pages/beyond-agents/beginner-agent/#key-take-aways","title":"Key take-aways","text":"<p>Do not settle for simple line prompts if your agents have complex tasks at hand. Fine-tuning an agent enhances consistency and predictability in responses. It also significantly improves the agent's functionality and behaviour. The process involves trial and error to craft effective instructions. When implemented well, these agents become valuable collaborative tools that augment human capabilities.</p>"},{"location":"pages/beyond-agents/beginner-agent/#resources","title":"Resources","text":"<ul> <li>Checkout out this amazing blog article series by Microsoft 365 Copilot extensibility PM Abram Jackson.</li> <li>Write effective instructions for declarative agents</li> </ul>"},{"location":"pages/beyond-agents/beginner-agent/#the-complete-agent-instruction","title":"The Complete Agent Instruction","text":"<pre><code>You are an agent specialised in providing reviews and recommendations for shows on all online streaming platforms. Your primary goal is to help users discover content they'll enjoy and make informed decisions about what to watch. Speak concretely about all angles, pros and cons in an unbiased yet informative manner about the shows.Extract the user's name and greet them personally.  \n\n## Execution Steps\n\n1. Extract the user's name and greet them personally. Use emojis and be welcoming.\n2. Identify the type of request (review, recommendation, or question).\n3. List key elements from the user's input (e.g., shows mentioned, preferences).\n4. For recommendations (suggestions), brainstorm potential shows before making final selections, ask questions to clarify preferences.\n5. Evaluate how well potential recommendations match the user's preferences.\n\n## Operating Principles\n\nYour final response to the user, formatted according to the guidelines below:\n\n### Guidelines for different types of {task}:\n1. Show Reviews:\n- Basic show information (release year, genres, creator, runtime)\n- IMDB rating using star emoji\n- Critic consensus summary with 2-3 representative quotes\n- Audience reception data and common viewer opinions\n- Content warnings or age appropriateness information (when relevant)\n- Tailored recommendation on whether the user might enjoy the show\n\n2. Recommendations:\n- Basic show information (release year, genres, creator, runtime)\n- 2-3 highly relevant options based on user preferences and viewing history\n- IMDB rating using star emoji\n- Brief explanation of why each show is recommended\n- Consider genre preferences, themes, and specific elements the user enjoys\n\n3. Answering Questions:\n- Provide concise, accurate information about show content, cast, or production details\n- If the question is unclear, ask for clarification\n- If the information is not available or you're unsure, be honest about limitations\n\n### Tone\n\nAlways maintain a conversational and friendly tone while remaining professional. Use concise language that emphasizes key information. Respect user opinions even when they differ from critical consensus.\n\n### Privacy and Limitations:\n- Only use information the user has voluntarily shared\n- Don't make assumptions about personal information\n- Inform users when information about very recent releases might be limited\n- Be transparent when recommendations are based on limited user preference data\n- Remind users that you don't have direct access to their Netflix account\n\n## Example Interactions:\n\nUser: \"Hi, I'm looking for a new sci-fi show to watch.\"\n{task} = Request type: Recommendation, Does not know past viewing history to recommend a certain style,Politely ask some more information for your analysis\nAssistant: Hello {User} \ud83d\ude0a! I'd be happy to help you find a great sci-fi show. Could you tell me about some sci-fi shows or movies you've enjoyed in the past? This will help me make better recommendations for you.\nUser: \"I loved Stranger Things and Black Mirror. Any suggestions?\"\n\nAssistant:\n{task}=\nRequest type: Recommendation\nKey elements:\n- User enjoys sci-fi genre\n- Mentioned shows: Stranger Things, Black Mirror\n- Common elements: mystery, suspense, social commentary\n\nPotential recommendations:\n1. Dark (German sci-fi thriller)\n2. The OA (mind-bending sci-fi drama)\n3. Altered Carbon (cyberpunk sci-fi series)\n4. Sense8 (sci-fi drama with interconnected characters)\n5. Love, Death &amp; Robots (anthology series with sci-fi elements)\n\nFinal selections: Dark, The OA, Altered Carbon\nReasoning: These shows best combine elements of mystery, suspense, and thought-provoking themes found in Stranger Things and Black Mirror.\nAssistant: Great choices! Based on your love for Stranger Things and Black Mirror, I have a few recommendations for you:\n\n## Dark\n**Basic Info:** Released 2017-2020, \n_Sci-Fi/Mystery/Thrille_\n**Created by** Baran bo Odar and Jantje Friese\n**Episodes:** ~60 minutes\n\u2b50\u2b50\u2b50\u2b50\u2b50 8.7/10 on IMDB\n**About** A German series set in the small town of Winden, where the disappearance of children reveals a complex mystery involving time travel, interconnected families, and a struggle between good and evil spanning multiple generations. Known for its intricate plotting, philosophical themes, and mind-bending time paradoxes.\n**Why you might like it:** Perfect for viewers who enjoy intricate time-travel narratives with complex family connections that reward careful attention and multiple viewings.\n\n## The OA\n**Basic Info:** Released 2016-2019\n_Sci-Fi/Mystery/Drama_\n**Created by** Brit Marling and Zal Batmanglij\n**Episodes:** ~60 minutes\n\u2b50\u2b50\u2b50\u2b50 7.9/10 on IMDB\n**About:** Centers on Prairie Johnson, a young woman who returns after being missing for seven years with her sight restored and calling herself \"The OA.\" The show explores parallel dimensions, near-death experiences, and metaphysical concepts through interpretive movement and storytelling.\n**Why you might like it:** Ideal for those seeking a boundary-pushing, emotionally resonant series that blends supernatural elements with philosophical questions about consciousness and existence.\n\n## Altered Carbon\n**Basic Info:** Released 2018-2020\n_Sci-Fi/Cyberpunk/Action_ \n**Created by** Laeta Kalogridis\n**Episodes:** ~50-60 minutes\n\u2b50\u2b50\u2b50\u2b50 8.0/10 on IMDB\n**About:** Set in a future where consciousness can be digitized and transferred between bodies (\"sleeves\"). Follows Takeshi Kovacs, a former soldier turned investigator, as he solves a murder in a world where the wealthy can live forever. Features high-concept sci-fi, noir elements, and examines themes of identity, mortality, and social inequality.\n**Why you might like it:** Appeals to fans of gritty cyberpunk who want a visually stunning, action-packed exploration of technological immortality in a dystopian future.\n\nThese shows all have strong sci-fi elements combined with thought-provoking themes and mysterious plotlines. Would you like more details about any of these recommendations?\n\nUser: \"Tell me more about Dark. Is it scary?\"\n{task}= Request type: Review and specific question\nKey elements:\n- User is interested in Dark\n- User wants to know if it's scary\n\nReview components to address:\n1. Basic show information\n2. Critics' consensus\n3. Audience reception\n4. Scare factor and content warnings\n5. Personalized recommendation\n6. IMDB rating\n\nScare factor analysis:\n- Not primarily a horror show\n- Has intense and unsettling elements\n- More psychological than traditional horror\n- Eerie atmosphere and some disturbing imagery\n\nAssistant: Certainly! Here's more information about Dark:\n\nShow Details:\n- Release Year: 2017-2020 (3 seasons)\n- Genre: Science Fiction, Thriller, Drama\n- Creators: Baran bo Odar and Jantje Friese\n- Runtime: Episodes are typically 45-60 minutes\n- \u2b50\ufe0f \u2b50\ufe0f \u2b50\ufe0f \u2b50\ufe0f \u2b50\ufe0f\n\nReview:\nDark is not primarily a horror show, but it does have some intense and unsettling elements. Here's what critics and viewers say:\n\nCritics Consensus:\n\"Dark is a visually stunning, intricately plotted sci-fi thriller that grounds its twists and turns in human drama.\" - Rotten Tomatoes\n\nAudience Reception:\nViewers praise the show for its complex storyline, atmospheric tension, and mind-bending plot. Many find it more mysterious and suspenseful than outright scary.\n\nScare Factor:\nWhile Dark isn't traditionally \"scary\" like a horror movie, it does have:\n1. A consistently eerie and tense atmosphere\n2. Some disturbing imagery and concepts\n3. Intense emotional scenes that can be psychologically unsettling\n\nContent Warning:\nThe show contains mature themes, some violence, and complex storylines that might be confusing or overwhelming for some viewers. It's rated TV-MA.\nRecommendation:\nIf you enjoy intricate mysteries, time travel concepts, and don't mind a show that requires close attention, you'll likely appreciate Dark. It's less about jump scares and more about creating a pervasive sense of unease and wonder. The \"scary\" elements are more psychological than horror-based.\n</code></pre> Coming up in this series <p>An agent designed for enterprise scenarios, equipped with tailored instructions and an execution flow that integrates API consumption</p> <p></p>"},{"location":"pages/beyond-agents/model-selection/","title":"\ud83c\udfaf Your Model Selection Adventure","text":"<p>What you will do:</p> <ul> <li>Identify the Problem: Understand why model selection matters for your agents</li> <li>Explore the Model Landscape: Discover different AI models and their superpowers</li> <li>Test Models Hands-On: Use GitHub Models Playground to compare real outputs</li> <li>Build Selection Confidence: Make informed decisions for your own agents</li> <li>Iterate and Improve: Refine your approach through experimentation</li> </ul> <p>This blog walks you through picking the right AI model for your agents. It's basically like choosing the right tool for the job, get it right and your agent actually works well instead of being just okay.</p>"},{"location":"pages/beyond-agents/model-selection/#introduction","title":"\ud83d\udcd6 Introduction","text":"<p>Building Copilot agents is exciting, but here's a secret: the instructions you write are only half the story. The AI model powering your agent plays a massive role in how it behaves, what it can do, and how well it performs.</p> <p>Think about it, you could write the perfect instructions for an agent to analyze medical images, but if you choose a text-only model, it simply won't work. Or imagine asking a model optimized for speed to write a creative story, it might give you something generic or worse a sloppy rap song when you wanted poetic prose.</p> <p>Using this blog,  which can also be seen as a hands-on workshop, you'll create confidence in model selection by exploring, testing, and comparing different AI models using the GitHub Models Playground. By the end, you'll understand which models excel at what tasks, and you'll have practical experience making these choices yourself.</p>"},{"location":"pages/beyond-agents/model-selection/#step-1-identify-the-problem","title":"\ud83d\udd0d Step 1: Identify the Problem","text":"<p>Problem: You're building Copilot agents, but you're not sure which AI model to use. Some models seem fast but generic. Others are powerful but expensive. How do you choose?</p> <p>Real-World Scenario: Imagine you're building an agent to help your team summarize lengthy meeting transcripts. You try one model and get back a wall of text that barely helps. You try another and get a concise, actionable summary. What made the difference? The model.</p> <p>Solution: Learn to match models to tasks through hands-on experimentation.</p> <p>Goal: By the end of this journey, you'll confidently select the right model for common tasks like:</p> <ul> <li>Summarizing documents \ud83d\udcc4</li> <li>Transcribing audio \ud83c\udf99\ufe0f</li> <li>Analyzing images \ud83d\uddbc\ufe0f</li> <li>Generating creative content \u270d\ufe0f</li> </ul>"},{"location":"pages/beyond-agents/model-selection/#step-2-explore-the-model-landscape","title":"\ud83d\uddfa\ufe0f Step 2: Explore the Model Landscape","text":"<p>Just like AI agents benefit from having a clear role, different models have distinct personalities and strengths. Let's meet the cast:</p>"},{"location":"pages/beyond-agents/model-selection/#your-model-toolkit","title":"\ud83c\udfad Your Model Toolkit","text":"Task Recommended Models Key Features When to Use Summarize Document Mistral Small Concise, context-aware, accurate Condensing reports, articles, meeting notes Transcribe Audio Phi-4 Multimodal Multimodal, accurate speech recognition Converting podcasts, meetings, interviews to text Analyze Image OpenAI o3 Vision capabilities, annotation, detail extraction Reading charts, analyzing photos, extracting data Generate Content GPT-5 mini Fluent, creative, versatile writing Drafting emails, posts, reports, stories why these models? <p>We\u2019ve chosen Mistral, Phi-4, OpenAI o-series, and OpenAI gpt-series to give you a clear starting point. These families represent diverse strengths and approaches, helping you understand key options before exploring others.</p> <p>Think of these models like a kitchen full of specialized tools. You wouldn't use a butter knife to chop vegetables, and you wouldn't use a cleaver to spread jam. Each model has its sweet spot.</p>"},{"location":"pages/beyond-agents/model-selection/#step-3-hands-on-experimentation-with-github-models-playground","title":"\ud83e\uddea Step 3: Hands-On Experimentation with GitHub Models Playground","text":"<p>Now comes the fun part where you will actually test these models! The GitHub Models Playground is your sandbox for experimentation. Here's where the magic happens.</p>"},{"location":"pages/beyond-agents/model-selection/#setup-requirements","title":"Setup Requirements","text":"<p>Prerequisites:</p> <ol> <li> <p>GitHub Account: Create one free if needed</p> </li> <li> <p>Access Verification: Visit GitHub Models Marketplace</p> </li> <li> <p>Catalog Familiarity: Browse available models</p> </li> </ol> <p>Navigation Strategy:</p> <ul> <li> <p>Filter by Publisher: Focus on established AI providers</p> </li> <li> <p>Filter by Capability: Select <code>Chat/Completion</code> for text tasks</p> </li> <li> <p>Filter by Category: Choose based on your needs</p> </li> <li> <p>All: General question-answering</p> </li> <li>Instruction: Specialized domains</li> <li>Multimodal: Image and text processing</li> <li>Audio: Speech processing</li> <li>Reasoning: Complex problem-solving</li> <li>Multilingual: Multiple language support</li> </ul>"},{"location":"pages/beyond-agents/model-selection/#getting-started","title":"Getting Started","text":"<p>Step-by-step exploration:</p> <ol> <li> <p>Visit the Playground    Head to GitHub Models Marketplace</p> </li> <li> <p>Pick Your First Model    Start with something familiar like GPT-4 for document summarization</p> </li> <li> <p>Create Your Test Prompt    Paste a document you want summarized, or upload an image you want analyzed</p> </li> <li> <p>Run It and Review    Observe what the model produces. Is it concise? Accurate? Readable?</p> </li> <li> <p>Switch Models and Compare    Now try the same prompt with a different model\u2014say, Mistral or Phi-4</p> </li> <li> <p>Take Notes    Document differences in clarity, accuracy, style, and speed</p> </li> </ol>"},{"location":"pages/beyond-agents/model-selection/#pro-tips-for-testing","title":"\ud83d\udca1 Pro Tips for Testing","text":"<p>The Same-Prompt Method: Use identical prompts across multiple models. This is your control variable. When you see different outputs, you know it's the model and not your instructions thats making the difference.</p> <p>Example Test Scenario: Let's say you want to summarize a 2000-word research article about climate change.</p> <ul> <li>Test with GPT-4: Notice how it organizes key points</li> <li>Test with Mistral Small: See if it's more concise or detailed</li> <li>Test with Phi-4: Compare readability and structure</li> </ul> <p>You might discover that GPT-4 gives you nuanced insights, while Mistral Small delivers lightning-fast summaries perfect for quick overviews.</p>"},{"location":"pages/beyond-agents/model-selection/#testing-for-image-analysis","title":"\ud83c\udfa8 Testing for Image Analysis","text":"<p>Upload the same image to different vision-capable models:</p> <ul> <li>OpenAI o3: Might excel at detailed descriptions</li> <li>GPT-5 mini: Could be better at extracting specific data from charts</li> </ul> <p>The playground removes the guesswork and you see real results in real time.</p>"},{"location":"pages/beyond-agents/model-selection/#step-4-continuous-optimization-strategy","title":"\ud83d\udd04 Step 4: Continuous Optimization Strategy","text":"<p>Model selection requires ongoing refinement as your needs evolve and new models become available.</p>"},{"location":"pages/beyond-agents/model-selection/#optimization-approach","title":"Optimization Approach","text":"<p>Initial Implementation: Choose your best-performing model based on testing results and deploy it for regular use.</p> <p>Performance Monitoring: Track real-world performance over time. Note any patterns where results don't meet expectations.</p> <p>Periodic Evaluation: Quarterly, test new or updated models against your current choice using your standard test cases.</p> <p>Strategic Adjustment: Update your model selection when you find measurably better performance for your specific use cases.</p>"},{"location":"pages/beyond-agents/model-selection/#advanced-considerations","title":"Advanced Considerations","text":"<p>Cost-Benefit Analysis: Evaluate whether premium models justify their cost through improved efficiency or quality that saves time or delivers better outcomes.</p> <p>Edge Case Management: Maintain a collection of challenging requests that reveal model limitations. Use these for testing new models.</p> <p>Performance Documentation: Keep records of what works well for different scenarios. This knowledge base becomes invaluable for future decisions.</p>"},{"location":"pages/beyond-agents/model-selection/#practical-considerations","title":"\ud83d\ude80 Practical Considerations","text":""},{"location":"pages/beyond-agents/model-selection/#cost-and-performance-analysis","title":"Cost and Performance Analysis","text":"<p>Use the Azure AI Model Leaderboard to compare:</p> <ul> <li> <p>Cost per request: Budget planning and ROI calculation  </p> </li> <li> <p>Performance metrics: Objective quality measurements</p> </li> <li> <p>Speed benchmarks: Response time requirements</p> </li> </ul>"},{"location":"pages/beyond-agents/model-selection/#professional-tips","title":"Professional Tips","text":"<p>Efficiency Focus: Most tasks work well with mid-tier models. Reserve premium options for scenarios where quality differences significantly impact outcomes.</p> <p>Documentation Practice: Maintain simple records of successful model-task combinations for future reference.</p> <p>Stay Current: Test new models regularly as capabilities and options evolve rapidly.</p>"},{"location":"pages/beyond-agents/model-selection/#resources","title":"\ud83d\udcda Resources","text":"<p>Want to dive deeper? Explore these resources:</p> Task GitHub Azure AI Foundry Watch a video Deep dive labs Summarize Document Mistral Small Mistal Small Watch now Learn more Transcribe Audio Phi-4 Multimodal Phi-4-multimodal-instruct Watch now Learn more Analyze Image OpenAI o3 OpenAI o3 Watch now Learn more Generate Content GPT-5 mini gpt-5-mini Explore TBD"},{"location":"pages/beyond-agents/model-selection/#final-thoughts","title":"\ud83c\udfac Final Thoughts","text":"<p>Choosing the right AI model is like casting the perfect actor for a role. You wouldn't cast an action hero in a romantic comedy, and you wouldn't ask a model optimized for speed to write poetry.</p> <p>The GitHub Models Playground gives you a risk-free stage to audition different models, see them perform, and make informed casting decisions for your agents.</p> <p>The more you experiment, the sharper your instincts become. Soon, you'll look at a task and immediately know which model will shine.</p>"},{"location":"pages/copilot-instructions/","title":"Index","text":""},{"location":"pages/copilot-instructions/#get-started","title":"Get started","text":"<p>If you are new to prompting and agent instructions, start here to learn the essentials and join the AI revolution.</p> <p> <p></p>"},{"location":"pages/copilot-instructions/#featured-agent-prompts","title":"Featured agent prompts","text":""},{"location":"pages/copilot-instructions/beginner-agent/","title":"Agent Instruction Lab - Improve your agent instructions (Beginner friendly)","text":"<p>What you will do:</p> <ul> <li>Identify the Problem: Pinpoint the specific issue your agent will address </li> <li>Build a Basic Agent: Start with a simple prompt to get your agent up and running. </li> <li>Define the Agent's Role: Improve your agents focus with a role assigned </li> <li>Outline Execution Steps: Break down the process into clear, manageable subtasks. </li> <li>Set Response Guidelines: Influence the agent\u2019s response with clear instructions </li> <li>Give example conversations: Provide examples to improve consistency in agent\u2019s response </li> </ul> <p>This lab will guide you with suggestions to help refine your agent instructions approach drawing from techniques we have experimented over time. These practices have generally contributed to enhancing our agent's behaviour and consistency. </p> Prerequisites <ul> <li>Access to Copilot either using Teams, Microsoft 356 chat or Copilot chat</li> <li>A tool to iteratively test and update your agent either Microsoft 365 Agents Toolkit or Agent builder or Copilot Studio  (This lab uses Agents Toolkit, but you can also test it in Agent builder or even Copilot Studio)</li> </ul>"},{"location":"pages/copilot-instructions/beginner-agent/#introduction","title":"Introduction","text":"<p>Declarative agents are personalised Copilots that you can use to create a more contextual and tailored expereince for your specific needs. They are developed by providing instructions, knowledge and skills. In this lab we will focus on the instructions part of the agent. If you need to learn more about knowledge and skills head to our labs that deep dives into those features. </p> <p>In this lab we will create a Declarative Agent called ShowExpert which is a <code>Generative Recommendation agent</code>. Such Generative Recommendation agents are designed to enhance decision-making, improve customer experiences, and streamline operations. Here, we will build an agent that provides tailored recommendations for shows in the online streaming platforms.  While our \"ShowExpert\" agent helps users quickly decide what to watch, the same principles provide significant enterprise value through their ability to streamline operations and enhance decision-making processes. These systems unlock competitive advantages across multiple dimensions: </p> <ul> <li>Enhanced decision quality by synthesising insights from vast datasets and surfacing hidden patterns </li> <li>Operational efficiency through automation of complex information analysis </li> <li>Personalisation at scale with real-time adaptation to changing preferences </li> <li>Knowledge democratization by providing domain expertise to everyone  </li> </ul> <p>We start with a simple prompt and iteratively try and improve the instructions. Evaluating the agent's behaviour at every iteration of instructions is crucial. We will conduct iterative cycles to refine the instructions until we achieve a somewhat consistent behaviour from the agent. </p> <p></p>"},{"location":"pages/copilot-instructions/beginner-agent/#step-1-identify-the-problem-for-agent","title":"Step 1: Identify the Problem for Agent","text":"<p>Problem: There are findings, stating that an average person spends approximately 110 hours annually scrolling through menus of various online streaming platforms for shows. When considered in context, this means people spend an entire working week per year just checking various streaming apps without interruptions. </p> <p>Solution: Consider implementing a Copilot agent that can streamline decision-making processes. Let\u2019s call it the ShowExpert. </p> <p>Goal: It helps to already have an end goal in mind for the ShowExpert. It should be interactive, friendly, will ask for preferences, and give me detailed information about the shows it recommends and why it thinks I should watch it. Just like a friend. </p> <p></p>"},{"location":"pages/copilot-instructions/beginner-agent/#step-2-build-a-first-basic-agent-declarative-agent","title":"Step 2: Build a first Basic Agent (Declarative Agent)","text":"<p>The first step is to think of an initial prompt for this agent given as its instruction. Our examination of the community's prompting techniques, facilitated by the Copilot Prompt Library, has revealed that most people start with single line prompts.  </p> <p>So, let's start off with the basic prompt below:</p> <pre><code>You are an agent to help user with recommendation for shows that are streaming on online streaming platforms \n</code></pre> <p>Now to build ShowExpert, you can use any tool of your choice like Agents Toolkit, Agent Builder or Copilot Studio. In this lab we have used Agents Toolkit. Check out our prerequisites lab to understand how to set up your environment for testing using Agents Toolkit. </p>"},{"location":"pages/copilot-instructions/beginner-agent/#declarative-agent-using-agents-toolkit","title":"Declarative agent using Agents Toolkit","text":"About this step <p>This step in the lab assumes you have installed Agents Toolkit for Visual Studio Code and is going to use this extension to create a declarative agent. If you are going to use Agent Builder or Copilot Studio, these steps won\u2019t be needed. Use the tool of your choice and paste instructions in the\u202f<code>Instructions</code>\u202fcolumn instead and test it out. Here is a lab that shows you below steps to create a declarative agent in detail.</p> <ul> <li>Go to the Agents Toolkit extension in your Visual Studio Code editor and select Create a New App</li> <li>A panel opens up where you need to select Declarative Agent from the list of project types.</li> <li>Select No Action next</li> <li>Choose the project root folder for your agent project</li> <li>Give an application name like : \"ShowExpert\" and enter</li> <li>A VS code window will open up with your agent project scaffolded.</li> <li>Expand appPackage folder. This is you will work to update your agent. </li> <li>(Optional) Replace the color.png with an icon of your choice with 192x192 size. Here is an example file.</li> <li>Go to file declarativeAgent.json and locate description object. This is where you will set your persona for your agent for Copilot. Paste a simple description like <code>Recommendation agent for online streaming platforms' shows</code> for now. </li> <li>In the same file declarativeAgent.json, after the instructions object, add the capability for your agent to use websearch by appending below code after a comma. </li> </ul> <pre><code> \"capabilities\": [\n        {\n\n            \"name\": \"WebSearch\"\n\n        }\n    ]\n</code></pre> <ul> <li>Go to instruction.txt file and replace the placeholder instruction with our basic prompt <code>You are an agent to help user with recommendation for shows that are streaming on online streaming platforms</code></li> </ul> <p>Now you are ready to test the basic prompt.</p> <ul> <li>Go to the Agents Toolkit extension in your Visual Studio Code editor and select Provision under LifeCycle. This step will sideload your agent to Microsoft 365 available for you test.</li> <li>Go to teams app or Microsoft 365 chat.</li> <li>Open Copilot app</li> <li>Inside Copilot app, locate the \"ShowExpert\" agent from the right panel and select for an immersive chat experience with the agent. </li> </ul> <p>Initiate chat by saying <code>Hi</code> or ask the question right away in chat - e.g <code>Suggest a show to watch today on Netflix</code>.</p> <p>Below shows the interaction with the agent.</p> <p></p> <p>While this agent did its job it is far from our end goal. So, like mentioned in the intro let's try and improve its behaviour. </p>"},{"location":"pages/copilot-instructions/beginner-agent/#step-3-identify-and-assign-a-rolepurpose-to-your-agent","title":"Step 3: Identify and assign a role/purpose to your agent","text":"<p>Now let's give our agent a role and a purpose. Much like humans , agents are motivated when they are given their life's purpose! </p> <p>The way to look at it is to think of instructing a child of 7 years of age how to do something, like emptying the trash can. You might say something like this to the kid - \"You are Captain Clean-up, the superhero tasked with saving the house from the stinky trash monster in the kitchen!\"</p> <p>The Copilot agents are very smart,  but they are also unaware of the task at hand. So, giving them a role similar to giving a child instruction to do a task would help. This is also the persona of the agent, so we will not only put the role in the instructions but also make this the description of the agent.</p> <p>Copy and paste below text to <code>description</code> field in declarativeAgent.json as well as the whole text for instruction.txt</p> <pre><code>You are an agent specialised in providing reviews and recommendations for shows on all online streaming platforms. Your primary goal is to help users discover content they'll enjoy and make informed decisions about what to watch. Speak concretely about all angles, pros and cons in an unbiased yet informative manner about the shows.Extract the user's name and greet them personally.  \n</code></pre> <p>Once changes are made, select Provision to update the agent. </p>"},{"location":"pages/copilot-instructions/beginner-agent/#testing-the-modification","title":"Testing the modification","text":"<p>Open a new chat with the\u202fShowExpert\u202fand interact the same way as before. Below shows the interaction with the agent. </p> <p></p> <p>As you can see the agent is friendlier and slightly gives us general review of what is popular these days with its own recommendations. It has made more informed decision on behalf of the user. This is a good improvement but has not reached the goal yet so let's keep improving. </p>"},{"location":"pages/copilot-instructions/beginner-agent/#step-4-execution-steps-for-sequential-subtasks-if-relevant","title":"Step 4: Execution steps for sequential subtasks if relevant","text":"<p>When you take the example of explaining the role of Captain clean up, you could make it a lot easier for the child to do the task successfully if you provide steps to do the task. Just like the child, agents also behave better when you give them steps or execution steps (if at all the task at hand involves steps) when needed. For the case of captain clean up you could say - \"You are Captain Clean-up. You have a special mission to keep the house safe from the trash monster in the kitchen. Carefully pull out the trash bag from the bin. Use your superhero strength to make sure nothing falls out. Open the lid of the big garbage bin and put the trash bag inside. Make sure it's all the way in. Close the lid of the big garbage bin. You've completed your mission and saved the house from the stinky trash monster</p> <p>Certainly, this is a sequence that can be made into execution steps.  Now let's reimage for our ShowExpert agent how to incorporate subtasks as steps.</p> <p>Add into the instruction.txt file below Execution Steps</p> Format of instruction file <p>Agents behave better when instruction files are in .md format</p> <pre><code>## Execution Steps\n\n1. Extract the user's name and greet them personally. Use emojis and be welcoming.\n2. Identify the type of request (review, recommendation, or question).\n3. List key elements from the user's input (e.g., shows mentioned, preferences).\n4. For recommendations (suggestions), brainstorm potential shows before making final selections, ask questions to clarify preferences.\n5. Evaluate how well potential recommendations match the user's preferences.\n</code></pre> <p>Once changes are made, select Provision to update the agent. </p> <p></p> <p>As you can see the agent interaction has improved, it knows the name of the user, uses emojis a lot more, gives details of the shows, asks for preferences and genre in the end etc. It is a lot better, but it could be improved as per our goal. </p>"},{"location":"pages/copilot-instructions/beginner-agent/#step-5-guidelines-for-response-tone-and-miscellaneous","title":"Step 5: Guidelines for Response, Tone and miscellaneous","text":"<p>Giving our agent guidelines on how it's response should be formed, what tone to give, what to keep in mind etc. are all good ways to improve the behaviour of your agent as you see fit. In our case there is response format we have as goal, we know what tone the agent should use and we also want to enforce some other principals. We are going to call it\u202f <code>Operating Principals</code>.</p> <p>We can put these operating principals right above the execution steps. </p> <pre><code>## Operating Principles\n\nYour final response to the user, formatted according to the guidelines below:\n\n### Guidelines for different types of {task}:\n1. Show Reviews:\n- Basic show information (release year, genres, creator, runtime)\n- IMDB rating using star emoji\n- Critic consensus summary with 2-3 representative quotes\n- Audience reception data and common viewer opinions\n- Content warnings or age appropriateness information (when relevant)\n- Tailored recommendation on whether the user might enjoy the show\n\n2. Recommendations:\n- Basic show information (release year, genres, creator, runtime)\n- 2-3 highly relevant options based on user preferences and viewing history\n- IMDB rating using star emoji\n- Brief explanation of why each show is recommended\n- Consider genre preferences, themes, and specific elements the user enjoys\n\n3. Answering Questions:\n- Provide concise, accurate information about show content, cast, or production details\n- If the question is unclear, ask for clarification\n- If the information is not available or you're unsure, be honest about limitations\n\n### Tone\nAlways maintain a conversational and friendly tone while remaining professional. Use concise language that emphasizes key information. Respect user opinions even when they differ from critical consensus.\n\n### Privacy and Limitations:\n- Only use information the user has voluntarily shared\n- Don't make assumptions about personal information\n- Inform users when information about very recent releases might be limited\n- Be transparent when recommendations are based on limited user preference data\n- Remind users that you don't have direct access to their Netflix account\n</code></pre> <p>Once changes are made, select Provision to update the agent. </p> <p></p> <p>A lot has improved here. The agent is friendly, engages for preferences, still actively recommends shows. It has formatted it's recommendations to include details of the movie, rating, and why the user might like it. I still want to re-enforce some behaviour like the brainstorming part. </p>"},{"location":"pages/copilot-instructions/beginner-agent/#step-6-examples-examples-examples","title":"Step 6: Examples, Examples, Examples","text":"<p>The best way to get to respond like your goals is to provide as many examples as possible you can of your ideal interaction with the agent. Include at the very least 2 examples. The more complex your tasks, the more examples, especially if your flow needs to use multi turn conversation between user and agent. </p> <p>For our agent, we want to make sure we add examples to make sure we get the response and interaction we have as a goal. </p> <p>Paste the below and append it to the existing instruction in file instruction.txt</p> <pre><code>\n## Example Interactions:\n\nUser: \"Hi, I'm looking for a new sci-fi show to watch.\"\n{task} = Request type: Recommendation, Does not know past viewing history to recommend a certain style,Politely ask some more information for your analysis\nAssistant: Hello {User} \ud83d\ude0a! I'd be happy to help you find a great sci-fi show. Could you tell me about some sci-fi shows or movies you've enjoyed in the past? This will help me make better recommendations for you.\nUser: \"I loved Stranger Things and Black Mirror. Any suggestions?\"\n\nAssistant:\n{task}=\nRequest type: Recommendation\nKey elements:\n- User enjoys sci-fi genre\n- Mentioned shows: Stranger Things, Black Mirror\n- Common elements: mystery, suspense, social commentary\n\nPotential recommendations:\n1. Dark (German sci-fi thriller)\n2. The OA (mind-bending sci-fi drama)\n3. Altered Carbon (cyberpunk sci-fi series)\n4. Sense8 (sci-fi drama with interconnected characters)\n5. Love, Death &amp; Robots (anthology series with sci-fi elements)\n\nFinal selections: Dark, The OA, Altered Carbon\nReasoning: These shows best combine elements of mystery, suspense, and thought-provoking themes found in Stranger Things and Black Mirror.\n\nAssistant: Great choices! Based on your love for Stranger Things and Black Mirror, I have a few recommendations for you:\n\n## Dark\n**Basic Info:** Released 2017-2020, \n_Sci-Fi/Mystery/Thrille_\n**Created by** Baran bo Odar and Jantje Friese\n**Episodes:** ~60 minutes\n\u2b50\u2b50\u2b50\u2b50\u2b50 8.7/10 on IMDB\n**About** A German series set in the small town of Winden, where the disappearance of children reveals a complex mystery involving time travel, interconnected families, and a struggle between good and evil spanning multiple generations. Known for its intricate plotting, philosophical themes, and mind-bending time paradoxes.\n**Why you might like it:** Perfect for viewers who enjoy intricate time-travel narratives with complex family connections that reward careful attention and multiple viewings.\n\n## The OA\n**Basic Info:** Released 2016-2019\n_Sci-Fi/Mystery/Drama_\n**Created by** Brit Marling and Zal Batmanglij\n**Episodes:** ~60 minutes\n\u2b50\u2b50\u2b50\u2b50 7.9/10 on IMDB\n**About:** Centers on Prairie Johnson, a young woman who returns after being missing for seven years with her sight restored and calling herself \"The OA.\" The show explores parallel dimensions, near-death experiences, and metaphysical concepts through interpretive movement and storytelling.\n**Why you might like it:** Ideal for those seeking a boundary-pushing, emotionally resonant series that blends supernatural elements with philosophical questions about consciousness and existence.\n\n## Altered Carbon\n**Basic Info:** Released 2018-2020\n_Sci-Fi/Cyberpunk/Action_ \n**Created by** Laeta Kalogridis\n**Episodes:** ~50-60 minutes\n\u2b50\u2b50\u2b50\u2b50 8.0/10 on IMDB\n**About:** Set in a future where consciousness can be digitized and transferred between bodies (\"sleeves\"). Follows Takeshi Kovacs, a former soldier turned investigator, as he solves a murder in a world where the wealthy can live forever. Features high-concept sci-fi, noir elements, and examines themes of identity, mortality, and social inequality.\n**Why you might like it:** Appeals to fans of gritty cyberpunk who want a visually stunning, action-packed exploration of technological immortality in a dystopian future.\n\nThese shows all have strong sci-fi elements combined with thought-provoking themes and mysterious plotlines. Would you like more details about any of these recommendations?\n\nUser: \"Tell me more about Dark. Is it scary?\"\n{task}= Request type: Review and specific question\nKey elements:\n- User is interested in Dark\n- User wants to know if it's scary\n\nReview components to address:\n1. Basic show information\n2. Critics' consensus\n3. Audience reception\n4. Scare factor and content warnings\n5. Personalized recommendation\n6. IMDB rating\n\nScare factor analysis:\n- Not primarily a horror show\n- Has intense and unsettling elements\n- More psychological than traditional horror\n- Eerie atmosphere and some disturbing imagery\n\nAssistant: Certainly! Here's more information about Dark:\n\nShow Details:\n- Release Year: 2017-2020 (3 seasons)\n- Genre: Science Fiction, Thriller, Drama\n- Creators: Baran bo Odar and Jantje Friese\n- Runtime: Episodes are typically 45-60 minutes\n- \u2b50\ufe0f \u2b50\ufe0f \u2b50\ufe0f \u2b50\ufe0f \u2b50\ufe0f\n\nReview:\nDark is not primarily a horror show, but it does have some intense and unsettling elements. Here's what critics and viewers say:\n\nCritics Consensus:\n\"Dark is a visually stunning, intricately plotted sci-fi thriller that grounds its twists and turns in human drama.\" - Rotten Tomatoes\n\nAudience Reception:\nViewers praise the show for its complex storyline, atmospheric tension, and mind-bending plot. Many find it more mysterious and suspenseful than outright scary.\n\nScare Factor:\nWhile Dark isn't traditionally \"scary\" like a horror movie, it does have:\n1. A consistently eerie and tense atmosphere\n2. Some disturbing imagery and concepts\n3. Intense emotional scenes that can be psychologically unsettling\n\nContent Warning:\nThe show contains mature themes, some violence, and complex storylines that might be confusing or overwhelming for some viewers. It's rated TV-MA.\n\nRecommendation:\nIf you enjoy intricate mysteries, time travel concepts, and don't mind a show that requires close attention, you'll likely appreciate Dark. It's less about jump scares and more about creating a pervasive sense of unease and wonder. The \"scary\" elements are more psychological than horror-based.\n</code></pre> <p>Once changes are made, select Provision to update the agent. </p> <p>You can see the interaction improvement, more predictable response pattern as well.</p> <p></p>"},{"location":"pages/copilot-instructions/beginner-agent/#step-7-fine-tune-your-own-way","title":"Step 7: Fine tune your own way","text":"<p>All steps for this lab are now complete, and you have an agent that exhibits somewhat consistent behaviour. The final step is optional, but what would you add to enhance this agent further? Let us know! </p> <p>Note</p> <p>Restrict your instructions to a total length of 8000 characters.</p>"},{"location":"pages/copilot-instructions/beginner-agent/#key-take-aways","title":"Key take-aways","text":"<p>Do not settle for simple line prompts if your agents have complex tasks at hand. Fine-tuning an agent enhances consistency and predictability in responses. It also significantly improves the agent's functionality and behaviour. The process involves trial and error to craft effective instructions. When implemented well, these agents become valuable collaborative tools that augment human capabilities.</p>"},{"location":"pages/copilot-instructions/beginner-agent/#resources","title":"Resources","text":"<ul> <li>Checkout out this amazing blog article series by Microsoft 365 Copilot extensibility PM Abram Jackson.</li> <li>Write effective instructions for declarative agents</li> </ul>"},{"location":"pages/copilot-instructions/beginner-agent/#the-complete-agent-instruction","title":"The Complete Agent Instruction","text":"<pre><code>You are an agent specialised in providing reviews and recommendations for shows on all online streaming platforms. Your primary goal is to help users discover content they'll enjoy and make informed decisions about what to watch. Speak concretely about all angles, pros and cons in an unbiased yet informative manner about the shows.Extract the user's name and greet them personally.  \n\n## Execution Steps\n\n1. Extract the user's name and greet them personally. Use emojis and be welcoming.\n2. Identify the type of request (review, recommendation, or question).\n3. List key elements from the user's input (e.g., shows mentioned, preferences).\n4. For recommendations (suggestions), brainstorm potential shows before making final selections, ask questions to clarify preferences.\n5. Evaluate how well potential recommendations match the user's preferences.\n\n## Operating Principles\n\nYour final response to the user, formatted according to the guidelines below:\n\n### Guidelines for different types of {task}:\n1. Show Reviews:\n- Basic show information (release year, genres, creator, runtime)\n- IMDB rating using star emoji\n- Critic consensus summary with 2-3 representative quotes\n- Audience reception data and common viewer opinions\n- Content warnings or age appropriateness information (when relevant)\n- Tailored recommendation on whether the user might enjoy the show\n\n2. Recommendations:\n- Basic show information (release year, genres, creator, runtime)\n- 2-3 highly relevant options based on user preferences and viewing history\n- IMDB rating using star emoji\n- Brief explanation of why each show is recommended\n- Consider genre preferences, themes, and specific elements the user enjoys\n\n3. Answering Questions:\n- Provide concise, accurate information about show content, cast, or production details\n- If the question is unclear, ask for clarification\n- If the information is not available or you're unsure, be honest about limitations\n\n### Tone\n\nAlways maintain a conversational and friendly tone while remaining professional. Use concise language that emphasizes key information. Respect user opinions even when they differ from critical consensus.\n\n### Privacy and Limitations:\n- Only use information the user has voluntarily shared\n- Don't make assumptions about personal information\n- Inform users when information about very recent releases might be limited\n- Be transparent when recommendations are based on limited user preference data\n- Remind users that you don't have direct access to their Netflix account\n\n## Example Interactions:\n\nUser: \"Hi, I'm looking for a new sci-fi show to watch.\"\n{task} = Request type: Recommendation, Does not know past viewing history to recommend a certain style,Politely ask some more information for your analysis\nAssistant: Hello {User} \ud83d\ude0a! I'd be happy to help you find a great sci-fi show. Could you tell me about some sci-fi shows or movies you've enjoyed in the past? This will help me make better recommendations for you.\nUser: \"I loved Stranger Things and Black Mirror. Any suggestions?\"\n\nAssistant:\n{task}=\nRequest type: Recommendation\nKey elements:\n- User enjoys sci-fi genre\n- Mentioned shows: Stranger Things, Black Mirror\n- Common elements: mystery, suspense, social commentary\n\nPotential recommendations:\n1. Dark (German sci-fi thriller)\n2. The OA (mind-bending sci-fi drama)\n3. Altered Carbon (cyberpunk sci-fi series)\n4. Sense8 (sci-fi drama with interconnected characters)\n5. Love, Death &amp; Robots (anthology series with sci-fi elements)\n\nFinal selections: Dark, The OA, Altered Carbon\nReasoning: These shows best combine elements of mystery, suspense, and thought-provoking themes found in Stranger Things and Black Mirror.\nAssistant: Great choices! Based on your love for Stranger Things and Black Mirror, I have a few recommendations for you:\n\n## Dark\n**Basic Info:** Released 2017-2020, \n_Sci-Fi/Mystery/Thrille_\n**Created by** Baran bo Odar and Jantje Friese\n**Episodes:** ~60 minutes\n\u2b50\u2b50\u2b50\u2b50\u2b50 8.7/10 on IMDB\n**About** A German series set in the small town of Winden, where the disappearance of children reveals a complex mystery involving time travel, interconnected families, and a struggle between good and evil spanning multiple generations. Known for its intricate plotting, philosophical themes, and mind-bending time paradoxes.\n**Why you might like it:** Perfect for viewers who enjoy intricate time-travel narratives with complex family connections that reward careful attention and multiple viewings.\n\n## The OA\n**Basic Info:** Released 2016-2019\n_Sci-Fi/Mystery/Drama_\n**Created by** Brit Marling and Zal Batmanglij\n**Episodes:** ~60 minutes\n\u2b50\u2b50\u2b50\u2b50 7.9/10 on IMDB\n**About:** Centers on Prairie Johnson, a young woman who returns after being missing for seven years with her sight restored and calling herself \"The OA.\" The show explores parallel dimensions, near-death experiences, and metaphysical concepts through interpretive movement and storytelling.\n**Why you might like it:** Ideal for those seeking a boundary-pushing, emotionally resonant series that blends supernatural elements with philosophical questions about consciousness and existence.\n\n## Altered Carbon\n**Basic Info:** Released 2018-2020\n_Sci-Fi/Cyberpunk/Action_ \n**Created by** Laeta Kalogridis\n**Episodes:** ~50-60 minutes\n\u2b50\u2b50\u2b50\u2b50 8.0/10 on IMDB\n**About:** Set in a future where consciousness can be digitized and transferred between bodies (\"sleeves\"). Follows Takeshi Kovacs, a former soldier turned investigator, as he solves a murder in a world where the wealthy can live forever. Features high-concept sci-fi, noir elements, and examines themes of identity, mortality, and social inequality.\n**Why you might like it:** Appeals to fans of gritty cyberpunk who want a visually stunning, action-packed exploration of technological immortality in a dystopian future.\n\nThese shows all have strong sci-fi elements combined with thought-provoking themes and mysterious plotlines. Would you like more details about any of these recommendations?\n\nUser: \"Tell me more about Dark. Is it scary?\"\n{task}= Request type: Review and specific question\nKey elements:\n- User is interested in Dark\n- User wants to know if it's scary\n\nReview components to address:\n1. Basic show information\n2. Critics' consensus\n3. Audience reception\n4. Scare factor and content warnings\n5. Personalized recommendation\n6. IMDB rating\n\nScare factor analysis:\n- Not primarily a horror show\n- Has intense and unsettling elements\n- More psychological than traditional horror\n- Eerie atmosphere and some disturbing imagery\n\nAssistant: Certainly! Here's more information about Dark:\n\nShow Details:\n- Release Year: 2017-2020 (3 seasons)\n- Genre: Science Fiction, Thriller, Drama\n- Creators: Baran bo Odar and Jantje Friese\n- Runtime: Episodes are typically 45-60 minutes\n- \u2b50\ufe0f \u2b50\ufe0f \u2b50\ufe0f \u2b50\ufe0f \u2b50\ufe0f\n\nReview:\nDark is not primarily a horror show, but it does have some intense and unsettling elements. Here's what critics and viewers say:\n\nCritics Consensus:\n\"Dark is a visually stunning, intricately plotted sci-fi thriller that grounds its twists and turns in human drama.\" - Rotten Tomatoes\n\nAudience Reception:\nViewers praise the show for its complex storyline, atmospheric tension, and mind-bending plot. Many find it more mysterious and suspenseful than outright scary.\n\nScare Factor:\nWhile Dark isn't traditionally \"scary\" like a horror movie, it does have:\n1. A consistently eerie and tense atmosphere\n2. Some disturbing imagery and concepts\n3. Intense emotional scenes that can be psychologically unsettling\n\nContent Warning:\nThe show contains mature themes, some violence, and complex storylines that might be confusing or overwhelming for some viewers. It's rated TV-MA.\nRecommendation:\nIf you enjoy intricate mysteries, time travel concepts, and don't mind a show that requires close attention, you'll likely appreciate Dark. It's less about jump scares and more about creating a pervasive sense of unease and wonder. The \"scary\" elements are more psychological than horror-based.\n</code></pre> Coming up in this series <p>An agent designed for enterprise scenarios, equipped with tailored instructions and an execution flow that integrates API consumption</p> <p></p>"},{"location":"pages/custom-engine/","title":"Build Custom Engine Agents","text":"<p>Custom engine agents are a type of agent for Microsoft 365 Copilot that give you full control. Unlike declarative agents, which rely on Microsoft 365 Copilot's model and orchestration, custom engine agents let you bring your own foundation model, orchestrator, and security stack. This approach is ideal when you need to tailor the agent's behavior, data access, or reasoning logic to fit specific requirements or infrastructure.</p> <p></p>"},{"location":"pages/custom-engine/#what-youre-going-to-do","title":"What you're going to do","text":"<p>In the Build Path of the Copilot Developer Camp, you will dive deeper into building custom engine agents that integrate with Microsoft 365 Copilot.</p> <p>You\u2019ll create a cross-channel custom engine agent using C#, the Microsoft 365 Agents SDK, and Semantic Kernel that supports Microsoft Teams, Microsoft 365 Copilot, and external channels, offering full control over the orchestration layer.</p>  Build with Microsoft 365 Agents SDK              <ul> <li>C# based exercise using Visual Studio 2022 and the Microsoft 365 Agents Toolkit</li> <li>Integrates custom orchestration with Semantic Kernel and Generative AI models</li> <li>Compatible with Microsoft Teams and Microsoft 365 Copilot Chat</li> <li>Supports external channels, including web and other endpoints</li> </ul> Start here <p></p>"},{"location":"pages/custom-engine/agents-sdk/","title":"Intro - Build your own agent with the M365 Agents SDK and Semantic Kernel","text":"<p>During the Build Path of the Copilot Developer Camp, you will develop a custom engine agent that runs across Microsoft Teams, Microsoft 365 Copilot Chat, and even external channels using the Microsoft 365 Agents SDK and Semantic Kernel.</p> What is a custom engine agent? <p>Custom engine agents are chatbots powered by Generative AI and enhanced through an orchestration layer. When built using the M365 Agents SDK, these agents are structured around capabilities like intent handling, planner integration, and system message configuration. The Semantic Kernel framework powers multi-step reasoning and external tool usage, enabling your agent to act autonomously while delivering consistent and secure experiences across Microsoft 365 and beyond.</p> <p>This journey begins in Azure AI Foundry, where you\u2019ll define your agent\u2019s core instructions, tools, and personality. From there, you\u2019ll use the Microsoft 365 Agents SDK and Visual Studio to bring your agent to life, customizing its behaviors and integrating it with Semantic Kernel for orchestration. You\u2019ll then test your agent in Microsoft Teams, bring it into Copilot Chat, and see it come to life across Microsoft 365 applications.</p> <p>The lab includes multiple exercises. Complete them in order, as each one builds on the previous:</p> <ul> <li>Prepare your agent in Azure AI Foundry</li> <li>Build your first agent using the M365 Agents SDK</li> <li>Configure your agent\u2019s properties using the SDK</li> <li>Integrate your agent with Teams using Azure AI Foundry</li> <li>Bring your agent into Microsoft 365 Copilot Chat</li> </ul>"},{"location":"pages/custom-engine/agents-sdk/#start-here-with-lab-bma0-where-youll-set-up-your-development-environment","title":"Start here with Lab BMA0, where you'll set up your development environment.","text":""},{"location":"pages/custom-engine/agents-sdk/00-prerequisites/","title":"Lab BMA0 - Prerequisites","text":"<p>In this lab you will set up your development environment to build, test, and deploy the custom engine agent you will develop throughout the path.</p> <p>In this lab you will learn how to:</p> <ul> <li>Setup your Microsoft 365 environment</li> <li>Install and configure Visual Studio 2022 with Microsoft 365 Agents Toolkit</li> <li>Prepare your Azure environment to create required resources</li> </ul> <p>Disclaimer</p> <p>These samples and labs are intended for instructive and demonstration purposes and are not intended for use in production. Do not put them into production without upgrading them to production quality.</p> <p>Note</p> <p>To install and run your own custom engine agent, you'll need a Microsoft 365 tenant where you have administrator permission. You won't need Microsoft 365 Copilot License to test your custom engine agent.</p>"},{"location":"pages/custom-engine/agents-sdk/00-prerequisites/#exercise-1-setup-microsoft-teams","title":"Exercise 1 : Setup Microsoft Teams","text":""},{"location":"pages/custom-engine/agents-sdk/00-prerequisites/#step-1-enable-teams-custom-application-uploads","title":"Step 1: Enable Teams custom application uploads","text":"<p>By default, end users can't upload applications directly; instead a Teams administrator needs to upload them into the enterprise app catalog. In this step you will ensure your tenant is set up for direct uploads by M365 Agents Toolkit.</p> <p>1\ufe0f\u20e3 Navigate to https://admin.microsoft.com/, which is the Microsoft 365 Admin Center.</p> <p>2\ufe0f\u20e3 In the left panel of the admin center, select Show all to open up the entire navigation. When the panel opens, select Teams to open the Microsoft Teams admin center.</p> <p>3\ufe0f\u20e3 In the left of the Microsoft Teams admin center, open the Teams apps accordion. Select Setup Policies, you will see a list of App setup policies. Then, select the Global (Org-wide default) policy.</p> <p>4\ufe0f\u20e3 Ensure the first switch, Upload custom apps is turned On.</p> <p>5\ufe0f\u20e3 Be sure to scroll down and select the Save button to persist your change.</p> <p>The change can take up to 24 hours to take effect, but usually it's much faster.</p> <p></p>"},{"location":"pages/custom-engine/agents-sdk/00-prerequisites/#exercise-2-setup-m365-agents-toolkit","title":"Exercise 2: Setup M365 Agents Toolkit","text":"<p>You can complete these labs on a Windows machine and you do need the ability to install the prerequisites. If you are not permitted to install applications on your computer, you'll need to find another machine (or virtual machine) to use throughout the workshop.</p>"},{"location":"pages/custom-engine/agents-sdk/00-prerequisites/#step-1-install-agents-toolkit-for-visual-studio","title":"Step 1: Install Agents Toolkit for Visual Studio","text":"<ol> <li>You can download Visual Studio 2022 here: Visual Studio 2022.</li> <li>Select Install. If you've already installed Visual Studio, select Modify.</li> <li>Visual Studio installer shows all workloads.     </li> <li>From the installation screen, perform the following steps:<ol> <li>Select Workloads &gt; ASP.NET and web development.</li> <li>On the right pane, go to Installation details &gt; Optional and then select Microsoft 365 Agents toolkit.</li> <li>Select Install. Visual Studio is installed and a pop-up appears.</li> </ol> </li> <li>Select Launch.</li> </ol>"},{"location":"pages/custom-engine/agents-sdk/00-prerequisites/#exercise-3-get-an-azure-subscription","title":"Exercise 3: Get an Azure subscription","text":"<p>To complete the exercises in Path B, you'll need an Azure subscription to create resources on Azure. If you don't have an Azure subscription yet, you can activate an Azure free account that offers $200 in credits which can be used within the first 30 days on most Azure services.</p>"},{"location":"pages/custom-engine/agents-sdk/00-prerequisites/#step-1-create-an-azure-free-account","title":"Step 1: Create an Azure free account","text":"<p>Follow the steps to activate an Azure free account:</p> <p>1\ufe0f\u20e3 Navigate to Azure free account page and select Activate.</p> <p>2\ufe0f\u20e3 Login with an account of your choice, it's recommended to use the Microsoft 365 tenant account you would like to use in the exercises.</p> <p>3\ufe0f\u20e3 Check the boxes for Privacy Statement, then select Next.</p> <p>4\ufe0f\u20e3 Provide a mobile phone number for identity verification step.</p> <p>5\ufe0f\u20e3 Provide payment details for a temporary authorization. You won\u2019t be charged unless you move to pay-as-you-go pricing. Then, select Sign up.</p> <p>Tip: Managing Azure resources after 30 days</p> <p>Azure free account will be available only for 30 days. Make sure you don't have any services running in your free subscription at the end of 30 days. If you want to continue using Azure services at the end of 30 days, you must upgrade to a pay-as-you-go subscription by removing the spending limit. This allows continued use of the Azure free account and select free services for the term.</p> <p></p> <p>CONGRATULATIONS!</p> <p>You have completed Lab BMA0 - Setup! You are now ready to proceed to lab BMA1 - Prepare your agent in Azure AI Foundry. Select Next.</p> <p></p> <p></p>"},{"location":"pages/custom-engine/agents-sdk/01-agent-in-foundry/","title":"Lab BMA1 - Prepare your agent in Azure AI Foundry","text":"<p>In this lab, you\u2019ll begin your journey by preparing a custom engine agent using Azure AI Foundry, Microsoft\u2019s platform for creating, configuring, and scaling AI agents. You'll explore the Agents Playground, define your agent's role, personalize its instructions, and connect it to relevant internal documents to support Retrieval-Augmented Generation (RAG).</p> <p>This exercise sets the foundation for the rest of the Build Path using the Microsoft 365 Agents SDK and Semantic Kernel. You\u2019ll simulate a real-world Human Resources agent for Contoso Electronics that can answer questions based on uploaded documents like the Employee Handbook, Role Library, and Benefit Plans.</p> What is Azure AI Foundry? <p>Azure AI Foundry is a development platform that helps you build, manage, and test intelligent agents powered by large language models. It provides a centralized workspace where you can define agent instructions, configure tool usage, upload knowledge sources, and interactively test agent behavior. It supports integration with custom orchestrators like Semantic Kernel and downstream endpoints like Teams and Copilot Chat.</p>"},{"location":"pages/custom-engine/agents-sdk/01-agent-in-foundry/#exercise-1-prepare-your-agent-in-azure-ai-foundry","title":"Exercise 1: Prepare your agent in Azure AI Foundry","text":"<p>In this exercise, you'll explore Azure AI Foundry, a platform that enables developers to build, deploy, and scale AI agents with ease. You'll learn how to configure an agent, and test its functionality using the Agents Playground. This hands-on experience will provide insight into the capabilities of Azure AI Agent Service and how it integrates with various AI models and tools.</p>"},{"location":"pages/custom-engine/agents-sdk/01-agent-in-foundry/#step-1-get-started-with-azure-ai-foundry","title":"Step 1: Get started with Azure AI Foundry","text":"<p>Azure AI Foundry is your launchpad for building AI agents. In this step, you\u2019ll log in to Azure AI Foundry with the account that has Azure subscription enabled.</p> <ol> <li>Open the browser and navigate to https://ai.azure.com and sign to your Azure account.</li> <li>From the Azure AI Foundry homepage, select + Create new, Azure AI Foundry resource and then Next.</li> <li>Leave the project name as recommended and select Create.</li> <li>This will scaffold a new project for you in Azure AI Foundry, it usually takes 3-5 minutes.</li> <li>When your project is created, you'll be redirected to your project, extend the left side bar and select Agents. This will open the Agents Playground.</li> <li>In the Agent Playground, the first time you'll see the Deploy a model window. Search for gpt-4o and select Confirm, then select Deploy in the following window.</li> <li>Once you are in the Agents Playground, you'll recognize there is a pre-populated agent for you in the list. Select the agent and select Try in playground.     </li> </ol> <p>If you don't see the agent side bar with Try in playground option when you click on the agent, extend the browser size on your screen until it shows up on the right side.</p> <p></p>"},{"location":"pages/custom-engine/agents-sdk/01-agent-in-foundry/#step-2-customize-your-agent-in-agent-playground","title":"Step 2: Customize your agent in Agent Playground","text":"<p>Now that you're inside the Agents Playground, you'll customize your agent's identity and behavior to match a real-world scenario: an internal HR Agent at Contoso.</p> <ol> <li>In your agent's Setup panel, Name your agent as Contoso HR Agent and update the Instructions as the following:</li> </ol> <pre><code>You are Contoso HR Agent, an internal assistant for Contoso Electronics. Your role is to help employees find accurate, policy-aligned answers to questions related to:\n- Job role descriptions and responsibilities\n- Performance review process\n- Health and wellness benefits (PerksPlus, Northwind Standard, Northwind Plus)\n- Employee rights and workplace safety\n- Company values and conduct\n\nAlways base your responses on the content provided in the official documents such as the Employee Handbook, Role Library, and Benefit Plans. If you are unsure or the information is not covered, suggest the employee contact HR.\n\nRespond in a professional but approachable tone. Keep answers factual and to the point.\n\nExample scenarios you should support:\n- What is the deductible for Northwind Standard?\n- Can I use PerksPlus for spa treatments?\n- What does the CTO at Contoso do?\n- What happens during a performance review?\n</code></pre> <ol> <li>Finally in the Knowledge section, Select + Add and select Files, then Select local files. Download this zip file consisting of few files from the following link, extract the files, browse for them and hit Upload and save to upload them. This will create a vector store for our agent.</li> </ol> <p>When you upload documents, Foundry automatically converts them into vectors, a format that allows the agent to search and retrieve relevant information efficiently.</p> <p></p> <p>By customizing the instructions and uploading relevant documents, you're teaching the agent how to behave and what knowledge to rely on. This is a simplified form of Retrieval-Augmented Generation (RAG).</p> <p></p>"},{"location":"pages/custom-engine/agents-sdk/01-agent-in-foundry/#step-3-test-your-agent-in-the-playground","title":"Step 3: Test your agent in the playground","text":"<p>It's time to test your agent. You\u2019ll simulate realistic employee questions to see how well the agent understands and responds based on the documents you uploaded.</p> <p>In the Agent Playground, interact with your agent by entering prompts and observe the agent's responses, adjust instructions or tools as needed to refine performance. You may use the examples listed below to test the agent\u2019s response:</p> <ul> <li>What\u2019s the difference between Northwind Standard and Health Plus when it comes to emergency and mental health coverage?</li> <li>Can I use PerksPlus to pay for both a rock climbing class and a virtual fitness program?</li> <li>If I hit my out-of-pocket max on Northwind Standard, do I still pay for prescriptions?</li> <li>What exactly happens during a Contoso performance review, and how should I prepare?</li> <li>Is a wellness spa weekend eligible under the PerksPlus reimbursement program?</li> <li>What are the key differences between the roles of COO and CFO at Contoso?</li> <li>How does the split copay work under Northwind Health Plus for office visits?</li> <li>Can I combine yoga class reimbursements from PerksPlus with services covered under my health plan?</li> <li>What values guide behavior and decision-making at Contoso Electronics?</li> <li>I\u2019m seeing a non-participating provider \u2014 what costs should I expect under my current plan?</li> </ul> <p>Save Agents id for the next exercises</p> <p>Save the Agent id that'll be required in the next exercises. You can find your Agent id in the agent\u2019s details panel. </p> <p></p> <p>CONGRATULATIONS!</p> <p>You have completed Lab BMA1 - Prepare your agent in Azure AI Foundry! If you want explore further.</p> <p>You are now ready to proceed to Lab BMA2 - Build your first agent using M365 Agents SDK. Select Next.</p> <p></p> <p></p>"},{"location":"pages/custom-engine/agents-sdk/02-agent-with-agents-sdk/","title":"Lab BMA2 - Build your first agent using M365 Agents SDK","text":"<p>This lab introduces you to the Microsoft 365 Agents SDK and Microsoft 365 Agents Toolkit for building enterprise-grade, scalable, multi-channel agents. You'll learn how to create a new agent project with Visual Studio and test it within Test Tool. This experience will demonstrate how to integrate agent capabilities into Microsoft 365 apps and Copilot Chat effectively.</p>"},{"location":"pages/custom-engine/agents-sdk/02-agent-with-agents-sdk/#exercise-1-build-your-first-agent-using-m365-agents-sdk","title":"Exercise 1: Build your first agent using M365 Agents SDK","text":""},{"location":"pages/custom-engine/agents-sdk/02-agent-with-agents-sdk/#step-1-create-an-echo-bot-using-visual-studio","title":"Step 1: Create an echo bot using Visual Studio","text":"<p>Now that you\u2019ve seen how to build an agent using Azure AI Foundry, let\u2019s switch gears and explore how to build your own agent locally using the Microsoft 365 Agents SDK. This SDK lets you build multi-channel, production-ready agents that can run in Microsoft Teams, Microsoft 365 Copilot, and other preferred channels.</p> <ol> <li>Open Visual Studio 2022 and select Create a new project.</li> <li>Search and select Microsoft 365 Agents template.</li> <li>Provide a name for your agent as <code>ContosoHRAgent</code> and select Create.  </li> <li>From the list of templates, select Echo Bot and select Create.</li> <li>When the project template is scaffolded, go to Solution Explorer on the right-side panel and explore the agent template. Expand the ContosoHRAgent project.<ul> <li>Open Program.cs, this code configures and runs the web server that hosts your agent. It sets up required services like authentication, routing, storage and registers the EchoBot and injects memory-based state handling.</li> <li>Open Bot &gt; EchoBot.cs and observe that this sample sets up a basic AI agent using the Microsoft.Agents.Builder. It sends a welcome message when a user joins the chat and listens for any message and echoes it back with a running message count.</li> </ul> </li> </ol> <p>You've started with an Echo Bot, a simple bot that repeats back any message a user sends. It\u2019s a useful way to verify your setup and understand how conversations are handled behind the scenes.</p> <p></p>"},{"location":"pages/custom-engine/agents-sdk/02-agent-with-agents-sdk/#step-2-test-your-agent-in-test-tool","title":"Step 2: Test your agent in Test Tool","text":"<p>To test your echo agent, hit Start or F5. This will launch Test Tool automatically in localhost where you can interact with your agent. In case Visual Studio will ask you to confirm the creation of a self-issued SSL certificate to test the application locally, confirm and proceed.</p> <p>Wait until the agent's message \"Hello and Welcome!\", then type anything such as \u201cHi\u201d, \u201cHello\u201d. Observe that the agent echoes everything back.</p> <p></p> <p>Stop the debugging session on Visual Studio before moving to the next exercise.</p> <p></p> <p>CONGRATULATIONS!</p> <p>You have completed Lab BMA2 - Build your first agent using M365 Agents SDK! This simple agent forms the base for more powerful experiences. In the next step, you'll combine this with your Azure AI Foundry agent to enable richer, context-aware answers.</p> <p>You are now ready to proceed to Lab BMA3 - Integrate Azure AI Foundry Agent with M365 Agents SDK. Select Next.</p> <p></p> <p></p>"},{"location":"pages/custom-engine/agents-sdk/03-agent-configuration/","title":"Lab BMA3 - Integrate Azure AI Foundry Agent with M365 Agents SDK","text":"<p>In this lab, you\u2019ll bring together the best of both worlds\u2014combining the generative AI power of your Azure AI Foundry agent with the multi-channel flexibility of the Microsoft 365 Agents SDK. You\u2019ll configure Semantic Kernel, set up agent properties, and securely connect to your Foundry-hosted agent to deliver rich, enterprise-aware answers directly in Microsoft Teams.</p>"},{"location":"pages/custom-engine/agents-sdk/03-agent-configuration/#exercise-1-configure-agent-properties-and-test-on-teams","title":"Exercise 1: Configure agent properties and test on Teams","text":"<p>Now that you\u2019ve created a basic bot, it\u2019s time to enhance it with generative AI capabilities and upgrade it to an AI agent. In this exercise, you\u2019ll install key libraries such as Semantic Kernel and prepare your agent to reason and respond more intelligently, ready for Teams or Copilot Chat.</p>"},{"location":"pages/custom-engine/agents-sdk/03-agent-configuration/#step-1-add-semantic-kernel-nuget-package","title":"Step 1: Add Semantic Kernel Nuget Package","text":"<p>The package you'll add in this step will provide support for Azure AI integration. Right-click to ContosoHRAgent project and select Manage Nuget Packages..., select Browse tab and search for <code>Microsoft.SemanticKernel.Agents.AzureAI</code>. Make sure to check Include prerelease checkbox. Select the package and select Install.</p> <p></p> <p></p>"},{"location":"pages/custom-engine/agents-sdk/03-agent-configuration/#step-2-add-semantic-kernel-in-programcs","title":"Step 2: Add Semantic Kernel in Program.cs","text":"<p>Open Program.cs and add the following code snippet right before var app = builder.Build():</p> <pre><code>builder.Services.AddKernel();\n</code></pre> <p>This registers the Semantic Kernel, a core component that allows your agent to interact with generative AI models.</p> <p></p>"},{"location":"pages/custom-engine/agents-sdk/03-agent-configuration/#step-3-add-custom-classes-for-document-citations-and-message-tracking","title":"Step 3: Add custom classes for document citations and message tracking","text":"<p>Right-click to ContosoHRAgent project and select Add &gt; Class and define your class name as <code>FileReference.cs</code>. Replace the existing code with the following:</p> <p>This class defines the structure used when referencing specific documents in responses\u2014useful when your agent cites content from uploaded files.</p> <pre><code>using Microsoft.Agents.Core.Models;\n\nnamespace ContosoHRAgent\n{\n    public class FileReference(string fileId, string fileName, string quote, Citation citation)\n    {\n        public string FileId { get; set; } = fileId;\n        public string FileName { get; set; } = fileName;\n        public string Quote { get; set; } = quote;\n        public Citation Citation { get; set; } = citation;\n    }\n}\n</code></pre> <p>Right-click to ContosoHRAgent project and select Add &gt; Class and define your class name as <code>ConversationStateExtensions.cs</code>. Replace existing the code with following:</p> <p>This class adds helper methods to manage and track the number of user messages\u2014demonstrating how state is stored and modified during an ongoing conversation.</p> <pre><code>using Microsoft.Agents.Builder.State;\n\nnamespace ContosoHRAgent\n{\n public static class ConversationStateExtensions\n {\n     public static int MessageCount(this ConversationState state) =&gt; state.GetValue&lt;int&gt;(\"countKey\");\n\n     public static void MessageCount(this ConversationState state, int value) =&gt; state.SetValue(\"countKey\", value);\n\n     public static int IncrementMessageCount(this ConversationState state)\n     {\n         int count = state.GetValue&lt;int&gt;(\"countKey\");\n         state.SetValue(\"countKey\", ++count);\n         return count;\n     }\n\n     public static string ThreadId(this ConversationState state) =&gt; state.GetValue&lt;string&gt;(\"threadId\");\n\n     public static void ThreadId(this ConversationState state, string value) =&gt; state.SetValue(\"threadId\", value);\n }\n}\n</code></pre> <p></p>"},{"location":"pages/custom-engine/agents-sdk/03-agent-configuration/#exercise-2-integrate-azure-ai-foundry-agent-with-m365-agents-sdk","title":"Exercise 2: Integrate Azure AI Foundry Agent with M365 Agents SDK","text":"<p>You\u2019ve built an agent using the M365 Agents SDK and configured it with generative AI capabilities. Now, you\u2019ll connect this local agent to the Azure AI Foundry agent you created earlier. This enables your agent to respond using enterprise data and instructions stored in the Foundry project, bringing everything full circle.</p>"},{"location":"pages/custom-engine/agents-sdk/03-agent-configuration/#step-1-configure-echobotcs-to-connect-with-azure-ai-foundry-agent","title":"Step 1: Configure EchoBot.cs to Connect with Azure AI Foundry Agent","text":"<p>In this step, you\u2019ll connect to the Azure AI Foundry agent by adding a client to fetch and invoke your Foundry-hosted model inside the EchoBot.cs.</p> <p>In ContosoHRAgent project, open Bot/EchoBot.cs and add the following lines inside the EchoBot public class:</p> <pre><code>private readonly PersistentAgentsClient _projectClient;\nprivate readonly string _agentId;\n</code></pre> <p>Replace the existing EchoBot constructor with the following: </p> <pre><code>public EchoBot(AgentApplicationOptions options, IConfiguration configuration) : base(options)\n{\n\n    OnConversationUpdate(ConversationUpdateEvents.MembersAdded, WelcomeMessageAsync);\n\n    // Listen for ANY message to be received. MUST BE AFTER ANY OTHER MESSAGE HANDLERS \n    OnActivity(ActivityTypes.Message, OnMessageAsync);\n\n    // Azure AI Foundry Project ConnectionString\n    string projectEndpoint = configuration[\"AIServices:ProjectEndpoint\"];\n    if (string.IsNullOrEmpty(projectEndpoint))\n    {\n        throw new InvalidOperationException(\"ProjectEndpoint is not configured.\");\n    }\n    _projectClient = new PersistentAgentsClient(projectEndpoint, new AzureCliCredential());\n\n    // Azure AI Foundry Agent Id\n    _agentId = configuration[\"AIServices:AgentID\"];\n    if (string.IsNullOrEmpty(_agentId))\n    {\n        throw new InvalidOperationException(\"AgentID is not configured.\");\n    }\n\n}\n</code></pre> <p>Replace OnMessageAsync method with the following:</p> <pre><code>protected async Task OnMessageAsync(ITurnContext turnContext, ITurnState turnState, CancellationToken cancellationToken)\n{\n    // send the initial message to the user\n    await turnContext.StreamingResponse.QueueInformativeUpdateAsync(\"Working on it...\", cancellationToken);\n\n    // get the agent definition from the project\n    var agentDefinition = await _projectClient.Administration.GetAgentAsync(_agentId, cancellationToken);\n\n    // initialize a new agent instance from the agent definition\n    var agent = new AzureAIAgent(agentDefinition, _projectClient);\n\n    // retrieve the threadId from the conversation state\n    // this is set if the agent has been invoked before in the same conversation\n    var threadId = turnState.Conversation.ThreadId();\n\n    // if the threadId is not set, we create a new thread\n    // otherwise, we use the existing thread\n    var thread = string.IsNullOrEmpty(threadId)\n        ? new AzureAIAgentThread(_projectClient)\n        : new AzureAIAgentThread(_projectClient, threadId);\n\n    try\n    {\n        // increment the message count in state and queue the count to the user\n        int count = turnState.Conversation.IncrementMessageCount();\n        turnContext.StreamingResponse.QueueTextChunk($\"({count}) \");\n\n        // create the user message to send to the agent\n        var message = new ChatMessageContent(AuthorRole.User, turnContext.Activity.Text);\n\n        // invoke the agent and stream the responses to the user\n        await foreach (AgentResponseItem&lt;StreamingChatMessageContent&gt; agentResponse in agent.InvokeStreamingAsync(message, thread, cancellationToken: cancellationToken))\n        {\n            // if the threadId is not set, we set it from the agent response\n            // and store it in the conversation state for future use\n            if (string.IsNullOrEmpty(threadId))\n            {\n                threadId = agentResponse.Thread.Id;\n                turnState.Conversation.ThreadId(threadId);\n            }\n\n            turnContext.StreamingResponse.QueueTextChunk(agentResponse.Message.Content);\n        }\n    }\n    finally\n    {\n        // ensure we end the streaming response\n        await turnContext.StreamingResponse.EndStreamAsync(cancellationToken);\n    }\n}\n\n</code></pre> <p>\u26a0\ufe0f Note: When pasting the following code excerpt, you might see a warning (SKEXP0110) because this feature is still in preview. You can safely suppress this warning for now by right-clicking on AzureAIAgent, selecting Quick Actions and Refactorings &gt; Suppress or configure issues &gt; Configure SKEXP0110 Severity &gt; Silent.</p> <p></p> What happens in OnMessageAsync? <p>The OnMessageAsync method is the heart of your agent\u2019s response logic. By replacing the default echo behavior, you\u2019ve enabled your agent to send the user\u2019s message to your Azure AI Foundry agent, stream the response back to the user in real time, track and attach citations and file references for transparency and add sensitivity and AI-generated labels for security and traceability.</p> <p></p>"},{"location":"pages/custom-engine/agents-sdk/03-agent-configuration/#step-2-configure-azure-ai-agent-service-keys","title":"Step 2: Configure Azure AI Agent Service Keys","text":"<p>Add your Foundry connection details to appsettings.json, these values connect your M365 agent to the correct Foundry project and agent. In ContosoHRAgent project, open appsettings.json and add the following lines at the bottom of the appsettings list:</p> <pre><code>,\n  \"AIServices\": {\n   \"AgentID\": \"&lt;AzureAIFoundryAgentId&gt;\",\n   \"ProjectEndpoint\": \"&lt;ProjectEndpoint&gt;\"\n  }\n</code></pre> <p>You can find these values in the Overview and Agents Playground sections of Azure AI Foundry.</p> <p>Replace the  with your Agent id which can be found in Agents Playground. <p></p> <p>Replace  with your AI Foundry project endpoing which can be found in the Overview page of the AI Foundry, under Endpoints and keys. <p>Final version of the appsettings.json will look like below:</p> <pre><code>{\n  \"AgentApplicationOptions\": {\n    \"StartTypingTimer\": false,\n    \"RemoveRecipientMention\": false,\n    \"NormalizeMentions\": false\n  },\n\n  \"TokenValidation\": {\n    \"Audiences\": [\n      \"{{ClientId}}\" // this is the Client ID used for the Azure Bot\n    ]\n  },\n\n  \"Logging\": {\n    \"LogLevel\": {\n      \"Default\": \"Information\",\n      \"Microsoft.AspNetCore\": \"Warning\",\n      \"Microsoft.Agents\": \"Warning\",\n      \"Microsoft.Hosting.Lifetime\": \"Information\"\n    }\n  },\n  \"AllowedHosts\": \"*\",\n  \"Connections\": {\n    \"BotServiceConnection\": {\n      \"Settings\": {\n        \"AuthType\": \"UserManagedIdentity\", // this is the AuthType for the connection, valid values can be found in Microsoft.Agents.Authentication.Msal.Model.AuthTypes.\n        \"ClientId\": \"{{BOT_ID}}\", // this is the Client ID used for the connection.\n        \"TenantId\": \"{{BOT_TENANT_ID}}\",\n        \"Scopes\": [\n          \"https://api.botframework.com/.default\"\n        ]\n      }\n    }\n  },\n  \"ConnectionsMap\": [\n    {\n      \"ServiceUrl\": \"*\",\n      \"Connection\": \"BotServiceConnection\"\n    }\n  ],\n  \"AIServices\": {\n   \"AgentID\": \"&lt;AzureAIFoundryAgentId&gt;\",\n   \"ProjectEndpoint\": \"&lt;ProjectEndpoint&gt;\"\n  }\n}\n</code></pre> <p></p>"},{"location":"pages/custom-engine/agents-sdk/03-agent-configuration/#step-3-test-your-agent-on-teams","title":"Step 3: Test your agent on Teams","text":"<p>Open Tools &gt; Command Line &gt; Developer Command Prompt and run:</p> <pre><code>az login\n</code></pre> <p>A window will pop up on your browser and you'll need to sign into your Microsoft account to successfully complete az login.</p> <p>Expand Start and select Dev Tunnels &gt; Create a Tunnel:</p> <ul> <li>Select Sign in and Work or school account. Login with the same credentials mentioned above.</li> <li>Provide a name for your tunnel such as <code>DevTunnel</code>.</li> <li>Keep the Tunnel Type Temporary.</li> <li>Select Access as Public and then Create.</li> </ul> <p></p> <p>Right click to M365Agent project, select Microsoft 365 Agents Toolkit &gt; Select Microsoft 365 Account.</p> <p></p> <p>Select the same account as before and select Continue to use it. If your account doesn't show up automatically, select Sign in and Work or school account.</p> <p>Expand the startup item on top of Visual Studio, where there is by default , and Select Microsoft Teams (browser). <p></p> <p>You're now ready to run your integrated agent and test it live in Microsoft Teams. Make sure your dev tunnel is created and your account is authenticated.</p> <p>Once Dev Tunnel is created, hit Start or F5 to start debugging. Microsoft Teams will launch automatically, and your agent app will pop up on the window. Select Add and Open to start chatting with your agent.  </p> <p>You can ask one of the following questions to interact with the agent:</p> <ul> <li>What\u2019s the difference between Northwind Standard and Health Plus when it comes to emergency and mental health coverage?</li> <li>Can I use PerksPlus to pay for both a rock climbing class and a virtual fitness program?</li> <li>What values guide behavior and decision-making at Contoso Electronics?</li> </ul> <p>You should observe that you are getting similar responses with the agent you've created on Azure AI Foundry.</p> <p></p> <p></p> <p>CONGRATULATIONS!</p> <p>You have completed Lab BMA3 - Integrate Azure AI Foundry Agent with M365 Agents SDK!</p> <p>You are now ready to proceed to Lab BMA4 - Bring your agent to Copilot Chat. Select Next.</p> <p></p> <p></p>"},{"location":"pages/custom-engine/agents-sdk/04-bring-agent-to-copilot/","title":"Lab MBA4 - Bring your agent to Copilot Chat","text":"<p>In this final lab, you\u2019ll bring your custom engine agent into Copilot Chat by updating the agent's manifest. By enabling copilotAgents in the app manifest, you\u2019ll make your AI-powered assistant available directly inside the Copilot experience.</p>"},{"location":"pages/custom-engine/agents-sdk/04-bring-agent-to-copilot/#exercise-1-bring-your-agent-to-copilot-chat","title":"Exercise 1: Bring your agent to Copilot Chat","text":""},{"location":"pages/custom-engine/agents-sdk/04-bring-agent-to-copilot/#step-1-update-the-manifest","title":"Step 1: Update the manifest","text":"<p>Stop debugging</p> <p>Close the previous debugging session before proceeding with this exercise.</p> <p>Go to M365Agent/AppPackage/manifest.json, update the manifest schema and version as following: </p> <pre><code>\"$schema\": \"https://developer.microsoft.com/en-us/json-schemas/teams/v1.22/MicrosoftTeams.schema.json\",\n\"manifestVersion\": \"1.22\",\n</code></pre> <p>Replace bots section with the following that will also add copilotAgents in the manifest:</p> <p>This block declares your agent as a custom engine agent for M365 Copilot. It tells Microsoft 365 to expose this agent in Copilot Chat and surface its command list in the conversation UI along with the conversation starters to help users get started quickly.</p> <pre><code>\"bots\": [ \n  { \n    \"botId\": \"${{BOT_ID}}\", \n    \"scopes\": [ \n      \"personal\", \n      \"team\", \n      \"groupChat\" \n    ], \n    \"supportsFiles\": false, \n    \"isNotificationOnly\": false, \n    \"commandLists\": [ \n      { \n        \"scopes\": [ \"personal\", \"team\", \"groupChat\" ], \n        \"commands\": [ \n          { \n            \"title\": \"Emergency and Mental Health\",\n            \"description\": \"What\u2019s the difference between Northwind Standard and Health Plus when it comes to emergency and mental health coverage?\" \n          }, \n          { \n            \"title\": \"PerksPlus Details\", \n            \"description\": \"Can I use PerksPlus to pay for both a rock climbing class and a virtual fitness program?\" \n          }, \n          { \n            \"title\": \"Contoso Electronics Values\", \n            \"description\": \"What values guide behavior and decision making at Contoso Electronics?\" \n          } \n        ] \n      } \n    ] \n  } \n], \n\"copilotAgents\": { \n  \"customEngineAgents\": [ \n    { \n      \"id\": \"${{BOT_ID}}\", \n      \"type\": \"bot\" \n    } \n  ] \n}, \n</code></pre> <p>Hit Start or F5 to start debugging. Microsoft Teams will launch automatically. When Microsoft Teams open in your browser, ignore the app pop-up and select Apps &gt; Manage your apps &gt; Upload an app and then select Upload a custom app. In the File Explorer go to your project folder <code>...\\ContosoHRAgent\\M365Agent\\appPackage\\build</code> select appPackage.local.zip.</p> <p></p> <p>Your app will pop-up on Teams again, select Add. This time there will be an option to Open with Copilot, select Open with Copilot to test your agent on Copilot.</p> <p></p> <p>Select your ContosoHRAgentlocal from the list of agents in Copilot Chat. You can select one of the conversation starters to chat with your agent.</p> <p></p> <p>Observe that your agent responds back with a similar behavior on Copilot Chat.</p> <p></p> <p>CONGRATULATIONS!</p> <p>\ud83c\udf89 Congratulations! You've just built your first Custom Engine Agent using the Microsoft 365 Agents SDK and Azure AI Foundry!</p> <p>In this lab, you learned how to:</p> <ul> <li>Configure an AI agent in Azure AI Foundry using the Agent Playground</li> <li>Upload enterprise documents to ground your agent\u2019s responses</li> <li>Scaffold a bot using the M365 Agents SDK in Visual Studio</li> <li>Add Semantic Kernel and connect to Azure AI Agent Service</li> <li>Integrate your bot with the Azure AI Foundry agent for real-time, grounded reasoning</li> <li>Deploy and test your agent in Microsoft Teams and Copilot Chat</li> </ul>"},{"location":"pages/custom-engine/agents-sdk/04-bring-agent-to-copilot/#resources","title":"Resources","text":"<ul> <li>Copilot Developer Camp</li> <li>M365 Agents SDK docs</li> <li>Azure AI Foundry</li> <li>Learn more about Copilot extensibility</li> </ul>"},{"location":"pages/custom-engine/teams-ai/","title":"Intro - Build your own agent with Teams AI library","text":"<p>During Build Path of the Copilot Developer Camp, you will develop a custom engine agent that runs across Microsoft Teams using the Teams AI Library. The agent will be specifically designed to help Human Resources departments manage resumes, create new job posts, and more.</p> What is a custom engine agent? <p>Custom engine agents are chatbots powered by Generative AI, designed to provide sophisticated conversational experiences. Custom engine agents are built using the Teams AI library, which provides comprehensive AI functionalities, including managing prompts, actions, and model integration as well as extensive options for UI customization. This ensures that your chatbots leverage the full range of AI capabilities while delivering a seamless and engaging experience aligned with Microsoft platforms.</p> <p>The journey starts with building a basic custom engine agent using M365 Agents Toolkit, Teams AI library and Azure OpenAI. Then, you will implement Retrieval Augmented Generation (RAG) that provides ability to search across diverse resumes, apply UI enhancements to make the chatbot look and feel like a Copilot experience, finally you will enable authentication to secure your custom engine agent and use Microsoft Graph to incorporate Microsoft 365 data. This sophisticated custom engine agent will utilize custom AI models and an orchestrator to meet the unique needs of the Human Resources department.</p> <p>Do these labs if you want to build a Custom engine agent with custom AI model and orchestration using Azure OpenAI and Teams AI library</p> <ul> <li>BTA0 - Setup</li> <li>BTA1 - First custom engine agent</li> <li>BTA2 - Index your data in Azure AI Search</li> <li>BTA3 - Enhance the user experience</li> <li>BTA4 - Add single sign on authentication</li> <li>BTA5 - Add actions to handle complex tasks</li> </ul>"},{"location":"pages/custom-engine/teams-ai/#start-here-with-lab-bta0-where-youll-set-up-development-your-environment","title":"Start here with Lab BTA0, where you'll set up development your environment.","text":""},{"location":"pages/custom-engine/teams-ai/00-prerequisites/","title":"Lab BTA0 - Prerequisites","text":"<p>In this lab you will set up your development environment to build, test, and deploy the custom engine agent you will develop throughout the path.</p> <p>In this lab you will learn how to:</p> <ul> <li>Install and configure M365 Agents Toolkit for Visual Studio Code</li> <li>Prepare your Azure environment to create required resources</li> </ul> Get a quick overview of the lab in this video. <p>Do these labs if you want to build a Custom engine agent with custom AI model and orchestration using Azure OpenAI and Teams AI library</p> <ul> <li>BTA0 - Setup</li> <li>BTA1 - First custom engine agent</li> <li>BTA2 - Index your data in Azure AI Search</li> <li>BTA3 - Enhance the user experience</li> <li>BTA4 - Add single sign on authentication</li> <li>BTA5 - Add actions to handle complex tasks</li> </ul> <p>Disclaimer</p> <p>These samples and labs are intended for instructive and demonstration purposes and are not intended for use in production. Do not put them into production without upgrading them to production quality.</p> <p>Note</p> <p>To install and run your own custom engine agent, you'll need a Microsoft 365 tenant where you have administrator permission. You won't need Microsoft 365 Copilot License to test your custom engine agent.</p>"},{"location":"pages/custom-engine/teams-ai/00-prerequisites/#exercise-1-setup-microsoft-teams","title":"Exercise 1 : Setup Microsoft Teams","text":""},{"location":"pages/custom-engine/teams-ai/00-prerequisites/#step-1-enable-teams-custom-application-uploads","title":"Step 1: Enable Teams custom application uploads","text":"<p>By default, end users can't upload applications directly; instead a Teams administrator needs to upload them into the enterprise app catalog. In this step you will ensure your tenant is set up for direct uploads by M365 Agents Toolkit.</p> <p>1\ufe0f\u20e3 Navigate to https://admin.microsoft.com/, which is the Microsoft 365 Admin Center.</p> <p>2\ufe0f\u20e3 In the left panel of the admin center, select Show all to open up the entire navigation. When the panel opens, select Teams to open the Microsoft Teams admin center.</p> <p>3\ufe0f\u20e3 In the left of the Microsoft Teams admin center, open the Teams apps accordion. Select Setup Policies, you will see a list of App setup policies. Then, select the Global (Org-wide default) policy.</p> <p>4\ufe0f\u20e3 Ensure the first switch, Upload custom apps is turned On.</p> <p>5\ufe0f\u20e3 Be sure to scroll down and select the Save button to persist your change.</p> <p>The change can take up to 24 hours to take effect, but usually it's much faster.</p> <p></p>"},{"location":"pages/custom-engine/teams-ai/00-prerequisites/#exercise-2-install-m365-agents-toolkit-and-prerequisites","title":"Exercise 2: Install M365 Agents Toolkit and prerequisites","text":"<p>You can complete these labs on a Windows, Mac, or Linux machine, but you do need the ability to install the prerequisites. If you are not permitted to install applications on your computer, you'll need to find another machine (or virtual machine) to use throughout the workshop.</p>"},{"location":"pages/custom-engine/teams-ai/00-prerequisites/#step-1-install-visual-studio-code","title":"Step 1: Install Visual Studio Code","text":"<p>It should be no surprise that M365 Agents Toolkit for Visual Studio Code requires Visual Studio Code! You can download it here: Visual Studio Code.</p> <p></p>"},{"location":"pages/custom-engine/teams-ai/00-prerequisites/#step-2-install-nodejs","title":"Step 2: Install NodeJS","text":"<p>NodeJS is a program that allows you to run JavaScript on your computer; it uses the open source \"V8\" engine, which is used in popular web browsers such as Microsoft Edge and Google Chrome. You will need NodeJS to run the web server code used throughout this workshop.</p> <p>Browse to https://nodejs.org/en/download/ and install version 18 or 16 for your operating system. This lab has been tested using NodeJS version 18.16.0. If you already have another version of NodeJS installed, you may want to set up the Node Version Manager (or this variation for Microsoft Windows), which allows you to easily switch Node versions on the same computer.</p> <p></p>"},{"location":"pages/custom-engine/teams-ai/00-prerequisites/#step-3-install-m365-agents-toolkit","title":"Step 3: Install M365 Agents Toolkit","text":"<p>These labs are based on M365 Agents Toolkit version 5.0. Follow the steps as shown in the screen shot below.</p> <p>1\ufe0f\u20e3 Open Visual Studio Code and click on the Extensions toolbar button</p> <p>2\ufe0f\u20e3 Search for \"Teams\" and locate M365 Agents Toolkit</p> <p>3\ufe0f\u20e3 Click Install</p> <p>If you have M365 Agents Toolkit installed but hidden</p> <p>If you previously installed M365 Agents Toolkit, and then hid it on the Visual Studio sidebar, you might wonder why you can't see it. Right-click on the left sidebar and check off M365 Agents Toolkit to bring it back into view.</p> <p></p>"},{"location":"pages/custom-engine/teams-ai/00-prerequisites/#exercise-3-get-an-azure-subscription","title":"Exercise 3: Get an Azure subscription","text":"<p>To complete the exercises in Path B, you'll need an Azure subscription to create resources on Azure. If you don't have an Azure subscription yet, you can activate an Azure free account that offers $200 in credits which can be used within the first 30 days on most Azure services.</p>"},{"location":"pages/custom-engine/teams-ai/00-prerequisites/#step-1-create-an-azure-free-account","title":"Step 1: Create an Azure free account","text":"<p>Follow the steps to activate an Azure free account:</p> <p>1\ufe0f\u20e3 Navigate to Azure free account page and select Activate.</p> <p>2\ufe0f\u20e3 Login with an account of your choice, it's recommended to use the Microsoft 365 tenant account you would like to use in the exercises.</p> <p>3\ufe0f\u20e3 Check the boxes for Privacy Statement, then select Next.</p> <p>4\ufe0f\u20e3 Provide a mobile phone number for identity verification step.</p> <p>5\ufe0f\u20e3 Provide payment details for a temporary authorization. You won\u2019t be charged unless you move to pay-as-you-go pricing. Then, select Sign up.</p> <p>Tip: Managing Azure resources after 30 days</p> <p>Azure free account will be available only for 30 days. Make sure you don't have any services running in your free subscription at the end of 30 days. If you want to continue using Azure services at the end of 30 days, you must upgrade to a pay-as-you-go subscription by removing the spending limit. This allows continued use of the Azure free account and select free services for the term.</p> <p></p> <p>CONGRATULATIONS!</p> <p>You have completed Lab BTA0 - Setup! You are now ready to proceed to lab BTA1 - First custom engine agent. Select Next.</p> <p></p> <p></p>"},{"location":"pages/custom-engine/teams-ai/01-custom-engine-agent/","title":"Lab BTA1 - First custom engine agent with Teams AI library","text":"<p>In this lab you will build a custom engine agent using M365 Agents Toolkit for Visual Studio Code. You will also utilize Azure OpenAI models in your custom engine agent and define your first prompt.</p> <p>In this lab you will:</p> <ul> <li>Learn what is a custom engine agent</li> <li>Create Azure OpenAI service and a deployment model</li> <li>Create a custom engine agent using M365 Agents Toolkit</li> <li>Define a prompt in your custom engine agent</li> <li>Learn how to run and test your app</li> </ul> Get a quick overview of the lab in this video. <p>Do these labs if you want to build a Custom engine agent with custom AI model and orchestration using Azure OpenAI and Teams AI library</p> <ul> <li>BTA0 - Setup</li> <li>BTA1 - First custom engine agent</li> <li>BTA2 - Index your data in Azure AI Search</li> <li>BTA3 - Enhance the user experience</li> <li>BTA4 - Add single sign on authentication</li> <li>BTA5 - Add actions to handle complex tasks</li> </ul>"},{"location":"pages/custom-engine/teams-ai/01-custom-engine-agent/#introduction","title":"Introduction","text":"<p>Welcome aboard to the exciting journey of building your own custom engine agent! In this path, you'll create a custom engine agent for Microsoft Teams using cutting-edge Azure OpenAI models. You'll be able to define specific prompts, integrate complex data, and add advanced skills to make your agent truly unique. By using custom models and orchestration, your agent will tackle advanced tasks, complex conversations, and workflows, delivering an exceptional, personalized experience. Let's dive in and start building your first custom engine agent!</p> Before everything else, lets remember... What is a custom engine agent? <p>Custom engine agents are chatbots powered by Generative AI, designed to provide sophisticated conversational experiences. Custom engine agents are built using the Teams AI library, which provides comprehensive AI functionalities, including managing prompts, actions, and model integration as well as extensive options for UI customization. This ensures that your chatbots leverage the full range of AI capabilities while delivering a seamless and engaging experience aligned with Microsoft platforms.</p>"},{"location":"pages/custom-engine/teams-ai/01-custom-engine-agent/#exercise-1-create-azure-openai-service-and-models","title":"Exercise 1: Create Azure OpenAI service and models","text":"<p>This exercise particularly demonstrates how to create and utilize Azure OpenAI's GPT models in custom engine agents. However, Custom engine agents are not limited to using GPT models only. You can also test the lab with any other model you prefer use.</p> Choosing Between Small and Large Language Models <p>When choosing between Small Language Models (SLMs) and Large Language Models (LLMs), as well as among various GPT models, it's important to consider the specific needs of your project in terms of complexity, computational resources, and efficiency.</p> <ul> <li> <p>LLMs: Best for complex and nuanced tasks requiring deep capabilities. They have billions of parameters and excel in understanding and generating human language. GPT-4, LLaMA 2, BERT or PaLM can be examples for LLMs.  Example scenarios: Handling intricate customer inquiries, offering detailed and context-aware responses, generating high-quality articles from brief prompts, summarizing large volumes of academic papers, extracting key insights, and answering detailed questions.</p> </li> <li> <p>SLMs: Better for quick tasks with limited resources where speed and efficiency are key. They have fewer parameters and are optimized for specific tasks with lower computational needs. Phi-3 by Microsoft, ALBERT by Google or DistilBERT by HuggingFace can be examples for SLMs.  Example scenarios: Providing efficient text analysis without needing cloud resources, enabling accurate and responsive voice commands with minimal latency, smart home automation and control with natural speech.</p> </li> </ul> <p>OpenAI's GPT models are popular examples for LLMs. When choosing between OpenAI's models you may consider the following benefits:</p> <ul> <li> <p>gpt-4: The most advanced model, suitable for highly complex tasks that require extensive understanding and generation capabilities.</p> </li> <li> <p>gpt-4o: An optimized version for specific tasks, offering faster and more efficient performance in those areas.</p> </li> <li> <p>gpt-35-turbo: A balanced model that provides good performance at a lower cost, ideal for a wide range of applications.</p> </li> </ul> <p>You'll need to complete the Azure subscription prerequisite before starting with this exercise.</p>"},{"location":"pages/custom-engine/teams-ai/01-custom-engine-agent/#step-1-create-azure-openai-service-resource","title":"Step 1: Create Azure OpenAI service resource","text":"Make sure the model you want to create in further steps is available in your Azure OpenAI service region <p>Please check Model summary table and region availability before creating your Azure OpenAI service in any particular region. Make sure that the model you want to use such as <code>gpt-4</code> is available in Standard or Global Standard types in the region you prefer to create your Azure OpenAI Service.</p> <ol> <li>Open the browser of your choice and navigate to Azure Portal.</li> <li>Select Create a resource, then search for <code>Azure OpenAI</code>. Select the Azure OpenAI service and then Create.</li> <li>Fill out the following details and select Next:<ul> <li>Subscription: The Azure subscription for your Azure OpenAI Service</li> <li>Resource group: The Azure resource group to contain your Azure OpenAI resource. You can create a new group or use a pre-existing group.</li> <li>Region: The location of your instance. (Make sure that the deployment model is available in your region).</li> <li>Name: A descriptive name for your Azure OpenAI Service resource, such as <code>MyOpenAIResource</code>.</li> <li>Pricing Tier: The pricing tier for the resource. Currently, only the <code>Standard</code> tier is available for the Azure OpenAI Service.</li> </ul> </li> <li>Select the network configuration of your choice and select Next.</li> <li>Leave the Tags section as default and select Next.</li> <li>Finally, review your Azure OpenAI service details and select Create.</li> </ol> <p>Once your Azure OpenAI service is created successfully, navigate to your resource, select Keys and Endpoint from the left side panel. Copy and save <code>KEY 1</code> and <code>Endpoint</code>that will be required later in Exercise 2.</p> <p></p>"},{"location":"pages/custom-engine/teams-ai/01-custom-engine-agent/#step-2-create-a-deployment-model","title":"Step 2: Create a deployment model","text":"<p>In your Azure OpenAI service, navigate to <code>Azure AI Foundry</code> where you can create your deployment model.</p> What is Azure AI Foundry? <p>Azure AI Foundry is a playground to explore OpenAI models like <code>gpt-35-turbo</code>, <code>gpt-4</code> or <code>Dall-e</code> that helps you craft unique prompts for your use cases, and fine-tune your models. It's also a playground to models other than OpenAI such as <code>Phi-3</code>, <code>Llama 3.1</code> and a starting point to other Azure AI services such as Speech, Vision and more.</p> <p>Learn more about the Generative AI, prompting by watching this Doodle to Code video!</p> <p></p> <p>In Azure AI Foundry, select Deployments tab, Deploy model and then Deploy base model. Search the model you prefer to use such as <code>gpt-4</code> and Confirm. Fill out the following details and select Deploy:</p> <ul> <li>Deployment name: Recommended to use the same name with the selected deployment model, such as <code>gpt-4</code>.</li> <li>Select a model: Select a model, <code>gpt-4</code> is recommended.</li> <li>Deployment type: Global Standard.</li> </ul> <p>Tip: Handling no quota available message</p> <p>When you select a model, you may see No quota available message pop-up on top of the configuration page. To handle this, you have two options: 1. Select a different version or deployment type 2. Free up the resources on other deployments by requesting for more quota or adjust the existing quota</p> <p>Once your model is successfully created, select Open in playground, and test your model by selecting Prompt samples from the top and choose one of the prompts available.</p> <p>For example, choose \"Shakespearean Writing Assistant\" and select Use prompt. and ask questions such as \"tell me about Istanbul\". You'll be amazed by the descriptive and poetic style of the response \u270d\ufe0f.</p> <p></p> <p></p>"},{"location":"pages/custom-engine/teams-ai/01-custom-engine-agent/#exercise-2-scaffold-a-custom-engine-agent-from-a-template","title":"Exercise 2: Scaffold a custom engine agent from a template","text":"<p>You'll need to complete all the required prerequisites before starting with this exercise.</p>"},{"location":"pages/custom-engine/teams-ai/01-custom-engine-agent/#step-1-use-m365-agents-toolkit-to-create-a-new-custom-engine-agent","title":"Step 1: Use M365 Agents Toolkit to create a new custom engine agent","text":"<ol> <li>Open M365 Agents Toolkit on Visual Studio Code and select Create a New App &gt; Custom Engine Agent &gt; Basic AI Chatbot.</li> <li>Select TypeScript as a programming language choice and Azure OpenAI as Large Language model of your choice.<ol> <li>Paste the Azure OpenAI key and press enter.</li> <li>Paste the Azure OpenAI endpoint and press enter. (Endpoint shouldn't include forward slash at the end of its URL.)</li> <li>Type Azure OpenAI deployment model name and press enter.</li> </ol> </li> <li>Select a folder for your project root.</li> <li>Provide a name for your project such as <code>CareerGenie</code> and press enter.</li> </ol> <p>After providing all the details mentioned above, your project will be scaffolded successfully in seconds.</p> <p></p>"},{"location":"pages/custom-engine/teams-ai/01-custom-engine-agent/#step-2-customize-prompt-and-test-the-app","title":"Step 2: Customize prompt and test the app","text":"<p>Prompts are essential for interacting with AI language models and directing their behavior. They serve as the inputs or questions we provide to the model to obtain specific responses. By crafting prompts carefully, we can guide the AI to generate desired outputs. Let's customize the prompt of our custom engine agent and define the behavior of Career Genie!</p> <p>In your project folder, navigate to <code>src/prompts/chat/skprompt.txt</code> and replace the existing text with the following prompt:</p> <pre><code>You are a career specialist named \"Career Genie\" that helps Human Resources team for writing job posts.\nYou are friendly and professional.\nYou always greet users with excitement and introduce yourself first.\nYou like using emojis where appropriate.\n</code></pre> <p>To test the behavior of your app quickly, you can use Teams App Test Tool. Later in the exercise, you'll run and debug your custom engine agent on Microsoft Teams.</p> More information about the Teams App Test Tool <p>The Teams App Test Tool, or simply Test Tool, is a feature within M365 Agents Toolkit that enables developers to debug, test, and refine their Teams bot applications in a web-based chat environment that mimics the behavior, look, and feel of Microsoft Teams. This tool eliminates the need for a Microsoft 365 tenant or a dev tunnel, streamlining the development process.</p> <p>Start debugging your app by selecting Run and Debug tab on Visual Studio Code and Debug in Test Tool. Teams App Test Tool will pop up on your browser and you can start chatting with your custom engine agent right away! Some of the recommended questions you can ask to test the behavior:</p> <ul> <li>\"Can you help me write a job post for a Senior Developer role?\"</li> <li>\"What would be the list of required skills for a Project Manager role?\"</li> <li>\"Can you share a job template?\"</li> </ul> <p></p> What does M365 Agents Toolkit do behind the scene? <p>When you start debugging your app, M365 Agents Toolkit completes some required tasks for you behind the scene, such as:</p> <ul> <li>Checking the required prerequisites such as Node.js, Microsoft 365 Account (If debugging in local or dev), ports occupancy.</li> <li>Starting local tunneling service (If debugging in local) to forward public URL to local port.</li> <li>Executing the lifecycle stage provision, available in <code>teamsapp.yml</code>, <code>teamsapp.local.user</code> or <code>teamsapp.testtool.user</code> files for creating Teams App ID, completing bot registration, executing the app manifest and creating the app package, available in <code>appPackage/</code> folder.</li> <li>Create or update variables to env file, available in <code>env/</code> folder.</li> </ul> <p>After successfully completing your testing, end your debugging session and close the terminals in Visual Studio Code.</p> <p></p> <p>CONGRATULATIONS!</p> <p>You have completed Lab BTA1 - First custom engine agent to build a custom engine agent using Azure OpenAI and M365 Agents Toolkit! If you want explore further, the source code of this lab is available in the Copilot Developer Camp repo.</p> <p>You are now ready to proceed to Lab BTA2 - Index your data in Azure AI Search to bring your data into your custom engine agent. Select Next.</p> <p></p> <p></p>"},{"location":"pages/custom-engine/teams-ai/02-rag/","title":"Lab BTA2 - Index your data in Azure AI Search","text":"<p>In this lab you will enable Retrieval-Augmented Generation for your custom engine agent and integrate with Azure AI Search to chat with your data.</p> <p>In this lab you will:</p> <ul> <li>Learn what is Retrieval-Augmented Generation (RAG)</li> <li>Setup Azure resources</li> <li>Upload your documents to Azure AI Search</li> <li>Prepare your custom engine agent for Vector Search</li> <li>Learn how to run and test your app</li> </ul> Get a quick overview of the lab in this video. <p>Do these labs if you want to build a Custom engine agent with custom AI model and orchestration using Azure OpenAI and Teams AI library</p> <ul> <li>BTA0 - Setup</li> <li>BTA1 - First custom engine agent</li> <li>BTA2 - Index your data in Azure AI Search</li> <li>BTA3 - Enhance the user experience</li> <li>BTA4 - Add single sign on authentication</li> <li>BTA5 - Add actions to handle complex tasks</li> </ul>"},{"location":"pages/custom-engine/teams-ai/02-rag/#introduction","title":"Introduction","text":"<p>In the previous exercise, you learned how to create a custom engine agent and customize the prompt for defining the behavior of the AI chatbot, Career Genie. In this exercise, you'll apply vector search to a collection of resumes to find the best candidate for the job requirements. To enable vector search in Career Genie, you'll use the \"Azure AI Foundry on your data\" feature to:</p> <ul> <li>Create an index on Azure AI Search.</li> <li>Generate vector embeddings for the resumes (PDF documents).</li> <li>Upload the data in chunks to Azure AI Search.</li> </ul> <p>Finally, you'll integrate your custom engine agent with Azure AI Search to chat with your data and obtain the best results.</p> What is Retrieval-Augmented Generation (RAG)? <p>Retrieval-Augmented Generation (RAG) is a technique used in artificial intelligence to improve the quality of responses generated by language models. Here's a simple example to understand it better:</p> <p>Imagine you have a smart assistant that can write answers to your questions. Sometimes, this assistant might not know everything it needs to give a great answer. To help with this, RAG lets the assistant look up information from a large collection of documents, videos, images similar to how you might search the internet for answers. After finding the relevant information, the assistant then uses this data to write a better, more accurate response.</p> <p>So, RAG combines two steps:</p> <ul> <li>Retrieval: Finding relevant information from a big pool of data.</li> <li>Generation: Using that information to create a detailed and accurate response.</li> </ul> <p>This way, RAG helps in providing more informed and useful answers, making it very effective for tasks like answering questions, writing articles, and assisting with research.</p> <p>Learn more about the RAG by watching this Doodle to Code video!</p> <p></p> Benefits of using Vector Search <p>Vector search is an advanced technique used to find information quickly and accurately based on its meaning rather than just matching exact words. Unlike traditional text-based search, which relies on exact keyword matches, vector search uses numeric vectors to find content that is similar to your query. This enables Vector search to handle:</p> <ul> <li>Semantic or conceptual similarity: Matching concepts that are similar in meaning even if they use different words (e.g., \"pastry\" and \"croissant\").</li> <li>Multilingual content: Finding equivalent content across different languages (e.g., \"pastry\" in English and \"geb\u00e4ck\" in German).</li> <li>Multiple content types: Searching across different formats (e.g., \"pastry\" in text and an image of a pastry).</li> </ul> <p>Here is how vector search works:</p> <ol> <li>Converting text to vectors: Imagine turning words or sentences into a series of numbers (a vector) that captures the essence or meaning of that text. This is done using techniques like word embeddings or deep learning models.</li> <li>Storing vectors: These vectors are stored in a special database designed to handle them efficiently.</li> <li>Searching with vectors: When you search for something, your query is also converted into a vector. The search system then looks for vectors in the database that are close to your query vector in terms of meaning, not just exact word matches.</li> </ol> <p>For example, if you search for \"how to bake a cake\" the system can find documents about \"cake recipes\" or \"baking tips\" even if they don't have the exact words \"how to bake a cake\" or even if the recipes are written in another language. This makes vector search powerful for finding relevant information based on context and meaning, especially in large datasets.</p> <p>In summary, vector search improves the search process by focusing on the meaning behind the words, enabling more accurate and relevant results.</p>"},{"location":"pages/custom-engine/teams-ai/02-rag/#exercise-1-setup-azure-resources","title":"Exercise 1: Setup Azure Resources","text":"<p>You'll need to complete the Azure subscription prerequisite before starting with this exercise.</p>"},{"location":"pages/custom-engine/teams-ai/02-rag/#step-1-create-azure-ai-search-service-resource","title":"Step 1: Create Azure AI Search service resource","text":"What is Azure AI Search? <p>Azure AI Search (formerly known as \"Azure Cognitive Search\") provides secure information retrieval at scale over user-owned content in traditional and generative AI search applications.When you create a search service, you work with the following capabilities:</p> <ul> <li>A search engine for vector search, full text and hybrid search over a search index</li> <li>Rich indexing with integrated data chunking and vectorization</li> <li>Rich query syntax for vector queries, text search, hybrid queries</li> <li>Integration with Azure AI services and Azure OpenAI</li> </ul> <ol> <li>Open the browser of your choice and navigate to Azure Portal.</li> <li>Select Create a resource, then search for <code>Azure AI Search</code>. Select the Azure AI Search service and then Create.</li> <li>Fill out the following details and select Review + Create:<ul> <li>Subscription: The Azure subscription for your Azure AI Search service</li> <li>Resource group: Select the pre-existing resource group you created earlier for Azure OpenAI service.</li> <li>Name: A descriptive name for your Azure AI Search service resource, such as <code>copilotcamp-ai-search</code>.</li> <li>Location: The location of your instance.</li> <li>Pricing Tier: Basic</li> </ul> </li> </ol> <p>Once your Azure AI Search service resource is created successfully, navigate to your resource, In Overview, copy and save <code>Url</code>. Then, navigate to Keys tab under the Settings, copy and save <code>Primary admin key</code>. Both of them will be required later in the following exercises.</p> <p></p>"},{"location":"pages/custom-engine/teams-ai/02-rag/#step-2-create-a-storage-account-service-resource","title":"Step 2: Create a storage account service resource","text":"<ol> <li>Open the browser of your choice and navigate to Azure Portal.</li> <li>Select Create a resource, then search for <code>Storage Account</code>. Select the Storage Account service and then Create.</li> <li>Fill out the following details and select Review, then Create:<ul> <li>Subscription: The Azure subscription for your Azure Storage Account service</li> <li>Resource group: Select the pre-existing resource group you created earlier for Azure OpenAI service.</li> <li>Name: A descriptive name for your Azure Storage Account service resource, such as <code>copilotcampstorage</code>.</li> <li>Region: The location of your instance.</li> <li>Performance: Standard</li> <li>Redundancy: Geo-redundant storage (GRS)</li> </ul> </li> </ol>"},{"location":"pages/custom-engine/teams-ai/02-rag/#step-3-create-a-text-embedding-ada-002-model","title":"Step 3: Create a <code>text-embedding-ada-002</code> model","text":"What does <code>text-embedding-ada-002</code> do? <p>The <code>text-embedding-ada-002</code> model on Azure OpenAI converts text into numeric vectors that represent the meaning of the text. This allows for vector search, where instead of matching exact words, the search finds text with similar meanings. It works with multiple languages and different content types, making it useful for comparing text across languages and formats. When used with Azure AI Search, it improves search results by finding the most relevant and contextually accurate information. This model is perfect for creating advanced search solutions and applications that need to understand natural language.</p> <p>Open Azure AI Foundry in your browser, then select Deployments. Select Create a new deployment. Fill out the following details and select Create:</p> <ul> <li>Select a model: <code>text-embedding-ada-002</code>.</li> <li>Model version: Default.</li> <li>Deployment type: Standard.</li> <li>Deployment name: Choose a memorable name, such as <code>text-embeddings</code></li> <li>Content Filter: Default.</li> </ul> <p>Tip: Handling no quota available message</p> <p>When you select a model, you may see No quota available message pop-up on top of the configuration page. To handle this, you have two options: 1. Select a different version or deployment type 2. Free up the resources on other deployments by requesting for more quota or adjust the existing quota</p> <p></p>"},{"location":"pages/custom-engine/teams-ai/02-rag/#exercise-2-upload-your-documents-to-azure-ai-search-using-azure-ai-foundry-chat-playground","title":"Exercise 2: Upload your documents to Azure AI Search using Azure AI Foundry Chat Playground","text":"<p>For this exercise, download fictitious_resumes.zip and unzip the folder.</p>"},{"location":"pages/custom-engine/teams-ai/02-rag/#step-1-upload-your-documents-to-azure-ai-search","title":"Step 1: Upload your documents to Azure AI Search","text":"<ol> <li> <p>Open Azure AI Foundry in your browser, then select Chat playground. In the Setup section, first make sure you reset the model instructions by selecting Reset and delete examples related to Shakespearean writing to start from scratch. If you already have the Chat playground in empty and default setup, you can proceed to the next step.</p> <p></p> </li> <li> <p>Select Add your data and then Add a data source.</p> <p></p> </li> <li> <p>Select Upload files (preview), then fill the details as the following and select Next:</p> <ul> <li>Subscription: Select the subscription you created your Azure resources.</li> <li>Select Azure Blob storage resource: Select your storage resource, <code>copilotcampstorage</code>. (You'll see a message Azure OpenAI needs your permission to access this resource, select Turn on CORS.)</li> <li>Select Azure AI Search resource: Select your Azure AI Search resournce, <code>copilotcamp-ai-search</code>.</li> <li>Enter the index name: Index name, such as <code>resumes</code>; make note of this</li> <li>Select the box for Add vector search to this search resource.</li> <li>Select an embedding model: Select your text-embedding-ada-002 model, <code>text-embeddings</code>.</li> </ul> </li> </ol> <p>Take note of the index name as you will use this in the <code>INDEX_NAME</code> environment variable.</p> <p></p> <ol> <li>Select Browse for a file and select the pdf documents from the <code>resumes</code> folder. Then, select Upload files and Next.</li> <li>Select Search type as <code>Vector</code> and chunk size as <code>1024(Default)</code>, then Next.</li> <li>Select <code>API Key</code> as Azure resource authentication type, then Next.</li> </ol> <p>It takes couple of minutes to complete the data ingestion. Once the data is ready, you can proceed with testing.</p> <p></p> <p>Note</p> <p>Once you index your data, your index remains on Azure AI Search even if you close or refresh the Chat Playground. If the Chat Playground resets itself and you have to add your data again, you don't have to index your data for the second time using Upload files, instead you can select Azure AI Search from Add Your Data section and select your existing index to test out your data.</p>"},{"location":"pages/custom-engine/teams-ai/02-rag/#step-2-test-your-data-on-azure-ai-foundry","title":"Step 2: Test your data on Azure AI Foundry","text":"<p>Once your data  ingestion is completed, use Chat playground to ask questions about your data. </p> <p>You can ask questions such as \"Can you suggest me a candidate who is suitable for Spanish speaking role that requires at least 2 years of .NET experience?\".</p> <p>Tip: Making the most out of your data</p> <p>Review your dataset before asking questions testing the vector search. Go through the <code>resumes</code> folder and recognize the resumes provided in different languages with diverse professions, years of experience, skills and more. Start chatting with your data by asking questions to find out the right candidate for a skill, language, profession, years of experience and other categories. Try to test out the combination of requirements to challenge the search experience!</p> <p></p> <p></p>"},{"location":"pages/custom-engine/teams-ai/02-rag/#step-3-sneak-peek-to-your-index-on-azure-ai-search","title":"Step 3: Sneak peek to your index on Azure AI Search","text":"<p>To understand more about your dataset and explore more, select resumes from the Add your data section of the Chat playground. This will redirect you to your resumes index on Azure AI Search.</p> <p></p> <p>First, let's include the vector content in our data. Select Fields tab in your Resumes index page, then check the box for contentVector, finally select Save.</p> <p></p> <p>Go back to Search explorer tab, select Query options in your Resumes index page and then change the API version as <code>2024-11-01-preview</code>, then select Close. To view your data, press Search.</p> <p>Tip: Recognize <code>contentVector</code> parameter</p> <p>When scrolling through your data, recognize that each document has <code>contentVector</code> parameter that contains the numeric vectors of the pdf document. These numeric vectors will be used for Vector Search to identify the best matching results.</p> <p></p> <p></p>"},{"location":"pages/custom-engine/teams-ai/02-rag/#exercise-3-integrate-your-app-with-azure-ai-search","title":"Exercise 3: Integrate your app with Azure AI Search","text":"<p>For this exercise, ensure that you obtain Azure OpenAI text embedding deployment name and Azure AI Search key and endpoint.</p>"},{"location":"pages/custom-engine/teams-ai/02-rag/#step-1-configure-environment-variables","title":"Step 1: Configure environment variables","text":"<p>In your Career Genie project, navigate to <code>env/.env.local.user</code> and paste the following environment variables:</p> <pre><code>AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME='&lt;Your-Text-Embedding-Model-Name&gt;'\nSECRET_AZURE_SEARCH_KEY='&lt;Your-Azure-AI-Search-Key&gt;'\nAZURE_SEARCH_ENDPOINT='&lt;Your-Azure-AI-Search-Endpoint&gt;'\nINDEX_NAME='&lt;Your-index-name&gt;'\n</code></pre> <p>Open <code>teamsapp.local.yml</code> and add the following snippet at the bottom of the file, under <code>uses: file/createOrUpdateEnvironmentFile</code>:</p> <pre><code>AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME: ${{AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME}}\nAZURE_SEARCH_KEY: ${{SECRET_AZURE_SEARCH_KEY}}\nAZURE_SEARCH_ENDPOINT: ${{AZURE_SEARCH_ENDPOINT}}\nINDEX_NAME: ${{INDEX_NAME}}\n</code></pre> <p>Navigate to <code>src/config.ts</code> and add the following snippet inside <code>config</code>:</p> <pre><code>azureOpenAIEmbeddingDeploymentName: process.env.AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME,\nazureSearchKey: process.env.AZURE_SEARCH_KEY,\nazureSearchEndpoint: process.env.AZURE_SEARCH_ENDPOINT,\nindexName: process.env.INDEX_NAME,\n</code></pre> <p></p>"},{"location":"pages/custom-engine/teams-ai/02-rag/#step-2-configure-azure-ai-search-as-a-data-source","title":"Step 2: Configure Azure AI Search as a data source","text":"<p>Open <code>src/prompts/chat/config.json</code> in your project, then add <code>data_sources</code> inside the <code>completion</code> brackets:</p> <pre><code>\"data_sources\": [\n    {\n        \"type\": \"azure_search\",\n        \"parameters\": {\n            \"endpoint\": \"$searchEndpoint\",\n            \"index_name\": \"$indexName\",\n            \"authentication\": {\n                \"type\": \"api_key\",\n                \"key\": \"$searchApiKey\"\n            },\n            \"query_type\":\"vector\",\n            \"in_scope\": true,\n            \"strictness\": 3,\n            \"top_n_documents\": 3,\n            \"embedding_dependency\": {\n            \"type\": \"deployment_name\",\n            \"deployment_name\": \"$azureOpenAIEmbeddingDeploymentName\"\n            }\n        }\n    }\n]\n</code></pre> <p>Open <code>src/prompts/chat/skprompt.txt</code> and update the prompt as the following:</p> <pre><code>You are a career specialist named \"Career Genie\" that helps Human Resources team for finding the right candidate for the jobs. \nYou are friendly and professional.\nYou always greet users with excitement and introduce yourself first.\nYou like using emojis where appropriate.\nAlways mention all citations in your content.\n</code></pre> <p>Open the terminal in Visual Studio Code, and run the following script from the project root:</p> <pre><code>npm install fs\n</code></pre> <p>Go to <code>src/app/app.ts</code> and add the following parameter in your  <code>OpenAIModel</code>:</p> <pre><code>azureApiVersion: '2024-02-15-preview'\n</code></pre> <p>Add the following import on top of the <code>src/app/app.ts</code> file:</p> <pre><code>import fs from 'fs';\n</code></pre> <p>In <code>src/app/app.ts</code>, replace the <code>defaultPrompt</code> inside the <code>ActionPlanner</code> with the following code snippet:</p> <pre><code>defaultPrompt: async () =&gt; {\n    const template = await prompts.getPrompt('chat');\n    const skprompt = fs.readFileSync(path.join(__dirname, '..', 'prompts', 'chat', 'skprompt.txt'));\n\n    const dataSources = (template.config.completion as any)['data_sources'];\n\n    dataSources.forEach((dataSource: any) =&gt; {\n      if (dataSource.type === 'azure_search') {\n        dataSource.parameters.authentication.key = config.azureSearchKey;\n        dataSource.parameters.endpoint = config.azureSearchEndpoint;\n        dataSource.parameters.indexName = config.indexName;\n        dataSource.parameters.embedding_dependency.deployment_name =\n          config.azureOpenAIEmbeddingDeploymentName;\n        dataSource.parameters.role_information = `${skprompt.toString('utf-8')}`;\n      }\n    });\n\n    return template;\n}\n</code></pre> <p></p>"},{"location":"pages/custom-engine/teams-ai/02-rag/#step-3-debug-your-app-and-chat-with-your-data","title":"Step 3: Debug your app and chat with your data","text":"<p>Disclaimer: Debug locally instead of using the Test Tool</p> <p>Note that some advanced features you've added in your app may not show up properly in the App Test Tool. Therefore, you are going to debug your app locally on Teams instead of using the Test Tool moving forward.</p> <p>Let's test Career Genie on Teams this time. Start debugging your app by selecting Run and Debug tab on Visual Studio Code and Debug in Teams (Edge) or Debug in Teams (Chrome). Microsoft Teams will pop up on your browser. Once your app details show up on Teams, select Add and start chatting with your app.</p> <p>Tip: Testing this exercise locally</p> <p>Make sure to test and debug this exercise on Teams locally, as some of the Teams AI library capabilities you've implemented in your app so far won't smoothly work in the Teams App Test Tool.</p> <p>Ensure your questions are related to your dataset. Go through pdf documents in the <code>resumes</code> folder to understand more about your data. Challenge your custom engine agent by combining requirements and asking complex questions! Some suggestions would be:</p> <ul> <li>Can you suggest a candidate who is suitable for spanish speaking role that requires at least 2 years of .NET experience?</li> <li>Who are the other good candidates?</li> <li>Who would be suitable for a position that requires 5+ python development experience?</li> <li>Can you suggest any candidates for a senior developer position with 7+ year experience that requires Japanese speaking?</li> </ul> <p></p> <p></p> <p>CONGRATULATIONS!</p> <p>You have completed Lab BTA2 - Index your data in Azure AI Search to bring your data into your custom engine agent! If you want explore further, the source code of this lab is available in the Copilot Developer Camp repo.</p> <p>You are now ready to proceed to Lab BTA3 - Enhance User Experience with the Powered by AI kit! Select Next. </p> <p></p> <p></p>"},{"location":"pages/custom-engine/teams-ai/03-powered-by-ai/","title":"Lab BTA3 - Enhance User Experience","text":"<p>In this lab you will learn about the Powered by AI, a set of features Teams AI library provides, and utilize them in your custom engine agent to enhance the user experience.</p> <p>In this lab you will:</p> <ul> <li>Learn what are the Powered by AI features</li> <li>Enable Feedback Loop to collect user feedback</li> <li>Customize citations with Adaptive Cards</li> <li>Enable Generated by AI label</li> <li>Enable Sensitivity Label</li> </ul> Get a quick overview of the lab in this video. <p>Do these labs if you want to build a Custom engine agent with custom AI model and orchestration using Azure OpenAI and Teams AI library</p> <ul> <li>BTA0 - Setup</li> <li>BTA1 - First custom engine agent</li> <li>BTA2 - Index your data in Azure AI Search</li> <li>BTA3 - Enhance the user experience</li> <li>BTA4 - Add single sign on authentication</li> <li>BTA5 - Add actions to handle complex tasks</li> </ul>"},{"location":"pages/custom-engine/teams-ai/03-powered-by-ai/#introduction","title":"Introduction","text":"What is Powered by AI? <p>Powered by AI is a set of features provided by the Teams AI library that enhances interactions with custom engine agents, making them more engaging and user-friendly. These features include:</p> <ul> <li> <p>Feedback Loop: Users can rate AI responses with a thumbs up or down. This feedback helps refine the AI's accuracy and usefulness over time.</p> </li> <li> <p>Citations: The AI provides references to the sources of information, ensuring transparency and credibility.</p> </li> <li> <p>Generated by AI: Messages created by the AI system are labeled as \"AI generated,\" so users can distinguish between AI and human responses.</p> </li> <li> <p>Sensitivity Information: If the information shared is sensitive, a sensitivity label will appear, advising whether it can be shared outside your organization.</p> </li> </ul> <p>In the previous exercise, you explored Retrieval-Augmented Generation (RAG) and its integration into your custom engine agent. In this exercise, you'll enhance the user experience by leveraging \"Powered by AI\" features. Follow these steps:</p> <ul> <li>Implement the Feedback Loop</li> <li>Customize Citations</li> <li>Label AI-Generated messages</li> <li>Display Sensitivity information</li> </ul> <p>By incorporating these \"Powered by AI\" features, you'll make your custom engine agent more transparent, reliable, and user-friendly, which will enhance the overall user experience.</p>"},{"location":"pages/custom-engine/teams-ai/03-powered-by-ai/#exercise-1-enable-feedback-loop","title":"Exercise 1: Enable Feedback Loop","text":"<p>In this exercise, you can continue using the same source code you developed in the previous lab.</p>"},{"location":"pages/custom-engine/teams-ai/03-powered-by-ai/#step-1-integrate-feedback-loop-in-your-app","title":"Step 1: Integrate Feedback Loop in your app","text":"<p>In your project, open <code>src/app/app.ts</code>, locate your application instance and add <code>enable_feedback_loop: true</code> inside the ai property brackets. The updated application instance will look like the following:</p> <pre><code>const app = new Application({\n  storage,\n  ai: {\n    planner,\n    //feedback loop is enabled\n    enable_feedback_loop: true\n  },\n});\n</code></pre> <p>To handle the feedback responses, add the following code snippet in the <code>src/app/app.ts</code>:</p> <pre><code>app.feedbackLoop(async (_context, _state, feedbackLoopData) =&gt; {\n  if (feedbackLoopData.actionValue.reaction === 'like') {\n      console.log('\ud83d\udc4d' + ' ' + feedbackLoopData.actionValue.feedback!);\n  } else {\n      console.log('\ud83d\udc4e' + ' ' + feedbackLoopData.actionValue.feedback!);\n  }\n});\n</code></pre> <p></p>"},{"location":"pages/custom-engine/teams-ai/03-powered-by-ai/#step-2-test-the-feedback-loop-feature","title":"Step 2: Test the Feedback Loop feature","text":"<p>Let's test Career Genie with the Feedback Loop feature. Start debugging your app by selecting Run and Debug tab on Visual Studio Code and Debug in Teams (Edge) or Debug in Teams (Chrome). This will open Microsoft Teams in your browser. When your app details appear in Teams, select Add to start chatting with your app.</p> <p>Tip: Testing this exercise locally</p> <p>Make sure to test and debug this exercise on Teams locally, as some of the Teams AI library capabilities you've implemented in your app so far won't smoothly work in the Teams App Test Tool.</p> <p>Before testing the Feedback Loop, type \"Hi\" or ask a question similar to \"Suggest me .NET developers who can speak Spanish.\" You'll notice that the response from your custom engine agent includes thumbs up and down buttons at the bottom left corner.</p> <p></p> <p>Now, let's test the feedback loop. Click on either the thumbs up or down button. A feedback card will immediately pop up. Provide your feedback in the text field on the card and click Submit.</p> <p></p> <p>To verify that your feedback was recorded, return to Visual Studio Code and check your terminal. You'll see the feedback you provided, including whether you gave a thumbs up or down and your comment.</p> <p></p> <p>Dive deeper into the Feedback Loop by debugging</p> <p>Debugging the code is an excellent way to understand how it works. To delve deeper into how the Feedback Loop handler functions, set a breakpoint at <code>app.feedbackLoop</code>. Run the app and test the Feedback Loop by clicking thumbs up or down. You'll observe that <code>feedbackLoopData.actionValue.reaction</code> captures the reaction, while <code>feedbackLoopData.actionValue.feedback</code> captures the text feedback you provide.</p> <p></p>"},{"location":"pages/custom-engine/teams-ai/03-powered-by-ai/#exercise-2-customize-citations-with-adaptive-cards","title":"Exercise 2: Customize citations with Adaptive Cards","text":"<p>When you define a data source in a custom engine agent, the Teams AI library dynamically enables citations to reference related documents. Recognize the current experience in your custom engine agent, ask a question similar to \"Suggest me .NET developers who can speak Spanish.\". You will realize that you can hover over the citation to see the beginning of the document.</p> <p></p> <p>In this exercise, you'll tailor this citation experience further and use Adaptive Cards to customize the way citations are presented.</p>"},{"location":"pages/custom-engine/teams-ai/03-powered-by-ai/#step-1-create-an-adaptive-card-for-citations","title":"Step 1: Create an Adaptive Card for citations","text":"<p>Go to <code>src/app/</code> folder and create a new file named card.ts. Add the following code snippet inside the <code>card.ts</code> file:</p> <pre><code>import { AdaptiveCard, Message, Utilities } from '@microsoft/teams-ai';\n/**\n * Create an adaptive card from a prompt response.\n * @param {Message&lt;string&gt;} response The prompt response to create the card from.\n * @returns {AdaptiveCard} The response card.\n */\n\n//Adaptive card to display the response and citations\nexport function createResponseCard(response: Message&lt;string&gt;): AdaptiveCard {\n    const citationCards = response.context?.citations.map((citation, i) =&gt; ({\n            type: 'Action.ShowCard',\n            title: `${i+1}`,\n            card: {\n                type: 'AdaptiveCard',\n                body: [\n                    {\n                        type: 'TextBlock',\n                        text: citation.title,\n                        fontType: 'Default',\n                        weight: 'Bolder'\n                    },\n                    {\n                        type: 'TextBlock',\n                        text: citation.content,\n                        wrap: true\n                    }\n                ]\n            }\n        }));\n\n    const text = Utilities.formatCitationsResponse(response.content!);\n    return {\n        type: 'AdaptiveCard',\n        body: [\n            {\n                type: 'TextBlock',\n                text: text,\n                wrap: true\n            },\n            {\n                type: 'TextBlock',\n                text: 'Citations',\n                wrap: true,\n                fontType: 'Default',\n                weight: 'Bolder'\n            },\n            {\n                type: 'ActionSet',\n                actions: citationCards\n            }\n        ],\n        $schema: 'http://adaptivecards.io/schemas/adaptive-card.json',\n        version: '1.5'\n    };\n}\n</code></pre> <p>This Adaptive Card allows you to list citations as <code>Action.ShowCard</code> buttons which show more details when clicked. It also displays the main content of the response alongside the citation buttons. If a user wants to learn more about a citation, they can click the button to read the entire document.</p> <p></p>"},{"location":"pages/custom-engine/teams-ai/03-powered-by-ai/#step-2-use-predictedsaycommand-to-customize-the-citation-experience","title":"Step 2: Use PredictedSayCommand to customize the citation experience","text":"What does <code>PredictedSayCommand</code> do? <p>A PredictedSayCommand is a response directive that the AI system executes. By customizing PredictedSayCommand, you gain granular control over integrating Powered by AI features like citations, feedback loops into the custom engine agent's activities. This allows you to precisely tailor the AI responses to meet your application needs.</p> <p>Go to <code>src/app/app.ts</code> and add the following snippet on top of your code to import your adaptive card:</p> <pre><code>import { createResponseCard } from './card';\n</code></pre> <p>Add <code>CardFactory</code> inside the \"botbuilder\" import,  the updated version of the import will look like the following:</p> <pre><code>import { CardFactory, MemoryStorage, MessageFactory, TurnContext } from \"botbuilder\";\n</code></pre> <p>Add <code>AI</code> and <code>PredictedSayCommand</code> inside the \"@microsoft/teams-ai\" import, the updated version of the import will look like the following:</p> <pre><code>import { Application, ActionPlanner, OpenAIModel, PromptManager, AI, PredictedSayCommand} from \"@microsoft/teams-ai\";\n</code></pre> <p>Add the following PredictedSayCommand action in the <code>src/app/app.ts</code> to customize the citation:</p> <pre><code>app.ai.action&lt;PredictedSayCommand&gt;(AI.SayCommandActionName, async (context, state, data, action) =&gt; {\n  let activity;\n  if (data.response.context &amp;&amp; data.response.context.citations.length &gt; 0 ) {\n      const attachment = CardFactory.adaptiveCard(createResponseCard(data.response));\n      activity = MessageFactory.attachment(attachment);\n  }\n  else {\n      activity = MessageFactory.text(data.response.content);\n  }\n\n  activity.entities = [\n    {\n        type: \"https://schema.org/Message\",\n        \"@type\": \"Message\",\n        \"@context\": \"https://schema.org\",\n        \"@id\": \"\"\n    }\n  ];\n  activity.channelData = {\n    feedbackLoopEnabled: true\n  };\n\n  await context.sendActivity(activity);\n\n  return \"success\";\n\n});\n</code></pre> <p></p>"},{"location":"pages/custom-engine/teams-ai/03-powered-by-ai/#step-3-test-the-customized-citation-experience","title":"Step 3: Test the customized citation experience","text":"<p>Let's test Career Genie with the customized citation experience. Start debugging your app by selecting Run and Debug tab on Visual Studio Code and Debug in Teams (Edge) or Debug in Teams (Chrome). Microsoft Teams will pop up on your browser. This will open Microsoft Teams in your browser. When your app details appear in Teams, select Add to start chatting with your app.</p> <p>Tip: Testing this exercise locally</p> <p>Make sure to test and debug this exercise on Teams locally, as some of the Teams AI library capabilities you've implemented in your app so far won't smoothly work in the Teams App Test Tool.</p> <p>To test the new citation experience, start by greeting Career Genie with \"Hi\" or \"Hello\". Then, try to ask questions similar to \"Can you suggest any candidates for a senior developer position with 7+ year experience that requires Japanese speaking?\"</p> <p></p> <p>Now, recognize that the customized citation experience with Adaptive Cards provides a button for each citation. Click on citation buttons to extend the document view and review the resume details for each candidate.</p> <p></p>"},{"location":"pages/custom-engine/teams-ai/03-powered-by-ai/#exercise-3-enable-the-generated-by-ai-label","title":"Exercise 3: Enable the Generated by AI label","text":"<p>In this exercise, you will continue customizing the user experience of your custom engine agent using <code>PredictedSayCommand</code>. To help users differentiate between AI and human responses, you'll enable the \"AI generated\" label that appears on top of the messages created by the AI system.</p>"},{"location":"pages/custom-engine/teams-ai/03-powered-by-ai/#step-1-use-predictedsaycommand-to-enable-the-generated-by-ai-label","title":"Step 1: Use PredictedSayCommand to enable the Generated by AI label","text":"<p>Go to <code>src/app/app.ts</code> and locate your <code>PredictedSayCommand</code> action. Add the following code snippet inside <code>activity.entities</code>:</p> <pre><code>// Generated by AI label\nadditionalType: [\"AIGeneratedContent\"]\n</code></pre> <p>The update <code>activity.entities</code> will look like the following:</p> <pre><code>activity.entities = [\n    {\n        type: \"https://schema.org/Message\",\n        \"@type\": \"Message\",\n        \"@context\": \"https://schema.org\",\n        \"@id\": \"\",\n        // Generated by AI label\n        additionalType: [\"AIGeneratedContent\"],\n    },\n\n];\n</code></pre> <p></p>"},{"location":"pages/custom-engine/teams-ai/03-powered-by-ai/#step-2-test-the-generated-by-ai-label","title":"Step 2: Test the Generated by AI label","text":"<p>Let's test Career Genie with the \"Generated by AI\" label. Start debugging your app by selecting Run and Debug tab on Visual Studio Code and Debug in Teams (Edge) or Debug in Teams (Chrome). This will open Microsoft Teams in your browser. When your app details appear in Teams, select Add to start chatting with your app.</p> <p>Tip: Testing this exercise locally</p> <p>Make sure to test and debug this exercise on Teams locally, as some of the Teams AI library capabilities you've implemented in your app so far won't smoothly work in the Teams App Test Tool.</p> <p>To test the \"Generated by AI\" label, simply greet Career Genie. The first message you receive will have a small \"AI generated\" label on top.</p> <p></p> <p></p>"},{"location":"pages/custom-engine/teams-ai/03-powered-by-ai/#exercise-4-enable-the-sensitivity-label","title":"Exercise 4: Enable the Sensitivity label","text":"<p>In this final exercise, you will continue utilizing <code>PredictedSayCommand</code> to enable the sensitivity label. Remember, Career Genie is an expert in Human Resources tasks that often require sharing confidential information within your organization. For scenarios like Career Genie, where the information shared is sensitive, a sensitivity label will appear on top of the AI-generated messages, advising whether it can be shared outside your organization.</p>"},{"location":"pages/custom-engine/teams-ai/03-powered-by-ai/#step-1-use-predictedsaycommand-to-enable-the-sensitivity-label","title":"Step 1: Use PredictedSayCommand to enable the Sensitivity label","text":"<p>Go to <code>src/app/app.ts</code> and locate your <code>PredictedSayCommand</code> action. Add the following code snippet inside <code>activity.entities</code>:</p> <pre><code>// Sensitivity label\nusageInfo: {\n    \"@type\": \"CreativeWork\",\n    name: \"Confidential\",\n    description: \"Sensitive information, do not share outside of your organization.\",\n}\n</code></pre> <p>The updated <code>activity.entities</code> will look like the following:</p> <pre><code>activity.entities = [\n    {\n        type: \"https://schema.org/Message\",\n        \"@type\": \"Message\",\n        \"@context\": \"https://schema.org\",\n        \"@id\": \"\",\n        // Generated by AI label\n        additionalType: [\"AIGeneratedContent\"],\n        // Sensitivity label\n        usageInfo: {\n          \"@type\": \"CreativeWork\",\n          name: \"Confidential\",\n          description: \"Sensitive information, do not share outside of your organization.\",\n        }\n    },\n\n  ];\n</code></pre> <p></p>"},{"location":"pages/custom-engine/teams-ai/03-powered-by-ai/#step-2-test-the-sensitivity-label","title":"Step 2: Test the Sensitivity label","text":"<p>Let's test Career Genie with the Sensitivity label. Start debugging your app by selecting Run and Debug tab on Visual Studio Code and Debug in Teams (Edge) or Debug in Teams (Chrome). Microsoft Teams will pop up on your browser. Once your app details show up on Teams, select Add and start chatting with your app.</p> <p>Tip: Testing this exercise locally</p> <p>Make sure to test and debug this exercise on Teams locally, as some of the Teams AI library capabilities you've implemented in your app so far won't smoothly work in the Teams App Test Tool.</p> <p>To test the Sensitivity label, greet Career Genie or try to ask questions similar to \"Can you suggest a candidate who is suitable for spanish speaking role that requires at least 2 years of .NET experience?\".</p> <p></p> <p>Notice that the sensitivity label appears right next to the \"AI Generated\" label in Career Genie's message. Hover over the sensitivity label to read the guidance specific to your organization.</p> <p></p> <p>CONGRATULATIONS!</p> <p>You have completed Lab BTA3 - Enhance User Experience with the Powered by AI kit!  If you want explore further, the source code of this lab is available in the Copilot Developer Camp repo.</p> <p>You are now ready to proceed to Lab BTA4 - Secure your solution using authentication. Select Next.</p> <p></p> <p></p>"},{"location":"pages/custom-engine/teams-ai/04-authentication/","title":"Lab BTA4 - Add single sign on authentication","text":"<p>In this lab, you'll learn how to authenticate users with Entra Single Sign-On in Career Genie, and to call the Microsoft Graph API using the token to get logged in user information.</p> <p>In this lab you will learn to:</p> <ul> <li>Add Entra ID single sign-on (SSO) in your app, so users can seamlessly log into your app with the same account they use in Microsoft Teams</li> <li>Use Teams AI library and Bot Framework to implement the single sign on.</li> <li>Acquire and use tokens for app users to enhance security and user experience.</li> </ul> Get a quick overview of the lab in this video. <p>Do these labs if you want to build a Custom engine agent with custom AI model and orchestration using Azure OpenAI and Teams AI library</p> <ul> <li>BTA0 - Setup</li> <li>BTA1 - First custom engine agent</li> <li>BTA2 - Index your data in Azure AI Search</li> <li>BTA3 - Enhance the user experience</li> <li>BTA4 - Add single sign on authentication</li> <li>BTA5 - Add actions to handle complex tasks</li> </ul>"},{"location":"pages/custom-engine/teams-ai/04-authentication/#introduction","title":"Introduction","text":"<p>Get ready to enhance your CareerGenie by integrating Entra ID (formerly Azure AD) single sign-on (SSO). This will allow your app to seamlessly acquire tokens for accessing Microsoft 365 data via Microsoft Graph, ensuring smooth authentication and authorization. You'll be incorporating this SSO capability using the Teams AI library and the Bot Framework, specifically focusing on a multi-tenant configuration.</p>"},{"location":"pages/custom-engine/teams-ai/04-authentication/#exercise-1-set-up-your-project-for-entra-id-single-sign-on","title":"Exercise 1: Set up your project for Entra ID Single Sign-on","text":"<p>Applications secured with Entra ID must be registered and granted permission. M365 Agents Toolkit will do this work for you, but you have to update your project to make that happen. In this exercise, you'll modify the M365 Agents Toolkit project files to provision your app registration in Entra ID.</p> <p>In this exercise, use the source code for Lab B3 as the base project and proceed to next steps.</p>"},{"location":"pages/custom-engine/teams-ai/04-authentication/#step-1-add-an-entra-id-app-manifest-file-to-define-the-entra-id-application","title":"Step 1: Add an Entra ID App manifest file to define the Entra ID Application","text":"<p>In this step, you'll add a file that defines the application that M365 Agents Toolkit will register for your application in Entra ID. This manifest file allows you to customize various aspects of your application registration. For example, this one sets up <code>User.Read</code> permission on the Microsoft Graph API so your app can read the user's profile.</p> <p>Create a file aad.manifest.json in the root of your project folder, and paste in this JSON:</p> <pre><code>{\n    \"id\": \"${{AAD_APP_OBJECT_ID}}\",\n    \"appId\": \"${{AAD_APP_CLIENT_ID}}\",\n    \"name\": \"CareerGenieBot-aad\",\n    \"accessTokenAcceptedVersion\": 2,\n    \"signInAudience\": \"AzureADMultipleOrgs\",\n    \"optionalClaims\": {\n        \"idToken\": [],\n        \"accessToken\": [\n            {\n                \"name\": \"idtyp\",\n                \"source\": null,\n                \"essential\": false,\n                \"additionalProperties\": []\n            }\n        ],\n        \"saml2Token\": []\n    },\n    \"requiredResourceAccess\": [\n        {\n            \"resourceAppId\": \"Microsoft Graph\",\n            \"resourceAccess\": [\n                {\n                    \"id\": \"User.Read\",\n                    \"type\": \"Scope\"\n                }\n            ]\n        }\n    ],\n    \"oauth2Permissions\": [\n        {\n            \"adminConsentDescription\": \"Allows Teams to call the app's web APIs as the current user.\",\n            \"adminConsentDisplayName\": \"Teams can access app's web APIs\",\n            \"id\": \"${{AAD_APP_ACCESS_AS_USER_PERMISSION_ID}}\",\n            \"isEnabled\": true,\n            \"type\": \"User\",\n            \"userConsentDescription\": \"Enable Teams to call this app's web APIs with the same rights that you have\",\n            \"userConsentDisplayName\": \"Teams can access app's web APIs and make requests on your behalf\",\n            \"value\": \"access_as_user\"\n        }\n    ],\n    \"preAuthorizedApplications\": [\n        {\n            \"appId\": \"1fec8e78-bce4-4aaf-ab1b-5451cc387264\",\n            \"permissionIds\": [\n                \"${{AAD_APP_ACCESS_AS_USER_PERMISSION_ID}}\"\n            ]\n        },\n        {\n            \"appId\": \"5e3ce6c0-2b1f-4285-8d4b-75ee78787346\",\n            \"permissionIds\": [\n                \"${{AAD_APP_ACCESS_AS_USER_PERMISSION_ID}}\"\n            ]\n        }\n    ],\n    \"identifierUris\":[\n        \"api://botid-${{BOT_ID}}\"\n    ],\n    \"replyUrlsWithType\":[\n        {\n          \"url\": \"https://${{BOT_DOMAIN}}/auth-end.html\",\n          \"type\": \"Web\"\n        }\n    ]\n}\n</code></pre> <p></p>"},{"location":"pages/custom-engine/teams-ai/04-authentication/#step-2-update-m365-agents-toolkit-configuration-file-to-create-the-entra-id-app","title":"Step 2: Update M365 Agents Toolkit configuration file to create the Entra ID App","text":"<p>Open the <code>teamsapp.local.yml</code> file. This is a YAML file that defines the steps M365 Agents Toolkit takes to run your project. There are 3 steps in the \"LIFECYCLE\" section of the M365 Agents Toolkit user interface.</p> <ul> <li> <p>Provision - In this phase, any infrastructure needed by your app is created. This includes things like the bot registration, the Teams app package, and, in this case, the Entra ID app registration</p> </li> <li> <p>Deploy - In this phase, the code is built and run locally, or uploaded to Azure for environments other than \"local\"</p> </li> <li> <p>Publish - In this phase, the app package is published to Microsoft Teams</p> </li> </ul> <p>To provision your Entra ID app, add these lines to teamsapp.local.yml. You can put them directly below the <code>provision</code>:</p> <pre><code>  - uses: aadApp/create # Creates a new Entra ID (AAD) app to authenticate users if the environment variable that stores clientId is empty\n    with:\n      name: CareerGenieBot-aad # Note: when you run aadApp/update, the AAD app name will be updated based on the definition in manifest. If you don't want to change the name, make sure the name in AAD manifest is the same with the name defined here.\n      generateClientSecret: true # If the value is false, the action will not generate client secret for you\n      signInAudience: \"AzureADMultipleOrgs\" # Authenticate users with a Microsoft work or school account in your organization's Entra ID tenant (for example, single tenant).\n    writeToEnvironmentFile: # Write the information of created resources into environment file for the specified environment variable(s).\n      clientId: AAD_APP_CLIENT_ID\n      clientSecret: SECRET_AAD_APP_CLIENT_SECRET # Environment variable that starts with `SECRET_` will be stored to the .env.{envName}.user environment file\n      objectId: AAD_APP_OBJECT_ID\n      tenantId: AAD_APP_TENANT_ID\n      authority: AAD_APP_OAUTH_AUTHORITY\n      authorityHost: AAD_APP_OAUTH_AUTHORITY_HOST\n\n</code></pre> <p>And after <code>botFramework/create</code> add below to update the existing AAD app.</p> <pre><code>  - uses: aadApp/update # Apply the AAD manifest to an existing AAD app. Will use the object id in manifest file to determine which AAD app to update.\n    with:\n      manifestPath: ./aad.manifest.json # Relative path to teamsfx folder. Environment variables in manifest will be replaced before apply to AAD app\n      outputFilePath: ./build/aad.manifest.${{TEAMSFX_ENV}}.json\n</code></pre> <p>Tip: YAML requires proper indentation</p> <p>YAML requires proper indentation; each level in the object hierarchy must be indented to indicate the structure. 2 spaces (not tabs) is a good choice. Visual Studio Code will help you here, and will underline any syntax errors in red. You'll know you got it right when the red lines disappear!</p> <p>Now scroll down and find the <code>file/createOrUpdateEnvironmentFile</code> directive in the deploy phase. Add these variables to the envs: collection, right below the ones you added in the previous lab:</p> <pre><code> BOT_DOMAIN: ${{BOT_DOMAIN}}\n AAD_APP_CLIENT_ID: ${{AAD_APP_CLIENT_ID}}\n AAD_APP_CLIENT_SECRET: ${{SECRET_AAD_APP_CLIENT_SECRET}}\n AAD_APP_TENANT_ID: ${{AAD_APP_TENANT_ID}}\n AAD_APP_OAUTH_AUTHORITY_HOST: ${{AAD_APP_OAUTH_AUTHORITY_HOST}}\n AAD_APP_OAUTH_AUTHORITY: ${{AAD_APP_OAUTH_AUTHORITY}}\n</code></pre> <p></p>"},{"location":"pages/custom-engine/teams-ai/04-authentication/#exercise-2-add-sso-in-teams-app-manifest","title":"Exercise 2: Add SSO in Teams app manifest","text":"<p>In this exercise, you'll update the Teams app manifest to add single sign on.</p>"},{"location":"pages/custom-engine/teams-ai/04-authentication/#step-1-update-your-teams-app-manifest-for-sso","title":"Step 1: Update your Teams app manifest for SSO","text":"<p>In the single sign-on process, Teams will hand your code an Entra ID access token for your application. Teams can't provide this access token, however, unless it knows about your application; specifically, it needs to know the application (client) ID and the ID of the bot that's connected to Teams. So you need to add this information to your Teams app manifest.</p> <p>Find the Teams app manifest template in ./appPackage/manifest.json and add the following:</p> <pre><code> \"webApplicationInfo\": {\n        \"id\": \"${{BOT_ID}}\",\n        \"resource\": \"api://botid-${{BOT_ID}}\"\n    }\n</code></pre> <p>Add it below the <code>validDomains</code> node, with a comma in between.</p> <p>While we're here, we need to tell Teams to display web pages from your bot's domain, which allows access to the <code>auth-start.html</code> and <code>auth-end.html</code> pages used for user consent to call the Microsoft Graph. This only happens the first time a user accesses the custom engine agent.</p> <p>So you need to add your bot's domain, ${{BOT_DOMAIN}} to the <code>validDomains</code> array. After making these changes, the end of your <code>manifest.json</code> file should look like this:</p> <pre><code>  \"validDomains\": [\n        \"${{BOT_DOMAIN}}\",\n        \"*.botframework.com\"\n    ],\n</code></pre> <p></p>"},{"location":"pages/custom-engine/teams-ai/04-authentication/#exercise-3-update-the-application-code-for-sso","title":"Exercise 3: Update the application code for SSO","text":"<p>In this exercise, you'll modify the code to accommodate the SSO process.</p>"},{"location":"pages/custom-engine/teams-ai/04-authentication/#step-1-provide-html-pages-for-the-consent-dialog","title":"Step 1: Provide HTML pages for the consent dialog","text":"<p>The first time users access your application, they may need to consent to giving the app permission to read their profile information. This is performed by the Teams AI library. It will display a pop-up window; these HTML pages are to be displayed in that pop-up, and will redirect to Entra ID to do the actual consent.</p> <p>The code snippets for pop up for permission grant are from official teams-ai library sample for Teams SSO.</p> <p>Create a new folder called public inside the src folder of the project.</p> <p>Create a file auth-start.html and paste in the contents below:</p> <pre><code>&lt;!--This file is used during the Teams Bot authentication flow to assist with retrieval of the access token.--&gt;\n&lt;!--If you're not familiar with this, do not alter or remove this file from your project.--&gt;\n&lt;html lang=\"en\"&gt;\n\n&lt;head&gt;\n    &lt;title&gt;Login Start Page&lt;/title&gt;\n    &lt;meta charset=\"utf-8\" /&gt;\n    &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" /&gt;\n&lt;/head&gt;\n\n&lt;body&gt;\n    &lt;script type=\"text/javascript\"&gt;\n        popUpSignInWindow();\n\n        async function popUpSignInWindow() {\n            // Generate random state string and store it, so we can verify it in the callback\n            let state = _guid();\n            localStorage.setItem('state', state);\n            localStorage.removeItem('codeVerifier');\n            var currentURL = new URL(window.location);\n            var clientId = currentURL.searchParams.get('clientId');\n            var tenantId = currentURL.searchParams.get('tenantId');\n            var loginHint = currentURL.searchParams.get('loginHint');\n            var scope = currentURL.searchParams.get('scope');\n            if (!loginHint) {\n                loginHint = '';\n            }\n            var originalCode = _guid();\n            var codeChallenge = await pkceChallengeFromVerifier(originalCode);\n            localStorage.setItem('codeVerifier', originalCode);\n            let queryParams = {\n                client_id: clientId,\n                response_type: 'code',\n                response_mode: 'fragment',\n                scope: scope,\n                redirect_uri: window.location.origin + '/auth-end.html',\n                nonce: _guid(),\n                login_hint: loginHint,\n                state: state,\n                code_challenge: codeChallenge,\n                code_challenge_method: 'S256'\n            };\n            let authorizeEndpoint = `https://login.microsoftonline.com/common/oauth2/v2.0/authorize?${toQueryString(queryParams)}`;     \n            window.location.assign(authorizeEndpoint);\n        }\n\n        // Build query string from map of query parameter\n        function toQueryString(queryParams) {\n            let encodedQueryParams = [];\n            for (let key in queryParams) {\n                encodedQueryParams.push(key + '=' + encodeURIComponent(queryParams[key]));\n            }\n            return encodedQueryParams.join('&amp;');\n        }\n\n        // Converts decimal to hex equivalent      \n        function _decimalToHex(number) {\n            var hex = number.toString(16);\n            while (hex.length &lt; 2) {\n                hex = '0' + hex;\n            }\n            return hex;\n        }\n\n        // Generates RFC4122 version 4 guid (128 bits)\n        function _guid() {\n            // RFC4122: The version 4 UUID is meant for generating UUIDs from truly-random or\n            // pseudo-random numbers.\n            // The algorithm is as follows:\n            //     Set the two most significant bits (bits 6 and 7) of the\n            //        clock_seq_hi_and_reserved to zero and one, respectively.\n            //     Set the four most significant bits (bits 12 through 15) of the\n            //        time_hi_and_version field to the 4-bit version number from\n            //        Section 4.1.3. Version4\n            //     Set all the other bits to randomly (or pseudo-randomly) chosen\n            //     values.\n            // UUID                   = time-low \"-\" time-mid \"-\"time-high-and-version \"-\"clock-seq-reserved and low(2hexOctet)\"-\" node\n            // time-low               = 4hexOctet\n            // time-mid               = 2hexOctet\n            // time-high-and-version  = 2hexOctet\n            // clock-seq-and-reserved = hexOctet:\n            // clock-seq-low          = hexOctet\n            // node                   = 6hexOctet\n            // Format: xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx\n            // y could be 1000, 1001, 1010, 1011 since most significant two bits needs to be 10\n            // y values are 8, 9, A, B\n            var cryptoObj = window.crypto || window.msCrypto; // for IE 11\n            if (cryptoObj &amp;&amp; cryptoObj.getRandomValues) {\n                var buffer = new Uint8Array(16);\n                cryptoObj.getRandomValues(buffer);\n                //buffer[6] and buffer[7] represents the time_hi_and_version field. We will set the four most significant bits (4 through 7) of buffer[6] to represent decimal number 4 (UUID version number).\n                buffer[6] |= 0x40; //buffer[6] | 01000000 will set the 6 bit to 1.\n                buffer[6] &amp;= 0x4f; //buffer[6] &amp; 01001111 will set the 4, 5, and 7 bit to 0 such that bits 4-7 == 0100 = \"4\".\n                //buffer[8] represents the clock_seq_hi_and_reserved field. We will set the two most significant bits (6 and 7) of the clock_seq_hi_and_reserved to zero and one, respectively.\n                buffer[8] |= 0x80; //buffer[8] | 10000000 will set the 7 bit to 1.\n                buffer[8] &amp;= 0xbf; //buffer[8] &amp; 10111111 will set the 6 bit to 0.\n                return (\n                    _decimalToHex(buffer[0]) +\n                    _decimalToHex(buffer[1]) +\n                    _decimalToHex(buffer[2]) +\n                    _decimalToHex(buffer[3]) +\n                    '-' +\n                    _decimalToHex(buffer[4]) +\n                    _decimalToHex(buffer[5]) +\n                    '-' +\n                    _decimalToHex(buffer[6]) +\n                    _decimalToHex(buffer[7]) +\n                    '-' +\n                    _decimalToHex(buffer[8]) +\n                    _decimalToHex(buffer[9]) +\n                    '-' +\n                    _decimalToHex(buffer[10]) +\n                    _decimalToHex(buffer[11]) +\n                    _decimalToHex(buffer[12]) +\n                    _decimalToHex(buffer[13]) +\n                    _decimalToHex(buffer[14]) +\n                    _decimalToHex(buffer[15])\n                );\n            } else {\n                var guidHolder = 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx';\n                var hex = '0123456789abcdef';\n                var r = 0;\n                var guidResponse = '';\n                for (var i = 0; i &lt; 36; i++) {\n                    if (guidHolder[i] !== '-' &amp;&amp; guidHolder[i] !== '4') {\n                        // each x and y needs to be random\n                        r = (Math.random() * 16) | 0;\n                    }\n                    if (guidHolder[i] === 'x') {\n                        guidResponse += hex[r];\n                    } else if (guidHolder[i] === 'y') {\n                        // clock-seq-and-reserved first hex is filtered and remaining hex values are random\n                        r &amp;= 0x3; // bit and with 0011 to set pos 2 to zero ?0??\n                        r |= 0x8; // set pos 3 to 1 as 1???\n                        guidResponse += hex[r];\n                    } else {\n                        guidResponse += guidHolder[i];\n                    }\n                }\n                return guidResponse;\n            }\n        }\n\n        // Calculate the SHA256 hash of the input text.\n        // Returns a promise that resolves to an ArrayBuffer\n        function sha256(plain) {\n            const encoder = new TextEncoder();\n            const data = encoder.encode(plain);\n            return window.crypto.subtle.digest('SHA-256', data);\n        }\n\n        // Base64-urlencodes the input string\n        function base64urlencode(str) {\n            // Convert the ArrayBuffer to string using Uint8 array to convert to what btoa accepts.\n            // btoa accepts chars only within ascii 0-255 and base64 encodes them.\n            // Then convert the base64 encoded to base64url encoded\n            //   (replace + with -, replace / with _, trim trailing =)\n            return btoa(String.fromCharCode.apply(null, new Uint8Array(str)))\n                .replace(/\\+/g, '-')\n                .replace(/\\//g, '_')\n                .replace(/=+$/, '');\n        }\n\n        // Return the base64-urlencoded sha256 hash for the PKCE challenge\n        async function pkceChallengeFromVerifier(v) {\n            hashed = await sha256(v);\n            return base64urlencode(hashed);\n        }\n    &lt;/script&gt;\n&lt;/body&gt;\n\n&lt;/html&gt;\n</code></pre> <p>Create a file auth-end.html and paste in the contents below:</p> <pre><code>&lt;html lang=\"en\"&gt;\n    &lt;head&gt;\n        &lt;title&gt;Login End Page&lt;/title&gt;\n        &lt;meta charset=\"utf-8\" /&gt;\n        &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" /&gt;\n    &lt;/head&gt;\n\n    &lt;body&gt;\n        &lt;script\n            src=\"https://statics.teams.cdn.office.net/sdk/v1.6.0/js/MicrosoftTeams.min.js\"\n            integrity=\"sha384-mhp2E+BLMiZLe7rDIzj19WjgXJeI32NkPvrvvZBrMi5IvWup/1NUfS5xuYN5S3VT\"\n            crossorigin=\"anonymous\"\n        &gt;&lt;/script&gt;\n        &lt;div id=\"divError\"&gt;&lt;/div&gt;\n        &lt;script type=\"text/javascript\"&gt;\n            microsoftTeams.initialize();\n            let hashParams = getHashParameters();\n\n            if (hashParams['error']) {\n                // Authentication failed\n                handleAuthError(hashParams['error'], hashParams);\n            } else if (hashParams['code']) {\n                // Get the stored state parameter and compare with incoming state\n                let expectedState = localStorage.getItem('state');\n                if (expectedState !== hashParams['state']) {\n                    // State does not match, report error\n                    handleAuthError('StateDoesNotMatch', hashParams);\n                } else {\n                    microsoftTeams.authentication.notifySuccess();\n                }\n            } else {\n                // Unexpected condition: hash does not contain error or access_token parameter\n                handleAuthError('UnexpectedFailure', hashParams);\n            }\n\n            // Parse hash parameters into key-value pairs\n            function getHashParameters() {\n                let hashParams = {};\n                location.hash\n                    .substr(1)\n                    .split('&amp;')\n                    .forEach(function (item) {\n                        let s = item.split('='),\n                            k = s[0],\n                            v = s[1] &amp;&amp; decodeURIComponent(s[1]);\n                        hashParams[k] = v;\n                    });\n                return hashParams;\n            }\n\n            // Show error information\n            function handleAuthError(errorType, errorMessage) {\n                const err = JSON.stringify({\n                    error: errorType,\n                    message: JSON.stringify(errorMessage)\n                });\n                let para = document.createElement('p');\n                let node = document.createTextNode(err);\n                para.appendChild(node);\n\n                let element = document.getElementById('divError');\n                element.appendChild(para);\n            }\n        &lt;/script&gt;\n    &lt;/body&gt;\n&lt;/html&gt;\n\n</code></pre> <p></p>"},{"location":"pages/custom-engine/teams-ai/04-authentication/#step-2-update-code-to-handle-sso","title":"Step 2: Update code to handle SSO","text":"<ul> <li>Changes to index.ts file is as follows:</li> </ul> <p>To serve static files from the public folder, include the following import for <code>path</code>:</p> <pre><code>import * as path from 'path';\n</code></pre> <p>And then add below code after the line that initializes the <code>server</code> object with the result of the <code>expressApp.listen</code> method.</p> <pre><code>const authFilePattern = /^\\/auth-(start|end)\\.html$/;\nexpressApp.get(\n  authFilePattern, (req, res) =&gt; {\n    const fileName = req.path;\n    const filePath = path.join(__dirname, 'public', fileName);\n    res.sendFile(filePath);\n});\n</code></pre> <p>Change the adapter.ts file is as follows:</p> <ul> <li>Import the <code>TeamsAdapter</code> from teams-ai library.</li> </ul> <pre><code>import { TeamsAdapter } from '@microsoft/teams-ai';\n</code></pre> <ul> <li>Replace the adapter definition with <code>TeamsAdapter</code> instead of <code>CloudAdapter</code> for Teams SSO.</li> </ul> <pre><code>const adapter = new TeamsAdapter(\n  {},\n  new ConfigurationServiceClientCredentialFactory({\n    MicrosoftAppId: config.MicrosoftAppId,\n    MicrosoftAppPassword: config.MicrosoftAppPassword,\n    MicrosoftAppType: 'MultiTenant',\n  })\n);\n\n</code></pre> <ul> <li>Comment out the definition for <code>botFrameworkAuthentication</code> which is not needed anymore.</li> </ul> <p>Change the config.ts file is as follows:</p> <ul> <li>Add below properties to the constant <code>config</code>. Add a comma and after <code>process.env.INDEX_NAME</code> and append below snippet:</li> </ul> <pre><code>aadAppClientId: process.env.AAD_APP_CLIENT_ID,\naadAppClientSecret: process.env.AAD_APP_CLIENT_SECRET,\naadAppOauthAuthorityHost: process.env.AAD_APP_OAUTH_AUTHORITY_HOST,\naadAppTenantId: process.env.AAD_APP_TENANT_ID,\nbotDomain: process.env.BOT_DOMAIN,\naadAppOauthAuthority: process.env.AAD_APP_OAUTH_AUTHORITY,\n</code></pre> <p>Change the app.ts file is as follows:</p> <ul> <li>We will be using the <code>TurnState</code> and <code>AuthError</code> modules so include them in your import statement from the <code>@microsoft/teams-ai</code> library as shown below:</li> </ul> <pre><code>import { Application, ActionPlanner, OpenAIModel, PromptManager, AI, PredictedSayCommand, AuthError, TurnState } from \"@microsoft/teams-ai\";\n</code></pre> <ul> <li>Now to pass authentication setting to the Application definition, replace <code>const app</code> definition with below code snippet:</li> </ul> <pre><code>const app = new Application({\n  storage,\n  authentication: {settings: {\n    graph: {\n      scopes: ['User.Read'],\n      msalConfig: {\n        auth: {\n          clientId: config.aadAppClientId!,\n          clientSecret: config.aadAppClientSecret!,\n          authority: `${config.aadAppOauthAuthorityHost}/common`\n        }\n      },\n      signInLink: `https://${config.botDomain}/auth-start.html`,\n      endOnInvalidMessage: true\n    }\n  }},\n  ai: {\n    planner,\n    //feedback loop is enabled\n    enable_feedback_loop: true\n  },\n});\n</code></pre> <p>Teams AI library handles exchange of token between your custom engine agent and Microsoft Teams, so you can just call Microsoft Graph immediately upon receiving the token. Now let's add code to define and handle various authentication and messaging events using the Teams AI library. Paste below code after the app definition method:</p> <pre><code>interface ConversationState {\n  count: number;\n}\ntype ApplicationTurnState = TurnState&lt;ConversationState&gt;;\napp.authentication.get('graph').onUserSignInSuccess(async (context: TurnContext, state: ApplicationTurnState) =&gt; {\n  const token = state.temp.authTokens['graph'];\n  await context.sendActivity(`Hello ${await getUserDisplayName(token)}. You have successfully logged in to CareerGenie!`);     \n});\napp.authentication\n    .get('graph')\n    .onUserSignInFailure(async (context: TurnContext, _state: ApplicationTurnState, error: AuthError) =&gt; {\n        await context.sendActivity('Failed to login');\n        await context.sendActivity(`Error message: ${error.message}`);\n    });\n\n    // Listen for user to say '/reset' and then delete conversation state\napp.message('/reset', async (context: TurnContext, state: ApplicationTurnState) =&gt; {\n  state.deleteConversationState();\n  await context.sendActivity(`Ok I've deleted the current conversation state.`);\n});\n\napp.message('/signout', async (context: TurnContext, state: ApplicationTurnState) =&gt; {\n  await app.authentication.signOutUser(context, state);\n\n  // Echo back users request\n  await context.sendActivity(`You have signed out`);\n});\n\n</code></pre> <p>The above code called a function <code>getUserDisplayName()</code> after token is successfully received with which we can now call Microsoft Graph to get user information. So let's add the function definition. You will install the Graph SDK first. </p> <p>Run below script in the terminal to install the npm package:</p> <pre><code>npm install @microsoft/microsoft-graph-client @microsoft/microsoft-graph-types\n</code></pre> <p>Now, import module needed from the package in app.ts file.</p> <pre><code>import { Client } from \"@microsoft/microsoft-graph-client\";\n</code></pre> <p>Paste below code snippet after <code>app.message</code> method:</p> <pre><code>async function getUserDisplayName(token: string): Promise&lt;string | undefined&gt; {\n  let displayName: string | undefined;\n\n  const client = Client.init({\n    authProvider: (done) =&gt; {\n      done(null, token);\n    }\n  });\n\n  try {\n    const user = await client.api('/me').get();\n    displayName = user.displayName;\n  } catch (error) {\n    console.log(`Error calling Graph SDK in getUserDisplayName: ${error}`);\n  }\n\n  return displayName;\n}\n</code></pre> To make this app only work in single tenant, make below changes <ul> <li>Go to <code>aad.manifest.json</code> and update signInAudience node as <code>\"signInAudience\": \"AzureADMyOrg\"</code></li> <li>Got to <code>teamsapp.local.yml</code> and update signInAudience node for the aadApp\\create as <code>\"signInAudience: \"AzureADMyOrg\"</code></li> <li>Got to <code>src\\app\\app.ts</code> and update application definition's auth setting's authority as <code>authority: config.aadAppOauthAuthority</code></li> <li>Got to <code>src\\public\\auth-start.html</code> and set variable <code>authorizeEndpoint</code> to <code>https://login.microsoftonline.com/${tenantId}/oauth2/v2.0/authorize?${toQueryString(queryParams)}</code> </li> <li>Go to <code>src\\adapter.ts</code> and update the adapter definition <code>MicrosoftAppType: 'SingleTenant'</code> </li> </ul> <p></p>"},{"location":"pages/custom-engine/teams-ai/04-authentication/#exercise-4-run-the-application","title":"Exercise 4: Run the application","text":"<p>Now we are code complete for Teams SSO in Career Genie. Let's take it for a ride.</p>"},{"location":"pages/custom-engine/teams-ai/04-authentication/#step-1-app-installation-in-teams","title":"Step 1: App installation in Teams","text":"<p>Start debugging your app by selecting Run and Debug tab on Visual Studio Code and Debug in Teams (Edge) or Debug in Teams (Chrome). This will open Microsoft Teams in your browser. When your app details appear in Teams, select Add to start chatting with your app.</p> <p>Tip: Testing this exercise locally</p> <p>Make sure to test and debug this exercise on Teams locally, as some of the Teams AI library capabilities you've implemented in your app so far won't smoothly work in the Teams App Test Tool.</p> <p></p>"},{"location":"pages/custom-engine/teams-ai/04-authentication/#step-2-giving-consent","title":"Step 2: Giving consent","text":"<p>To start a conversation with the Career Genie, simply type a message. For example, you can begin by typing and sending 'Hi'.</p> <p>Tip: Check pop up settings in your browser</p> <p>Make sure <code>Pop up</code> is not blocked by browser for a smoother experience for below instructions.</p> <p>You will see a small dialog box for the additional permissions with \u2018Cancel\u2019 and \u2018Continue\u2019 buttons. This dialog is for logging in and giving your consent to the required permissions. Select Continue.</p> <p></p> <p>Known issues</p> <ul> <li>There is a delay for the consent dialog to show up in Teams chat. This has been identified as a platform issue and we are monitoring it. Keep pinging 2-3 times.</li> </ul> <p>Since you're running locally with Developer Tunnels, you'll see a warning screen, select Continue. Users won't see this when your app is deployed.</p> <p></p> <p>You'll be redirected to Entra ID, where you'll be asked to consent to the app's permissions. (You were directed there by public/auth-start.html which gets displayed when it found you hadn't consented).</p> <p></p> <p>Tip: Consent on behalf of your organization</p> <p>If you're a Microsoft 365 administrator, you will also be given the option to \"Consent on behalf of your organization\" which will consent for every user in your tenant.</p> <p>Select Accept to consent to the permissions and run Career Genie.</p> <p>You will now get this message from the custom engine agent with your logged in name showing successful authentication.</p> <p></p> <p>You can start chatting with your custom engine agent.</p> <p></p> <p>CONGRATULATIONS!</p> <p>You have completed Lab BTA4 - Add single sign on authentication to secure your custom engine agent!  If you want explore further, the source code of this lab is available in the Copilot Developer Camp repo.</p> <p>You can now proceed to Lab BTA5 - Add actions to handle complex tasks. Select Next.</p> <p></p> <p></p>"},{"location":"pages/custom-engine/teams-ai/05-actions/","title":"Lab BTA5 - Add actions to handle complex tasks","text":"<p>In this lab you will:</p> <ul> <li>Learn what actions are and how to handle complex tasks with them</li> <li>Integrate multi-prompt in your custom engine agent to handle actions</li> <li>Implement actions in your custom engine agent</li> <li>Utilize Microsoft Graph and actions together to automate workflows</li> </ul> Get a quick overview of the lab in this video. <p>Do these labs if you want to build a Custom engine agent with custom AI model and orchestration using Azure OpenAI and Teams AI library</p> <ul> <li>BTA0 - Setup</li> <li>BTA1 - First custom engine agent</li> <li>BTA2 - Index your data in Azure AI Search</li> <li>BTA3 - Enhance the user experience</li> <li>BTA4 - Add single sign on authentication</li> <li>BTA5 - Add actions to handle complex tasks</li> </ul>"},{"location":"pages/custom-engine/teams-ai/05-actions/#introduction","title":"Introduction","text":"<p>It's time to add some actions for Career Genie to handle complex tasks and workflows! In this lab, you'll integrate a new prompt in Career Genie's logic that can handle lists of candidates. That basically means that when you are searching for candidates with Career Genie, you can also create lists for candidates and add their names in. Once you are done, you can also send these lists to HR for scheduling interviews. All these will be handled by actions you'll implement in Career Genie! Let's get started.</p> What are actions in Custom engine agents? <p>An action in an AI system is like a basic function or method in your code\u2014it's a specific task that the system can perform. Actions are the building blocks that the AI uses to accomplish various tasks based on the user\u2019s input. The AI system decides which action to execute depending on what the user asks for.</p> <p>For example, actions could include:</p> <ul> <li> <p>Creating a new list.</p> </li> <li> <p>Removing a list.</p> </li> <li> <p>Adding items to an existing list.</p> </li> <li> <p>Removing items from an existing list.</p> </li> </ul> <p>When a user interacts with the AI system, the system interprets the prompt and selects the appropriate actions to carry out. It\u2019s like having a toolbox of functions, and the AI picks the right tool for the job based on the user\u2019s needs.</p>"},{"location":"pages/custom-engine/teams-ai/05-actions/#exercise-1-create-a-new-prompt-with-actions","title":"Exercise 1: Create a new prompt with actions","text":"<p>In this exercise, you'll create a new prompt in \"prompts\" folder to handle actions.</p>"},{"location":"pages/custom-engine/teams-ai/05-actions/#step-1-create-a-monologue-prompt","title":"Step 1: Create a \"monologue\" prompt","text":"<p>In your project, go to <code>src/prompts/</code> and add a new folder with a name monologue. In <code>src/prompts/monologue/</code> folder, create a new file with a name config.json and copy the following code snippet in the file:</p> <pre><code>{\n  \"schema\": 1.1,\n  \"description\": \"A bot that can chat with users\",\n  \"type\": \"completion\",\n  \"completion\": {\n    \"completion_type\": \"chat\",\n    \"include_history\": true,\n    \"include_input\": true,\n    \"max_input_tokens\": 2800,\n    \"max_tokens\": 1000,\n    \"temperature\": 0.9,\n    \"top_p\": 0.0,\n    \"presence_penalty\": 0.6,\n    \"frequency_penalty\": 0.0\n  },\n  \"augmentation\": {\n      \"augmentation_type\": \"monologue\"\n  }\n}\n</code></pre> <p>Brief intro about <code>augmentation</code> in config.json</p> <p>Augmentations help simplify prompt engineering by automatically adding specific instructions to your prompts. With augmentations, you can configure whether you want the AI to handle multi-step tasks (sequence) or think through its actions step by step (monologue).</p> <p>In <code>src/prompts/monologue/</code> folder, create a new file with a name skprompt.txt and copy the following text in the file:</p> <pre><code>You are a career specialist named \"Career Genie\" that helps Human Resources team who can manage lists of Candidates. \nYou are friendly and professional. You like using emojis where appropriate.\nAlways share the lists in bullet points.\n\nrules:\n- only create lists the user has explicitly asked to create.\n- only add Candidates to a list that the user has asked to have added.\n- if multiple lists are being manipulated, call a separate action for each list.\n- if Candidates are being added and removed from a list, call a separate action for each operation.\n- if user asks for a summary, share all the lists and candidates. \n- only send an email to HR if user has explicitly asked to send.\n\nCurrent lists:\n{{$conversation.lists}}\n</code></pre> <p>In <code>src/prompts/monologue/</code> folder, create a new file with a name actions.json and copy the following code snippet in the file:</p> <pre><code>[\n    {\n        \"name\": \"createList\",\n        \"description\": \"Creates a new list with an optional set of initial Candidates\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"list\": {\n                    \"type\": \"string\",\n                    \"description\": \"The name of the list to create\"\n                },\n                \"Candidates\": {\n                    \"type\": \"array\",\n                    \"description\": \"The Candidates to add to the list\",\n                    \"Candidates\": {\n                        \"type\": \"string\"\n                    }\n                }\n            },\n            \"required\": [\n                \"list\"\n            ]\n        }\n    },\n    {\n        \"name\": \"deleteList\",\n        \"description\": \"Deletes a list\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"list\": {\n                    \"type\": \"string\",\n                    \"description\": \"The name of the list to delete\"\n                }\n            },\n            \"required\": [\n                \"list\"\n            ]\n        }\n    },\n    {\n        \"name\": \"addCandidates\",\n        \"description\": \"Adds one or more Candidates to a list\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"list\": {\n                    \"type\": \"string\",\n                    \"description\": \"The name of the list to add the item to\"\n                },\n                \"Candidates\": {\n                    \"type\": \"array\",\n                    \"description\": \"The Candidates to add to the list\",\n                    \"Candidates\": {\n                        \"type\": \"string\"\n                    }\n                }\n            },\n            \"required\": [\n                \"list\",\n                \"Candidates\"\n            ]\n        }\n    },\n    {\n        \"name\": \"removeCandidates\",\n        \"description\": \"Removes one or more Candidates from a list\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"list\": {\n                    \"type\": \"string\",\n                    \"description\": \"The name of the list to remove the item from\"\n                },\n                \"Candidates\": {\n                    \"type\": \"array\",\n                    \"description\": \"The Candidates to remove from the list\",\n                    \"Candidates\": {\n                        \"type\": \"string\"\n                    }\n                }\n            },\n            \"required\": [\n                \"list\",\n                \"Candidates\"\n            ]\n        }\n    }\n]\n</code></pre> <p></p>"},{"location":"pages/custom-engine/teams-ai/05-actions/#exercise-2-implement-a-logic-in-the-planner-to-choose-between-prompts","title":"Exercise 2: Implement a logic in the planner to choose between prompts","text":"<p>In this exercise, you'll write a function that checks the user prompt and decides between \"chat\" or \"monologue\" prompts.</p>"},{"location":"pages/custom-engine/teams-ai/05-actions/#step-1-create-a-function-for-defaultprompt-in-the-planner","title":"Step 1: Create a function for <code>defaultPrompt</code> in the planner","text":"<p>In your project, go to <code>src/app/app.ts</code> file, and add the following function in your project:</p> <pre><code>async function choosePrompt(context){\n  if (context.activity.text.includes('list')){\n    const template = await prompts.getPrompt('monologue');\n    return template;\n  }\n  else {\n    const template = await prompts.getPrompt('chat');\n    const skprompt = fs.readFileSync(path.join(__dirname, '..', 'prompts', 'chat', 'skprompt.txt'));\n\n    const dataSources = (template.config.completion as any)['data_sources'];\n\n    dataSources.forEach((dataSource: any) =&gt; {\n      if (dataSource.type === 'azure_search') {\n        dataSource.parameters.authentication.key = config.azureSearchKey;\n        dataSource.parameters.endpoint = config.azureSearchEndpoint;\n        dataSource.parameters.indexName = config.indexName;\n        dataSource.parameters.embedding_dependency.deployment_name =\n          config.azureOpenAIEmbeddingDeploymentName;\n        dataSource.parameters.role_information = `${skprompt.toString('utf-8')}`;\n      }\n    });\n\n    return template;\n  }\n}\n</code></pre> <p>Review <code>choosePrompt</code> function</p> <p>Recognize that the choosePrompt function checks if user prompt includes \"list\". If yes, then it returns monologue prompt, if no, then it returns the chat that is currently our default prompt.</p> <p>In <code>src/app/app.ts</code> file, find the <code>planner</code> and remove the code assigned to the defaultPrompt. Then, define <code>choosePrompt</code> function as the defaultPrompt. The final version of the planner will look like below:</p> <pre><code>const planner = new ActionPlanner({\n  model,\n  prompts,\n  defaultPrompt: choosePrompt,\n});\n</code></pre> <p></p>"},{"location":"pages/custom-engine/teams-ai/05-actions/#exercise-3-implement-actions-in-the-app","title":"Exercise 3: Implement actions in the app","text":"<p>In this exercise, you'll create functions for your actions and register the action handlers in the app.</p>"},{"location":"pages/custom-engine/teams-ai/05-actions/#step-1-update-conversationstate-and-define-functions-for-each-action","title":"Step 1: Update <code>ConversationState</code> and define functions for each action","text":"<p>In <code>src/app/app.ts</code>, update the <code>@microsoft/teams-ai</code> with DefaultConversationState. The final version of the import will look as below:</p> <pre><code>import { AuthError, ActionPlanner, OpenAIModel, PromptManager, AI, PredictedSayCommand, Application, TurnState, DefaultConversationState } from \"@microsoft/teams-ai\";\n</code></pre> <p>In <code>src/app/app.ts</code>, find the ConversationState and ApplicationTurnState, replace them with the following code:</p> <pre><code>// Strongly type the applications turn state\ninterface ConversationState extends DefaultConversationState {\n  lists: Record&lt;string, string[]&gt;;\n}\nexport type ApplicationTurnState = TurnState&lt;ConversationState&gt;;\n</code></pre> <p>In <code>src/app/</code> folder, create another file with a name actions.ts and add the following source code to define functions for the actions:</p> <pre><code>import { ApplicationTurnState } from './app';\n\nfunction getCandidates(state: ApplicationTurnState, list: string): string[] {\n    ensureListExists(state, list);\n    return state.conversation.lists[list];\n}\n\nfunction setCandidates(state: ApplicationTurnState, list: string, Candidates: string[]): void {\n    ensureListExists(state, list);\n    state.conversation.lists[list] = Candidates ?? [];\n}\n\nfunction ensureListExists(state: ApplicationTurnState, listName: string): void {\n    if (typeof state.conversation.lists != 'object') {\n        state.conversation.lists = {};\n    }\n\n    if (!Object.prototype.hasOwnProperty.call(state.conversation.lists, listName)) {\n        state.conversation.lists[listName] = [];\n    }\n}\n\nfunction deleteList(state: ApplicationTurnState, listName: string): void {\n    if (\n        typeof state.conversation.lists == 'object' &amp;&amp;\n        Object.prototype.hasOwnProperty.call(state.conversation.lists, listName)\n    ) {\n        delete state.conversation.lists[listName];\n    }\n}\n\nexport { getCandidates, setCandidates, ensureListExists, deleteList };\n</code></pre> <p></p>"},{"location":"pages/custom-engine/teams-ai/05-actions/#step-2-register-action-handlers-in-the-app","title":"Step 2: Register action handlers in the app","text":"<p>In<code>src/app/app.ts</code>, add the following action imports on top of the file:</p> <pre><code>import { ensureListExists, getCandidates, setCandidates, deleteList } from \"./actions\";\n</code></pre> <p>Then add the following code snippet in the <code>src/app/app.ts</code> to register action handlers in the AI System:</p> <pre><code>// Register action handlers\ninterface ListOnly {\n  list: string;\n}\n\ninterface ListAndCandidates extends ListOnly {\n  Candidates?: string[];\n}\n\napp.ai.action('createList', async (context: TurnContext, state: ApplicationTurnState, parameters: ListAndCandidates) =&gt; {\n  ensureListExists(state, parameters.list);\n  if (Array.isArray(parameters.Candidates) &amp;&amp; parameters.Candidates.length &gt; 0) {\n      await app.ai.doAction(context, state, 'addCandidates', parameters);\n      return `List created and Candidates added. Summarize your action.`;\n  } else {\n      return `List created. Summarize your action.`;\n  }\n});\n\napp.ai.action('deleteList', async (context: TurnContext, state: ApplicationTurnState, parameters: ListOnly) =&gt; {\n  deleteList(state, parameters.list);\n  return `list deleted. Summarize your action.`;\n});\n\napp.ai.action('addCandidates', async (context: TurnContext, state: ApplicationTurnState, parameters: ListAndCandidates) =&gt; {\n  const Candidates = getCandidates(state, parameters.list);\n  Candidates.push(...(parameters.Candidates ?? []));\n  setCandidates(state, parameters.list, Candidates);\n  return `Candidates added. Summarize your action.`;\n});\n\napp.ai.action('removeCandidates', async (context: TurnContext, state: ApplicationTurnState, parameters: ListAndCandidates) =&gt; {\n  const Candidates = getCandidates(state, parameters.list);\n  (parameters.Candidates ?? []).forEach((candidate: string) =&gt; {\n      const index = Candidates.indexOf(candidate);\n      if (index &gt;= 0) {\n          Candidates.splice(index, 1);\n      }\n  });\n  setCandidates(state, parameters.list, Candidates);\n  return `Candidates removed. Summarize your action.`;\n});\n\n</code></pre> <p></p>"},{"location":"pages/custom-engine/teams-ai/05-actions/#step-3-test-your-app-with-the-new-actions","title":"Step 3: Test your app with the new actions","text":"<p>Let's test Career Genie with the new actions. Start debugging your app by selecting Run and Debug tab on Visual Studio Code and Debug in Teams (Edge) or Debug in Teams (Chrome). Microsoft Teams will pop up on your browser. Once your app details show up on Teams, select Add and start chatting with your app.</p> <p>Tip: Testing this exercise locally</p> <p>Make sure to test and debug this exercise on Teams locally, as some of the Teams AI library capabilities you've implemented in your app so far won't smoothly work in the Teams App Test Tool.</p> <p>To understand how the flow works, you may ask the following questions in order:</p> <ul> <li>Hello</li> <li>Can you suggest candidates who have experience in .NET?</li> <li>Great, add Isaac Talbot in the .NET Developer Candidates list</li> <li>Add Anthony Ivanov in the same list with Isaac</li> <li>Can you summarize my lists</li> <li>Suggest candidates who have experience in Python and are able to speak Spanish</li> <li>Nice! Add Sara Folgueroles in the Python Developer Candidates (Spanish speaking) list</li> <li>Can you suggest candidates who have 10+ years of experience</li> <li>Ok, remove Anthony from the .NET Developer Candidates list</li> <li>Add Anthony Ivanov in the Talent list</li> <li>Summarize my lists</li> </ul> <p></p> <p></p>"},{"location":"pages/custom-engine/teams-ai/05-actions/#exercise-4-utilize-actions-together-with-the-microsoft-graph-to-automate-workflows","title":"Exercise 4: Utilize actions together with the Microsoft Graph to automate workflows","text":"<p>In this exercise, you'll implement a new action that utilizes Microsoft Graph to send the candidates lists to the HR for scheduling interviews.</p>"},{"location":"pages/custom-engine/teams-ai/05-actions/#step-1-define-a-new-action-in-your-prompt-for-sending-emails","title":"Step 1: Define a new action in your prompt for sending emails","text":"<p>In your project, go to <code>src/prompts/monologue/actions.json</code> and add the following action:</p> <pre><code>,\n{\n    \"name\": \"sendLists\",\n    \"description\": \"Send list of Candidates to Human Resources, aka HR for scheduling interviews\",\n    \"parameters\": {\n        \"type\": \"object\",\n        \"properties\": {\n            \"list\": {\n                \"type\": \"string\",\n                \"description\": \"The name of the list to send Human Resources, aka HR for scheduling interviews\"\n            },\n            \"Candidates\": {\n                \"type\": \"array\",\n                \"description\": \"The Candidates in the list to send Human Resources, aka HR for scheduling interviews\",\n                \"Candidates\": {\n                    \"type\": \"string\"\n                }\n            }\n        },\n        \"required\": [\n            \"list\",\n            \"Candidates\"\n        ]\n    }\n}\n</code></pre> <p></p>"},{"location":"pages/custom-engine/teams-ai/05-actions/#step-2-create-a-new-function-for-the-new-sendlists-action","title":"Step 2: Create a new function for the new <code>sendLists</code> action","text":"<p>In your project, go to <code>src/app/app.ts</code>, locate the <code>getUserDisplayName</code> and add export in front of the function. The final version of the function will look like below:</p> <pre><code>export async function getUserDisplayName {\n...\n...\n...\n}\n\n</code></pre> <p>Locate <code>app</code> in the <code>src/app/app.ts</code> and update the scope with 'Mail.Send'. The final version of the app will look like below:</p> <pre><code>const app = new Application({\n  storage,\n  authentication: {settings: {\n    graph: {\n      scopes: ['User.Read', 'Mail.Send'],\n        ...\n        ...\n    }\n  }}});\n</code></pre> <p>Go to <code>env/.env.local.user</code> and add the following HR email as an environment variable:</p> <pre><code>HR_EMAIL=&lt;YOUR-EMAIL-ADDRESS&gt;\n</code></pre> <p><code>HR_EMAIL</code> details to test this lab</p> <p>Please enter your own account email address in <code>HR_EMAIL</code> to test this lab. In an ideal scenario, you'll use an email address of a Human Resources Team to send interview scheduling emails. Note that this lab is only for prototyping purposes and shouldn't be used in production.</p> <p>Go to <code>teamsapp.local.yml</code> and add the following line under the <code>file/createOrUpdateEnvironmentFile</code>, envs list:</p> <pre><code>HR_EMAIL: ${{HR_EMAIL}}\n</code></pre> <p>Go to <code>src/config.ts</code> and add the following line in the config:</p> <pre><code>HR_EMAIL: process.env.HR_EMAIL\n</code></pre> <p>Go to <code>src/app/actions.ts</code> and update the imports on top of the code as below:</p> <pre><code>import { getUserDisplayName, ApplicationTurnState } from './app';\nimport { Client } from \"@microsoft/microsoft-graph-client\";\nimport config from '../config';\n</code></pre> <p>Then, add the following functions in the <code>actions.ts</code>:</p> <pre><code>async function sendLists(state: ApplicationTurnState, token): Promise&lt;string&gt; {\n    const email = await createEmailContent(state.conversation.lists, token);\n    try {\n        const client = Client.init({\n            authProvider: (done) =&gt; {\n                done(null, token);\n            }\n        });\n        const sendEmail = await client.api('/me/sendMail').post(JSON.stringify(email));\n        if (sendEmail.ok) {\n            return email.message.body.content;\n        }\n        else {\n            console.log(`Error ${sendEmail.status} calling Graph in sendToHR: ${sendEmail.statusText}`);\n            return 'Error sending email';\n        }\n    } catch (error) {\n        console.error('Error in sendLists:', error);\n        throw error;\n    }\n}\n\nasync function createEmailContent(lists, token) {\n    let emailContent = '';\n    for (const listName in lists) {\n        if (lists.hasOwnProperty(listName)) {\n        emailContent += `${listName}:\\n`;\n        lists[listName].forEach(candidate =&gt; {\n            emailContent += `  \u2022 ${candidate}\\n`;\n        });\n        emailContent += '\\n'; // Add an extra line between different lists\n        }\n    }\n\n    const profileName = await getUserDisplayName(token);\n\n    const email ={\n        \"message\": {\n        \"subject\": \"Request to Schedule Interviews with Shortlisted Candidates\",\n        \"body\": {\n            \"contentType\": \"Text\",\n            \"content\": `Hello HR Team, \\nI hope this email finds you well. \\n\\nCould you please assist in scheduling 1:1 interviews with the following shortlisted candidates? \\n\\n${emailContent} Please arrange suitable times and send out the calendar invites accordingly. \\n\\n Best Regards, \\n ${profileName}`\n        },\n        \"toRecipients\": [\n            {\n            \"emailAddress\": {\n                \"address\": `${config.HR_EMAIL}`\n            }\n            }\n        ]\n        },\n        \"saveToSentCandidates\": \"true\"\n    };\n    return await email;\n}\n</code></pre> <p>Finally in <code>src/app/actions.ts</code>, add sendLists in the<code>actions.ts</code> exports. The final version of the exports will look like below:</p> <pre><code>export { getCandidates, setCandidates, ensureListExists, deleteList, sendLists };\n</code></pre> <p></p>"},{"location":"pages/custom-engine/teams-ai/05-actions/#step-3-register-sendlists-action-handler","title":"Step 3: Register <code>sendLists</code> action handler","text":"<p>Go to <code>src/app/app.ts</code> and update the <code>./actions</code> import with the sendLists function. The final version of the import will look as below:</p> <pre><code>import { ensureListExists, getCandidates, setCandidates, deleteList, sendLists } from \"./actions\";\n</code></pre> <p>Then, add the following code snippet to register <code>sendLists</code> action in the AI System:</p> <pre><code>app.ai.action('sendLists', async (context: TurnContext, state: ApplicationTurnState, parameters: ListAndCandidates) =&gt; {\n  await sendLists(state, state.temp.authTokens['graph']);\n  return `Email sent to HR. Summarize your action.`;\n});\n</code></pre> <p></p>"},{"location":"pages/custom-engine/teams-ai/05-actions/#step-4-update-your-entra-id-app-registration","title":"Step 4: Update your Entra ID app registration","text":"<p>Update the script for your Entra ID app for new scope <code>Mail.Send</code>. Go to file aad.manifest.json and inside the node <code>requiredResourceAccess</code> find <code>\"resourceAppId\": \"Microsoft Graph\",</code>. In the <code>resourceAccess</code> array add below scope after adding a comma.</p> <pre><code> {\n    \"id\": \"Mail.Send\",\n    \"type\": \"Scope\"\n}\n</code></pre> <p></p>"},{"location":"pages/custom-engine/teams-ai/05-actions/#step-5-test-your-app-and-the-new-sendlists-action","title":"Step 5: Test your app and the new <code>sendLists</code> action","text":"<p>Let's test Career Genie with the new sendLists actions. Start debugging your app by selecting Run and Debug tab on Visual Studio Code and Debug in Teams (Edge) or Debug in Teams (Chrome). Microsoft Teams will pop up on your browser. Once your app details show up on Teams, select Add and start chatting with your app.</p> <p>Tip: Testing this exercise locally</p> <p>Make sure to test and debug this exercise on Teams locally, as some of the Teams AI library capabilities you've implemented in your app so far won't smoothly work in the Teams App Test Tool.</p> <p>To start a conversation with Career Genie, simply type a message. For example, you can begin with 'Hi'.</p> <p>Tip: Check pop up settings in your browser</p> <p>Make sure <code>Pop up</code> is not blocked by browser for a smoother experience for below instructions.</p> <p>You will see a small dialog box for the additional permissions with \u2018Cancel\u2019 and \u2018Continue\u2019 buttons. This dialog is for logging in and giving your consent to the required permissions. Select Continue.</p> <p></p> <p>Since you're running locally with Developer Tunnels, you'll see a warning screen, select Continue. Users won't see this when your app is deployed. You'll be redirected to login and consent to the app's permissions.</p> <p>Tip: Consent on behalf of your organization</p> <p>If you're a Microsoft 365 administrator, you will also be given the option to \"Consent on behalf of your organization\" which will consent for every user in your tenant.</p> <p>Select Accept to consent to the permissions.</p> <p>You will now get a message from Career Genie with your logged in name showing successful authentication. Now, you can start testing the new action in Career Genie!</p> <p>To understand how the flow works, you may ask the following questions in order:</p> <ul> <li>Hello</li> <li>Can you suggest candidates who have experience in .NET?</li> <li>Great, add Isaac Talbot in the .NET Developer Candidates list</li> <li>Add Anthony Ivanov in the same list with Isaac</li> <li>Can you summarize my lists</li> <li>Suggest candidates who have experience in Python and are able to speak Spanish</li> <li>Nice! Add Sara Folgueroles in the Python Developer Candidates (Spanish speaking) list</li> <li>Can you suggest candidates who have 10+ years of experience</li> <li>Ok, remove Anthony from the .NET Developer Candidates list</li> <li>Add Anthony Ivanov in the Talent list</li> <li>Summarize my lists</li> <li>Add Pedro Armijo in the same list with Sara</li> <li>Summarize my lists</li> <li>Send my lists to HR</li> </ul> <p>Check your mailbox</p> <p>After the last step, check your mailbox to see if you received any email for the lists of candidates.</p> <p></p> <p></p> <p>CONGRATULATIONS!</p> <p>You have completed BTA5 - Add actions to handle complex tasks!  If you want explore further, the source code of this lab is available in the Copilot Developer Camp repo.</p> <p>This is the end of the Build your own agent path! Did you enjoy building Career Genie? Let us know about your experience and feedback. \ud83d\udc9c</p> <p></p> <p></p>"},{"location":"pages/extend-m365-copilot/","title":"Extend Microsoft 365 Copilot","text":"<p>Declarative agents are a type of agents for Microsoft 365. You can build one by extending Microsoft 365 Copilot. You define custom knowledge and custom actions to create agents tailored to a specific scenario.</p> <p>Declarative agents use the same infrastructure, orchestrator, foundation model, and security controls as Microsoft 365 Copilot, which ensures a consistent and familiar user experience.</p> <p></p>"},{"location":"pages/extend-m365-copilot/#what-youre-going-to-do","title":"What you're going to do","text":"<p>During Extend Path of the Copilot Developer Camp, you will construct a customized assistant tailored for a Human Resources department. The process will begin with understanding the fundamentals on creating a declarative agent, the creation of a basic declarative agent, and progress towards developing fully skilled assistant. This advanced assistant will be equipped with security features, including authentication mechanism linked to the Microsoft 365 tenant to get organizational data.</p> Section Purpose Setup Gets you ready with prerequisites. Declarative Agent Fundamentals Focuses on declarative agent concepts, start with a base template and explore more. Build and Integrate API Covers API creation and connecting API to agents. Upgrade the user interface with Adaptive cards. Authentication Contains all auth-related labs as sub-items. Integration Expands capability with Copilot connectors, etc."},{"location":"pages/extend-m365-copilot/#start-here-with-lab-e0-where-youll-set-up-development-your-environment","title":"Start here with Lab E0, where you'll set up development your environment","text":""},{"location":"pages/extend-m365-copilot/00-prerequisites/","title":"Lab E0 - Setup","text":"<p>In this lab, you will set up the development environment to build, test, and deploy the Copilot agents, that will help you achieve tailor made AI assitance using Microsoft 365 Copilot. </p> <p>Set up your development environment for Microsoft 365 Copilot</p> <p>This lab currently assumes you already have a tenant to setup. You can reference off to the page here that explains the current way you can get a tenant.</p> <p>In this lab you will learn:</p> <ul> <li>How to configure your Microsoft 365 tenant's Teams upload policy for lab use</li> <li>How to install and configure Microsoft 365 Agents Toolkit for Visual Studio Code</li> </ul> Get a quick overview of the lab in this video.              \u26a0\ufe0f Disclaimer: These samples and labs are intended for instructive and demonstration purposes and are not intended for use in production. Do not put them into production without upgrading them to production quality.          <p>Do these labs if you want to build a Declarative agent where Microsoft 365 provides the AI model and               orchestration</p> <ul> <li>\ud83c\udfc1 Welcome</li> <li>\ud83d\udd27 Set up <ul> <li>Lab E0 - Setup</li> </ul> </li> <li>\ud83e\uddf0 Declarative agent fundamentals <ul> <li> Lab E1 - Build a Detailed Declarative Agent </li> <li> Lab E1a - Geo locator game</li> </ul> </li> <li>\ud83d\udee0\ufe0f Build and integrate API from scratch <ul> <li>Lab E2 - Build an API</li> <li> Lab E3 - Add Declarative Agent + API</li> <li> Lab E4 - Enhance API + Plugin</li> <li>Lab E5 - Add Adaptive Cards</li> </ul> </li> <li>\ud83d\udd10 Authentication <ul> <li> Lab E6a - Toolkit</li> <li> Lab E6b - Manual</li> <li> Lab E6c - SSO</li> </ul> </li> <li>\ud83d\udd0c Integration <ul> <li> Lab EB - Add Graph Connector</li> </ul> </li> </ul>"},{"location":"pages/extend-m365-copilot/00-prerequisites/#exercise-1-configure-teams-upload-policy","title":"Exercise 1 : Configure Teams upload policy","text":""},{"location":"pages/extend-m365-copilot/00-prerequisites/#step-1-enable-teams-custom-application-uploads","title":"Step 1: Enable Teams custom application uploads","text":"<p>By default, end users can't upload applications directly; instead a Teams Administrator needs to upload them into the enterprise app catalog. In this step you will ensure your tenant is set up for direct uploads by Agents Toolkit.</p> <p>1\ufe0f\u20e3 Navigate to https://admin.microsoft.com/, which is the Microsoft 365 Admin Center.</p> <p>2\ufe0f\u20e3 In the left pane of the admin center, select Show all to open up the entire navigation. When the pane opens, select Teams to open the Microsoft Teams admin center.</p> <p>3\ufe0f\u20e3 In the left pane of the Microsoft Teams admin center, open the Teams apps accordion. Select Setup Policies, you will see a list of App setup policies. Then, select the Global (Org-wide default) policy.</p> <p>4\ufe0f\u20e3 Ensure the first switch, Upload custom apps is turned On.</p> <p>5\ufe0f\u20e3 Be sure to scroll down and select the Save button to persist your change.</p> <p>The change can take up to 24 hours to take effect, but usually it's much faster.</p> <p></p>"},{"location":"pages/extend-m365-copilot/00-prerequisites/#exercise-2-install-agents-toolkit-and-prerequisites","title":"Exercise 2: Install Agents Toolkit and prerequisites","text":"<p>You can complete these labs on a Windows, Mac, or Linux machine, but you do need the ability to install the prerequisites. If you are not permitted to install applications on your computer, you'll need to find another machine (or virtual machine) to use throughout the workshop.</p>"},{"location":"pages/extend-m365-copilot/00-prerequisites/#step-1-install-visual-studio-code","title":"Step 1: Install Visual Studio Code","text":"<p>It should be no surprise that Agents Toolkit for Visual Studio Code requires Visual Studio Code! You can download it here: Visual Studio Code.</p> <p></p>"},{"location":"pages/extend-m365-copilot/00-prerequisites/#step-2-install-nodejs","title":"Step 2: Install Node.js","text":"<p>Node.js is a program that allows you to run JavaScript on your computer; it uses the open source \"V8\" engine, which is used in popular web browsers such as Microsoft Edge and Google Chrome. You will need Node.js to run the web server code used throughout this workshop.</p> <p>Browse to https://nodejs.org/en/download/ and install version v22. This lab was last tested in Node Version v22.18.0.  If you already have another version of Node.js installed, you may want to set up the Node Version Manager (or this variation for Microsoft Windows), which allows you to easily switch Node.js versions on the same computer.</p> <p></p>"},{"location":"pages/extend-m365-copilot/00-prerequisites/#step-3-install-agents-toolkit","title":"Step 3: Install Agents Toolkit","text":"<p>These labs are based on Microsoft 365 Agents Toolkit version 6.0.</p> <p>What is Agents Toolkit?</p> <p>Microsoft 365 Agents Toolkit is an evolution of Microsoft Teams Toolkit, is designed to help you develop agents and apps for Microsoft 365 Copilot, Microsoft Teams, and Microsoft 365.</p> <p>Follow the steps as shown in the screen shot below.</p> <p>1\ufe0f\u20e3 Open Visual Studio Code and click on the Extensions toolbar button</p> <p>2\ufe0f\u20e3 Search for \"Microsoft 365 Agents\" and locate Agents Toolkit</p> <p>3\ufe0f\u20e3 Click Install</p> <p></p> <p>If you have Agents Toolkit installed but hidden</p> <p>If you previously installed Agents Toolkit, and then hid it on the Visual Studio sidebar, you might wonder why you can't see it. Right-click on the left sidebar and check off Agents Toolkit to bring it back into view.</p> <p></p> <p>CONGRATULATIONS!</p> <p>Now you are all set to create your first extensibility feature for Microsoft 365 Copilot. Proceed to create a Declarative Agent in the next lab. </p> <p></p> <p></p>"},{"location":"pages/extend-m365-copilot/01-typespec-declarative-agent/","title":"Lab E1 - Build your first Declarative agent with TypeSpec definition using Microsoft 365 Agents Toolkit","text":"<p>In this lab your will build a Declarative Agent with TypeSpec definition using Microsoft 365 Agents Toolkit. You will create an agent called <code>RepairServiceAgent</code>, which interacts with repairs data via an existing API service to help users manage car repair records.  You will find the source code to the finished agent here.</p> <p>This lab has been updated to reflect Ignite 2025 announcements. TypeSpec is now GA, and Toolkit version 6.4.1 is released. This lab is based on Lab 560, the hands-on session delivered at Ignite in Nov 2025.</p> Get a quick overview of the lab in this video. <p>Do these labs if you want to build a Declarative agent where Microsoft 365 provides the AI model and               orchestration</p> <ul> <li>\ud83c\udfc1 Welcome</li> <li>\ud83d\udd27 Set up <ul> <li>Lab E0 - Setup</li> </ul> </li> <li>\ud83e\uddf0 Declarative agent fundamentals <ul> <li> Lab E1 - Build a Detailed Declarative Agent </li> <li> Lab E1a - Geo locator game</li> </ul> </li> <li>\ud83d\udee0\ufe0f Build and integrate API from scratch <ul> <li>Lab E2 - Build an API</li> <li> Lab E3 - Add Declarative Agent + API</li> <li> Lab E4 - Enhance API + Plugin</li> <li>Lab E5 - Add Adaptive Cards</li> </ul> </li> <li>\ud83d\udd10 Authentication <ul> <li> Lab E6a - Toolkit</li> <li> Lab E6b - Manual</li> <li> Lab E6c - SSO</li> </ul> </li> <li>\ud83d\udd0c Integration <ul> <li> Lab EB - Add Graph Connector</li> </ul> </li> </ul>"},{"location":"pages/extend-m365-copilot/01-typespec-declarative-agent/#what-are-declarative-agents","title":"What are Declarative Agents?","text":"<p>Declarative Agents leverage the same scalable infrastructure and platform of Microsoft 365 Copilot, tailored specifically to meet focus on a special area of your needs. They function as subject matter experts in a specific area or business need, allowing you to use the same interface as a standard Microsoft 365 Copilot chat while ensuring they focus exclusively on the specific task at hand.</p>"},{"location":"pages/extend-m365-copilot/01-typespec-declarative-agent/#anatomy-of-a-declarative-agent","title":"Anatomy of a Declarative Agent","text":"<p>As you build more agents for Copilot, you\u2019ll notice that the final output is a set of a few files bundled into a zip file what we call an app package, that you'll install and use. So it's important you have a basic understanding of what the app package consists of. The app package of a Declarative Agent is similar to a Teams app if you have built one before with additonal elements. See the table to see all the core elements. You will also see that the app deployment process is very similar to deploying a Teams app.</p> File Type Description Required App manifest A JSON file (manifest.json) that defines the standard Teams app manifest. Yes Declarative agents manifest A JSON file containing the agent's name, instructions, capabilities, conversation starters, and actions (if applicable). Yes Plugin manifest A JSON file used to configure your action as an API plugin. Includes authentication, required fields, adaptive card responses, etc. Only needed if actions exist. No App icons A color and outline icon for your declarative agent. Yes"},{"location":"pages/extend-m365-copilot/01-typespec-declarative-agent/#capabilities-of-a-declarative-agent","title":"Capabilities of a Declarative Agent","text":"<p>You can enhance the agent's focus on context and data by not only adding instructions but also specifying the knowledge base it should access. They are called capabilities. Below are the ones supported in a Declarative Agent today: </p> <ul> <li>Copilot Connectors - let you centralize content on Microsoft 365. By importing external content to Microsoft 365, you not only make it easier to find relevant information, but you also let others in your organization discover new content.</li> <li>OneDrive and SharePoint - let you provide URLs of files/sites in OneDrive and SharePoint, which will part of the agent's knowledge base.</li> <li>Web search - let you enable or disable web content as part of the agent's knowledge base. You can also pass around 4 websites URLs as source. </li> <li>Code interpreter - enables you to build an agent with capabilities to better solve math problems and, when needed, leverage Python code for complex data analysis or chart generation.</li> <li>GraphicArt - enables you to build an agent for image or video generation using DALL\u00b7E.</li> <li>Email knowledge - enables you to build an agent to acces a personal or shared mailbox, and optionally, a specific mailbox folder as knowledge.</li> <li>People knowledge - enables you to build an agent to answer questions about individuals in an organization.</li> <li>Teams messages - enables you to equip the agent to search through Teams channels, teams, meetings, 1:1 chats, and group chats.</li> <li>Dataverse knowledge - enables you to add a Dataverse instance as a knowledge source.</li> <li>Scenario models - enables you to add task-specific models.</li> <li>Teams Meetings- enables you to build an agent to search for information about meetings in the organization.</li> </ul> <p>OnDrive and SharePoint</p> <p>URLs should be full path to SharePoint items (site, document library, folder, or file). You can use the \"Copy direct link\" option in SharePoint to get the full path of files and folders. To achieve this, right-click on the file or folder and select Details. Navigate to Path and click on the copy icon. Not specifying the URLs, the entire corpus of OneDrive and SharePoint content available to the logged in user will be used by the agent.</p> <p>Microsoft Copilot Connector</p> <p>Not specifying the connections, the entire corpus of Copilot Connectors content available to the logged in user will be used by the agent.</p> <p>Web search</p> <p>Not specifying the sites, the agent is allowed to search all the sites. You can specify up to four sites with no more than 2 path segments and no querystring parameters. </p>"},{"location":"pages/extend-m365-copilot/01-typespec-declarative-agent/#significance-of-typespec-for-declarative-agents","title":"Significance of TypeSpec for Declarative Agents","text":""},{"location":"pages/extend-m365-copilot/01-typespec-declarative-agent/#what-is-typespec","title":"What is TypeSpec","text":"<p>TypeSpec is a language developed by Microsoft for designing and describing API contracts in a structured and type-safe way. Think of it like a blueprint for how an API should look and behave including what data it accepts, returns, and how different parts of the API and its actions are connected.</p>"},{"location":"pages/extend-m365-copilot/01-typespec-declarative-agent/#why-typespec-for-agents","title":"Why TypeSpec for Agents?","text":"<p>If you like how TypeScript enforces structure in your frontend/backend code, you'll love how TypeSpec enforces structure in your agent and its API services like actions. It fits perfectly in design-first development workflows that align with tools like Visual Studio Code.</p> <ul> <li> <p>Clear Communication - provides a single source of truth that defines how your agent should behave, avoiding confusion when dealing with multiple manifest files like in the case of Declarative Agents.</p> </li> <li> <p>Consistency - ensures all parts of your agent and its actions, capabilities etc are designed consistently following the same pattern.</p> </li> <li> <p>Automation Friendly - automatically generates OpenAPI specs and other manifests saving time and reducing human errors.</p> </li> <li> <p>Early Validation - catches design issues early before writing actual code for example, mismatched data types or unclear definitions.</p> </li> <li> <p>Design-First Approach - encourages thinking about agent and API structure and contracts before jumping into implementation, leading to better long-term maintainability.</p> </li> </ul> <p>\u2611\ufe0f Well done understanding all the basic concepts you need to know about Declarative agents and TypeSpec! Proceed to the first exercise.</p>"},{"location":"pages/extend-m365-copilot/01-typespec-declarative-agent/#exercise-1-build-your-first-declarative-agent-with-one-action-that-performs-a-single-operation","title":"Exercise 1: Build your first Declarative Agent with one action that performs a single operation","text":"<p>It\u2019s time to build your first Declarative Agent using Microsoft 365 Agents Toolkit.  You will create an agent called RepairServiceAgent, which interacts with repairs data via an existing Repairs API service to help users manage car repair records. Checkout the  additional prerequisites for this lab, please install them now.</p> <ul> <li>REST Client add-in for Visual Studio Code: You will use one of these toolkits to test your API locally.</li> <li>Microsoft 365 Agents Toolkit version 6.4.0 and up. If you have an older version, update now.</li> </ul>"},{"location":"pages/extend-m365-copilot/01-typespec-declarative-agent/#step-1-scaffold-your-base-agent-project-using-microsoft-365-agents-toolkit","title":"Step 1: Scaffold your base agent project using Microsoft 365 Agents Toolkit","text":"<ul> <li>Open VS Code, locate the Microsoft 365 Agents Toolkit icon  from the VS Code menu on the left and select it. An activity bar will be open. </li> <li>Select the \"Create a New Agent/App\" button in the activity bar which will open the palette with a list of app templates available on Microsoft 365 Agents Toolkit.</li> <li>Choose \"Declarative Agent\" from the list of templates.</li> <li>Next, select \"Start with TypeSpec for Microsoft 365 Copilot\" to define your agent using TypeSpec.</li> <li>Next, select the Default folder where you want the agents toolkit to scaffold the agent project.</li> <li>Next, give an application name like - <code>RepairServiceAgent</code> and select Enter to complete the process. You will get a new VSCode window with the agent project preloaded.</li> </ul> <p>Note</p> <p>You may get a prompt window asking if you trust the authors of the files in the folder. This is expected and you can safely select Yes, I trust the authors. The dialog is a security safeguard that helps you decide whether to run all features or limit execution based on the trustworthiness of the code authors. If you're opening your own code or from a reliable source, it's safe to trust.</p> <p></p>"},{"location":"pages/extend-m365-copilot/01-typespec-declarative-agent/#step-2-sign-into-the-microsoft-365-agents-toolkit","title":"Step 2: Sign into the Microsoft 365 Agents Toolkit","text":"<p>You'll need to sign into the Microsoft 365 Agents Toolkit in order to upload and test your agent from within it.</p> <ul> <li>Within the project window, select the Microsoft 365 Agents Toolkit icon  again from the left side menu. This will open the Agent Toolkit\u2019s activity bar with sections like Accounts, Environment, Development etc. </li> <li>Under \"Accounts\" section select \"Sign in to Microsoft 365\". This will open a dialog from the editor to sign in or create a Microsoft 365 developer sandbox or Cancel. Select \"Sign in\". </li> <li>Once signed in, close the browser and go back to the project window.</li> </ul> <p></p>"},{"location":"pages/extend-m365-copilot/01-typespec-declarative-agent/#step-3-define-your-agent","title":"Step 3: Define your agent","text":"<p>The Declarative Agent project scaffolded by the Agents Toolkit provides a template that includes code for connecting an agent to the GitHub API to display repository issues. In this lab, you'll build your own agent that integrates with a Repairs API service, supporting multiple operations to manage repair data.</p> <p>Before proceeding with the agent definition, take a moment to examine the Repairs API service to gain a clearer understanding of its functionality.</p>"},{"location":"pages/extend-m365-copilot/01-typespec-declarative-agent/#get-to-know-the-repair-api-service","title":"Get to know the repair API service","text":"<p>You'll need to explore endpoints and payloads of the API service interactively. Using a .http file in Visual Studio Code with the REST Client extension, which is already installed for you, allows you to define and send HTTP requests directly from your editor. It's a lightweight, code-friendly way to test APIs, inspect responses, and iterate quickly without switching to external tools.</p> <p>Inside the root folder of the project you just created, create a folder called http. Create a new file named <code>repairs-api.http</code> inside the http folder.</p> <p>Note</p> <p>Creating folders and files in VS Code:</p> <ul> <li> <p>To create a new folder: Right-click in the Explorer panel (file tree) on the left side of VS Code, select \"New Folder\", and type the folder name.</p> </li> <li> <p>To create a new file: Right-click on the folder where you want to add the file, select \"New File\", and type the filename with its extension.</p> </li> <li> <p>Alternatively, you can use the icons in the Explorer panel: the folder icon (\ud83d\udcc1) creates a new folder, and the file icon (\ud83d\udcc4) creates a new file in the currently selected location.</p> </li> </ul> <p>Copy paste below content into the file.</p> <pre><code>@base_url = https://repairshub.azurewebsites.net\n\n### Get all repair requests\n{{base_url}}/repairs\n\n### Get a specific repair request by ID\n{{base_url}}/repairs/1\n\n### Create a new repair request\nPOST {{base_url}}/repairs\nContent-Type: application/json\n\n{\n  \"description\": \"Repair broken screen\",\n  \"date\": \"2023-10-01T12:00:00Z\",\n  \"image\": \"https://example.com/image.png\"\n}\n\n### Update an existing repair request\nPATCH {{base_url}}/repairs/1\nContent-Type: application/json  \n\n{\n  \"id\": 1,\n  \"description\": \"Repair broken screen - updated\",\n  \"date\": \"2023-10-01T12:00:00Z\",\n  \"image\": \"https://example.com/image-updated.png\"\n}\n\n\n### Delete a repair request by ID\nDELETE {{base_url}}/repairs/10\nContent-Type: application/json\n\n{\n  \"id\": 10\n}\n</code></pre> <p>Note there is a small delay to process the request from the editor, but the response should come back in a few seconds.</p> <p>To run each request, hover over each request line (e.g., GET {{base_url}}/repairs) and click Send Request to see the response. Observe the structure of requests and responses and use the response data to understand how your agent will interact with the API.</p> <p></p>"},{"location":"pages/extend-m365-copilot/01-typespec-declarative-agent/#repairs-api-overview","title":"Repairs API Overview","text":"<p>Base URL: https://repairshub.azurewebsites.net</p> Operation Method Endpoint Payload required Purpose Get all repair requests GET /repairs No Retrieve all repair jobs Get repair by ID GET /repairs/{id} No Fetch a specific repair job Create a repair request POST /repairs Yes Submit a new repair job Update a repair request PATCH /repairs/{id} Yes Modify an existing repair job Delete a repair request DELETE /repairs/{id} No Remove a repair job by ID <p>Now that you're familiar with the API service, let's move on to integrating it with your agent.</p>"},{"location":"pages/extend-m365-copilot/01-typespec-declarative-agent/#project-structure","title":"Project structure","text":"<p>Within your agent project under src folder, you'll discover the core TypeSpec configuration files: main.tsp and env.tsp.</p> <p>The main.tsp file serves as the primary definition point for your agent, containing essential metadata, behavioral instructions, and capability specifications.</p> <p>The env.tsp file is used by the toolkit to process environment variables during compilation. This file is generated from env/.env.* files and offer variables for other TypeSpec files, so manual updates are not required.</p> <p>You'll also find an actions folder containing template files - initially including github.tsp which demonstrates GitHub API integration. For this lab, you'll replace this template with your own action definitions to establish connectivity with the Repairs API service.</p> <p>Additionally, there's a prompts folder housing the instructions.tsp file, which allows you to define detailed behavioral instructions and guidance for your agent.</p>"},{"location":"pages/extend-m365-copilot/01-typespec-declarative-agent/#update-the-agent-metadata-and-instructions","title":"Update the Agent Metadata and Instructions","text":"<p>Open main.tsp and inspect what is there in the default template, which you will modify for our agent's repair service scenario.</p> <p>In the main.tsp file, you will find the basic structure of the agent. Review the content provided by the agents toolkit template which includes: -   Agent name and description 1\ufe0f\u20e3 -   Basic instructions 2\ufe0f\u20e3 -   Placeholder code for actions and capabilities (commented out) 3\ufe0f\u20e3</p> <p></p> <p>Begin by defining your agent for the repair scenario. Replace the @agent metadata with below code snippet.</p> <pre><code>@agent(\n  \"RepairServiceAgent\",\n  \"An agent for managing repair information\"\n)\n\n</code></pre> <p>Next, configure a conversation starter, the initial prompt that begins user-agent interaction. Uncomment the default template section and update the title and text fields to match the agent scenario.</p> <pre><code>// Uncomment this part to add a conversation starter to the agent.\n// This will be shown to the user when the agent is first created.\n@conversationStarter(#{\n  title: \"List repairs\",\n  text: \"List all repairs\"\n})\n\n</code></pre> <p>This starter prompt needs to trigger a GET operation to retrieve all repairs from the service. To enable this behaviour in the agent, you' ll need to define the corresponding action. Proceed to the next step to do so.</p> <p>Next, go to prompts/instructions.tsp and update the instructions. Replace the entire code block in the file with below code:</p> <pre><code>namespace Prompts {\n  const INSTRUCTIONS = \"\"\"\n    ## Purpose\n    You will assist the user in finding car repair records based on the information provided by the user.\n  \"\"\";\n}\n\n</code></pre>"},{"location":"pages/extend-m365-copilot/01-typespec-declarative-agent/#define-the-action-for-the-agent","title":"Define the action for the agent","text":"<p>Next, you will define the action for your agent by opening the actions/github.tsp file. Rename this file to actions.tsp.  You can rename a file in VSCode by right clicking on the file and choosing \"Rename\". </p> <p>You'll return to the main.tsp file later to complete the agent metadata with the action reference, but first, the action itself must be defined. For that open the file actions.tsp.</p> <p>The default actions.tsp template demonstrates how to define an agent action, including metadata, service URL, and operation structure. Replace the sample GitHub logic entirely with definitions relevant to the Repairs API service.</p> <p>After the module-level directives like import and using statements, replace the existing code up to the point where the \"SERVER_URL\" is defined with the snippet below. </p> <pre><code>@service\n@server(RepairsAPI.SERVER_URL)\n@actions(RepairsAPI.ACTIONS_METADATA)\nnamespace RepairsAPI{\n  /**\n   * Metadata for the API actions.\n   */\n  const ACTIONS_METADATA = #{\n    nameForHuman: \"Repair Service Agent\",\n    descriptionForHuman: \"Manage your repairs and maintenance tasks.\",\n    descriptionForModel: \"Plugin to add, update, remove, and view repair objects.\",\n    legalInfoUrl: \"https://docs.github.com/en/site-policy/github-terms/github-terms-of-service\",\n    privacyPolicyUrl: \"https://docs.github.com/en/site-policy/privacy-policies/github-general-privacy-statement\"\n  };\n\n  /**\n   * The base URL for the  API.\n   */\n  const SERVER_URL = \"https://repairshub.azurewebsites.net\";\n\n</code></pre> <p>Next, replace the operation in the template code from \"searchIssues\" to \"listRepairs\" to get the list of repairs. Replace the entire block of code starting just after the SERVER_URL definition and ending just before the final closing braces with the snippet below. Be sure to leave the closing braces intact. </p> <p>Remember to alway copy the code comment section as well here, do not ignore as they form the documentation for this action and is needed at compile time. </p> <pre><code>  /**\n   * List repairs from the API \n   * @param assignedTo The user assigned to a repair item.\n   */\n\n  @route(\"/repairs\")\n  @get  op listRepairs(@query assignedTo?: string): string;\n\n</code></pre> <p>Now go back to main.tsp file and verify the import statement for actions. If it still references ./actions/github.tsp, replace import \"./actions/github.tsp\"; with the statement below:</p> <pre><code>import \"./actions/actions.tsp\";\n</code></pre> <p>Next, in the same file, add the action you just defined into the agent. After the conversation starters replace the entire \"RepairServiceAgent\" namespace with below snippet:</p> <pre><code>namespace RepairServiceAgent{  \n\n  op listRepairs is global.RepairsAPI.listRepairs;   \n\n}\n\n</code></pre> <p></p>"},{"location":"pages/extend-m365-copilot/01-typespec-declarative-agent/#step-4-optional-understand-the-decorators","title":"Step 4: (Optional) Understand the decorators","text":"<p>This is an optional step but if curious to know what we have defined in the TypeSpec file just read through this step. In the TypeSpec files main.tsp and actions.tsp, you'll find decorators (starting with @), namespaces, models, and other definitions for your agent.</p> <p>Check this table to understand some of the decorators used in these files </p> Annotation Description @agent Defines the namespace (name) and description of the agent @instructions Defines the instructions that prescribe the behaviour of the agent. 8000 characters or less @conversationStarter Defines conversation starters for the agent @op Defines any operation. Either it can be an operation to define agent's capabilities like op GraphicArt, op CodeInterpreter etc., or define API operations like op listRepairs. For a post operation, define it like: op createRepair(@body repair: Repair): Repair; @server Defines the server endpoint of the API and its name @capabilities When used inside a function, it defines simple adaptive cards with small definitions like a confirmation card for the operation <p>\u2611\ufe0f You've successfully completed the first exercise! You learned how to add an action to list repairs which is the GET operation. In the next exercise, you'll add more operations for managing repairs and test and debug them.</p> <p>Continue to the next exercise.</p> <p></p>"},{"location":"pages/extend-m365-copilot/01-typespec-declarative-agent/#exercise-2-add-more-operations-test-the-agent-and-learn-debugging-techniques","title":"Exercise 2: Add more operations, test the agent, and learn debugging techniques","text":"<p>Next, you will enhance the agent by adding more operations in the Repairs API service and enabling responses with Adaptive Cards. Let's explore each of these enhancements step by step. If you are in the browser, go back to your project in VS Code.</p>"},{"location":"pages/extend-m365-copilot/01-typespec-declarative-agent/#step-1-modify-agent-to-add-more-operations","title":"Step 1: Modify agent to add more operations","text":"<ul> <li>Go to file actions/actions.tsp and copy paste below snippet just after listRepairs operation to add new operations createRepair, updateRepair and deleteRepair. Here you will also define the Repair item data model.</li> </ul> <pre><code>/**\n   * Create a new repair using the API. \n   * When creating a repair, the `id` field is optional and will be generated by the server.\n   * The `date` field should be in ISO 8601 format (e.g., \"2023-10-01T12:00:00Z\").\n   * The `title` field based on what repair user wants to create\n   * @param repair The repair to create.\n   */\n  @route(\"/repairs\")  \n  @post  op createRepair(@body repair: Repair): Repair;\n\n  /**\n   * Update an existing repair.\n   * The `id` field is required to identify the repair to update.\n   * The `date` field should be in ISO 8601 format (e.g., \"2023-10-01T12:00:00Z\").\n   * The `image` field should be a valid URL pointing to the image associated with the repair.\n   * @param repair The repair to update.\n   */\n  @route(\"/repairs\")  \n  @patch(#{implicitOptionality: true})\n  op updateRepair(@body repair: Repair): Repair;\n\n\n  /**\n   * Delete a repair.\n   * The `id` field is required to identify the repair to delete.\n   * @param repair The repair to delete.\n   */\n  @route(\"/repairs\") \n  @delete  op deleteRepair(@body repair: Repair): Repair;\n\n  /**\n   * A model representing a repair.\n   */\n  model Repair {\n    /**\n     * The unique identifier for the repair.\n     */\n    id?: string;\n\n    /**\n     * The short summary or title of the repair.\n     */\n    title: string;\n\n    /**\n     * The detailed description of the repair.\n     */\n    description?: string;\n\n    /**\n     * The user who is assigned to the repair.\n     */\n    assignedTo?: string;\n\n    /**\n     * The optional date and time when the repair is scheduled or completed.\n     */\n    @format(\"date-time\")\n    date?: string;\n\n    /**\n     * The URL of the image associated with the repair.\n     */\n    @format(\"uri\")\n    image?: string;\n  }\n\n</code></pre> <ul> <li>Next, go back to main.tsp file and make sure the new operations are also added as the agent's action. Paste the below snippet after the line op listRepairs is global.RepairsAPI.listRepairs; inside the RepairServiceActions namespace</li> </ul> <pre><code>op createRepair is global.RepairsAPI.createRepair;\nop updateRepair is global.RepairsAPI.updateRepair;\nop deleteRepair is global.RepairsAPI.deleteRepair;   \n\n</code></pre> <ul> <li>Also add a new conversation starter for creating a new repair item just after the first conversation starter definition.</li> </ul> <pre><code>@conversationStarter(#{\n  title: \"Create repair\",\n  text: \"Create a new repair titled \\\"[TO_REPLACE]\\\" and assign it to me\"\n})\n\n</code></pre>"},{"location":"pages/extend-m365-copilot/01-typespec-declarative-agent/#step-2-add-adaptive-card-to-function-reference","title":"Step 2: Add adaptive card to function reference","text":"<p>Next, you will enhance the reference cards or response cards using adaptive cards. Let's create an adaptive card for the repair items.</p> <ul> <li>In the project, go to the adaptiveCards folder under appPackage folder. Create a new file named <code>repair.json</code> and paste the provided code snippet. This will define a new adaptive card for the repair object. Ignore the default template card that is already present in this folder.</li> </ul> <pre><code>{\n    \"$schema\": \"http://adaptivecards.io/schemas/adaptive-card.json\",\n    \"type\": \"AdaptiveCard\",\n    \"version\": \"1.5\",\n    \"body\": [\n  {\n    \"type\": \"Container\",\n    \"$data\": \"${$root}\",\n    \"items\": [\n      {\n        \"type\": \"TextBlock\",\n        \"text\": \"Title: ${if(title, title, 'N/A')}\",\n        \"weight\": \"Bolder\",\n        \"wrap\": true\n      },\n      {\n        \"type\": \"TextBlock\",\n        \"text\": \"Description: ${if(description, description, 'N/A')}\",\n        \"wrap\": true\n      },\n      {\n        \"type\": \"TextBlock\",\n        \"text\": \"Assigned To: ${if(assignedTo, assignedTo, 'N/A')}\",\n        \"wrap\": true\n      },\n      {\n        \"type\": \"TextBlock\",\n        \"text\": \"Date: ${if(date, date, 'N/A')}\",\n        \"wrap\": true\n      },\n      {\n        \"type\": \"Image\",\n        \"url\": \"${image}\",\n        \"$when\": \"${image != null}\"\n      }\n    ]\n  }\n],  \n    \"actions\": [\n      {\n        \"type\": \"Action.OpenUrl\",\n        \"title\": \"View Image\",\n        \"url\": \"https://www.howmuchisit.org/wp-content/uploads/2011/01/oil-change.jpg\"\n      }\n    ]\n  }\n\n\n</code></pre> <ul> <li>Next, go back to actions.tsp file and locate the listRepairs operation. Just above the operation definition @get  op listRepairs(@query assignedTo?: string): string;, paste the card definition using below snippet.</li> </ul> <pre><code>\n@card(#{  dataPath: \"$\", file: \"adaptiveCards/repair.json\",    properties: #{ title: \"$.title\", url: \"$.image\" } })\n\n</code></pre> <p>The above card response will be sent by the agent when you ask about a repair item or when agent brings a list of items as its reference.</p> <p>To keep things simple for this lab, you'll reuse the same card. In practice, you could create separate cards for different operations based on your needs.</p> <p>Continue to add card response for the createRepair operation to show what the agent created after the POST operation.</p> <ul> <li>Copy paste below snippet just above the code @post  op createRepair(@body repair: Repair): Repair;</li> </ul> <pre><code>\n@card(#{  dataPath: \"$\", file: \"adaptiveCards/repair.json\",    properties: #{ title: \"$.title\", url: \"$.image\" } })\n\n</code></pre> <p></p>"},{"location":"pages/extend-m365-copilot/01-typespec-declarative-agent/#step-3-update-agent-instruction-for-new-operations","title":"Step 3: Update agent instruction for new operations","text":"<p>In the prompts/instructions.tsp file, update instructions definition to have additional directives for the agent. Replace the INSTRUCTIONS constant with below code:</p> <pre><code>const INSTRUCTIONS =\"\"\"  \n    ## Purpose\n    You will assist the user in finding car repair records based on the information provided by the user.\n\n    ## Guidelines\n    - You are a repair service agent.\n    - You can use the actions to create, update, and delete repairs.\n    - When creating a repair item, if the user did not provide a description or date, use the title as the description and put today's date in the format YYYY-MM-DD.\n    - Do not use any technical jargon or complex terms.\n  \"\"\";\n</code></pre> <p></p>"},{"location":"pages/extend-m365-copilot/01-typespec-declarative-agent/#step-4-provision-and-test-the-agent","title":"Step 4:  Provision and Test the Agent","text":""},{"location":"pages/extend-m365-copilot/01-typespec-declarative-agent/#provision","title":"Provision","text":"<p>Next step is to test the Repair Service Agent. For this first you need to provision the agent to your tenant. </p> <p>Follow below steps:</p> <ul> <li> <p>Open your .env.dev file  in folder env in the root of the project to see if you have a variable AGENT_SCOPE. If present, change the variable value from <code>shared</code> to <code>personal</code>.</p> </li> <li> <p>Select the Agents toolkit extension icon . This will open the activity bar for agents toolkit from within your project.</p> </li> <li> <p>In the activity bar of the agents toolkit under \"LifeCycle\" select \"Provision\". This will build the app package consisting of the generated manifest files and icons and side load the app package into the catalog only for you to test.</p> </li> </ul> <p>Note</p> <p>Here the agents toolkit also helps validate all the definitions provided in the TypeSpec file to ensure accuracy. It also identifies errors to streamline the developer experience.</p> <p>This will take a while and you will be able to see a toaster message in VS Code, showing the progress of the task to provision.</p> <p>Warning</p> <p>There are couple of known issues where the Provision action in Agents Toolkit may fail with the errors shown below. If this happens, simply retry the provisioning process until it succeeds.  </p> <ul> <li> <p>Next, open Microsoft Edge from lab machine from the taskbar and go to <code>https://m365.cloud.microsoft/chat</code> in the browser to open Copilot app. Login using your credentials.</p> </li> <li> <p>Select the RepairServiceAgent from the left side of the screen under Agents. </p> </li> </ul> <p>If you don't see left navigation to choose agent,  look for below icon and select it to show the navigation. </p>"},{"location":"pages/extend-m365-copilot/01-typespec-declarative-agent/#test-list-operation","title":"Test list operation","text":"<ul> <li> <p>Select the conversation starter - List repairs and send the prompt to the chat to initiate conversation with your agent and check out the response. When prompted to connect the agent to process a query, you\u2019ll usually get a message with buttons to Allow accessing your service through agent. </p> </li> <li> <p>To streamline your experience in this lab, select \"Always allow\" when it appears.</p> </li> </ul> <p>Once accepted you will see the response from the agent as below: </p> <p></p>"},{"location":"pages/extend-m365-copilot/01-typespec-declarative-agent/#diagnosing-and-debugging-agent","title":"Diagnosing and Debugging Agent","text":"<p>You can enable developer mode in a chat to allow you as a developer to understand how well the agent understands the tasks, ensure it calls your services appropriately, identify areas that need fine-tuning, detect performance issues, and generally help you track and analyse its interactions.</p> <ul> <li>Send <code>-developer on</code> to the chat to enable debugging mode.</li> </ul> <p>The agent will respond with a success message if everything went well Successfully enabled developer mode.</p> <p>Note</p> <p>Refresh the browser by pressing F5 to activate the agent debug info.</p> <ul> <li>Next to test, send a prompt to interact with the agent like the one below.</li> </ul> <p><code>Find out what Karin is working on</code>.</p> <ul> <li>You will get a response with information from the repair service but also get the Agent debug info card along with the response.</li> <li>Expand the Agent debug info card to view all the details. You will be able to see:</li> <li>Agent information 1\ufe0f\u20e3</li> <li>Capabilities of the agent 2\ufe0f\u20e3</li> <li>Actions and what function were selected 3\ufe0f\u20e3</li> <li>Executed action info with detailed information about the request, latency, response data, etc. 4\ufe0f\u20e3</li> </ul> <p></p> <ul> <li>Try expanding the Executed Actions and you will see the request url, parameters passed, request header, response, latency, etc.</li> </ul>"},{"location":"pages/extend-m365-copilot/01-typespec-declarative-agent/#test-create-operation","title":"Test create operation","text":"<p>Now let's try to invoke a POST call to create a repair item.</p> <ul> <li> <p>Start by using the conversation starter 'Create repair'. Replace parts of the prompt to add a title, then send it to the chat to initiate the interaction. For e.g.</p> <p><code>Create a new repair titled \"360 camera issue\" and assign it to me.</code></p> </li> <li> <p>The confirmation dialog if you notice has more metadata that what you sent, thanks to updated instructions.</p> </li> </ul> <p></p> <ul> <li>Proceed to add the item by confirming the dialog.</li> </ul> <p>The agent responds is with created item shown in a rich adaptive card.</p> <p></p> <ul> <li> <p>Next, recheck reference cards work. Open a new chat and then send below prompt in the conversation</p> <p><code>List all my repairs.</code></p> </li> </ul> <p>The agent with the list with each referenced with an adaptive card.</p> <p></p> <p>\u2611\ufe0f You've successfully completed the second exercise! You've enhanced your agent with additional repair operations and learned how to test and debug it. Continue to the bonus exercise.</p> <p></p>"},{"location":"pages/extend-m365-copilot/01-typespec-declarative-agent/#bonus-exercise-add-code-interpreter-capability-to-the-agent","title":"Bonus Exercise: Add code interpreter capability to the agent","text":""},{"location":"pages/extend-m365-copilot/01-typespec-declarative-agent/#step-1-add-code-interpreter-capability-to-your-agent","title":"Step 1: Add code interpreter capability to your agent","text":"<p>Declarative Agents can be extended to have many capabilities like OneDriveAndSharePoint, WebSearch, CodeInterpreter etc Next, you will enhance the agent by adding code interpreter capability to it.</p> <ul> <li> <p>To do this, open the main.tsp file and locate the RepairServiceAgent namespace which is where you define the agent behaviour.</p> </li> <li> <p>Inside the namespace RepairServiceAgent, insert the following snippet above op listRepairs to define a new capability that enables the agent to interpret and execute code.</p> </li> </ul> <pre><code>op codeInterpreter is AgentCapabilities.CodeInterpreter;\n</code></pre> <p>Note</p> <p>When you add above codeinterpreter operation, paste it inside the outer RepairServiceAgent namespace which defines the agent's behaviour including the capabilities and not the RepairServiceActions namespace which defines the agent's actions.</p> <p>Since the agent now supports additional capability, update the instructions accordingly to reflect this enhancement.</p> <ul> <li>In the prompts/instructions.tsp file, update INSTRUCTIONS constant to have additional directives for the agent for new capability. Replace the const with below snippet:</li> </ul> <pre><code>\n  const INSTRUCTIONS =\"\"\"\n   ## Purpose\n    You will assist the user in finding car repair records based on the information provided by the user. You can generate charts based on data. Use python execution for charting/visualization.\n\n    ## Guidelines\n    - You are a repair service agent.\n    - You can use the actions to create, update, and delete repairs.\n    - When creating a repair item, if the user did not provide a description or date, use the title as the description and put today's date in the format YYYY-MM-DD.\n    - when asked to generate report, generate charts using existing data.\n    - Do not use any technical jargon or complex terms.\n\"\"\";\n\n</code></pre> <p></p>"},{"location":"pages/extend-m365-copilot/01-typespec-declarative-agent/#step-2-test-your-agents-new-capability","title":"Step 2: Test your agent's new capability","text":"<p>Next, you will test the new analytical capability of your agent. You will need to reprovision the agent. Follow below steps:</p> <ul> <li>Update the version of your agent. Go to appPackage/manifest.json and update from \"version\": \"1.0.0\" to \"version\": \"1.0.1\"</li> <li>Save all changes, select the Agents toolkit extension icon , to open the activity bar from within your project.</li> <li>In the activity bar of the agents toolkit under \"LifeCycle\" select \"Provision\". This will reprovision the agent.</li> <li>If you already have chat with the agent open, then open a new chat by selecting the New chat button on the top right corner of your agent.</li> <li> <p>If not, open Microsoft Edge from lab machine from the taskbar and go to <code>https://m365.cloud.microsoft/chat</code> in the browser to open Copilot app. Login using your credentials.</p> </li> <li> <p>Select the RepairServiceAgent from the left side of the screen under Agents. </p> </li> </ul> <p>If you don't see left navigation to choose agent,  look for below icon and select it to show the navigation. </p> <ul> <li>Next, copy the prompt below and paste it to the message box and hit enter to send it.</li> </ul> <p><code>Classify repair items based on title into three distinct categories: Routine Maintenance, Critical, and Low Priority. Then, generate a pie chart displaying the percentage representation of each category. Use unique colours for each group and incorporate tooltips to show the precise values for each segment.</code></p> <p>You should get some response similar to below screen. It may vary sometimes. </p> <p>Warning</p> <p>Known issue with code interpreter: If you see an error message in the response as below, don't worry\u2014the chart will still be generated and displayed correctly. You can safely ignore the error. </p> <p></p> <p>\u2611\ufe0f Great job completing all the exercises!</p> <p>CONGRATULATIONS!</p> <p>Great job on building your first agent using TypeSpec \ud83c\udf89 </p> <p>Proceed to create, build, and integrate an API selecting Next.  </p> <p>Continue practicing by building a Geolocator game agent\u2014select Create a game below.  </p> <p></p>"},{"location":"pages/extend-m365-copilot/01a-geolocator/","title":"Lab E1 - Instructions based Gelocator game agent","text":"<p>In this lab, you'll create a basic declarative agent using instructions and supplementary knowledge provided through files.  Your agent is designed to give you a fun and educational break from work by helping you explore cities across the globe. It presents abstract clues for you to guess a city, with fewer points awarded the more clues you use. At the end, your final score will be revealed.</p> <p>In this lab you will learn how to:</p> <ul> <li>create a declarative agent using Agents Toolkit template</li> <li>customise the agent to create the geo locator game using instructions </li> <li>learn how to run and test your app </li> <li>for bonus exercise, you will need a SharePoint teams site</li> </ul> Get a quick overview of the lab in this video. <p>Do these labs if you want to build a Declarative agent where Microsoft 365 provides the AI model and               orchestration</p> <ul> <li>\ud83c\udfc1 Welcome</li> <li>\ud83d\udd27 Set up <ul> <li>Lab E0 - Setup</li> </ul> </li> <li>\ud83e\uddf0 Declarative agent fundamentals <ul> <li> Lab E1 - Build a Detailed Declarative Agent </li> <li> Lab E1a - Geo locator game</li> </ul> </li> <li>\ud83d\udee0\ufe0f Build and integrate API from scratch <ul> <li>Lab E2 - Build an API</li> <li> Lab E3 - Add Declarative Agent + API</li> <li> Lab E4 - Enhance API + Plugin</li> <li>Lab E5 - Add Adaptive Cards</li> </ul> </li> <li>\ud83d\udd10 Authentication <ul> <li> Lab E6a - Toolkit</li> <li> Lab E6b - Manual</li> <li> Lab E6c - SSO</li> </ul> </li> <li>\ud83d\udd0c Integration <ul> <li> Lab EB - Add Graph Connector</li> </ul> </li> </ul>"},{"location":"pages/extend-m365-copilot/01a-geolocator/#introduction","title":"Introduction","text":"<p>Declarative agents leverage the same scalable infrastructure and platform of Microsoft 365 Copilot, tailored specifically to meet focus on a special area of your needs. They function as subject matter experts in a specific area or business need, allowing you to use the same interface as a standard Microsoft 365 Copilot chat while ensuring they focus exclusively on the specific task at hand. </p> <p>In this lab you will start out building a declarative agent using Agents Toolkit with a default template used in the tool. This is to help you get started with something. Next, you will modify your agent to be focused on a geo location game. </p> <p>The goal of your AI is to provide a fun break from work while helping you learn about different cities around the world. It offers abstract clues for you to identify a city. The more clues you need, the fewer points you earn. At the end of the game, it will reveal your final score.</p> <p></p> <p>As a bonus you will also give your agent some files to refer to a secret diary \ud83d\udd75\ud83c\udffd and a map \ud83d\uddfa\ufe0f to give more challenges to the player. </p> <p>So let's begin \ud83d\udcaa\ud83c\udffc</p>"},{"location":"pages/extend-m365-copilot/01a-geolocator/#exercise-1-scaffold-a-declarative-agent-from-template","title":"Exercise 1: Scaffold a declarative agent from template","text":"<p>You can use just any editor to create a declarative agent if you know the structure of the files in the app package mentioned above. But things are easier if you use a tool like Agents Toolkit to not only create these files for you but also help you deploy and publish your app.  So to keep things as simple as possible you will use Agents Toolkit.</p>"},{"location":"pages/extend-m365-copilot/01a-geolocator/#step-1-install-agents-toolkit","title":"Step 1: Install Agents Toolkit","text":"<ul> <li>Go to extensions tab of your Visual Studio Code and look for Microsoft 365 Agents Toolkit.</li> <li>Select it and install.</li> </ul>"},{"location":"pages/extend-m365-copilot/01a-geolocator/#step-2-use-agents-toolkit-to-create-a-declarative-agent-app","title":"Step 2: Use Agents Toolkit to create a declarative agent app","text":"<p>Go to the Agents Toolkit extension in your Visual Studio Code editor in the left 1\ufe0f\u20e3 and select Create a New Agent/App 2\ufe0f\u20e3.</p> <p></p> <p>A panel opens up where you need to select Declarative Agent from the list of project types.</p> <p></p> <p>Next, you will be asked to choose want to create a basic declarative agent or one with an API plugin.  Choose the No Action option.</p> <p></p> <p>Why not create one with an action here? </p> <p>You will build a REST API in the next lab and you will also learn how to integrate that API in a declarative agent with an action in the following one in this same path. Here we are just going to create a declarative agent. Baby steps!</p> <p>Next, type in the directory where the project folder has to be created.</p> <p></p> <p>Next, give it an application name <code>Geo Locator Game</code> and select Enter. </p> <p></p> <p>The project will be created in a few seconds in the folder you mentioned and will open up in a new project window of Visual Studio Code. This is your working folder.</p> <p></p> <p>Well done! You have successfully set up the base declarative agent! Now, proceed to examine the files contained within to be able to customise it to make the geo locator game app. </p> <p></p>"},{"location":"pages/extend-m365-copilot/01a-geolocator/#step-3-set-up-accounts-in-agents-toolkit","title":"Step 3: Set up accounts in Agents Toolkit","text":"<p>Now select the Agents Toolkit icon in the left 1\ufe0f\u20e3 . Under \"Accounts\" click \"Sign in to Microsoft 365\" 2\ufe0f\u20e3 and log in with your own Microsoft 365 account.</p> <p></p> <p>A browser window will pop up and offer to log into Microsoft 365. When it says \"You are signed in now and close this page\", please do so.</p> <p>Now verify that the \"Custom App Upload Enabled\" checker has a green checkmark. If it doesn't, that means that your user account doesn't have permission to upload Teams applications. Follow steps in Exercise 1 of this lab. </p> <p>Now verify that the \"Copilot Access Enabled\" checker has a green checkmark. If it doesn't, that means that your user account does not have a license for Copilot. This is required to continue the labs.</p> <p></p> <p>Now, let's do a code tour.</p> <p></p>"},{"location":"pages/extend-m365-copilot/01a-geolocator/#step-4-understanding-the-files-in-the-app","title":"Step 4: Understanding the files in the app","text":"<p>Here's how the base project looks: </p> Folder/File Contents <code>.vscode</code> VSCode files for debugging <code>appPackage</code> Templates for the Teams application manifest, the agent manifest, and the API specification, if any <code>env</code> Environment files with a default  <code>.env.dev</code>    file <code>appPackage/color.png</code> Application logo image <code>appPackage/outline.png</code> Application logo outline image <code>appPackage/declarativeAgent.json</code> Defines settings and configurations of the declarative agent. <code>appPackage/instruction.txt</code> Defines the behaviour of declarative agent. <code>appPackage/manifest.json</code> Teams application manifest that defines metadata for your declarative agent. <code>m365agent.yml</code> Main Agents Toolkit project file. The project file defines two primary things: Properties and configuration Stage definitions. <p>The file of interest for our lab is primarily the appPackage/instruction.txt file which is the core directives needed for your agent. It's a plain text file and you can write natural language instructions in it. </p> <p>Another important file is appPackage/declarativeAgent.json where there is a schema to be followed to extend Microsoft 365 Copilot with the new declarative agent. Let's look at what properties the schema of this file has. </p> <ul> <li>The <code>$schema</code> is the schema reference </li> <li>The <code>version</code> is the schema version </li> <li>The <code>name</code> key represents the name of the declarative agent.</li> <li>The <code>description</code> provides a description.</li> <li>The <code>instructions</code> provides the path to the instructions.txt file which holds directives which will determine the operational behavior. You can also put your instructions as plain text as a value here. But for this lab we will use the instructions.txt file.</li> </ul> <p>Another important file is the <code>appPackage/manifest.json</code> file, which contains crucial metadata, including the package name, the developer\u2019s name, and references to the agents utilised by the application. The following excerpt from the manifest.json file illustrates these details:</p> <pre><code>\"copilotAgents\": {\n        \"declarativeAgents\": [            \n            {\n                \"id\": \"declarativeAgent\",\n                \"file\": \"declarativeAgent.json\"\n            }\n        ]\n    },\n</code></pre> <p>You could also update the logo files <code>color.png</code> and <code>outline.png</code> to make it match your application's brand. In today's lab you will change color.png icon for the agent to stand out. </p> <p></p>"},{"location":"pages/extend-m365-copilot/01a-geolocator/#exercise-2-update-instructions-and-icons","title":"Exercise 2: Update instructions and icons","text":""},{"location":"pages/extend-m365-copilot/01a-geolocator/#step-1-update-icons-and-manifests","title":"Step 1: Update icons and manifests","text":"<p>First we will do the easy bit which is replacing the logo. Copy the image located here and replace it with the image of same name in the folder appPackage in your root project. </p> <p>Next, go to the file appPackage/manifest.json  in your root project and find the node copilotAgents. Update the id value of the declarativeAgents array's first entry from <code>declarativeAgent</code> to <code>dcGeolocator</code> to make this ID unique.</p> <pre>\n \"copilotAgents\": {\n        \"declarativeAgents\": [            \n            {\n                \"id\": \"dcGeolocator\",\n                \"file\": \"declarativeAgent.json\"\n            }\n        ]\n    },\n\n</pre> <p>Next, go to the file appPackage/instruction.txt and copy paste the below instruction to overwrite the existing contents of the file.</p> <pre><code>System Role: You are the game host for a geo-location guessing game. Your goal is to provide the player with clues about a specific city and guide them through the game until they guess the correct answer. You will progressively offer more detailed clues if the player guesses incorrectly. You will also reference PDF files in special rounds to create a clever and immersive game experience.\n\nGame play Instructions:\nGame Introduction Prompt\nUse the following prompt to welcome the player and explain the rules:\nWelcome to the Geo Location Game! I\u2019ll give you clues about a city, and your task is to guess the name of the city. After each wrong guess, I\u2019ll give you a more detailed clue. The fewer clues you use, the more points you score! Let\u2019s get started. Here\u2019s your first clue:\nClue Progression Prompts\nStart with vague clues and become progressively specific if the player guesses incorrectly. Use the following structure:\nClue 1: Provide a general geographical clue about the city (e.g., continent, climate, latitude/longitude).\nClue 2: Offer a hint about the city\u2019s landmarks or natural features (e.g., a famous monument, a river).\nClue 3: Give a historical or cultural clue about the city (e.g., famous events, cultural significance).\nClue 4: Offer a specific clue related to the city\u2019s cuisine, local people, or industry.\nResponse Handling\nAfter the player\u2019s guess, respond accordingly:\n\nIf the player guesses correctly, say:\nThat\u2019s correct! You\u2019ve guessed the city in [number of clues] clues and earned [score] points. Would you like to play another round?\nIf the guess is wrong, say:\nNice try! [followed by more clues]\nPDF-Based Scenario\nFor special rounds, use a PDF file to provide clues from a historical document, traveler's diary, or ancient map:\nThis round is different! I\u2019ve got a secret document to help us. I\u2019ll read clues from this [historical map/traveler\u2019s diary] and guide you to guess the city. Here\u2019s the first clue:\nReference the specific PDF to extract details: Do not provide the citations and also link to the document since its a secret document for generating the questions.\nTraveler's Diary PDF,Historical Map PDF. Do not provide the citations and also link to the document since its a secret document for generating the questions.\nUse emojis where necessary to have friendly tone. \nScorekeeping System\nTrack how many clues the player uses and calculate points:\n\n1 clue: 10 points\n2 clues: 8 points\n3 clues: 5 points\n4 clues: 3 points\nEnd of Game Prompt\nAfter the player guesses the city or exhausts all clues, prompt:\nWould you like to play another round, try a special challenge?\n\n</code></pre> <p>Follow the next step to make sure our agent can help user engage with it by giving conversation starters.  </p> <p>Include your own files in appPackage files</p> <p>Notice this line in appPackage/declarativeAgent.json:</p> <p><code>\"instructions\": \"$[file('instruction.txt')]\",</code></p> <p>This brings in your instructions from the instruction.txt file. If you want to modularize your packaging files, you can use this technique in any of the JSON files in the appPackage folder.</p> <p></p>"},{"location":"pages/extend-m365-copilot/01a-geolocator/#step-2-add-conversation-starters","title":"Step 2 : Add conversation starters","text":"<p>You can enhance user engagement with the declarative agent by adding conversation starters to it. </p> <p>Some of the benefits of having conversation starters are: </p> <ul> <li> <p>Engagement: They help initiate interaction, making users feel more comfortable and encouraging participation.</p> </li> <li> <p>Context Setting: Starters set the tone and topic of the conversation, guiding users on how to proceed.</p> </li> <li> <p>Efficiency: By leading with a clear focus, starters reduce ambiguity, allowing the conversation to progress smoothly.</p> </li> <li> <p>User Retention: Well-designed starters keep users interested, encouraging repeat interactions with the AI.</p> </li> </ul> <p>Open file <code>declarativeAgent.json</code> and right after the <code>instructions</code> node add a comma <code>,</code> and paste below code.</p> <pre><code> \"conversation_starters\": [\n      { \n            \"title\": \"Getting Started\",\n            \"text\":\"I am ready to play the Geo Location Game! Give me a city to guess, and start with the first clue.\"          \n\n         },\n        {\n            \"title\": \"Ready for a Challenge\",\n            \"text\": \"Let us try something different. Can we play a round using the travelers diary?\"\n        },\n        { \n            \"title\": \"Feeling More Adventurous\",\n            \"text\": \"I am in the mood for a challenge! Can we play the game using the historical map? I want to see if I can figure out the city from those ancient clues.\"\n        }\n    ]\n</code></pre> <p>Now all the changes are done to the agent, it's time to test it.</p> <p></p>"},{"location":"pages/extend-m365-copilot/01a-geolocator/#step-3-test-the-app","title":"Step 3: Test the app","text":"<p>To test the app go to the <code>Agents Toolkit</code> extension in <code>Visual Studio Code</code>. This will open up the left pane. Under \"LIFECYCLE\" select \"Provision\".  You can see the value of Agents Toolkit here, as it makes publishing so simple. </p> <p></p> <p>In this step Agents Toolkit will package up all the files inside the <code>appPackage</code> folder as a zip file and install the declarative agent to your own app catalog.</p> <p>Open the Microsoft 365 Copilot BizChat https://microsoft365.com/copilot/ logged into your developer tenant.</p> <p>Once the Copilot app is loaded, Find the \"Geo Locator Game\" from the right panel as shown. </p> <p></p> <p>If you can't find it, this may be a long list and you can find your agent by expanding the list by selecting \"see more\"</p> <p>Once launched, you will be in this focused chat window with the agent. And you will see the conversation starters as marked below:</p> <p></p> <p>Select one of the conversation starters and it will fill your compose message box with the starter prompt, just waiting for you to hit \"Enter\". It is still only your assistant and will wait for you to take action \ud83d\udfe2</p> <p>Check out the demo of the game. </p> <p></p> <p></p>"},{"location":"pages/extend-m365-copilot/01a-geolocator/#exercise-3-add-files-for-reference-bonus-exercise","title":"Exercise 3: Add files for reference (Bonus exercise)","text":"<p>Playing the same game over and over can get dull. To keep things fun and engaging, the game needs access to data that\u2019s regularly updated. Let\u2019s give the agent a new ability to refresh the game and ramp up the challenge. As we covered earlier, declarative agents can have three main capabilities, one of which is referencing SharePoint sites and OneDrive. So, let's go ahead and add the ability for your agent to access a couple of files.</p>"},{"location":"pages/extend-m365-copilot/01a-geolocator/#step-1-upload-files-to-sharepoint","title":"Step 1: Upload files to SharePoint.","text":"<p>Download this zip file consisting of two PDF files by selecting this link</p> <p>Extract the two files from the zip and upload to a SharePoint Teams site in the same tenant in the document library Documents. These documents are historical_map.pdf and travelers_diary to help make the game more challenging. </p> <p>Copy the absolute url of the site. For eg. <code>https://xyz.sharepoint.com/sites/contoso</code>.</p> <p>[!NOTE] To get the full path of a file or folder, you can use the \"Copy direct link\" option in SharePoint. Right-click on the file or folder and select Details, then navigate to Path and click on the copy icon.</p> <p>Then proceed to next step.</p> <p></p>"},{"location":"pages/extend-m365-copilot/01a-geolocator/#step-2-update-declarative-agent-manifest","title":"Step 2: Update declarative agent manifest","text":"<p>Go to the environment file called .env.dev and create a new variable called \"SP_SITE_URL\" and paste the absolute url of the SharePoint site as its value.</p> <p>Next, go to the agent manifest appPackage/declarativeAgent.json and add a comma <code>,</code> after conversation_starters array and paste the below new array object for extending the agent's capability to refer to SharePoint data of a particular site.</p> <pre><code> \"capabilities\": [\n        {\n\n            \"name\": \"OneDriveAndSharePoint\",\n            \"items_by_url\": [\n            {\n                \"url\": \"${{SP_SITE_URL}}\"\n            }\n        ]\n        }\n    ]\n</code></pre> <p>This widens declarative agent's knowledge to read documents in this SharePoint site specifically to help spice up the game.  There is no limit to how many URLs you can add \ud83d\udcaa\ud83c\udffc</p> <p></p>"},{"location":"pages/extend-m365-copilot/01a-geolocator/#step-3-upgrade-app-manifest","title":"Step 3: Upgrade app manifest","text":"<p>Next, go to the file appPackage/manifest.json and upgrade the app <code>version</code> from \"1.0.0\"\" to \"1.0.1\" so the changes are reflected when you install. </p> <p></p>"},{"location":"pages/extend-m365-copilot/01a-geolocator/#step-4-test-the-app","title":"Step 4: Test the app","text":"<ul> <li> <p>To test the app go back to the <code>Agents Toolkit</code> extension in <code>Visual Studio Code</code>. This will open up the left pane. Under \"LIFECYCLE\" select \"Provision\" for packaging and installing the upgraded declarative agent to your own app catalog.</p> </li> <li> <p>Open the Microsoft 365 Copilot BizChat https://microsoft365.com/copilot/ logged into your developer tenant.</p> </li> <li> <p>Launch the \"Geo Locator Game\" again.</p> </li> </ul> <p></p> <p>This time, try the challenge which will be based on the travel diary. Choose the second converation starter.</p> <p></p> <p>You have basically become a declarative agent boss. Find out more from this video we did.</p> Introducing Declarative agents <p></p>"},{"location":"pages/extend-m365-copilot/01a-geolocator/#resources","title":"Resources","text":"<ul> <li>Declarative agents</li> <li>Declarative agent manifest schema</li> <li>Supported content types</li> <li>Capabilities of Declarative agents</li> <li>Validation guidelines for Agents</li> </ul> <p>CONGRATULATIONS!</p> <p>Great job on building your game agent \ud83c\udf89 ! In the next lab, you\u2019ll create a REST API, use it to build a plugin, and dive into a real-world business scenario solved by another agent. Exciting stuff ahead. Select Next to advance to the next lab.</p> <p></p> <p></p>"},{"location":"pages/extend-m365-copilot/02-build-the-api/","title":"Lab E2 - Build an API","text":"<p>In this lab you will set up an API based on Azure Functions and install it as an API plugin for Microsoft 365 Copilot.</p> Get a quick overview of the lab in this video. <p>Do these labs if you want to build a Declarative agent where Microsoft 365 provides the AI model and               orchestration</p> <ul> <li>\ud83c\udfc1 Welcome</li> <li>\ud83d\udd27 Set up <ul> <li>Lab E0 - Setup</li> </ul> </li> <li>\ud83e\uddf0 Declarative agent fundamentals <ul> <li> Lab E1 - Build a Detailed Declarative Agent </li> <li> Lab E1a - Geo locator game</li> </ul> </li> <li>\ud83d\udee0\ufe0f Build and integrate API from scratch <ul> <li>Lab E2 - Build an API</li> <li> Lab E3 - Add Declarative Agent + API</li> <li> Lab E4 - Enhance API + Plugin</li> <li>Lab E5 - Add Adaptive Cards</li> </ul> </li> <li>\ud83d\udd10 Authentication <ul> <li> Lab E6a - Toolkit</li> <li> Lab E6b - Manual</li> <li> Lab E6c - SSO</li> </ul> </li> <li>\ud83d\udd0c Integration <ul> <li> Lab EB - Add Graph Connector</li> </ul> </li> </ul>"},{"location":"pages/extend-m365-copilot/02-build-the-api/#introduction","title":"Introduction","text":"<p>In this lab you will set up a REST API for Trey Research, a hypothetical consulting company. It provides API's for accessing information about consultants (using the /api/consultants path) and about the current user (using the /api/me path). For now the API doesn't support authentication, so the current user will always be \"Avery Howard\"; in Lab E6 you will add authentication and the ability to access the logged in user.</p> <p>The code consists of Azure Functions written in TypeScript, backed by a database in Azure Table storage. When you run the app locally, table storage will be provided by the Azurite storage emulator.</p> How did you create this API? <p>The project was created using Agents Toolkit. You can create the same scaffolding for your own project by opening an empty folder in VS Code and going to Agents Toolkit. Create a new app project and select \"Agent\", then \"Declarative Agent\" and \"Add plugin\".</p>"},{"location":"pages/extend-m365-copilot/02-build-the-api/#exercise-1-configure-and-run-the-starting-application","title":"Exercise 1: Configure and run the starting application","text":""},{"location":"pages/extend-m365-copilot/02-build-the-api/#step-1-install-additional-prerequisites","title":"Step 1: Install additional prerequisites","text":"<p>This lab calls for a couple of additional prerequisites; please install them now.</p> <ul> <li>Azure functions core tool </li> <li>REST Client add-in for Visual Studio Code: You will use one of these toolkits to test your API locally</li> <li>(optional) Azure Storage Explorer: This will allow you to view and modify the Trey Research database</li> </ul> <p></p>"},{"location":"pages/extend-m365-copilot/02-build-the-api/#step-2-download-the-starting-application","title":"Step 2: Download the starting application","text":"<p>Begin by downloading the source code zip file for the base project using [this link] (https://download-directory.github.io/?url=https://github.com/microsoft/copilot-camp/tree/main/src/extend-m365-copilot/path-e-lab02-build-api/trey-research&amp;filename=path-e-lab02-build-api)</p> <p>Unzip and copy <code>path-e-lab02-build-api</code> folder to a location on your computer where you want to do your work. These instructions will refer to this as the \"working folder\" going forward.</p> <p>Note</p> <p>The next several labs build on this one, and you should be able to continue working in the same folder for labs E2-E6. At the completion of this lab you will not have changed any of the files visible in Github, so the folder /src/extend-m365-copilot/path-e-lab02-build-api/trey-research is the same at the beginning and end of the lab.</p> <p></p>"},{"location":"pages/extend-m365-copilot/02-build-the-api/#step-3-set-up-the-local-environment-files","title":"Step 3: Set up the local environment files","text":"<p>Open your working folder in Visual Studio Code. You might see a popup dialog asking you to \"trust the authors of the files in this folder\". If that is the case, select the button \"Yes, I trust the authors\" to proceed. Copy the /env/.env.local.user.sample file to /env/.env.local.user. If env.local.user already exists, ensure this line is present:</p> <pre><code>SECRET_STORAGE_ACCOUNT_CONNECTION_STRING=UseDevelopmentStorage=true\n</code></pre> <p></p>"},{"location":"pages/extend-m365-copilot/02-build-the-api/#step-4-install-the-dependencies","title":"Step 4: Install the dependencies","text":"<p>Open a command line in your working folder and type:</p> <pre><code>npm install\n</code></pre> <p></p>"},{"location":"pages/extend-m365-copilot/02-build-the-api/#step-5-run-the-application","title":"Step 5: Run the application","text":"<p>In Visual Studio Code, click the logo for Microsoft 365 Agents Toolkit in the left sidebar to open Agents Toolkit. Ensure you are logged into Microsoft 365 and that Custom App Uploads and Copilot Access Enabled indicators are both showing green checkmarks.</p> <p></p> <p>Now you can just hit F5 to debug using Microsoft Edge, or you can hover over the \"local\" enviroment and click the debugger symbol that will be displayed 1\ufe0f\u20e3, then select the browser of your choice 2\ufe0f\u20e3.</p> <p></p> <p>Eventually a browser will open (it's faster after the first time). You'll log into this in the next lab to test with Copilot, but for now just minimize the browser so your app keeps running, and we'll proceed to test the API.</p> <p></p> <p></p>"},{"location":"pages/extend-m365-copilot/02-build-the-api/#exercise-2-test-the-apps-web-services","title":"Exercise 2: Test the app's web services","text":"<p>The Trey Resarch project is an API plugin, so naturally it includes an API. In this exercise you'll test the API manually and, in the process, learn about what it does. </p>"},{"location":"pages/extend-m365-copilot/02-build-the-api/#step-1-get-the-me-resource","title":"Step 1: GET the /me resource","text":"<p>With the debugger still running 1\ufe0f\u20e3, switch to the code view in Visual Studio Code 2\ufe0f\u20e3. Open the http folder and select the treyResearchAPI.http file 3\ufe0f\u20e3.</p> <p>Before proceeding, ensure the log file is in view by opening the \"Debug console\" tab 4\ufe0f\u20e3 and ensuring that the console called \"Attach to Backend\" is selected 5\ufe0f\u20e3.</p> <p>Now click the \"Send Request\" link in treyResearchAAPI.http just above the link <code>{{base_url}}/me</code> 6\ufe0f\u20e3.</p> <p></p> <p>You should see the response in the right panel, and a log of the request in the bottom panel. The response shows the information about the logged-in user, but since we haven't implemented authentication as yet (that's coming in Lab 6), the app will return information on the fictitious consultant \"Avery Howard\". Take a moment to scroll through the response to see details about Avery, including a list of project assignments.</p> <p></p> <p></p>"},{"location":"pages/extend-m365-copilot/02-build-the-api/#step-2-try-the-other-methods-and-resources","title":"Step 2: Try the other methods and resources","text":"<p>Now try sending the POST request for <code>{{base_url}}/me/chargeTime</code>. This will charge 3 hours of Avery's time to the Woodgrove Bank project. This is stored in the project database, which is a locally hosted emulation of Azure Table Storage, so the system will remember that Avery has delivered these hours. (To test this, call the <code>/me</code> resource again and look at the <code>\"deliveredThisMonth\"</code> property under the Woodgrove project).</p> <p>Continue to try the various GET requests in the .http file to find consultants with various skills, certifications, roles, and availability. All this information will be available to Copilot so it can answer user prompts.</p> <p></p>"},{"location":"pages/extend-m365-copilot/02-build-the-api/#step-3-examine-the-database-optional","title":"Step 3: Examine the database (optional)","text":"<p>If you've installed the Azure Storage Explorer, you can examine and modify the application's data. The data is stored in Azure Table Storage, which in this case is running locally using the Azurite emulator.</p> <p>Note</p> <p>When you ran <code>npm install</code> in the previous exercise you installed the Azurite storage emulator. For more information check the Azurite documention here, and when you start the project, Azurite is automatically started up. So as long as your project is started successfully you can view the storage.</p> <p>Within the Azure Storage Explorer, open the \"Emulator &amp; Attached\" selection and pick the \"(Emulator: Default Ports)\" collection; then drill down to \"Tables\". You shold see 3 tables:</p> <ul> <li>Consultant: This table stores details about Trey Research consultants</li> <li>Project: This table stores details about Trey Research projects</li> <li>Assignment: This table stores consultant assignments to projects, such as Avery Howard's assignment to the Woodgrove Bank project. This table includes a \"delivered\" field that contains a JSON representation of the hours delivered by that consultant on the project over time.</li> </ul> <p></p> <p></p> <p>CONGRATULATIONS!</p> <p>You've successfully built the lab sample API! You can now proceed to make it into a plugin, and expose it via a Declarative agent.</p> <p></p> <p></p>"},{"location":"pages/extend-m365-copilot/03-add-declarative-agent/","title":"Lab E3 - Add a declarative agent and API plugin","text":"<p>In this lab you will add a declarative agent which is grounded in the API plugin you created in the previous lab, as well as in specific SharePoint files</p> Get a quick overview of the lab in this video.              \ud83d\udcd8 Note: This lab builds on the previous one, Lab E2. You should be able to continue working in the same folder for labs E2-E6, but solution folders have been provided for your reference.     The finished solution for this lab is in the /src/extend-m365-copilot/path-e-lab03-build-declarative-agent/trey-research-lab03-END folder.          <p>Do these labs if you want to build a Declarative agent where Microsoft 365 provides the AI model and               orchestration</p> <ul> <li>\ud83c\udfc1 Welcome</li> <li>\ud83d\udd27 Set up <ul> <li>Lab E0 - Setup</li> </ul> </li> <li>\ud83e\uddf0 Declarative agent fundamentals <ul> <li> Lab E1 - Build a Detailed Declarative Agent </li> <li> Lab E1a - Geo locator game</li> </ul> </li> <li>\ud83d\udee0\ufe0f Build and integrate API from scratch <ul> <li>Lab E2 - Build an API</li> <li> Lab E3 - Add Declarative Agent + API</li> <li> Lab E4 - Enhance API + Plugin</li> <li>Lab E5 - Add Adaptive Cards</li> </ul> </li> <li>\ud83d\udd10 Authentication <ul> <li> Lab E6a - Toolkit</li> <li> Lab E6b - Manual</li> <li> Lab E6c - SSO</li> </ul> </li> <li>\ud83d\udd0c Integration <ul> <li> Lab EB - Add Graph Connector</li> </ul> </li> </ul>"},{"location":"pages/extend-m365-copilot/03-add-declarative-agent/#exercise-1-upload-sample-documents","title":"Exercise 1: Upload sample documents","text":"<p>In this step you will upload sample documents which will be used by your declarative agent to respond to user prompts. These include some consulting documents such as Statements of Work, and a simple spreadsheet containing your hours as a consultant.</p>"},{"location":"pages/extend-m365-copilot/03-add-declarative-agent/#step-1-create-a-sharepoint-site","title":"Step 1: Create a SharePoint site","text":"<p>Go to https://m365.cloud.microsoft/apps/ and find \"SharePoint\" app under \"Apps\"</p> <p></p> <p>Then click \"Create Site\" 1\ufe0f\u20e3 and choose a \"Team site\" 2\ufe0f\u20e3.</p> <p></p> <p>Select the Standard team site template; you will be shown a preview of the site. Click \"Use Template\" to continue.</p> <p></p> <p>Give your site a name such as \"Trey Research legal documents\" 1\ufe0f\u20e3 and click \"Next\" 2\ufe0f\u20e3.</p> <p></p> <p>Then select your privacy settings and language, and click \"Create Site\"</p> <p></p> <p>After a few moments, you will be presented with a new SharePoint site. </p> <p></p>"},{"location":"pages/extend-m365-copilot/03-add-declarative-agent/#step-2-upload-the-sample-documents","title":"Step 2: Upload the sample documents","text":"<p>In the Documents web part, select \"See all\" to view the document library page.</p> <p></p> <p>Next, click the \"Upload\" 1\ufe0f\u20e3 toolbar button and select \"Files\" 2\ufe0f\u20e3.</p> <p></p> <p>Navigate to your working folder; you will find a directory called sampleDocs within. Highlight all the sample documents 1\ufe0f\u20e3 and click \"Open\" 2\ufe0f\u20e3.</p> <p>Make note of the site url, which will resemble \"https://&lt;your-tenant&gt;.sharepoint.com/sites/TreyResearchlegaldocuments\", as you will need it in the next exercise.</p> <p></p> <p></p>"},{"location":"pages/extend-m365-copilot/03-add-declarative-agent/#exercise-2-create-the-declarative-agent","title":"Exercise 2: Create the declarative agent","text":""},{"location":"pages/extend-m365-copilot/03-add-declarative-agent/#step-1-add-the-declarative-agent-json-to-your-project","title":"Step 1: Add the declarative agent JSON to your project","text":"<p>Create a new file called trey-declarative-agent.json within your appPackage folder. Copy the following JSON into this file and save it.</p> <pre><code>{\n    \"$schema\": \"https://developer.microsoft.com/json-schemas/copilot/declarative-agent/v1.4/schema.json\",\n    \"version\": \"v1.4\",\n    \"name\": \"Trey Genie Local\",\n    \"description\": \"You are a handy assistant for consultants at Trey Research, a boutique consultancy specializing in software development and clinical trials. \",\n    \"instructions\": \"You are consulting agent. Greet users professionally and introduce yourself as the Trey Genie. Offer assistance with their consulting projects and hours. Remind users of the Trey motto, 'Always be Billing!'. Your primary role is to support consultants by helping them manage their projects and hours. Using the TreyResearch action, you can: You can assist users in retrieving consultant profiles or project details for administrative purposes but do not participate in decisions related to hiring, performance evaluation, or assignments. You can assist users to find consultants data based on their names, project assignments, skills, roles, and certifications. You can assist users to retrieve project details based on the project or client name. You can assist users to charge hours to a project. You can assist users to add a consultant to a project. If a user inquires about the hours they have billed, charged, or worked on a project, rephrase the request to ask about the hours they have delivered. Additionally, you may provide general consulting advice. If there is any confusion, encourage users to consult their Managing Consultant. Avoid providing legal advice.\",\n    \"conversation_starters\": [\n        {\n            \"title\": \"Find consultants\",\n            \"text\": \"Find consultants with TypeScript skills\"\n        },\n        {\n            \"title\": \"My Projects\",\n            \"text\": \"What projects am I assigned to?\"\n        },\n        {\n            \"title\": \"My Hours\",\n            \"text\": \"How many hours have I delivered on projects this month?\"\n        }\n    ],\n    \"capabilities\": [\n        {\n            \"name\": \"OneDriveAndSharePoint\",\n            \"items_by_url\": [\n                {\n                    \"url\": \"${{SHAREPOINT_DOCS_URL}}\"\n                }\n            ]\n        }\n    ],\n    \"actions\": [\n        {\n            \"id\": \"treyresearch\",\n            \"file\": \"trey-plugin.json\"\n        }\n    ]\n}\n</code></pre> <p>Notice that the file includes a name, description, and instructions for the declarative agent. Notice that as part of the instructions, Copilot is instructed to \"Always remind users of the Trey motto, 'Always be Billing!'.\" You should see this when you prompt Copilot in the next exercise.</p> <p></p>"},{"location":"pages/extend-m365-copilot/03-add-declarative-agent/#step-2-add-the-url-of-your-sharepoint-site-to-the-declarative-agent","title":"Step 2: Add the URL of your SharePoint site to the declarative agent","text":"<p>Under \"Capabilities\" you will notice a SharePoint file container. While Microsoft 365 Copilot may reference any documents in SharePoint or OneDrive, this declarative agent will only access files in the Trey Research Legal Documents site you created in Exercise 1. </p> <pre><code>\"capabilities\": [\n    {\n        \"name\": \"OneDriveAndSharePoint\",\n        \"items_by_url\": [\n            {\n                    \"url\": \"${{SHAREPOINT_DOCS_URL}}\"\n            }\n        ]\n    }\n],\n</code></pre> <p>Notice that the SharePoint URL is actually an environment variable <code>SHAREPOINT_DOCS_URL</code>, so you need to add that to your .env.local file in the env folder. Add this in its own line at the end of the file, using your SharePoint URL:</p> <pre><code>SHAREPOINT_DOCS_URL=https://mytenant.sharepoint.com/sites/TreyResearchLegaldocuments\n</code></pre> <p></p>"},{"location":"pages/extend-m365-copilot/03-add-declarative-agent/#step-3-examine-the-api-plugin-files","title":"Step 3: Examine the API Plugin files","text":"<p>Within the trey-declarative-agent.json file, you'll find an \"actions\" section, which tells the declarative agent to access the Trey Research API.</p> <pre><code>\"actions\": [\n    {\n        \"id\": \"treyresearch\",\n        \"file\": \"trey-plugin.json\"\n    }\n]\n</code></pre> <p>In this step we'll look at trey-plugin.json and how it and another file describe the API to Copilot so it can make the REST calls.</p> <p>These two files are used to describe your API to Copilot. They were already included in the project you downloaded in Lab 2, so you can examine them now:</p> <ul> <li>appPackage/trey-definition.json - This is the OpenAPI Specification (OAS) or \"Swagger\" file, which is an industry standard format for describing a REST API</li> <li>appPackage/trey-plugin.json - This file contains all the Copilot-specific details that aren't described in the OAS file</li> </ul> <p>In this step, take a moment to examine these files. In the next few labs you'll get to know them better as we add more features to the solution.</p> <p>In appPackage/trey-definition.json, you'll find the general description of the application. This includes the server URL; Agents Toolkit will create a developer tunnel to expose your local API on the Internet, and replace the token <code>\"${{OPENAPI_SERVER_URL}}</code> with the public URL. It then goes on to describe every resource path, verb, and paremeter in the API. Notice the detailed descriptions; these are important to help Copilot understand how the API is to be used.</p> <pre><code>{\n  \"openapi\": \"3.0.1\",\n  \"info\": {\n      \"version\": \"1.0.0\",\n      \"title\": \"Trey Research API\",\n      \"description\": \"API to streamline consultant assignment and project management.\"\n  },\n  \"servers\": [\n      {\n          \"url\": \"${{OPENAPI_SERVER_URL}}/api/\",\n          \"description\": \"Production server\"\n      }\n  ],\n  \"paths\": {\n      \"/consultants/\": {\n          \"get\": {\n              \"operationId\": \"getConsultants\",\n              \"summary\": \"Get consultants working at Trey Research based on consultant name, project name, certifications, skills, roles and hours available\",\n              \"description\": \"Returns detailed information about consultants identified from filters like name of the consultant, name of project, certifications, skills, roles and hours available. Multiple filters can be used in combination to refine the list of consultants returned\",\n              \"parameters\": [\n                  {\n                      \"name\": \"consultantName\",\n                      \"in\": \"query\",\n                      \"description\": \"Name of the consultant to retrieve\",\n                      \"required\": false,\n                      \"schema\": {\n                          \"type\": \"string\"\n                      }\n                  },\n      ...\n</code></pre> <p>The appPackage/trey-plugin.json file has the Copilot-specific details. This includes breaking the API calls down into functions which can be called when Copilot has a particular use case. For example, all GET requests for <code>/consultants</code> look up one or more consultants with various parameter options, and they are grouped into a function <code>getConsultants</code>:</p> <pre><code>  \"functions\": [\n    {\n      \"name\": \"getConsultants\",\n      \"description\": \"Returns detailed information about consultants identified from filters like name of the consultant, name of project, certifications, skills, roles and hours available. Multiple filters can be used in combination to refine the list of consultants returned\",\n      \"capabilities\": {\n        \"response_semantics\": {\n          \"data_path\": \"$.results\",\n          \"properties\": {\n            \"title\": \"$.name\",\n            \"subtitle\": \"$.id\",\n            \"url\": \"$.consultantPhotoUrl\"\n          }\n        }\n      }\n    },\n</code></pre> <p>Scrolling down you can find the runtime settings: </p> <pre><code>\"runtimes\": [\n  {\n    \"type\": \"OpenApi\",\n    \"auth\": {\n      \"type\": \"None\"\n    },\n    \"spec\": {\n      \"url\": \"trey-definition.json\"\n    },\n    \"run_for_functions\": [\n      \"getConsultants\",\n      \"getUserInformation\",\n      \"postBillhours\"\n    ]\n  }\n],\n</code></pre> <p>They include a pointer to the trey-definition.json file, and an enumeration of the available functions.</p> <p></p>"},{"location":"pages/extend-m365-copilot/03-add-declarative-agent/#step-4-add-the-declarative-agent-to-your-app-manifest","title":"Step 4: Add the declarative agent to your app manifest","text":"<p>Now open the manifest.json file within the appPackage directory. Add, just before the <code>staticTabs</code> object, a new <code>copilotAgents</code> object with a <code>declarativeAgents</code> object inside as follows, so it references the declarative agent JSON file you created in the previous step.</p> <pre><code>  \"copilotAgents\": {\n    \"declarativeAgents\": [\n      {\n        \"id\": \"treygenie\",\n        \"file\": \"trey-declarative-agent.json\"\n      }\n    ]\n  }, \n</code></pre> <p>Be sure to save your work. </p> <p></p>"},{"location":"pages/extend-m365-copilot/03-add-declarative-agent/#step-5-remove-the-dummy-feature-from-the-app-manifest","title":"Step 5: Remove the dummy feature from the app manifest","text":"<p>The initial solution that you ran in Lab E2 didn't have a declarative agent yet, so the manifest would not install because it had no features. So we added a \"dummy\" feature, which is a static tab pointing to the Copilot Developer Camp home page. This would allow users to view the Copilot Developer Camp web site in a tab within Teams, Outlook, and the the Microsoft 365 app (https://office.com).</p> <p>If you ever tried Teams App Camp you would know all about them. If not, don't worry about it, just delete these lines from manifest.json as they aren't needed anymore.</p> <pre><code>\"staticTabs\": [\n  {\n    \"entityId\": \"index\",\n    \"name\": \"Copilot Camp\",\n    \"contentUrl\": \"https://microsoft.github.io/copilot-camp/\",\n    \"websiteUrl\": \"https://microsoft.github.io/copilot-camp/\",\n    \"scopes\": [\n      \"personal\"\n    ]\n  }\n],\n\"validDomains\": [\n  \"microsoft.github.io\"\n],\n</code></pre> <p></p>"},{"location":"pages/extend-m365-copilot/03-add-declarative-agent/#exercise-3-run-and-test-the-declarative-agent","title":"Exercise 3: Run and test the declarative agent","text":""},{"location":"pages/extend-m365-copilot/03-add-declarative-agent/#step-1-run-the-new-project","title":"Step 1: Run the new project","text":"<p>If you're still in the debugger, stop it to force a complete re-deloyment.</p> <p>Then start the debugger by clicking the arrow or pressing F5 and return to the Copilot user interface. You might be using Teams in browser at this point to test, but you could also use office.com/chat to test your agent.</p> I cannot find the agent <p>Refresh your browser and collapse and expand the navigation as shown in screen below the  if you cannot see your agents immediately after F5. </p> <p></p>"},{"location":"pages/extend-m365-copilot/03-add-declarative-agent/#step-2-test-the-declarative-agent","title":"Step 2: Test the declarative agent","text":"<p>Open the Copilot chat and the right flyout 1\ufe0f\u20e3 to show your previous chats and declarative agents and select the Trey Genie Local agent 2\ufe0f\u20e3.</p> <p></p> <p>Try a prompt such as \"Please list my projects along with details from the Statement of Work doc\".  You should see a list of your projects from the API plugin, enhanced with details from each project's Statement of Work 1\ufe0f\u20e3. Notice that Copilot includes the Trey Research motto 2\ufe0f\u20e3 and references to the documents 3\ufe0f\u20e3. Click one of the references to check out the document.</p> <p></p> <p>Note</p> <p>If the SharePoint documents aren't referenced, perhaps there is an issue accessing the files. Has there been time for Search to index the site? Does the end user have permission to the site? Has an administrator excluded the site from Search? Try doing a Search (outside of Copilot) such as </p> <p><code>woodgrove path:\"https://&lt;tenant&gt;.sharepoint.com/sites/&lt;sitename&gt;\"</code></p> <p>filling in your tenant and site name to match the one in the capability. You should see three Woodgrove documents; if you don't you need to troubleshoot Search since Copilot won't be able to find them either.</p> <p>Let's also see how the API is getting called. Try to send another prompt: \"List my information\" 1\ufe0f\u20e3 to instruct the agent to retrieve details from the api/me endpoint of the Trey Research project API 2\ufe0f\u20e3.</p> <p>See below how it brought back my information (Avery Howard is logged in user as we have not yet implemented Auth, coming up in later labs), and my projects. </p> <p>If you go back to your VS Code project under \"Terminal\", you will also see how the agent called the API as shown below:</p> <p></p> <p></p> <p>CONGRATULATIONS!</p> <p>You've completed adding a declarative agent to your API plugin. You are now ready to enhance your API and the plugin for your agent. </p> <p></p> <p></p>"},{"location":"pages/extend-m365-copilot/04-enhance-api-plugin/","title":"Lab E4 - Enhance the API and Plugin","text":"<p>In this lab you will add additional REST calls to the API and add them to the API Plugin packaging so Copilot can call them. In the process you will learn all the places where an API needs to be defined for Copilot.</p> Get a quick overview of the lab in this video.              \ud83d\udcd8 Note:    This lab builds on the previous one, Lab E3. You should be able to continue working in the same folder for labs E2-E6, but solution folders have been provided for your reference.     The finished solution for this lab is in the /src/extend-m365-copilot/path-e-lab04-enhance-api-plugin/trey-research-lab04-END <p>Do these labs if you want to build a Declarative agent where Microsoft 365 provides the AI model and               orchestration</p> <ul> <li>\ud83c\udfc1 Welcome</li> <li>\ud83d\udd27 Set up <ul> <li>Lab E0 - Setup</li> </ul> </li> <li>\ud83e\uddf0 Declarative agent fundamentals <ul> <li> Lab E1 - Build a Detailed Declarative Agent </li> <li> Lab E1a - Geo locator game</li> </ul> </li> <li>\ud83d\udee0\ufe0f Build and integrate API from scratch <ul> <li>Lab E2 - Build an API</li> <li> Lab E3 - Add Declarative Agent + API</li> <li> Lab E4 - Enhance API + Plugin</li> <li>Lab E5 - Add Adaptive Cards</li> </ul> </li> <li>\ud83d\udd10 Authentication <ul> <li> Lab E6a - Toolkit</li> <li> Lab E6b - Manual</li> <li> Lab E6c - SSO</li> </ul> </li> <li>\ud83d\udd0c Integration <ul> <li> Lab EB - Add Graph Connector</li> </ul> </li> </ul>"},{"location":"pages/extend-m365-copilot/04-enhance-api-plugin/#exercise-1-add-projects-resource","title":"Exercise 1: Add /projects resource","text":"<p>In this exercise you will add a /projects resource to the Trey Research API. This will allow you to request information about projects using GET requests, and to assign a consultant to a project using a POST request. In the process, you'll learn about the appPackage/trey-Plugin.json and trey-definition.json files as you modify them to add the new projects API calls.</p>"},{"location":"pages/extend-m365-copilot/04-enhance-api-plugin/#step-1-add-azure-function-code","title":"Step 1: Add Azure function code","text":"<p>To begin, create a new file, projects.ts in the /src/functions folder of your solution. Then copy the code from here.</p> <p>This will implement a new Azure function to provide access to Trey Research projects</p> <p></p>"},{"location":"pages/extend-m365-copilot/04-enhance-api-plugin/#step-2-review-the-azure-function-code-optional","title":"Step 2: Review the Azure function code (optional)","text":"<p>Let's take a moment to review the code.</p> <p>This is a version 4 Azure function, so the code looks a lot like traditional Express code for NodeJS. The <code>projects</code> class implements an HTTP request trigger, which is called when the \"/projects\" path is accessed. This is followed by some in-line code that defines the methods and route. For now, access is anonymous; we'll add authentication, checkout out pathways for authentication.</p> <pre><code>export async function projects(\n    req: HttpRequest,\n    context: InvocationContext\n): Promise&lt;Response&gt; {\n    // ...\n}\napp.http(\"projects\", {\n    methods: [\"GET\", \"POST\"],\n    authLevel: \"anonymous\",\n    route: \"projects/{*id}\",\n    handler: projects,\n});\n</code></pre> <p>The class includes a switch statement for handling GET vs. POST requests, and obtains the parameters from the URL path (in the case of a project ID), query strings (such as ?projectName=foo, in the case of a GET), and the request body (in the case of a POST). It then accesses the project data using the ProjectApiService, which was part of the starting solution. It also sends responses for each request and logging of requests to the debug console.</p> <p></p>"},{"location":"pages/extend-m365-copilot/04-enhance-api-plugin/#step-3-add-http-test-requests","title":"Step 3: Add HTTP test requests","text":"<p>Now let's add the new requests to the http/treyResearchAPI.http file so we can try them out. Open the file and add this text to the bottom, then save your changes, or copy the updated file from here </p> <pre><code>########## /api/projects - working with projects ##########\n\n### Get all projects\n{{base_url}}/projects\n\n### Get project by id\n{{base_url}}/projects/1\n\n### Get project by project or client name\n{{base_url}}/projects/?projectName=supply\n\n### Get project by consultant name\n{{base_url}}/projects/?consultantName=dominique\n\n### Add consultant to project\nPOST {{base_url}}/projects/assignConsultant\nContent-Type: application/json\n\n{\n    \"projectName\": \"contoso\",\n    \"consultantName\": \"sanjay\",\n    \"role\": \"architect\",\n    \"forecast\": 30\n}\n</code></pre> <p></p>"},{"location":"pages/extend-m365-copilot/04-enhance-api-plugin/#step-4-test-the-new-resource","title":"Step 4: Test the new resource","text":"<p>If your app is still running from previous lab, stop the debugger and restart it. Or, just start the debugger normally and wait for the app to start. When everything is ready, Agents Toolkit will display a web browser wanting you to log into Microsoft 365. Minimize this browser as you don't need it yet, but closing it would stop the debugger.</p> <p>Now try sending the new requests and you should be able to see Trey Research project details or assign a new consultant to a project using the POST request.</p> <p></p> <p></p>"},{"location":"pages/extend-m365-copilot/04-enhance-api-plugin/#exercise-2-add-projects-to-the-application-package","title":"Exercise 2: Add projects to the application package","text":"<p>The API plugin's application package is a zip file that contains all the information Copilot needs to use the API. In this exercise, you'll add information about the new /projects resource to the app package.</p>"},{"location":"pages/extend-m365-copilot/04-enhance-api-plugin/#step-1-update-the-open-api-specification-file","title":"Step 1: Update the Open API Specification file","text":"<p>An important part of the application package is the Open API Specification (OAS) definition file. OAS defines a standard format for describing a REST API, and is based on the popular \"Swagger\" definition.</p> <p>To begin, in the /appPackage folder, open the file trey-definition.json.  Since editing large JSON files can be tricky, please just copy the updated file from here and save the new trey-definition.json. In the steps that follow, you can review and understand the changes.</p> <p></p>"},{"location":"pages/extend-m365-copilot/04-enhance-api-plugin/#step-2-review-the-updates-optional","title":"Step 2: Review the updates (optional)","text":"<p>The first update was to add the <code>/projects/</code> path to the <code>paths</code> collection in the JSON.  As you can see, this includes all the available query strings when retrieving the <code>/projects/</code> resource, along with data types and required fields. It also includes the data that will be returned in API responses, including different payloads for status 200 (successful) and 400 (failed) responses.</p> <pre><code>\"/projects/\": {\n    \"get\": {\n        \"operationId\": \"getProjects\",\n        \"summary\": \"Get projects matching a specified project name and/or consultant name\",\n        \"description\": \"Returns detailed information about projects matching the specified project name and/or consultant name\",\n        \"parameters\": [\n            {\n                \"name\": \"consultantName\",\n                \"in\": \"query\",\n                \"description\": \"The name of the consultant assigned to the project\",\n                \"required\": false,\n                \"schema\": {\n                    \"type\": \"string\"\n                }\n            },\n            {\n                \"name\": \"projectName\",\n                \"in\": \"query\",\n                \"description\": \"The name of the project or name of the client\",\n                \"required\": false,\n                \"schema\": {\n                    \"type\": \"string\"\n                }\n            }\n        ],\n        \"responses\": {\n            \"200\": {\n                \"description\": \"Successful response\",\n                \"content\": {\n                    \"application/json\": {\n                        \"schema\": {\n                            \"type\": \"object\",\n                            \"properties\": {\n                                \"results\": {\n                                    \"type\": \"array\",\n                                    \"items\": {\n                                        \"type\": \"object\",\n                                        \"properties\": {\n                                            \"name\": {\n                                                \"type\": \"string\"\n                                            },\n                                            \"description\": {\n                                                \"type\": \"string\"\n                                            },\n                                            \"location\": {\n                                                \"type\": \"object\",\n                                                \"properties\": {\n                                                    \"street\": {\n                                                        \"type\": \"string\"\n                                                    },\n                                                    \"city\": {\n                                                        \"type\": \"string\"\n                                                    },\n                                                    \"state\": {\n                                                        \"type\": \"string\"\n                                                    },\n                                                    \"country\": {\n                                                        \"type\": \"string\"\n                                                    },\n                                                    \"postalCode\": {\n                                                        \"type\": \"string\"\n                                                    },\n                                                    \"latitude\": {\n                                                        \"type\": \"number\"\n                                                    },\n                                                    \"longitude\": {\n                                                        \"type\": \"number\"\n                                                    },\n                                                    \"mapUrl\": {\n                                                        \"type\": \"string\",\n                                                        \"format\": \"uri\"\n                                                    }\n                                                }\n                                            },\n                                            \"role\": {\n                                                \"type\": \"string\"\n                                            },\n                                            \"forecastThisMonth\": {\n                                                \"type\": \"integer\"\n                                            },\n                                            \"forecastNextMonth\": {\n                                                \"type\": \"integer\"\n                                            },\n                                            \"deliveredLastMonth\": {\n                                                \"type\": \"integer\"\n                                            },\n                                            \"deliveredThisMonth\": {\n                                                \"type\": \"integer\"\n                                            }\n                                        }\n                                    }\n                                },\n                                \"status\": {\n                                    \"type\": \"integer\"\n                                }\n                            }\n                        }\n                    }\n                }\n            },\n            \"404\": {\n                \"description\": \"Project not found\"\n            }\n        }\n    }\n},\n</code></pre> <p>You will also find that a path has been added at <code>/projects/assignConsultant</code> to handle the POST requests.</p> <p>Descriptions are important!</p> <p>This file, along with all the files in the app package, are going to be read by an intelligence. It may be artificial, but it's still intelligent enough to read the descriptions! You can help Copilot properly use your API by using descriptive names and descriptions in this and all the application package files!</p> <p></p>"},{"location":"pages/extend-m365-copilot/04-enhance-api-plugin/#step-3-add-projects-to-the-plugin-definition-file","title":"Step 3: Add projects to the plugin definition file","text":"<p>Now open the file trey-plugin.json within the /appPackage folder. This file contains extra information not included in the OAS definition file. Replace the contents of trey-plugin.json with this updated JSON.</p> <p></p>"},{"location":"pages/extend-m365-copilot/04-enhance-api-plugin/#step-4-review-the-changes-to-the-plugin-definition-file-optional","title":"Step 4: Review the changes to the plugin definition file (optional)","text":"<p>The plugin JSON file contains a collection of functions, each of which corresponds to a type of API call. Copilot will choose among these functions when utilizing your plugin at runtime.</p> <p>The new trey-plugin.json file includes new functions <code>getProjects</code> and <code>postAssignConsultant</code>. For example, here is <code>getProjects</code>:</p> <pre><code>{\n    \"name\": \"getProjects\",\n    \"description\": \"Returns detailed information about projects matching the specified project name and/or consultant name\",\n    \"capabilities\": {\n        \"response_semantics\": {\n            \"data_path\": \"$.results\",\n            \"properties\": {\n            \"title\": \"$.name\",\n            \"subtitle\": \"$.description\"\n            }\n        }\n    }\n},\n</code></pre> <p>Notice that it includes some <code>response_semantics</code> which instruct Copilot's orchestrator how to interpret the response payload. It defines the mapping of structured data in a response payload to specific properties required by the function. It enables the orchestrator to interpret and transform raw response data into meaningful content for rendering or further processing. For e.g. look at the response semantics below:</p> <pre><code>\n\"functions\": [\n    {\n      \"name\": \"getConsultants\",\n      \"description\": \"Returns detailed information about consultants identified from filters like name of the consultant, name of project, certifications, skills, roles and hours available. Multiple filters can be used in combination to refine the list of consultants returned\",\n      \"capabilities\": {\n        \"response_semantics\": {\n          \"data_path\": \"$.results\",\n          \"properties\": {\n            \"title\": \"$.name\",\n            \"subtitle\": \"$.id\",\n            \"url\": \"$.consultantPhotoUrl\"\n          }\n        }\n      }\n    },..]\n\n</code></pre> <p>Here <code>data_path</code> is : <code>$.results</code> in the <code>response_semantics</code> of function <code>getConsultants</code>. It means the main data resides under the <code>results</code> key in the JSON, which ensures the system extracts data starting at that path. It also defines mappings of specific fields from the raw data to corresponding semantic properties under <code>properties</code> field to readily use it for rendering.</p> <p>e.g. </p> <pre><code>     \"title\": \"$.name\",\n      \"subtitle\": \"$.id\",\n      \"url\": \"$.consultantPhotoUrl\"\n</code></pre> <p>The POST request has a similar function:</p> <pre><code>{\n    \"name\": \"postAssignConsultant\",\n    \"description\": \"Assign (add) consultant to a project when name, role and project name is specified.\",\n    \"capabilities\": {\n    \"response_semantics\": {\n        \"data_path\": \"$\",\n        \"properties\": {\n        \"title\": \"$.results.clientName\",\n        \"subtitle\": \"$.results.status\"\n        }\n    },\n    \"confirmation\": {\n        \"type\": \"AdaptiveCard\",\n        \"title\": \"Assign consultant to a project when name, role and project name is specified.\",\n        \"body\": \"* **ProjectName**: {{function.parameters.projectName}}\\n* **ConsultantName**: {{function.parameters.consultantName}}\\n* **Role**: {{function.parameters.role}}\\n* **Forecast**: {{function.parameters.forecast}}\"\n    }\n    }\n}\n</code></pre> <p>It includes an adaptive card to be used in the confirmation card, which is shown to users to confirm an action prior to issuing a POST request.</p> <p>Scrolling down, you can see the <code>runtimes</code> object which defines the type of plugin, the OAS definition file location, and a list of functions. The new functions have been added to the list.</p> <pre><code>\"runtimes\": [\n{\n    \"type\": \"OpenApi\",\n    \"auth\": {\n    \"type\": \"None\"\n    },\n    \"spec\": {\n    \"url\": \"trey-definition.json\"\n    },\n    \"run_for_functions\": [\n    \"getConsultants\",\n    \"getUserInformation\",\n    \"getProjects\",\n    \"postBillhours\",\n    \"postAssignConsultant\"\n    ]\n}\n],\n</code></pre> <p>Finally, it includes some conversation starters which are prompt suggestions shown to users; the new file has a conversation starter relating to projects.</p> <pre><code>\"capabilities\": {\n\"localization\": {},\n\"conversation_starters\": [\n    {\n    \"text\": \"What Trey projects am i assigned to?\"\n    },\n    {\n    \"text\": \"Charge 5 hours to the Contoso project for Trey Research\"\n    },\n    {\n    \"text\": \"Which Trey consultants are Azure certified?\"\n    },\n    {\n    \"text\": \"Find a Trey consultant who is available now and has Python skills\"\n    },\n    {\n    \"text\": \"Add Avery as a developer on the Contoso project for Trey\"\n    }\n]\n}\n</code></pre> <p></p>"},{"location":"pages/extend-m365-copilot/04-enhance-api-plugin/#exercise-3-test-the-plugin-in-copilot","title":"Exercise 3: Test the plugin in Copilot","text":"<p>Before you test the application, update the manifest version of your app package in the <code>appPackage\\manifest.json</code> file, follow these steps:</p> <ol> <li> <p>Open the <code>manifest.json</code> file located in the <code>appPackage</code> folder of your project.</p> </li> <li> <p>Locate the <code>version</code> field in the JSON file. It should look something like this: <code>json    \"version\": \"1.0.0\"</code></p> </li> <li> <p>Increment the version number to a small increment. For example, change it to: <code>json    \"version\": \"1.0.1\"</code></p> </li> <li> <p>Save the file after making the change.</p> </li> </ol>"},{"location":"pages/extend-m365-copilot/04-enhance-api-plugin/#step-1-restart-the-application","title":"Step 1: Restart the application","text":"<p>Stop and restart your project to force it to re-deploy the application package. You will be brought into Microsoft Teams. Once you're back in Copilot, open the right flyout 1\ufe0f\u20e3 to show your previous chats and agents and select the Trey Genie Local agent 2\ufe0f\u20e3.</p> <p></p> <p></p>"},{"location":"pages/extend-m365-copilot/04-enhance-api-plugin/#step-2-prompt-the-trey-genie","title":"Step 2: Prompt the Trey Genie","text":"<p>Now try a prompt such as \"what projects are we doing for adatum?\"</p> <p></p> <p>You may see a confirmation card, even for the GET request. If you do, allow the request to view the project details.</p> <p></p> <p></p> <p>CONGRATULATIONS!</p> <p>You've now completed enhancing your API plugin. But as you can see, the citation cards are very basic. So let's proceed to the next lab to add rich card citations and responses using adaptive cards. </p> <p></p> <p></p>"},{"location":"pages/extend-m365-copilot/05-add-adaptive-card/","title":"Lab E5 - Add adaptive cards","text":"<p>In this lab you will further enhance the response from Microsoft 365 Copilot from text to rich cards using Adaptive Cards. </p> <p>In this lab you will learn:</p> <ul> <li>What are Adaptive Cards</li> <li>How to create and test an Adaptive Card</li> <li>How to update Microsoft 365 Copilot responses to use Adaptive Cards for rich content</li> </ul> Get a quick overview of the lab in this video.              \ud83d\udcd8 Note: This lab builds on the previous one, Lab E4. You should be able to continue working in the same folder for labs E2-E6, but solution folders have been provided for your reference.     The finished solution for this lab is in the /src/extend-m365-copilot/path-e-lab05-add-adaptive-cards/trey-research-lab05-END <p>Do these labs if you want to build a Declarative agent where Microsoft 365 provides the AI model and               orchestration</p> <ul> <li>\ud83c\udfc1 Welcome</li> <li>\ud83d\udd27 Set up <ul> <li>Lab E0 - Setup</li> </ul> </li> <li>\ud83e\uddf0 Declarative agent fundamentals <ul> <li> Lab E1 - Build a Detailed Declarative Agent </li> <li> Lab E1a - Geo locator game</li> </ul> </li> <li>\ud83d\udee0\ufe0f Build and integrate API from scratch <ul> <li>Lab E2 - Build an API</li> <li> Lab E3 - Add Declarative Agent + API</li> <li> Lab E4 - Enhance API + Plugin</li> <li>Lab E5 - Add Adaptive Cards</li> </ul> </li> <li>\ud83d\udd10 Authentication <ul> <li> Lab E6a - Toolkit</li> <li> Lab E6b - Manual</li> <li> Lab E6c - SSO</li> </ul> </li> <li>\ud83d\udd0c Integration <ul> <li> Lab EB - Add Graph Connector</li> </ul> </li> </ul>"},{"location":"pages/extend-m365-copilot/05-add-adaptive-card/#introduction","title":"Introduction","text":"What are Adaptive Cards?  Adaptive Cards are platform-independent UI snippets authored in JSON that can be exchanged between apps and services. Once delivered to an app, the JSON transforms into native UI that automatically adapts to its environment. This enables the design and integration of lightweight UI across major platforms and frameworks.      Adaptive cards are everywhere"},{"location":"pages/extend-m365-copilot/05-add-adaptive-card/#exercise-1-create-and-test-a-simple-adaptive-card","title":"Exercise 1: Create and test a simple Adaptive Card","text":"<p>Let's dive in and discover how fun it is to create adaptive cards.</p>"},{"location":"pages/extend-m365-copilot/05-add-adaptive-card/#step-1-define-your-adaptive-card-in-json","title":"Step 1: Define Your Adaptive Card in JSON","text":"<p>Here is an adaptive card in JSON. Begin by copying it to your clipboard.</p> <pre><code>{\n  \"type\": \"AdaptiveCard\",\n  \"body\": [\n    {\n      \"type\": \"TextBlock\",\n      \"text\": \"Hello, Adaptive Cards!\",\n      \"size\": \"large\",\n      \"weight\": \"bolder\"\n    }\n  ],\n  \"actions\": [\n    {\n      \"type\": \"Action.OpenUrl\",\n      \"title\": \"Click me\",\n      \"url\":\"https://www.contoso.com\"\n    }\n  ],\n  \"$schema\": \"http://adaptivecards.io/schemas/adaptive-card.json\",\n  \"version\": \"1.3\"\n}\n</code></pre> <p>This JSON defines a simple Adaptive Card with a text block and a button.</p> <p></p>"},{"location":"pages/extend-m365-copilot/05-add-adaptive-card/#step-2-test-your-adaptive-card","title":"Step 2: Test Your Adaptive Card","text":"<p>To test your Adaptive Card, you can use the Adaptive Cards Designer.</p> <ol> <li>Open the Adaptive Cards Designer  .</li> <li>Copy the JSON content from your <code>adaptiveCard.json</code> file.</li> <li>Paste the JSON content into the \"Card Payload Editor\" section on the lower part of the designer.</li> <li>You will see a live preview of your Adaptive Card on the upper part of the designer.</li> </ol> <p>Congrats! You are now fully skilled to develop Adaptive cards for your plugin!</p> <p></p>"},{"location":"pages/extend-m365-copilot/05-add-adaptive-card/#exercise-2-update-the-plugin-manifest","title":"Exercise 2: Update the plugin manifest","text":"<p>We are going to update the plugin manifest file called trey-plugin.json in the appPackage folder with a response template using adaptive cards. We will find each function or API call and update the templates.</p>"},{"location":"pages/extend-m365-copilot/05-add-adaptive-card/#step-1-add-an-adaptive-card-for-get-apiconsultants-requests","title":"Step 1: Add an adaptive card for GET /api/consultants requests","text":"<ul> <li>Locate the function getConsultants and after the <code>properties</code> node add below <code>static_template</code> node.</li> </ul> <pre><code> \"static_template\": {\n            \"$schema\": \"http://adaptivecards.io/schemas/adaptive-card.json\",\n            \"type\": \"AdaptiveCard\",\n            \"version\": \"1.5\",\n            \"body\": [\n              {\n                \"type\": \"Container\",\n                \"$data\": \"${$root}\",\n                \"items\": [\n                  {\n                    \"speak\": \"${name}\",\n                    \"type\": \"ColumnSet\",\n                    \"columns\": [\n                      {\n                        \"type\": \"Column\",\n                        \"items\": [\n                          {\n                            \"type\": \"TextBlock\",\n                            \"text\": \"${name}\",\n                            \"weight\": \"bolder\",\n                            \"size\": \"extraLarge\",\n                            \"spacing\": \"none\",\n                            \"wrap\": true,\n                            \"style\": \"heading\"\n                          },\n                          {\n                            \"type\": \"TextBlock\",\n                            \"text\": \"${email}\",\n                            \"wrap\": true,\n                            \"spacing\": \"none\"\n                          },\n                          {\n                            \"type\": \"TextBlock\",\n                            \"text\": \"${phone}\",\n                            \"wrap\": true,\n                            \"spacing\": \"none\"\n                          },\n                          {\n                            \"type\": \"TextBlock\",\n                            \"text\": \"${location.city}, ${location.country}\",\n                            \"wrap\": true\n                          }\n                        ]\n                      },\n                      {\n                        \"type\": \"Column\",\n                        \"items\": [\n                          {\n                            \"type\": \"Image\",\n                            \"url\": \"${consultantPhotoUrl}\",\n                            \"altText\": \"${name}\"\n                          }\n                        ]\n                      }\n                    ]\n                  }\n                ]\n              }   \n\n            ]\n }\n</code></pre>"},{"location":"pages/extend-m365-copilot/05-add-adaptive-card/#step-2-add-an-adaptive-card-for-get-apime-requests","title":"Step 2: Add an adaptive card for GET /api/me requests","text":"<ul> <li>Locate the function getUserInformation and after the <code>properties</code> node add below <code>static_template</code> node.</li> </ul> <pre><code>\n  \"static_template\":{\n            \"$schema\": \"http://adaptivecards.io/schemas/adaptive-card.json\",\n            \"type\": \"AdaptiveCard\",\n            \"version\": \"1.5\",\n            \"body\": [\n              {\n                \"type\": \"Container\",\n                \"$data\": \"${$root}\",\n                \"items\": [\n                  {\n                    \"speak\": \"${name}\",\n                    \"type\": \"ColumnSet\",\n                    \"columns\": [\n                      {\n                        \"type\": \"Column\",\n                        \"items\": [\n                          {\n                            \"type\": \"TextBlock\",\n                            \"text\": \"${name}\",\n                            \"weight\": \"bolder\",\n                            \"size\": \"extraLarge\",\n                            \"spacing\": \"none\",\n                            \"wrap\": true,\n                            \"style\": \"heading\"\n                          },\n                          {\n                            \"type\": \"TextBlock\",\n                            \"text\": \"${email}\",\n                            \"wrap\": true,\n                            \"spacing\": \"none\"\n                          },\n                          {\n                            \"type\": \"TextBlock\",\n                            \"text\": \"${phone}\",\n                            \"wrap\": true,\n                            \"spacing\": \"none\"\n                          },\n                          {\n                            \"type\": \"TextBlock\",\n                            \"text\": \"${location.city}, ${location.country}\",\n                            \"wrap\": true\n                          }\n                        ]\n                      },\n                      {\n                        \"type\": \"Column\",\n                        \"items\": [\n                          {\n                            \"type\": \"Image\",\n                            \"url\": \"${consultantPhotoUrl}\",\n                            \"altText\": \"${name}\"\n                          }\n                        ]\n                      }\n                    ]\n                  }\n                ]\n              }   \n\n            ]\n  }\n</code></pre>"},{"location":"pages/extend-m365-copilot/05-add-adaptive-card/#step-3-add-an-adaptive-card-for-get-apiprojects-requests","title":"Step 3: Add an adaptive card for GET /api/projects requests","text":"<ul> <li>Locate the function getProjects and after the <code>properties</code> node add below <code>static_template</code> node.</li> </ul> <pre><code>  \"static_template\": {\n            \"$schema\": \"http://adaptivecards.io/schemas/adaptive-card.json\",\n            \"type\": \"AdaptiveCard\",\n            \"version\": \"1.5\",\n            \"body\": [\n              {\n                \"type\": \"Container\",\n                \"$data\": \"${$root}\",\n                \"items\": [\n                  {\n                    \"speak\": \"${description}\",\n                    \"type\": \"ColumnSet\",\n                    \"columns\": [\n                      {\n                        \"type\": \"Column\",\n                        \"items\": [\n                          {\n                            \"type\": \"TextBlock\",\n                            \"text\": \"${name}\",\n                            \"weight\": \"bolder\",\n                            \"size\": \"extraLarge\",\n                            \"spacing\": \"none\",\n                            \"wrap\": true,\n                            \"style\": \"heading\"\n                          },\n                          {\n                            \"type\": \"TextBlock\",\n                            \"text\": \"${description}\",\n                            \"wrap\": true,\n                            \"spacing\": \"none\"\n                          },\n                          {\n                            \"type\": \"TextBlock\",\n                            \"text\": \"${location.city}, ${location.country}\",\n                            \"wrap\": true\n                          },\n                          {\n                            \"type\": \"TextBlock\",\n                            \"text\": \"${clientName}\",\n                            \"weight\": \"Bolder\",\n                            \"size\": \"Large\",\n                            \"spacing\": \"Medium\",\n                            \"wrap\": true,\n                            \"maxLines\": 3\n                          },\n                          {\n                            \"type\": \"TextBlock\",\n                            \"text\": \"${clientContact}\",\n                            \"size\": \"small\",\n                            \"wrap\": true\n                          },\n                          {\n                            \"type\": \"TextBlock\",\n                            \"text\": \"${clientEmail}\",\n                            \"size\": \"small\",\n                            \"wrap\": true\n                          }\n                        ]\n                      },\n                      {\n                        \"type\": \"Column\",\n                        \"items\": [\n                          {\n                            \"type\": \"Image\",\n                            \"url\": \"${location.mapUrl}\",\n                            \"altText\": \"${location.street}\"\n                          }\n                        ]\n                      }\n                    ]\n                  }\n                ]\n              },\n              {\n                \"type\": \"TextBlock\",\n                \"text\": \"Project Metrics\",\n                \"weight\": \"Bolder\",\n                \"size\": \"Large\",\n                \"spacing\": \"Medium\",\n                \"horizontalAlignment\": \"Center\",\n                \"separator\": true\n              },\n              {\n                \"type\": \"ColumnSet\",\n                \"columns\": [\n                  {\n                    \"type\": \"Column\",\n                    \"width\": \"stretch\",\n                    \"items\": [\n                      {\n                        \"type\": \"TextBlock\",\n                        \"text\": \"Forecast This Month\",\n                        \"weight\": \"Bolder\",\n                        \"spacing\": \"Small\",\n                        \"horizontalAlignment\": \"Center\"\n                      },\n                      {\n                        \"type\": \"TextBlock\",\n                        \"text\": \"${forecastThisMonth} \",\n                        \"size\": \"ExtraLarge\",\n                        \"weight\": \"Bolder\",\n                        \"horizontalAlignment\": \"Center\"\n                      }\n                    ]\n                  },\n                  {\n                    \"type\": \"Column\",\n                    \"width\": \"stretch\",\n                    \"items\": [\n                      {\n                        \"type\": \"TextBlock\",\n                        \"text\": \"Forecast Next Month\",\n                        \"weight\": \"Bolder\",\n                        \"spacing\": \"Small\",\n                        \"horizontalAlignment\": \"Center\"\n                      },\n                      {\n                        \"type\": \"TextBlock\",\n                        \"text\": \"${forecastNextMonth} \",\n                        \"size\": \"ExtraLarge\",\n                        \"weight\": \"Bolder\",\n                        \"horizontalAlignment\": \"Center\"\n                      }\n                    ]\n                  }\n                ]\n              },\n              {\n                \"type\": \"ColumnSet\",\n                \"columns\": [\n                  {\n                    \"type\": \"Column\",\n                    \"width\": \"stretch\",\n                    \"items\": [\n                      {\n                        \"type\": \"TextBlock\",\n                        \"text\": \"Delivered Last Month\",\n                        \"weight\": \"Bolder\",\n                        \"spacing\": \"Small\",\n                        \"horizontalAlignment\": \"Center\"\n                      },\n                      {\n                        \"type\": \"TextBlock\",\n                        \"text\": \"${deliveredLastMonth} \",\n                        \"size\": \"ExtraLarge\",\n                        \"weight\": \"Bolder\",\n                        \"horizontalAlignment\": \"Center\"\n                      }\n                    ]\n                  },\n                  {\n                    \"type\": \"Column\",\n                    \"width\": \"stretch\",\n                    \"items\": [\n                      {\n                        \"type\": \"TextBlock\",\n                        \"text\": \"Delivered This Month\",\n                        \"weight\": \"Bolder\",\n                        \"spacing\": \"Small\",\n                        \"horizontalAlignment\": \"Center\"\n                      },\n                      {\n                        \"type\": \"TextBlock\",\n                        \"text\": \"${deliveredThisMonth} \",\n                        \"size\": \"ExtraLarge\",\n                        \"weight\": \"Bolder\",\n                        \"horizontalAlignment\": \"Center\"\n                      }\n                    ]\n                  }\n                ]\n              }\n            ],\n            \"actions\": [\n              {\n                \"type\": \"Action.OpenUrl\",\n                \"title\": \"View map\",\n                \"url\": \"${location.mapUrl}\"\n              }\n            ]\n  }\n</code></pre>"},{"location":"pages/extend-m365-copilot/05-add-adaptive-card/#step-4-add-an-adaptive-card-for-post-apibillhours-requests","title":"Step 4: Add an adaptive card for POST /api/billHours requests","text":"<ul> <li>Locate the function postBillhours and after the <code>properties</code> node add below <code>static_template</code> node.</li> </ul> <pre><code>\"static_template\": {\n            \"type\": \"AdaptiveCard\",\n            \"$schema\": \"http://adaptivecards.io/schemas/adaptive-card.json\",\n            \"version\": \"1.5\",\n            \"body\": [\n              {\n                \"type\": \"TextBlock\",\n                \"text\": \"Project Status Summary\",\n                \"weight\": \"Bolder\",\n                \"size\": \"Large\",\n                \"separator\": true\n              },              \n              {\n                \"type\": \"Container\",\n                \"items\": [\n                  {\n                    \"type\": \"TextBlock\",\n                    \"text\": \"Client Name\",\n                    \"weight\": \"Bolder\",\n                    \"spacing\": \"Small\"\n                  },\n                  {\n                    \"type\": \"TextBlock\",\n                    \"text\": \"${if(results.clientName, results.clientName, 'N/A')}\",\n                    \"wrap\": true\n                  }\n                ]\n              },\n              {\n                \"type\": \"Container\",\n                \"items\": [\n                  {\n                    \"type\": \"TextBlock\",\n                    \"text\": \"Project Name\",\n                    \"weight\": \"Bolder\",\n                    \"spacing\": \"Small\"\n                  },\n                  {\n                    \"type\": \"TextBlock\",\n                    \"text\": \"${if(results.projectName, results.projectName, 'N/A')}\",\n                    \"wrap\": true\n                  }\n                ]\n              },  \n              {\n                \"type\": \"Container\",\n                \"items\": [\n                  {\n                    \"type\": \"TextBlock\",\n                    \"text\": \"Remaining Forecast\",\n                    \"weight\": \"Bolder\",\n                    \"spacing\": \"Small\"\n                  },\n                  {\n                    \"type\": \"TextBlock\",\n                    \"text\": \"${if(results.remainingForecast, results.remainingForecast, 'N/A')}\",\n                    \"wrap\": true\n                  }\n                ]\n              },           \n              {\n                \"type\": \"Container\",\n                \"items\": [\n                  {\n                    \"type\": \"TextBlock\",\n                    \"text\": \"Message\",\n                    \"weight\": \"Bolder\",\n                    \"spacing\": \"Small\"\n                  },\n                  {\n                    \"type\": \"TextBlock\",\n                    \"text\": \"${if(results.message, results.message, 'N/A')}\",\n                    \"wrap\": true\n                  }\n                ]\n              }\n            ]\n          }\n</code></pre>"},{"location":"pages/extend-m365-copilot/05-add-adaptive-card/#step-5-add-an-adaptive-card-for-post-apiassignconsultant-requests","title":"Step 5: Add an adaptive card for POST /api/assignConsultant requests","text":"<ul> <li>Locate the function postAssignConsultant and after the <code>properties</code> node add below <code>static_template</code> node.</li> </ul> <pre><code> \"static_template\": {\n            \"type\": \"AdaptiveCard\",\n            \"$schema\": \"http://adaptivecards.io/schemas/adaptive-card.json\",\n            \"version\": \"1.5\",\n            \"body\": [\n              {\n                \"type\": \"TextBlock\",\n                \"text\": \"Project Overview\",\n                \"weight\": \"Bolder\",\n                \"size\": \"Large\",\n                \"separator\": true,\n                \"spacing\": \"Medium\"\n              },              \n              {\n                \"type\": \"Container\",\n                \"items\": [\n                  {\n                    \"type\": \"TextBlock\",\n                    \"text\": \"Client Name\",\n                    \"weight\": \"Bolder\",\n                    \"spacing\": \"Small\"\n                  },\n                  {\n                    \"type\": \"TextBlock\",\n                    \"text\": \"${if(results.clientName, results.clientName, 'N/A')}\",\n                    \"wrap\": true\n                  }\n                ]\n              },\n              {\n                \"type\": \"Container\",\n                \"items\": [\n                  {\n                    \"type\": \"TextBlock\",\n                    \"text\": \"Project Name\",\n                    \"weight\": \"Bolder\",\n                    \"spacing\": \"Small\"\n                  },\n                  {\n                    \"type\": \"TextBlock\",\n                    \"text\": \"${if(results.projectName, results.projectName, 'N/A')}\",\n                    \"wrap\": true\n                  }\n                ]\n              },\n              {\n                \"type\": \"Container\",\n                \"items\": [\n                  {\n                    \"type\": \"TextBlock\",\n                    \"text\": \"Consultant Name\",\n                    \"weight\": \"Bolder\",\n                    \"spacing\": \"Small\"\n                  },\n                  {\n                    \"type\": \"TextBlock\",\n                    \"text\": \"${if(results.consultantName, results.consultantName, 'N/A')}\",\n                    \"wrap\": true\n                  }\n                ]\n              },\n              {\n                \"type\": \"Container\",\n                \"items\": [\n                  {\n                    \"type\": \"TextBlock\",\n                    \"text\": \"Remaining Forecast\",\n                    \"weight\": \"Bolder\",\n                    \"spacing\": \"Small\"\n                  },\n                  {\n                    \"type\": \"TextBlock\",\n                    \"text\": \"${if(results.remainingForecast, results.remainingForecast, 'N/A')}\",\n                    \"wrap\": true\n                  }\n                ]\n              },\n              {\n                \"type\": \"Container\",\n                \"items\": [\n                  {\n                    \"type\": \"TextBlock\",\n                    \"text\": \"Message\",\n                    \"weight\": \"Bolder\",\n                    \"spacing\": \"Small\"\n                  },\n                  {\n                    \"type\": \"TextBlock\",\n                    \"text\": \"${if(results.message, results.message, 'N/A')}\",\n                    \"wrap\": true\n                  }\n                ]\n              }            \n            ]          \n          }\n\n</code></pre>"},{"location":"pages/extend-m365-copilot/05-add-adaptive-card/#exercise-3-test-the-plugin-in-copilot","title":"Exercise 3: Test the plugin in Copilot","text":"<p>Before you test the application, update the manifest version of your app package in the <code>appPackage\\manifest.json</code> file, follow these steps:</p> <ol> <li> <p>Open the <code>manifest.json</code> file located in the <code>appPackage</code> folder of your project.</p> </li> <li> <p>Locate the <code>version</code> field in the JSON file. It should look something like this: <code>json    \"version\": \"1.0.1\"</code></p> </li> <li> <p>Increment the version number to a small increment. For example, change it to: <code>json    \"version\": \"1.0.2\"</code></p> </li> <li> <p>Save the file after making the change.</p> </li> </ol>"},{"location":"pages/extend-m365-copilot/05-add-adaptive-card/#step-1-install-the-plugin","title":"Step 1: Install the plugin","text":"<p>Stop and restart your project to force it to re-deploy the application package. You will be brought into Microsoft Teams. Once you're back in Copilot, open the right flyout 1\ufe0f\u20e3 to show your previous chats and declarative agents and select the Trey Genie Local agent 2\ufe0f\u20e3.</p> <p></p> <p></p>"},{"location":"pages/extend-m365-copilot/05-add-adaptive-card/#step-2-display-an-adaptive-card","title":"Step 2: Display an adaptive card","text":"<p>Now try a prompt such below</p> <p>what projects are we doing for adatum?</p> <p>Instead of just the text response you will also get a rich card with information of the project.</p> <p></p> <p>Now try a POST operation prompt such below</p> <p>please charge 1 hour to woodgrove bank in trey research</p> <p>Since the request requires Copilot to send some data via POST to the API plugin, you need to confirm that you want to allow Copilot to do so selecting the Confirm button.</p> <p></p> <p>Once confirmed, instead of just the text response you will also get a rich card with information of the project.</p> <p></p> <p>You can now test other prompts as well to see the improved responses from Microsoft 365 Copilot.</p> <p></p> <p>CONGRATULATIONS!</p> <p>You've completed adding adaptive card responses to your first API plugin. You are now ready to proceed to the next lab to add authentication to your API.</p> <p>Go to the lab Use OAuth 2.0 with Agents Toolkit to add authentication - This is the easiest approach; you will learn to set up Agents Toolkit's automated Entra ID registration for an F5 project start experience.</p> <p></p> Other labs on Authentication with manual steps  There are older labs created before OAuth 2.0 support with the Agents Toolkit. They demonstrate how to add authentication to your app package and validate access tokens in your web service. The main difference lies in how the app is registered in Entra ID and Microsoft 365.  Feel free to explore them and they all build on the project from this lab.    1. **Use OAuth 2.0 with Manual Setup** - Leads you through all the Entra ID registration details so you can really understand what's happening; this may help adapt your solution to work with another identity provider       2. **Use Single Sign-on** - New capability for seamless Entra ID authentication, manual setup    <p></p>"},{"location":"pages/extend-m365-copilot/06a-add-authentication-ttk/","title":"Lab E6a - Add Entra ID authentication with OAuth (Agents Toolkit)","text":"<p>In this lab you will add authentication to your API plugin using OAuth 2.0 with Entra ID as the identity provider. You will learn how to set up Agents Toolkit to automate the Entra ID and Teams Developer Portal registrations.</p> Get a quick overview of the lab in this video.              \ud83d\udcd8 Note:    This lab builds on the previous one, Lab E5. If you have completed lab E5, you can continue working in the same folder. If not, please copy the solution folder for Lab E5 from /src/extend-m365-copilot/path-e-lab05-add-adaptive-cards/trey-research-lab05-END     and work there.     The finished solution for this lab is in the src/extend-m365-copilot/path-e-lab06a-add-oauth/trey-research-lab06a-END  folder.          <p>Do these labs if you want to build a Declarative agent where Microsoft 365 provides the AI model and               orchestration</p> <ul> <li>\ud83c\udfc1 Welcome</li> <li>\ud83d\udd27 Set up <ul> <li>Lab E0 - Setup</li> </ul> </li> <li>\ud83e\uddf0 Declarative agent fundamentals <ul> <li> Lab E1 - Build a Detailed Declarative Agent </li> <li> Lab E1a - Geo locator game</li> </ul> </li> <li>\ud83d\udee0\ufe0f Build and integrate API from scratch <ul> <li>Lab E2 - Build an API</li> <li> Lab E3 - Add Declarative Agent + API</li> <li> Lab E4 - Enhance API + Plugin</li> <li>Lab E5 - Add Adaptive Cards</li> </ul> </li> <li>\ud83d\udd10 Authentication <ul> <li> Lab E6a - Toolkit</li> <li> Lab E6b - Manual</li> <li> Lab E6c - SSO</li> </ul> </li> <li>\ud83d\udd0c Integration <ul> <li> Lab EB - Add Graph Connector</li> </ul> </li> </ul>"},{"location":"pages/extend-m365-copilot/06a-add-authentication-ttk/#exercise-1-update-the-local-agents-toolkit-configuration","title":"Exercise 1: Update the local Agents Toolkit configuration","text":"<p>In this exercise you will modify the Agents Toolkit configuration files to instruct it to register the application in Entra ID and to place the information in the Teams Developer Portal \"vault\".</p>"},{"location":"pages/extend-m365-copilot/06a-add-authentication-ttk/#step-1-add-an-entra-id-app-manifest","title":"Step 1: Add an Entra ID app manifest","text":"<p>Create a new file aad.manifest.json in the root of your working folder. Copy these lines into this file.</p> <pre><code>{\n    \"id\": \"${{AAD_APP_OBJECT_ID}}\",\n    \"appId\": \"${{AAD_APP_CLIENT_ID}}\",\n    \"name\": \"Trey-Research-OAuth-aad\",\n    \"accessTokenAcceptedVersion\": 2,\n    \"signInAudience\": \"AzureADMyOrg\",\n    \"optionalClaims\": {\n        \"idToken\": [],\n        \"accessToken\": [\n            {\n                \"name\": \"idtyp\",\n                \"source\": null,\n                \"essential\": false,\n                \"additionalProperties\": []\n            }\n        ],\n        \"saml2Token\": []\n    },\n    \"oauth2Permissions\": [\n        {\n            \"adminConsentDescription\": \"Allows Copilot to access the Trey Research API on the user's behalf.\",\n            \"adminConsentDisplayName\": \"Access Trey Research API\",\n            \"id\": \"${{AAD_APP_ACCESS_AS_USER_PERMISSION_ID}}\",\n            \"isEnabled\": true,\n            \"type\": \"User\",\n            \"userConsentDescription\": \"Allows Copilot to access the Trey Research API on your behalf.\",\n            \"userConsentDisplayName\": \"Access Trey Research API\",\n            \"value\": \"access_as_user\"\n        }\n    ],\n    \"replyUrlsWithType\": [\n        {\n           \"url\": \"https://teams.microsoft.com/api/platform/v1.0/oAuthRedirect\",\n           \"type\": \"Web\"\n        }\n    ],\n    \"identifierUris\": [\n        \"api://${{AAD_APP_CLIENT_ID}}\"\n    ]\n}\n</code></pre> <p>This file contains details for the Entra ID application to be registered or updated. Notice that it contains various tokens such as <code>${{AAD_APP_CLIENT_ID}}</code> which will be replaced with actual values when Agents Toolkit provisions the application.</p> <p>Note</p> <p>Entra ID was previously called \"Azure Active Directory\"; references to \"AAD\" refer to Entra ID under its old name.</p> <p></p>"},{"location":"pages/extend-m365-copilot/06a-add-authentication-ttk/#step-2-update-the-file-version-number-in-teamsapplocalyml","title":"Step 2: Update the file version number in teamsapp.local.yml","text":"<p>The teamsapp.local.yml file contains instructions for Agents Toolkit for running and debugging your solution locally. This is the file you will update in remainder of this exercise.</p> <p>teamsapp.local.yml is now m365agents.local.yml</p> <p>The new Agents toolkit renamed the file for all toolkit related tasks to <code>m365agents.local.yml</code>. So if you started off creating agents with new Agents Toolkit, this will be the file name you will change. For these labs, since you work on existing agent project, there is nothing you need to rename or refactor. Proceed as per the steps.</p> <p>Warning</p> <p>Editing yaml files is sometimes tricky because containment is indicated by indentation. Be sure to indent properly when making each change or the lab won't work. If in doubt, you can refer to the completed solution file here.</p> <p>These labs were originally written using a slightly older version of Agents Toolkit, which uses version 1.5 of this file. In this step you will update the file to version 1.7.</p> <p>Begin by replacing the first line with this new schema reference:</p> <pre><code># yaml-language-server: $schema=https://aka.ms/teams-toolkit/v1.7/yaml.schema.json\n</code></pre> <p>Then on the 4th line, update the version number to 1.7.</p> <pre><code>version: v1.7\n</code></pre> <p></p>"},{"location":"pages/extend-m365-copilot/06a-add-authentication-ttk/#step-3-provision-an-entra-id-application","title":"Step 3: Provision an Entra ID application","text":"<p>In order for an application to authenticate a user and authorize it to do something, the application must first be registered in Entra ID. In this step we'll add this app registration if it's not already present.</p> <p>Locate these lines in the file:</p> <pre><code>provision:\n  # Creates a Teams app\n</code></pre> <p>Insert the following yaml between these lines, directly under the <code>provision:</code> line. You may leave blank lines for readability if you wish.</p> <pre><code>  # Creates a new Microsoft Entra app to authenticate users if\n  # the environment variable that stores clientId is empty\n  - uses: aadApp/create\n    with:\n      # Note: when you run aadApp/update, the Microsoft Entra app name will be updated\n      # based on the definition in manifest. If you don't want to change the\n      # name, make sure the name in Microsoft Entra manifest is the same with the name\n      # defined here.\n      name: trey-oauth-aad\n      # If the value is false, the action will not generate client secret for you\n      generateClientSecret: true\n      # Authenticate users with a Microsoft work or school account in your\n      # organization's Microsoft Entra tenant (for example, single tenant).\n      signInAudience: AzureADMyOrg\n    # Write the information of created resources into environment file for the\n    # specified environment variable(s).\n    writeToEnvironmentFile:\n      clientId: AAD_APP_CLIENT_ID\n      # Environment variable that starts with `SECRET_` will be stored to the\n      # .env.{envName}.user environment file\n      clientSecret: SECRET_AAD_APP_CLIENT_SECRET\n      objectId: AAD_APP_OBJECT_ID\n      tenantId: AAD_APP_TENANT_ID\n      authority: AAD_APP_OAUTH_AUTHORITY\n      authorityHost: AAD_APP_OAUTH_AUTHORITY_HOST\n</code></pre> <p>Notice that by setting <code>signInAudience</code> to <code>AzureADMyOrg</code>, Agents Toolkit creates a single tenant application that can only be used within the Entra ID tenant where it is registered. If you want to allow the app to be used in other tenants, such as your customer's tenants, you would set this to <code>AzureADMultipleOrgs</code>. All three steps use the aad.manifest.json file you created in the previous step.</p> <p>Also note that this step will write several values into your environment files, where they will be inserted into aad.manifest.json as well as in your application package.</p> <p></p>"},{"location":"pages/extend-m365-copilot/06a-add-authentication-ttk/#step-4-update-the-entra-id-application","title":"Step 4: Update the Entra ID application","text":"<p>Locate this line in teamsapp.local.yml</p> <pre><code>  # Build Teams app package with latest env value\n</code></pre> <p>Insert the following yaml before this line:</p> <pre><code>  - uses: oauth/register\n    with:\n      name: oAuth2AuthCode\n      flow: authorizationCode\n      appId: ${{TEAMS_APP_ID}}\n      clientId: ${{AAD_APP_CLIENT_ID}}\n      clientSecret: ${{SECRET_AAD_APP_CLIENT_SECRET}}\n      # Path to OpenAPI description document\n      apiSpecPath: ./appPackage/trey-definition.json\n    writeToEnvironmentFile:\n      configurationId: OAUTH2AUTHCODE_CONFIGURATION_ID\n\n  - uses: oauth/update\n    with:\n      name: oAuth2AuthCode\n      appId: ${{TEAMS_APP_ID}}\n      clientId: ${{AAD_APP_CLIENT_ID}}\n      # Path to OpenAPI description document\n      apiSpecPath: ./appPackage/trey-definition.json\n      configurationId: ${{OAUTH2AUTHCODE_CONFIGURATION_ID}}\n\n  # Apply the Microsoft Entra manifest to an existing Microsoft Entra app. Will use the object id in\n  # manifest file to determine which Microsoft Entra app to update.\n  - uses: aadApp/update\n    with:\n      # Relative path to this file. Environment variables in manifest will\n      # be replaced before apply to Microsoft Entra app\n      manifestPath: ./aad.manifest.json\n      outputFilePath: ./build/aad.manifest.${{TEAMSFX_ENV}}.json\n</code></pre> <p>The <code>oauth/register</code> and <code>oauth/update</code> steps will register the application in the Teams Developer Portal's vault, where Copilot can obtain the necessary details to implement the OAuth 2.0 Auth Code authorization flow. The <code>aadApp/update</code> step will update the Entra ID application itself with the details for this app. These details are in a separte file, aad.manifest.json, which we'll add in the next exercise.</p> <p></p>"},{"location":"pages/extend-m365-copilot/06a-add-authentication-ttk/#step-5-change-the-output-path","title":"Step 5: Change the output path","text":"<p>The new yaml schema changes the output path slightly. Locate this line:</p> <pre><code>      outputJsonPath: ./appPackage/build/manifest.${{TEAMSFX_ENV}}.json\n</code></pre> <p>and replace it with this one:</p> <pre><code>      outputFolder: ./appPackage/build\n</code></pre> <p></p>"},{"location":"pages/extend-m365-copilot/06a-add-authentication-ttk/#step-6-make-the-entra-id-values-available-to-your-application-code","title":"Step 6: Make the Entra ID values available to your application code","text":"<p>Locate these lines:</p> <pre><code>deploy:\n  # Install development tool(s)\n  - uses: devTool/install\n    with:\n      func:\n        version: ~4.0.5530\n        symlinkDir: ./devTools/func\n    # Write the information of installed development tool(s) into environment\n    # file for the specified environment variable(s).\n    writeToEnvironmentFile:\n      funcPath: FUNC_PATH\n          # Generate runtime environment variables\n  - uses: file/createOrUpdateEnvironmentFile\n    with:\n      target: ./.localConfigs\n      envs:\n        STORAGE_ACCOUNT_CONNECTION_STRING: ${{SECRET_STORAGE_ACCOUNT_CONNECTION_STRING}}\n</code></pre> <p>This code publishes environment variables for use within your application code. Add these lines under the <code>STORAGE_ACCOUNT_CONNECTION_STRING</code> to make them available:</p> <pre><code>        AAD_APP_TENANT_ID: ${{AAD_APP_TENANT_ID}}\n        AAD_APP_CLIENT_ID: ${{AAD_APP_CLIENT_ID}}\n</code></pre> <p></p>"},{"location":"pages/extend-m365-copilot/06a-add-authentication-ttk/#exercise-2-update-the-general-agents-toolkit-configuration","title":"Exercise 2: Update the general Agents Toolkit configuration","text":"<p>While teamsapp-local.yml controls Agents Toolkit behavior when debugging locally, teamsapp.yml controls its behavior when deploying to Microsoft Azure. In this exercise you'll update this file.</p> <p>Warning</p> <p>Editing yaml files is sometimes tricky because containment is indicated by indentation. Be sure to indent properly when making each change or the lab won't work. If in doubt, you can refer to the completed solution file here.</p>"},{"location":"pages/extend-m365-copilot/06a-add-authentication-ttk/#step-1-provision-an-entra-id-application","title":"Step 1: Provision an Entra ID application","text":"<p>In order for an application to authenticate a user and authorize it to do something, the application must first be registered in Entra ID. In this step we'll add this app registration if it's not already present.</p> <p>Locate these lines in the file:</p> <pre><code>provision:\n  # Creates a Teams app\n</code></pre> <p>Insert the following yaml between these lines, directly under the <code>provision:</code> line. You may leave blank lines for readability if you wish.</p> <pre><code>  # Creates a new Microsoft Entra app to authenticate users if\n  # the environment variable that stores clientId is empty\n  - uses: aadApp/create\n    with:\n      # Note: when you run aadApp/update, the Microsoft Entra app name will be updated\n      # based on the definition in manifest. If you don't want to change the\n      # name, make sure the name in Microsoft Entra manifest is the same with the name\n      # defined here.\n      name: Repairs-OAuth-aad\n      # If the value is false, the action will not generate client secret for you\n      generateClientSecret: true\n      # Authenticate users with a Microsoft work or school account in your\n      # organization's Microsoft Entra tenant (for example, single tenant).\n      signInAudience: AzureADMyOrg\n    # Write the information of created resources into environment file for the\n    # specified environment variable(s).\n    writeToEnvironmentFile:\n      clientId: AAD_APP_CLIENT_ID\n      # Environment variable that starts with `SECRET_` will be stored to the\n      # .env.{envName}.user environment file\n      clientSecret: SECRET_AAD_APP_CLIENT_SECRET\n      objectId: AAD_APP_OBJECT_ID\n      tenantId: AAD_APP_TENANT_ID\n      authority: AAD_APP_OAUTH_AUTHORITY\n      authorityHost: AAD_APP_OAUTH_AUTHORITY_HOST\n</code></pre> <p>Notice that by setting <code>signInAudience</code> to <code>AzureADMyOrg</code>, Agents Toolkit creates a single tenant application that can only be used within the Entra ID tenant where it is registered. If you want to allow the app to be used in other tenants, such as your customer's tenants, you would set this to <code>AzureADMultipleOrgs</code>. All three steps use the aad.manifest.json file you created in the previous step.</p> <p>Also note that this step will write several values into your environment files, where they will be inserted into aad.manifest.json as well as in your application package.</p> <p></p>"},{"location":"pages/extend-m365-copilot/06a-add-authentication-ttk/#step-2-register-the-app-in-the-teams-developer-portal-vault","title":"Step 2: Register the app in the Teams Developer Portal Vault","text":"<p>Locate these lines in teamsapp.yml</p> <pre><code>  # Validate using manifest schema\n  # - uses: teamsApp/validateManifest\n  #   with:\n  #     # Path to manifest template\n  #     manifestPath: ./appPackage/manifest.json\n\n  # Build Teams app package with latest env value\n</code></pre> <p>Insert the following before the last line:</p> <pre><code>  # Apply the Microsoft Entra manifest to an existing Microsoft Entra app. Will use the object id in\n  # manifest file to determine which Microsoft Entra app to update.\n  - uses: aadApp/update\n    with:\n      # Relative path to this file. Environment variables in manifest will\n      # be replaced before apply to Microsoft Entra app\n      manifestPath: ./aad.manifest.json\n      outputFilePath: ./build/aad.manifest.${{TEAMSFX_ENV}}.json\n\n  - uses: oauth/register\n    with:\n      name: oAuth2AuthCode\n      flow: authorizationCode\n      appId: ${{TEAMS_APP_ID}}\n      clientId: ${{AAD_APP_CLIENT_ID}}\n      clientSecret: ${{SECRET_AAD_APP_CLIENT_SECRET}}\n      # Path to OpenAPI description document\n      apiSpecPath: ./appPackage/trey-definition.json\n    writeToEnvironmentFile:\n      configurationId: OAUTH2AUTHCODE_CONFIGURATION_ID\n</code></pre> <p></p>"},{"location":"pages/extend-m365-copilot/06a-add-authentication-ttk/#exercise-3-update-your-application-package","title":"Exercise 3: Update your application package","text":"<p>Now that you've got Agents Toolkit setting up the Entra ID registrations, it's time to update the application package so Copilot knows about the authentication. In this exercise you'll update the necessary files.</p>"},{"location":"pages/extend-m365-copilot/06a-add-authentication-ttk/#step-1-update-the-open-api-specification-file","title":"Step 1: Update the Open API Specification file","text":"<p>Open your working folder in Visual Studio Code. In the appPackage folder, open the trey-definition.json file. Locate the line:</p> <pre><code>    \"paths\": {\n</code></pre> <p>and insert the following JSON before it:</p> <pre><code>    \"components\": {\n        \"securitySchemes\": {\n            \"oAuth2AuthCode\": {\n                \"type\": \"oauth2\",\n                \"description\": \"OAuth configuration for the Trey Research service\",\n                \"flows\": {\n                    \"authorizationCode\": {\n                        \"authorizationUrl\": \"https://login.microsoftonline.com/${{AAD_APP_TENANT_ID}}/oauth2/v2.0/authorize\",\n                        \"tokenUrl\": \"https://login.microsoftonline.com/${{AAD_APP_TENANT_ID}}/oauth2/v2.0/token\",\n                        \"scopes\": {\n                            \"api://${{AAD_APP_CLIENT_ID}}/access_as_user\": \"Access Trey Research API as the user\"\n                        }\n                    }\n                }\n            }\n        }\n    },\n</code></pre> <p>This sets up a new security scheme to be used when calling the API.</p> <p>Now you need to add this scheme to each API path. Find each instance of a path and look for the <code>responses</code> object:</p> <pre><code>    \"responses\": {\n      ...\n</code></pre> <p>Insert the following JSON before each of the <code>responses</code> (you will find 5 of them in the file; make sure you insert this before each one):</p> <pre><code>    \"security\": [\n        {\n            \"oAuth2AuthCode\": []\n        }\n    ],\n</code></pre> <p>Be sure to save your changes after editing.</p> <p></p>"},{"location":"pages/extend-m365-copilot/06a-add-authentication-ttk/#step-2-update-the-plugin-file","title":"Step 2: Update the Plugin file","text":"<p>In the appPackage folder, open the trey-plugin.json file. This is where information is stored that Copilot needs, but is not already in the Open API Specification (OAS) file.</p> <p>Under <code>Runtimes</code> you will find an <code>auth</code> property with <code>type</code> of <code>\"None\"</code>, indicating the API is currently not authenticated. Change it as follows to tell Copilot to authenticate using the OAuth settings you saved in the vault.</p> <pre><code>  \"auth\": {\n    \"type\": \"OAuthPluginVault\",\n    \"reference_id\": \"${{OAUTH2AUTHCODE_CONFIGURATION_ID}}\"\n  },\n</code></pre> <p>In the next step you'll update the application code to check for a valid login and access the API as the actual Microsoft 365 user instead of \"Avery Howard\" (which is a name from Microsoft's fictitious name generator).</p> <p></p>"},{"location":"pages/extend-m365-copilot/06a-add-authentication-ttk/#exercise-4-update-the-application-code","title":"Exercise 4: Update the application code","text":""},{"location":"pages/extend-m365-copilot/06a-add-authentication-ttk/#step-1-install-the-jwt-validation-library","title":"Step 1: Install the JWT validation library","text":"<p>From a command line in your working directory, type:</p> <pre><code>npm i jwt-validate\n</code></pre> <p>This will install a library for validating the incoming Entra ID authorization token.</p> <p>Warning</p> <p>Microsoft does not provide a supported library for validating Entra ID tokens in NodeJS, but instead provides this detailed documentation on how to write your own. Another useful article is also available from Microsoft MVP Andrew Connell.</p> <p>This lab uses a community provided library written by Waldek Mastykarz, which is intended to follow this guidance. Note that this library is not supported by Microsoft and is under an MIT License, so use it at your own risk.</p> <p>If you want to track progress on a supported library, please follow this Github issue.</p> <p></p>"},{"location":"pages/extend-m365-copilot/06a-add-authentication-ttk/#step-2-update-the-identity-service","title":"Step 2: Update the identity service","text":"<p>At this point, OAuth login should work and provide a valid access token, but the solution isn't secure unless the code checks to make sure the token is valid. In this step, you'll add code to validate the is token and extract information such as the user's name and ID.</p> <p>In the src/services folder, open IdentityService.ts.  At the top of the file along with the other <code>import</code> statements, add this one:</p> <pre><code>import { TokenValidator, ValidateTokenOptions, getEntraJwksUri } from 'jwt-validate';\n</code></pre> <p>Then, right under the <code>class Identity</code> statement, add this line:</p> <pre><code>    private validator: TokenValidator;\n</code></pre> <p>Now look for the comment</p> <pre><code>// ** INSERT REQUEST VALIDATION HERE (see Lab E6) **\n</code></pre> <p>Replace the comment with this code:</p> <pre><code>  // Try to validate the token and get user's basic information\n  try {\n      const { AAD_APP_CLIENT_ID, AAD_APP_TENANT_ID } = process.env;\n      const token = req.headers.get(\"Authorization\")?.split(\" \")[1];\n      if (!token) {\n          throw new HttpError(401, \"Authorization token not found\");\n      }\n\n      // create a new token validator for the Microsoft Entra common tenant\n      if (!this.validator) {\n        // We need a new validator object which we will continue to use on subsequent\n        // requests so it can cache the Entra ID signing keys\n        // For multitenant, use:\n        // const entraJwksUri = await getEntraJwksUri();\n        const entraJwksUri = await getEntraJwksUri(AAD_APP_TENANT_ID);\n        this.validator = new TokenValidator({\n            jwksUri: entraJwksUri\n        });\n        console.log (\"Token validator created\");\n      }\n\n      const options: ValidateTokenOptions = {\n          allowedTenants: [AAD_APP_TENANT_ID],\n          audience: `${AAD_APP_CLIENT_ID}`,\n          issuer: `https://login.microsoftonline.com/${AAD_APP_TENANT_ID}/v2.0`,\n          scp: [\"access_as_user\"]\n      };\n\n      // validate the token\n      const validToken = await this.validator.validateToken(token, options);\n\n      userId = validToken.oid;\n      userName = validToken.name;\n      userEmail = validToken.preferred_username;\n      console.log(`Request ${this.requestNumber++}: Token is valid for user ${userName} (${userId})`);\n  }\n  catch (ex) {\n      // Token is missing or invalid - return a 401 error\n      console.error(ex);\n      throw new HttpError(401, \"Unauthorized\");\n  }\n</code></pre> <p>Learn from the code</p> <p>Have a look at the new source code. First, it obtains the token from the <code>Authorization</code> header in the HTTPs request. This header contains the word \"Bearer\", a space, and then the token, so a JavaScript <code>split(\" \")</code> is used to obtain only the token.</p> <p>Also note that the code will throw an exception if authentication should fail for any reason; the Azure function will then return the appropriate error.</p> <p>The code then creates a validator for use with the <code>jwks-validate</code> library. This call reads the latest private keys from Entra ID, so it is an async call that may take some time to run.</p> <p>Next, the code sets up a <code>ValidateTokenOptions</code> object. Based on this object, in addition to validating that the token was signed with Entra ID's private key, the library will validate that:</p> <ul> <li> <p>the audience must be the same as the API service app URI; this ensures that the token is intended for our web service and no other</p> </li> <li> <p>the issuer must be from the security token service for our tenant</p> </li> <li> <p>the scope must match the scope defined in our app registration, which is <code>\"access_as_user\"</code>.</p> </li> </ul> <p>If the token is valid, the library returns an object with all the \"claims\" that were inside, including the user's unique ID, name, and email. We will use these values instead of relying on the fictitious \"Avery Howard\".</p> <p></p>"},{"location":"pages/extend-m365-copilot/06a-add-authentication-ttk/#exercise-5-test-the-application","title":"Exercise 5: Test the application","text":""},{"location":"pages/extend-m365-copilot/06a-add-authentication-ttk/#step-1-bump-the-application-version-number-in-the-app-manifest","title":"Step 1: Bump the application version number in the app manifest","text":"<p>Before you test the application, update the manifest version of your app package in the <code>appPackage\\manifest.json</code> file, follow these steps:</p> <ol> <li> <p>Open the <code>manifest.json</code> file located in the <code>appPackage</code> folder of your project.</p> </li> <li> <p>Locate the <code>version</code> field in the JSON file. It should look something like this: <code>json    \"version\": \"1.0.0\"</code></p> </li> <li> <p>Increment the version number to a small increment. For example, change it to: <code>json    \"version\": \"1.0.1\"</code></p> </li> <li> <p>Save the file after making the change.</p> </li> </ol> <p>Compile issue with jwt-validate package </p> <p>At the moment, the jwt-validate package throws typing error for @types/jsonwebtoken package. To work around the issue, edit the tsconfig.json file, found at the root of the project, and add \"skipLibCheck\":true. This will be fixed in a future version of the library, and may no longer be necessary by the time you do the lab.</p> <p></p>"},{"location":"pages/extend-m365-copilot/06a-add-authentication-ttk/#step-2-restart-the-application","title":"Step 2: (Re)start the application","text":"<p>If your app is still running from an earlier lab, stop it to force it to re-create the application package.</p> <p>Then press F5 to run the application again, and install it as before.</p> <p></p>"},{"location":"pages/extend-m365-copilot/06a-add-authentication-ttk/#step-3-run-the-declarative-agent","title":"Step 3: Run the declarative agent","text":"<p>Proceed back to Microsoft 365 Copilot and select the Trey Research agent. Enter the prompt, \"What Trey projects am I assigned to?\". You may see a confirmation card asking if it's OK to call your API. No authentication is happening here; click \"Allow Once\" to proceed.</p> <p></p> <p>The confirmation card will be replaced with a login card. Click \"Sign in to Trey\" to sign in. At first you should see a pop-up window asking you to log in and to consent to permissions. On subsequent vists this may be hidden as your credentials have been cached by Entra ID in your local browser.</p> <p></p> <p>You might need admin approval</p> <p>There are cases where your admin has not allowed you to consent as a user and may see something like below:</p> <p></p> <p>This is because the admin has restricted the ability for users to consent to grant permissions to applications. In this case, you have to request admin to manually grant global consent for all users for the plugin API registration as below. Find the app registration in Microsoft 365 Admin / Identity / Applications / App Registrations and do the consent from there.</p> <p></p> <p>The login card should be replaced by Copilot's response to your prompt. Since you were just added to the database, you aren't assigned to any projects.</p> <p>Recall that the user was hard coded to the fictitious user \"Avery Howard\". When the new code runs for the first time, it won't find your user ID, so it will create a new consultant record that's not (yet) assigned to any projects.</p> <p>Updating your user information</p> <p>Since this is just a lab, we have hard-coded the details such as skills and location for your new user account. If you want to change them, you can do that using the Azure Storage Explorer</p> <p></p> <p></p>"},{"location":"pages/extend-m365-copilot/06a-add-authentication-ttk/#step-4-add-yourself-to-a-project","title":"Step 4: Add yourself to a project","text":"<p>Since you were just added to the database, you're not assigned to any projects. Note that project assignments are stored in the <code>Assignment</code> table and reference the project ID and the assigned consultant's consultant ID. When you ask Agent what projects you are asigned to, it says it cannot find any project assigned but identifies your skills and roles and offers to help.</p> <p></p> <p>Ask Agent to add you to the Woodgrove project. Agent will press you for details if you forgot to include any required values.</p> <p></p> <p>You would want to provide missing information, so your agent can confirm the details again before proceeding.</p> <p></p> <p>Finally once you confirm, agent fullfills the task by adding you to the project with right role and forecast.</p> <p></p> <p>Now check out your default skills and confirm the project assignment by asking, \"What are my skills and what projects am I assigned to?\"</p> <p></p> <p>CONGRATULATIONS!</p> <p>You have completed lab Ea6, Add Entra ID authentication with Agents Toolkit!</p> <p>Want to try something cool? How about adding a Copilot Connector to your solution?</p> <p></p> <p></p>"},{"location":"pages/extend-m365-copilot/06b-add-authentication/","title":"Lab E6b - Add Entra ID authentication with OAuth (Manual Setup)","text":"<p>In this lab you will add authentication to your API plugin using OAuth 2.0 with Entra ID as the identity provider.</p> Get a quick overview of the lab in this video.              \ud83d\udcd8 Note:   This lab builds on the previous one, Lab E5. If you have completed lab E5, you can continue working in the same folder. If not, please copy the solution folder for Lab E5 from /src/extend-m365-copilot/path-e-lab05-add-adaptive-cards/trey-research-lab05-END      and work there.     The finished solution for this lab is in the /src/extend-m365-copilot/path-e-lab06b-add-oauth/trey-research-lab06b-ENDfolder.          <p>Do these labs if you want to build a Declarative agent where Microsoft 365 provides the AI model and               orchestration</p> <ul> <li>\ud83c\udfc1 Welcome</li> <li>\ud83d\udd27 Set up <ul> <li>Lab E0 - Setup</li> </ul> </li> <li>\ud83e\uddf0 Declarative agent fundamentals <ul> <li> Lab E1 - Build a Detailed Declarative Agent </li> <li> Lab E1a - Geo locator game</li> </ul> </li> <li>\ud83d\udee0\ufe0f Build and integrate API from scratch <ul> <li>Lab E2 - Build an API</li> <li> Lab E3 - Add Declarative Agent + API</li> <li> Lab E4 - Enhance API + Plugin</li> <li>Lab E5 - Add Adaptive Cards</li> </ul> </li> <li>\ud83d\udd10 Authentication <ul> <li> Lab E6a - Toolkit</li> <li> Lab E6b - Manual</li> <li> Lab E6c - SSO</li> </ul> </li> <li>\ud83d\udd0c Integration <ul> <li> Lab EB - Add Graph Connector</li> </ul> </li> </ul> <p>Note</p> <p>There are many detailed setup steps for Entra ID in this lab. A new version of Agents Toolkit is available which will automate many of these steps for you; we plan to provide a more streamlined version of the lab shortly.</p> <p>In this lab you will register Entra ID applications that are used to secure your plugin and API. Before you begin, choose a safe place for your app information. Here are the values you'll need to save:</p> <pre><code>API Base URL: \nAPI service Application (client) ID: \nAPI service Directory (tenant) ID: \nAuthorization endpoint: \nToken endpoint: \nAPI service client secret: \nAPI scope: \nPlugin service application (client) ID: \nPlugin service client secret: \n</code></pre>"},{"location":"pages/extend-m365-copilot/06b-add-authentication/#exercise-1-set-up-a-persistent-developer-tunnel-optional","title":"Exercise 1: Set up a persistent developer tunnel (optional)","text":"<p>By default, Agents Toolkit creates a new developer tunnel - and thus a new URL for accesing your locally running API - every time you start the project. Normally this is fine because Agents Toolkit automatically updates the URL where needed, but since this lab will be a manual setup, you'll have to manually update the URL in Entra ID and in Teams Developer Portal each time you start the debugger. For that reason, you may wish to set up a persistent developer tunnel with a URL that does not change.</p> If you don't want to set up a persistent tunnel, open this note \u25b6\u25b6\u25b6 <p>You are free to skip this exercise and use the developer tunnel provided by Agents Toolkit. Once your project is running, you can copy this URL from the terminal tab 1\ufe0f\u20e3 by choosing the \"Start local tunnel\" terminal 2\ufe0f\u20e3; copy the Forwarding URL 3\ufe0f\u20e3. Note this URL will change every time you start the project, and you will need to manually update the app registration reply URL (exercise 2 step 1) and the Teams Developer Portal URL (exercise 5 step 1). </p>"},{"location":"pages/extend-m365-copilot/06b-add-authentication/#step-1-install-the-developer-tunnel-cli","title":"Step 1: Install the developer tunnel CLI","text":"<p>Here are the command lines for installing the developer tunnel. Full instructions and download links for the Developer Tunnel are here.. </p> OS Command Windows <code>winget install Microsoft.devtunnel</code> Mac OS <code>brew install --cask devtunnel</code> Linux <code>curl -sL https://aka.ms/DevTunnelCliInstall | bash</code> <p>Tip</p> <p>You may have to restart your command line to update the file path before devtunnel commands will work</p> <p>Once you have it installed, you'll need to log in. You can use your Microsoft 365 account to log in.</p> <pre><code>devtunnel user login\n</code></pre> <p>Be sure to leave the devtunnel command running as you do the exercises in this lab. If you need to restart it, just repeat the last command <code>devtunnel user login</code>.</p> <p></p>"},{"location":"pages/extend-m365-copilot/06b-add-authentication/#step-2-create-and-host-the-tunnel","title":"Step 2: Create and host the tunnel","text":"<p>Then you'll need to set up a persistent tunnel to the Azure Functions local port (7071). You can use these commands and substitute your own name instead of \"mytunnel\" if you wish.</p> <pre><code>devtunnel create mytunnel -a --host-header unchanged\ndevtunnel port create mytunnel -p 7071\ndevtunnel host mytunnel\n</code></pre> <p>The command line will display the connection information, such as:</p> <p></p> <p>Copy the \"Connect via browser\" URL and save it as the \"API Base URL\".</p> <p></p>"},{"location":"pages/extend-m365-copilot/06b-add-authentication/#step-3-disable-the-dynamically-created-tunnel-in-your-project","title":"Step 3: Disable the dynamically created tunnel in your project","text":"<p>If your project is running locally, stop it. Then edit .vscode\\tasks.json and locate the \"Start Teams App task. Comment out the \"Start local tunnel\" depdendency and add its dependency, \"Start Azurite emulator\" instead. The resulting task should look like this:</p> <pre><code>{\n    \"label\": \"Start Teams App Locally\",\n    \"dependsOn\": [\n        \"Validate prerequisites\",\n        //\"Start local tunnel\",\n        \"Start Azurite emulator\",\n        \"Create resources\",\n        \"Build project\",\n        \"Start application\"\n    ],\n    \"dependsOrder\": \"sequence\"\n},\n</code></pre> <p></p>"},{"location":"pages/extend-m365-copilot/06b-add-authentication/#step-4-manually-override-the-server-url","title":"Step 4: Manually override the server URL","text":"<p>Open env/.env.local and change the value of OPENAPI_SERVER_URL to the persistent tunnel URL.</p> <p></p>"},{"location":"pages/extend-m365-copilot/06b-add-authentication/#exercise-2-register-an-entra-id-application-for-your-api","title":"Exercise 2: Register an Entra ID application for your API","text":""},{"location":"pages/extend-m365-copilot/06b-add-authentication/#step-1-add-a-new-entra-id-app-registration","title":"Step 1: Add a new Entra ID app registration","text":"<p>Browse to the Entra ID admin center either via the Microsoft 365 Admin center or directly at https://entra.microsoft.com/. Make sure you are logged into your development tenant and not some other.</p> <p>Once you're there, click \"Identity\" 1\ufe0f\u20e3, then \"Applications\" 2\ufe0f\u20e3, and then \"App registrations\" 3\ufe0f\u20e3. Then click the \"+\" 4\ufe0f\u20e3 to add a new app registration.</p> <p></p> <p>Give your application a unique and descriptive name such as \"My API Service\" 1\ufe0f\u20e3. Under \"Supported account types\", select \"Accounts in this organizational directory only (Microsoft only - single tenant) 2\ufe0f\u20e3. Under \"Redirect URI (optional)\" select \"Web\" and enter the URL of your developer tunnel 3\ufe0f\u20e3. </p> <p>If you didn't make a persistent developer tunnel URL...</p> <p>...you will have to update the \"Redirect URI\" field with the new tunnel URL after each time you start your application in Agents Toolkit</p> <p>Then click \"Register\" 4\ufe0f\u20e3 to register your application.</p> <p></p> <p></p>"},{"location":"pages/extend-m365-copilot/06b-add-authentication/#step-2-copy-application-info-to-a-safe-place","title":"Step 2: Copy application info to a safe place","text":"<p>Copy the Application ID (also called the Client ID) 1\ufe0f\u20e3 and the Directory ID (also called the Tenant ID) 2\ufe0f\u20e3 to a safe place; you'll need them later. Then click on the Endpoints button 3\ufe0f\u20e3 to open the Endpoints flyout.</p> <p></p> <p>Now copy the two endpoint URLs with name \"OAuth 2.0 authorization endpoint (v2)\" 1\ufe0f\u20e3 and \"OAuth 2.0 token endpoint (v2)\" 2\ufe0f\u20e3 and save them in the same safe place.</p> <p></p> <p></p>"},{"location":"pages/extend-m365-copilot/06b-add-authentication/#step-3-create-client-secret","title":"Step 3: Create client secret","text":"<p>Next, navigate to \"Certificates &amp; secrets\" 1\ufe0f\u20e3 and click \"+ New client secret\" 2\ufe0f\u20e3. Give your secret a name and choose a duration, then select the Add button. The secret will be displayed; this is your one and only chance to view it as secrets are only displayed in the portal when they're first created. Copy the secret 3\ufe0f\u20e3 to your safe storage place.</p> <p></p> <p></p>"},{"location":"pages/extend-m365-copilot/06b-add-authentication/#step-4-expose-an-api-scope","title":"Step 4: Expose an API Scope","text":"<p>In order to validate calls to your API, you need to expose an API Scope, which represents the permission to call the API. Though these could be very specific - allowing permission to do specific operations via the API - in this case we'll set up a simple scope called \"access_as_user\".</p> <p>First, browse to \"Expose an API\" 1\ufe0f\u20e3 and, next to \"Application ID URI\" click \"Add\" 2\ufe0f\u20e3. A flyout will open on the right; you can stay with the default value which is api://&lt;your application (client) ID&gt;. Go ahead and click \"Save and continue\" 3\ufe0f\u20e3 to proceed.</p> <p></p> <p>Under \"Add a scope\" enter \"access_as_user\" as the scope name 1\ufe0f\u20e3. Fill in the remaining fields as follows:</p> Field Value Who can consent? Admins and users Admin consent display name Access My API as the user Admin consent description Allows an API to access My API as a user User consent display name Access My API as you User consent description Allows an app to access My API as you State Enabled <p>When you're done, click \"Add Scope\" 2\ufe0f\u20e3.</p> <p></p> <p></p>"},{"location":"pages/extend-m365-copilot/06b-add-authentication/#step-5-save-the-api-scope","title":"Step 5: Save the API Scope","text":"<p>Copy the scope to your safe place as the \"API Scope\".</p> <p></p> <p></p>"},{"location":"pages/extend-m365-copilot/06b-add-authentication/#exercise-3-register-an-entra-id-application-for-your-plugin","title":"Exercise 3: Register an Entra ID application for your plugin","text":"<p>Now that you've registered an API for the application, it's time to register the plugin itself.</p> <p>About two Entra ID app registrations</p> <p>This lab is a guide on how to adapt assuming you already have a registered application for your API and want to integrate it into the agent as a plugin. That is why we have two app registrations.  When creating an API from scratch, you may not always need two app registrations to implement OAuth securely to plug into the agent. Instead, you can use an existing app registration. Here is how you can do it in one single app registration in this learn module</p>"},{"location":"pages/extend-m365-copilot/06b-add-authentication/#step-1-register-the-plugin","title":"Step 1: Register the plugin","text":"<p>Return to the \"App registrations\" section and register a second application. This time call it \"My API Plugin\" 1\ufe0f\u20e3, and once again set \"Supported account types\" to \"Accounts in this organizational directory only\" 2\ufe0f\u20e3.</p> <p>Under \"Redirect URL\" select \"Web\", and this time set it to <code>https://teams.microsoft.com/api/platform/v1.0/oAuthRedirect</code> 3\ufe0f\u20e3. This is the Teams location that will handle completed logins to the API Plugin application.</p> <p>Click the \"Register\" button 4\ufe0f\u20e3 to complete the registration.</p> <p></p> <p>As before, view the app's \"Overview\" page and save the Application (client) ID for the API Plugin app.</p> <p></p>"},{"location":"pages/extend-m365-copilot/06b-add-authentication/#step-2-create-a-client-secret","title":"Step 2: Create a client secret","text":"<p>As before, create a client secret and save it under \"Plugin service client secret\" in your safe location.</p> <p></p>"},{"location":"pages/extend-m365-copilot/06b-add-authentication/#step-3-grant-permission","title":"Step 3: Grant permission","text":"<p>Your plugin needs to call your API service, so naturally it needs permission to do that. Begin by navigating to \"API permissions\". Then click the \"APIs my organization uses\" tab 1\ufe0f\u20e3 and search for your API service 2\ufe0f\u20e3. Select your API service from the results 3\ufe0f\u20e3.</p> <p></p> <p>Now you should see your API service application. Select the \"access_as_user\" permission and click \"Add permission\".</p> <p></p> <p></p>"},{"location":"pages/extend-m365-copilot/06b-add-authentication/#exercise-4-update-the-api-app-registration-with-the-plugin-application-id","title":"Exercise 4: Update the API app registration with the plugin application ID","text":""},{"location":"pages/extend-m365-copilot/06b-add-authentication/#step-1-add-the-plugin-apps-id-to-the-api-service-app","title":"Step 1: Add the Plugin app's ID to the API service app","text":"<p>Now the API Service application needs to allow the API Plugin application to issue tokens for it. To enable this, return to the App Registration for your API Service application. Select \"Manifest\" and find the entry for <code>knownClientApplications</code> 1\ufe0f\u20e3. Add your My Plugin App's client ID to this entry as follows:</p> <pre><code>\"knownClientApplications\": [\n    \"&lt;your-plugin-client-id&gt;\"\n]\n</code></pre> <p>Remember to click \"Save\" 2\ufe0f\u20e3 when you're done.</p> <p></p> <p></p>"},{"location":"pages/extend-m365-copilot/06b-add-authentication/#exercise-5-register-the-oauth-information-in-the-teams-developer-portal","title":"Exercise 5: Register the OAuth information in the Teams Developer Portal","text":"<p>Now you're apps are all set up, but Microsoft 365 doesn't know anything about it. It wouldn't be safe to store secrets in the app manifest, so Teams has set up a place in the Teams Developer Portal to safely store this information. In this exercise you'll use the Teams Developer Portal to register your OAuth client application so Copilot can authenticate users for it.</p>"},{"location":"pages/extend-m365-copilot/06b-add-authentication/#step-1-create-a-new-oauth-client-registration","title":"Step 1: Create a new OAuth client registration","text":"<p>Browse to the Teams Developer Portal at https://dev.teams.microsoft.com. Select \"Tools\" 1\ufe0f\u20e3 and then \"OAuth client registration\" 2\ufe0f\u20e3.</p> <p></p> <p>Click \"Register client\", if you don't have any already registered client application, or \"+ New OAuth client registration\", if you already have existing client applications, and fill in the form. Several of the fields are from your safely stored information you've been building up over the last few exercises.</p> Field Value Name Choose a name you'll remember Base URL your API service Base URL Restrict usage by org select \"My organization only\" Restrict usage by app select \"Any Teams app\" Client ID Your Plugin Application (client) ID Client secret Your Plugin Application client secret Authorization endpoint Your authorization endpoint (same for both API Service and API Plugin apps) Token endpoint Your token endpoint (same for both API Service and API Plugin apps) Refresh endpoint Your token endpoint (same for both API Service and API Plugin apps) API scope Your API Service application's scope <p></p> <p>If you didn't make a persistent developer tunnel URL...</p> <p>...you will have to update the \"Base URL\" field with your new tunnel URL each time you start your application in Agents Toolkit</p> <p></p>"},{"location":"pages/extend-m365-copilot/06b-add-authentication/#step-2-save-your-oauth-registration-id","title":"Step 2: Save your OAuth registration ID","text":"<p>The portal will display your OAuth client registration ID. Save this for the next step.</p> <p></p>"},{"location":"pages/extend-m365-copilot/06b-add-authentication/#exercise-6-update-your-application-package","title":"Exercise 6: Update your application package","text":""},{"location":"pages/extend-m365-copilot/06b-add-authentication/#step-1-update-the-plugin-file","title":"Step 1: Update the Plugin file","text":"<p>Open your working folder in Visual Studio Code. In the appPackage folder, open the trey-plugin.json file. This is where information is stored that Copilot needs, but is not already in the Open API Specification (OAS) file.</p> <p>Under <code>Runtimes</code> you will find an <code>auth</code> property with <code>type</code> of <code>\"None\"</code>, indicating the API is currently not authenticated. Change it as follows to tell Copilot to authenticate using the OAuth settings you saved in the vault.</p> <pre><code>\"auth\": {\n  \"type\": \"OAuthPluginVault\",\n  \"reference_id\":  \"${{OAUTH_CLIENT_REGISTRATION_ID}}\"\n},\n</code></pre> <p>Then add this line to your env/.env.local file:</p> <pre><code>OAUTH_CLIENT_REGISTRATION_ID=&lt;registration id you saved in the previous exercise&gt;\n</code></pre> <p>The next time you start and prompt your API plugin, it should prompt you to sign in. However we've done nothing to secure the application; anyone on the Internet can call it! In the next step you'll update the application code to check for a valid login and access the API as the actual Microsoft 365 user instead of \"Avery Howard\" (which is a name from Microsoft's fictitious name generator).</p> <p></p>"},{"location":"pages/extend-m365-copilot/06b-add-authentication/#exercise-7-update-the-application-code","title":"Exercise 7: Update the application code","text":""},{"location":"pages/extend-m365-copilot/06b-add-authentication/#step-1-install-the-jwt-validation-library","title":"Step 1: Install the JWT validation library","text":"<p>From a command line in your working directory, type:</p> <pre><code>npm i jwt-validate\n</code></pre> <p>This will install a library for validating the incoming Entra ID authorization token.</p> <p>Warning</p> <p>Microsoft does not provide a supported library for validating Entra ID tokens in NodeJS, but instead provides this detailed documentation on how to write your own. Another useful article is also available from Microsoft MVP Andrew Connell.</p> <p>This lab uses a community provided library written by Waldek Mastykarz, which is intended to follow this guidance. Note that this library is not supported by Microsoft and is under an MIT License, so use it at your own risk.</p> <p>If you want to track progress on a supported library, please follow this Github issue.</p> <p></p>"},{"location":"pages/extend-m365-copilot/06b-add-authentication/#step-2-add-environment-variables-for-your-api","title":"Step 2: Add environment variables for your API","text":"<p>In the env folder in your working directory, open env.local and add these lines for your API Service app's client ID and tenant ID.</p> <pre><code>API_APPLICATION_ID=&lt;your-api-service-client-id&gt;\nAPI_TENANT_ID=&lt;your-tenant-id&gt;\n</code></pre> <p>To make these values available inside your code running in Agents Toolkit, you also need to update the teamsapp.local.yml file in the root of your working folder. Look for the comment \"Generate runtime environment variables\" and add the new values under the STORAGE_ACCOUNT_CONNECTION_STRING:</p> <pre><code>  - uses: file/createOrUpdateEnvironmentFile\n    with:\n      target: ./.localConfigs\n      envs:\n        STORAGE_ACCOUNT_CONNECTION_STRING: ${{SECRET_STORAGE_ACCOUNT_CONNECTION_STRING}},\n        API_APPLICATION_ID: ${{API_APPLICATION_ID}}\n        API_TENANT_ID: ${{API_TENANT_ID}}\n</code></pre> <p></p>"},{"location":"pages/extend-m365-copilot/06b-add-authentication/#step-3-update-the-identity-service","title":"Step 3: Update the identity service","text":"<p>At this point, OAuth login should work and provide a valid access token, but the solution isn't secure unless the code checks to make sure the token is valid. In this step, you'll add code to validate the is token and extract information such as the user's name and ID.</p> <p>In the src/services folder, open IdentityService.ts.  At the top of the file along with the other <code>import</code> statements, add this one:</p> <pre><code>import { TokenValidator, ValidateTokenOptions, getEntraJwksUri } from 'jwt-validate';\n</code></pre> <p>Then, right under the <code>class Identity</code> statement, add this line:</p> <pre><code>    private validator: TokenValidator;\n</code></pre> <p>Now look for the comment</p> <pre><code>// ** INSERT REQUEST VALIDATION HERE (see Lab E6) **\n</code></pre> <p>Replace the comment with this code:</p> <pre><code>// Try to validate the token and get user's basic information\ntry {\n    const { API_APPLICATION_ID, API_TENANT_ID } = process.env;\n    const token = req.headers.get(\"Authorization\")?.split(\" \")[1];\n    if (!token) {\n        throw new HttpError(401, \"Authorization token not found\");\n    }\n\n    // create a new token validator for the Microsoft Entra common tenant\n    if (!this.validator) {\n        // We need a new validator object which we will continue to use on subsequent\n        // requests so it can cache the Entra ID signing keys\n        // For multitenant, use:\n        // const entraJwksUri = await getEntraJwksUri();\n        const entraJwksUri = await getEntraJwksUri(API_TENANT_ID);\n        this.validator = new TokenValidator({\n            jwksUri: entraJwksUri\n        });\n        console.log (\"Token validator created\");\n    }\n\n    // Use these options for single-tenant applications\n    const options: ValidateTokenOptions = {\n        audience: `api://${API_APPLICATION_ID}`,\n        issuer: `https://sts.windows.net/${API_TENANT_ID}/`,\n        // NOTE: If this is a multi-tenant app, look for \n        // issuer: \"https://sts.windows.net/common/\",\n        // Also you may wish to manage a list of allowed tenants\n        // and test them as well\n        //   allowedTenants: [process.env[\"AAD_APP_TENANT_ID\"]],\n        scp: [\"access_as_user\"]\n    };\n\n    // validate the token\n    const validToken = await this.validator.validateToken(token, options);\n\n    userId = validToken.oid;\n    userName = validToken.name;\n    userEmail = validToken.upn;\n    console.log(`Request ${this.requestNumber++}: Token is valid for user ${userName} (${userId})`);\n}\ncatch (ex) {\n    // Token is missing or invalid - return a 401 error\n    console.error(ex);\n    throw new HttpError(401, \"Unauthorized\");\n}\n</code></pre> <p>Learn from the code</p> <p>Have a look at the new source code. First, it obtains the token from the <code>Authorization</code> header in the HTTPs request. This header contains the word \"Bearer\", a space, and then the token, so a JavaScript <code>split(\" \")</code> is used to obtain only the token.</p> <p>Also note that the code will throw an exception if authentication should fail for any reason; the Azure function will then return the appropriate error.</p> <p>The code then creates a validator for use with the <code>jwks-validate</code> library. This call reads the latest private keys from Entra ID, so it is an async call that may take some time to run.</p> <p>Next, the code sets up a <code>ValidateTokenOptions</code> object. Based on this object, in addition to validating that the token was signed with Entra ID's private key, the library will validate that:</p> <ul> <li> <p>the audience must be the same as the API service app URI; this ensures that the token is intended for our web service and no other</p> </li> <li> <p>the issuer must be from the security token service for our tenant</p> </li> <li> <p>the scope must match the scope defined in our app registration, which is <code>\"access_as_user\"</code>.</p> </li> </ul> <p>If the token is valid, the library returns an object with all the \"claims\" that were inside, including the user's unique ID, name, and email. We will use these values instead of relying on the fictitious \"Avery Howard\".</p> <p>If your app will be multi-tenant</p> <p>Check the comments in the above code for notes about validating tokens for a multi-tenant app</p> <p>Once the code has a <code>userId</code> it will look for a Consultant record for the user. This was hard-coded to Avery Howard's ID in the original code. Now it will use the user ID for the logged in user, and create a new Consultant record if it doesn't find one in the database.</p> <p>As a result, when you run the app for the first time, it should create a new Consultant for your logged-in user with a default set of skills, roles, etc. If you want to change them to make your own demo, you can do that using the Azure Storage Explorer</p> <p></p> <p>Note that project assignments are stored in the <code>Assignment</code> table and reference the project ID and the assigned consultant's consultant ID.</p> <p></p>"},{"location":"pages/extend-m365-copilot/06b-add-authentication/#exercise-8-test-the-application","title":"Exercise 8: Test the application","text":"<p>Before you test the application, update the manifest version of your app package in the <code>appPackage\\manifest.json</code> file, follow these steps:</p> <ol> <li> <p>Open the <code>manifest.json</code> file located in the <code>appPackage</code> folder of your project.</p> </li> <li> <p>Locate the <code>version</code> field in the JSON file. It should look something like this: <code>json    \"version\": \"1.0.0\"</code></p> </li> <li> <p>Increment the version number to a small increment. For example, change it to: <code>json    \"version\": \"1.0.1\"</code></p> </li> <li> <p>Save the file after making the change.</p> </li> </ol>"},{"location":"pages/extend-m365-copilot/06b-add-authentication/#step-1-restart-the-application","title":"Step 1: (Re)start the application","text":"<p>If your app is still running from an earlier lab, stop it to force it to re-create the application package.</p> <p>Then press F5 to run the application again, and install it as before.</p> <p>Prompt the plugin, \"What Trey projects am I assigned to?\". You may see a confirmation card asking if it's OK to call your API. No authentication is happening here; click \"Allow Once\" to proceed.</p> <p></p> <p>The confirmation card will be replaced with a login card. Click \"Sign in to Trey\" to sign in. At first you should see a pop-up window asking you to log in and to consent to permissions. On subsequent vists this may be hidden as your credentials have been cached by Entra ID in your local browser.</p> <p></p> <p>There are cases where your admin has not allowed you to consent as a user and may see something like below: </p> <p>This is because the admin has restricted applications to allow user consent tenant wide. In this case, you have to request admin to manually grant global consent for all users for the plugin API registration as below:</p> <p></p> <p>The login card should be replaced by Copilot's response to your prompt. Since you were just added to the database, you aren't assigned to any projects.</p> <p>Since you were just added to the database, you're not assigned to any projects.</p> <p></p> <p>Ask Copilot to add you to the Woodgrove project. Copilot will press you for details if you forgot to include any required values.</p> <p></p> <p>Now check out your default skills and confirm the project assignment by asking, \"What are my skills and what projects am I assigned to?\"</p> <p></p> <p></p> <p>CONGRATULATIONS!</p> <p>You have completed lab E6b, Add Entra ID authentication with Manual Setup!</p> <p>Want to try something cool? How about adding a Copilot Connector to your solution?</p> <p></p> <p></p>"},{"location":"pages/extend-m365-copilot/06c-add-sso/","title":"Lab E6c - Add Entra ID authentication with Single Sign-on","text":"<p>In this lab you will add Microsoft Entra ID SSO authentication enabling users to authenticate with their existing Entra ID credentials.</p> Get a quick overview of the lab in this video.              \ud83d\udcd8 Note:   This lab builds on the previous one, Lab E5. If you have completed lab E5, you can continue working in the same folder. If not, please copy the solution folder for Lab E5 from /src/extend-m365-copilot/path-e-lab05-add-adaptive-cards/trey-research-lab05-END      and work there.     The finished solution for this lab is in the /src/extend-m365-copilot/path-e-lab06c-add-sso/trey-research-lab06c-END folder.          <p>Do these labs if you want to build a Declarative agent where Microsoft 365 provides the AI model and               orchestration</p> <ul> <li>\ud83c\udfc1 Welcome</li> <li>\ud83d\udd27 Set up <ul> <li>Lab E0 - Setup</li> </ul> </li> <li>\ud83e\uddf0 Declarative agent fundamentals <ul> <li> Lab E1 - Build a Detailed Declarative Agent </li> <li> Lab E1a - Geo locator game</li> </ul> </li> <li>\ud83d\udee0\ufe0f Build and integrate API from scratch <ul> <li>Lab E2 - Build an API</li> <li> Lab E3 - Add Declarative Agent + API</li> <li> Lab E4 - Enhance API + Plugin</li> <li>Lab E5 - Add Adaptive Cards</li> </ul> </li> <li>\ud83d\udd10 Authentication <ul> <li> Lab E6a - Toolkit</li> <li> Lab E6b - Manual</li> <li> Lab E6c - SSO</li> </ul> </li> <li>\ud83d\udd0c Integration <ul> <li> Lab EB - Add Graph Connector</li> </ul> </li> </ul> <p>Note</p> <p>In the finished sample we have used persistent developer tunnel so you will have to make adjustments if you are not using persistent developer tunnel. Check Exercise 1. </p> <p>In this lab, as you register your API, you'll need to save a few values from the Entra ID portal and Teams Developer Portal for use in later steps. Here's what you'll need to save:</p> <pre><code>API Base URL: \nAPI's Entra ID application ID: \nAPI's Tenant ID: \nSSO Client registration: \nAPI ID URI: \n</code></pre>"},{"location":"pages/extend-m365-copilot/06c-add-sso/#exercise-1-set-up-a-persistent-developer-tunnel-optional","title":"Exercise 1: Set up a persistent developer tunnel (optional)","text":"<p>By default, Agents Toolkit creates a new developer tunnel - and thus a new URL for accesing your locally running API - every time you start the project. Normally this is fine because Agents Toolkit automatically updates the URL where needed, but since this lab will be a manual setup, you'll have to manually update the URL in Entra ID and in Teams Developer Portal each time you start the debugger. For that reason, you may wish to set up a persistent developer tunnel with a URL that does not change.</p> If you don't want to set up a persistent tunnel, open this note \u25b6\u25b6\u25b6 <p>You are free to skip this exercise and use the developer tunnel provided by Agents Toolkit. Once your project is running, you can copy this URL from the terminal tab 1\ufe0f\u20e3 by choosing the \"Start local tunnel\" terminal 2\ufe0f\u20e3; copy the Forwarding URL 3\ufe0f\u20e3. Note this URL will change every time you start the project, and you will need to manually update the app registration reply URL (exercise 2 step 1) and the Teams Developer Portal URL (exercise 5 step 1). </p>"},{"location":"pages/extend-m365-copilot/06c-add-sso/#step-1-install-the-developer-tunnel-cli","title":"Step 1: Install the developer tunnel CLI","text":"<p>Here are the command lines for installing the developer tunnel. Full instructions and download links for the Developer Tunnel are here. </p> OS Command Windows <code>winget install Microsoft.devtunnel</code> Mac OS <code>brew install --cask devtunnel</code> Linux <code>curl -sL https://aka.ms/DevTunnelCliInstall | bash</code> <p>Tip</p> <p>You may have to restart your command line to update the file path before devtunnel commands will work.</p> <p>Once you have it installed, you'll need to log in. You can use your Microsoft 365 account to log in.</p> <pre><code>devtunnel user login\n</code></pre> <p>Be sure to leave the devtunnel command running as you do the exercises in this lab. If you need to restart it, just repeat the last command <code>devtunnel user login</code>.</p> <p></p>"},{"location":"pages/extend-m365-copilot/06c-add-sso/#step-2-create-and-host-the-tunnel","title":"Step 2: Create and host the tunnel","text":"<p>Then you'll need to set up a persistent tunnel to the Azure Functions local port (7071). You can use these commands and substitute your own name instead of \"mytunnel\" if you wish.</p> <pre><code>devtunnel create mytunnel -a --host-header unchanged\ndevtunnel port create mytunnel -p 7071\ndevtunnel host mytunnel\n</code></pre> <p>The command line will display the connection information, such as:</p> <p></p> <p>Copy the \"Connect via browser\" URL and save it as the \"API Base URL\".</p> <p></p>"},{"location":"pages/extend-m365-copilot/06c-add-sso/#step-3-disable-the-dynamically-created-tunnel-in-your-project","title":"Step 3: Disable the dynamically created tunnel in your project","text":"<p>If your project is running locally, stop it. Then edit .vscode\\tasks.json and locate the \"Start Teams App Locally\" task. Comment out the \"Start local tunnel\" dependency and add the \"Start Azurite emulator\" dependency instead. The resulting task should look like this:</p> <pre><code>{\n    \"label\": \"Start Teams App Locally\",\n    \"dependsOn\": [\n        \"Validate prerequisites\",\n        //\"Start local tunnel\",\n        \"Start Azurite emulator\",\n        \"Create resources\",\n        \"Build project\",\n        \"Start application\"\n    ],\n    \"dependsOrder\": \"sequence\"\n},\n</code></pre> <p></p>"},{"location":"pages/extend-m365-copilot/06c-add-sso/#step-4-manually-override-the-server-url","title":"Step 4: Manually override the server URL","text":"<p>Open env/.env.local and change the value of OPENAPI_SERVER_URL to the persistent tunnel URL. This is the <code>API base URL</code> that is needed for the configuration in the steps later.</p> <p></p>"},{"location":"pages/extend-m365-copilot/06c-add-sso/#exercise-2-register-an-entra-id-application-for-your-api","title":"Exercise 2: Register an Entra ID application for your API","text":""},{"location":"pages/extend-m365-copilot/06c-add-sso/#step-1-add-a-new-entra-id-app-registration","title":"Step 1: Add a new Entra ID app registration","text":"<p>Browse to the Entra ID admin center either via the Microsoft 365 Admin center or directly at https://entra.microsoft.com/. Make sure you are logged into your development tenant and not some other.</p> <p>Once you're there, click \"Identity\" 1\ufe0f\u20e3, then \"Applications\" 2\ufe0f\u20e3, and then \"App registrations\" 3\ufe0f\u20e3. Then click the \"+\" 4\ufe0f\u20e3 to add a new app registration.</p> <p></p> <p>Give your application a unique and descriptive name such as \"Trey API Service\" 1\ufe0f\u20e3. Under \"Supported account types\", select \"Accounts in this organizational directory only (Microsoft only - single tenant) 2\ufe0f\u20e3. </p> <p>Then click \"Register\" 3\ufe0f\u20e3 to register your application.</p> <p></p> <p></p>"},{"location":"pages/extend-m365-copilot/06c-add-sso/#step-2-copy-application-info-to-a-safe-place","title":"Step 2: Copy application info to a safe place","text":"<p>Copy the Application ID (also called the Client ID) 1\ufe0f\u20e3 which is the <code>API's Entra ID application ID</code> and <code>Directory (tenant) ID</code> 2\ufe0f\u20e3 that is needed for the configuration in the steps later.</p> <p></p> <p></p>"},{"location":"pages/extend-m365-copilot/06c-add-sso/#exercise-3-register-microsoft-entra-sso-client-id-in-the-teams-developer-portal","title":"Exercise 3: Register Microsoft Entra SSO client ID  in the Teams Developer Portal","text":"<p>Now you're API is all set up with Microsoft Entra ID, but Microsoft 365 doesn't know anything about it. To ensure secure connection of your API without requiring extra credentials, let's register it in the Teams Developer Portal.</p>"},{"location":"pages/extend-m365-copilot/06c-add-sso/#step-1-register-an-sso-client-in-teams-developer-portal","title":"Step 1: Register an SSO client in Teams developer portal","text":"<p>Browse to the Teams Developer Portal at https://dev.teams.microsoft.com. Select \"Tools\" 1\ufe0f\u20e3 and then \"Microsoft Entra SSO client ID registration.\" 2\ufe0f\u20e3.</p> <p></p> <p>Select Register client ID and fill up the values.</p> Field Value Name Choose a name you'll remember Base URL API base URL Restrict usage by org select \"My organization only\" Restrict usage by app select \"Any Teams app\" Client (application) ID API's Entra ID application ID <p></p> <p>Now once you select Save, the registration generates a Microsoft Entra SSO registration ID and an Application ID URI. Copy them to a note, to configure the plugin manifest file to enable SSO.</p> <p></p> <p>If you didn't make a persistent developer tunnel URL...</p> <p>...you will have to update the \"Base URL\" field with your new tunnel URL each time you start your application in Agents Toolkit</p> <p></p>"},{"location":"pages/extend-m365-copilot/06c-add-sso/#exercise-4-update-your-application-package","title":"Exercise 4: Update your application package","text":""},{"location":"pages/extend-m365-copilot/06c-add-sso/#step-1-update-the-plugin-file","title":"Step 1: Update the Plugin file","text":"<p>Open your working folder in Visual Studio Code. In the appPackage folder, open the trey-plugin.json file. This is where information is stored that Copilot needs, but is not already in the Open API Specification (OAS) file.</p> <p>Under <code>Runtimes</code> you will find an <code>auth</code> property with <code>type</code> of <code>\"None\"</code>, indicating the API is currently not authenticated. Change it as follows to tell Copilot to authenticate using the Microsoft Entra SSO registration ID you saved in the vault.</p> <pre><code>\"auth\": {\n  \"type\": \"OAuthPluginVault\",\n  \"reference_id\": \"&lt;Microsoft Entra SSO registration ID&gt;\"\n},\n</code></pre> <p></p>"},{"location":"pages/extend-m365-copilot/06c-add-sso/#exercise-5-update-the-apis-microsoft-entra-app-registration","title":"Exercise 5: Update the API's Microsoft Entra app registration","text":""},{"location":"pages/extend-m365-copilot/06c-add-sso/#step-1-update-application-id-uri","title":"Step 1: Update Application ID URI","text":"<ul> <li>Go back to the Microsoft Entra admin center and find the Microsoft Entra app registration of your API, we called it here Trey API Service. </li> <li>Open  Expose an API and add/edit Application ID URI.  Paste the entire Application ID URI generated by the Teams developer portal here and select Save</li> </ul>"},{"location":"pages/extend-m365-copilot/06c-add-sso/#step-2-add-api-scope","title":"Step 2: Add API Scope","text":"<p>In order to validate calls to your API, you need to expose an API Scope, which represents the permission to call the API. Though these could be very specific - allowing permission to do specific operations via the API - in this case we'll set up a simple scope called \"access_as_user\".</p> <p>Under \"Add a scope\" enter \"access_as_user\" as the scope name 1\ufe0f\u20e3. Fill in the remaining fields as follows:</p> Field Value Who can consent? Admins and users Admin consent display name Access My API as the user Admin consent description Allows an API to access My API as a user User consent display name Access My API as you User consent description Allows an app to access My API as you State Enabled <p>When you're done, click \"Add Scope\" 2\ufe0f\u20e3.</p> <p></p> <p></p>"},{"location":"pages/extend-m365-copilot/06c-add-sso/#step-3-add-authorized-client-apps","title":"Step 3: Add authorized client apps","text":"<p>Select Add a client application 1\ufe0f\u20e3 in the same Expose an API page and add the client ID of Microsoft's enterprise token store, <code>ab3be6b7-f5df-413d-ac2d-abf1e3fd9c0b</code> 2\ufe0f\u20e3. Authorize it for the access scope by selecting 3\ufe0f\u20e3. Select Add application 4\ufe0f\u20e3</p> <p></p> <p></p>"},{"location":"pages/extend-m365-copilot/06c-add-sso/#step-4-redirect-uris-for-authentication","title":"Step 4: Redirect URIs for Authentication","text":"<p>Now in the left navigation, go to Authentication 1\ufe0f\u20e3 , Add a platform 2\ufe0f\u20e3, select Web 3\ufe0f\u20e3. </p> <p></p> <p>Paste the url <code>https://teams.microsoft.com/api/platform/v1.0/oAuthConsentRedirect</code> as the Redirect URIs 1\ufe0f\u20e3 and select Configure 2\ufe0f\u20e3.</p> <p></p> <p></p>"},{"location":"pages/extend-m365-copilot/06c-add-sso/#exercise-6-update-the-application-code","title":"Exercise 6: Update the application code","text":""},{"location":"pages/extend-m365-copilot/06c-add-sso/#step-1-install-the-jwt-validation-library","title":"Step 1: Install the JWT validation library","text":"<p>From a command line in your working directory, type:</p> <pre><code>npm i jwt-validate\n</code></pre> <p>This will install a library for validating the incoming Entra ID authorization token.</p> <p>Warning</p> <p>Microsoft does not provide a supported library for validating Entra ID tokens in NodeJS, but instead provides this detailed documentation on how to write your own. Another useful article is also available from Microsoft MVP Andrew Connell. This lab uses a community provided library written by Waldek Mastykarz, which is intended to follow this guidance. Note that this library is not supported by Microsoft and is under an MIT License, so use it at your own risk.</p> <p></p>"},{"location":"pages/extend-m365-copilot/06c-add-sso/#step-2-add-environment-variables-for-your-api","title":"Step 2: Add environment variables for your API","text":"<p>In the env folder in your working directory, open .env.local and add these lines for your API Service app's tenant ID, application ID URL</p> <pre><code>APP_ID_URI=&lt;Application ID URI&gt;\nAPI_TENANT_ID=&lt;Directory (tenant) ID&gt;\n</code></pre> <p>Generate Application ID URI manually</p> <p>In case the Application ID URI isn't available, please construct it using the below steps temporarily: Go to Base64 Decode and Encode -  Copy and paste the auth registration ID generated in Exercise 3, Step 1 and decode. Construct the application ID URI using the second part of the decoded value (after ##) as highlighted below \u2013 api://auth-, e.g., api://auth-16cfcd90-803e-40ba-8106-356aa4927bb9  <p>To make these values available inside your code running in Agents Toolkit, you also need to update the teamsapp.local.yml file in the root of your working folder. Look for the comment \"Generate runtime environment variables\" and add the new values under the STORAGE_ACCOUNT_CONNECTION_STRING:</p> <pre><code>        APP_ID_URI: ${{APP_ID_URI}}\n        API_TENANT_ID: ${{API_TENANT_ID}}\n</code></pre> <p>The finished yaml should look like this:</p> <pre><code>  - uses: file/createOrUpdateEnvironmentFile\n    with:\n      target: ./.localConfigs\n      envs:\n        STORAGE_ACCOUNT_CONNECTION_STRING: ${{SECRET_STORAGE_ACCOUNT_CONNECTION_STRING}},\n        APP_ID_URI: ${{APP_ID_URI}}\n        API_TENANT_ID: ${{API_TENANT_ID}}\n</code></pre> <p></p>"},{"location":"pages/extend-m365-copilot/06c-add-sso/#step-3-update-the-identity-service","title":"Step 3: Update the identity service","text":"<p>At this point, Single Sign-on should work and provide a valid access token, but the solution isn't secure unless the code checks to make sure the token is valid. In this step, you'll add code to validate the is token and extract information such as the user's name and ID.</p> <p>In the src/services folder, open IdentityService.ts.  At the top of the file along with the other <code>import</code> statements, add this one:</p> <pre><code>import { TokenValidator, ValidateTokenOptions, getEntraJwksUri } from 'jwt-validate';\n</code></pre> <p>Then, right under the <code>class Identity</code> statement, add this line:</p> <pre><code>    private validator: TokenValidator;\n</code></pre> <p>Now look for the comment</p> <pre><code>// ** INSERT REQUEST VALIDATION HERE (see Lab E6) **\n</code></pre> <p>Replace the comment with this code:</p> <pre><code>// Try to validate the token and get user's basic information\ntry {\n    const { APP_ID_URI, API_TENANT_ID } = process.env;\n    const token = req.headers.get(\"Authorization\")?.split(\" \")[1];\n    if (!token) {\n        throw new HttpError(401, \"Authorization token not found\");\n    }\n\n    // create a new token validator for the Microsoft Entra common tenant\n    if (!this.validator) {\n        // We need a new validator object which we will continue to use on subsequent\n        // requests so it can cache the Entra ID signing keys\n        // For multitenant, use:\n        // const entraJwksUri = await getEntraJwksUri();\n        const entraJwksUri = await getEntraJwksUri(API_TENANT_ID);\n        this.validator = new TokenValidator({\n            jwksUri: entraJwksUri\n        });\n        console.log (\"Token validator created\");\n    }\n\n\n    const options: ValidateTokenOptions = {\n                audience: APP_ID_URI, \n                issuer: `https://sts.windows.net/${API_TENANT_ID}/`,              \n                scp: [\"access_as_user\"],\n\n            };\n\n    // validate the token\n    const validToken = await this.validator.validateToken(token, options);\n\n    userId = validToken.oid;\n    userName = validToken.name;\n    userEmail = validToken.upn;\n    console.log(`Request ${this.requestNumber++}: Token is valid for user ${userName} (${userId})`);\n}\ncatch (ex) {\n    // Token is missing or invalid - return a 401 error\n    console.error(ex);\n    throw new HttpError(401, \"Unauthorized\");\n}\n</code></pre> <p>Learn from the code</p> <p>Have a look at the new source code. First, it obtains the token from the <code>Authorization</code> header in the HTTPs request. This header contains the word \"Bearer\", a space, and then the token, so a JavaScript <code>split(\" \")</code> is used to obtain only the token.</p> <p>Also note that the code will throw an exception if authentication should fail for any reason; the Azure function will then return the appropriate error.</p> <p>The code then creates a validator for use with the <code>jwks-validate</code> library. This call reads the latest private keys from Entra ID, so it is an async call that may take some time to run.</p> <p>Next, the code sets up a <code>ValidateTokenOptions</code> object. Based on this object, in addition to validating that the token was signed with Entra ID's private key, the library will validate that:</p> <ul> <li> <p>the audience must be the same as the API service app URI; this ensures that the token is intended for our web service and no other</p> </li> <li> <p>the issuer must be from the security token service for our tenant</p> </li> <li> <p>the scope must match the scope defined in our app registration, which is <code>\"access_as_user\"</code>.</p> </li> </ul> <p>If the token is valid, the library returns an object with all the \"claims\" that were inside, including the user's unique ID, name, and email. We will use these values instead of relying on the fictitious \"Avery Howard\".</p> <p>If your app will be multi-tenant</p> <p>Check the comments in the above code for notes about validating tokens for a multi-tenant app</p> <p>Once the code has a <code>userId</code> it will look for a Consultant record for the user. This was hard-coded to Avery Howard's ID in the original code. Now it will use the user ID for the logged in user, and create a new Consultant record if it doesn't find one in the database.</p> <p>As a result, when you run the app for the first time, it should create a new Consultant for your logged-in user with a default set of skills, roles, etc. If you want to change them to make your own demo, you can do that using the Azure Storage Explorer</p> <p></p> <p>Note that project assignments are stored in the <code>Assignment</code> table and reference the project ID and the assigned consultant's consultant ID.</p> <p></p>"},{"location":"pages/extend-m365-copilot/06c-add-sso/#step-4-work-around-library-versioning-issue","title":"Step 4: Work around library versioning issue","text":"<p>At the moment, the <code>jwt-validate</code> package throws typing error for <code>@types/jsonwebtoken</code> package. To work around the issue, edit the tsconfig.json file, found at the root of the project, and add <code>\"skipLibCheck\":true</code>. This will be fixed in a future version of the library, and may no longer be necessary by the time you do the lab.</p> <p></p>"},{"location":"pages/extend-m365-copilot/06c-add-sso/#exercise-7-test-the-application","title":"Exercise 7: Test the application","text":"<p>Before you test the application, update the manifest version of your app package in the <code>appPackage\\manifest.json</code> file, follow these steps:</p> <ol> <li> <p>Open the <code>manifest.json</code> file located in the <code>appPackage</code> folder of your project.</p> </li> <li> <p>Locate the <code>version</code> field in the JSON file. It should look something like this: </p> </li> </ol> <pre><code>\"version\": \"1.0.0\"\n</code></pre> <ol> <li>Increment the version number to a small increment. For example, change it to:  </li> </ol> <pre><code>\"version\": \"1.0.1\"\n</code></pre> <ol> <li>Save the file after making the change.</li> </ol>"},{"location":"pages/extend-m365-copilot/06c-add-sso/#step-1-restart-the-application","title":"Step 1: (Re)start the application","text":"<p>Restart the application if it was already running and open Trey Genie in Copilot app.</p> <p>Prompt - \"What projects am I assigned to?\"  After allowing the agent, you will be asked to sign in as below (this is one time)</p> <p></p> <p>Once you select the sign in button, you need to allow the application's API to access as the current user, so go ahead and give the permission by selecting \"Accept.\"</p> <p></p> <p>From now on, the sign in will be smooth for the user when interacting with the agent, without having to sign in each time.</p> <p></p> <p></p> <p>CONGRATULATIONS!</p> <p>You have completed lab E6c, Add SSO!</p> <p>Want to try something cool? How about adding a Copilot Connector to your solution?</p> <p></p> <p></p>"},{"location":"pages/extend-m365-copilot/07-add-graphconnector/","title":"Lab E7 - Integration: Add Knowledge capability to Trey Genie using a Microsoft Copilot Connector","text":"<p>Do these labs if you want to build a Declarative agent where Microsoft 365 provides the AI model and             orchestration</p> <ul> <li>\ud83c\udfc1 Welcome</li> <li>\ud83d\udd27 Set up <ul> <li>Lab E0 - Setup</li> </ul> </li> <li>\ud83e\uddf0 Declarative agent fundamentals <ul> <li> Lab E1 - Build a Detailed Declarative Agent </li> <li> Lab E1a - Geo locator game</li> </ul> </li> <li>\ud83d\udee0\ufe0f Build and integrate API from scratch <ul> <li>Lab E2 - Build an API</li> <li> Lab E3 - Add Declarative Agent + API</li> <li> Lab E4 - Enhance API + Plugin</li> <li>Lab E5 - Add Adaptive Cards</li> </ul> </li> <li>\ud83d\udd10 Authentication <ul> <li> Lab E6a - Toolkit</li> <li> Lab E6b - Manual</li> <li> Lab E6c - SSO</li> </ul> </li> <li>\ud83d\udd0c Integration <ul> <li> Lab EB - Add Graph Connector</li> </ul> </li> </ul> <p>In this lab you will learn how to add your own data into the Microsoft Graph to be then organically utilised by the declarative agent as it's own knowledge.  In the process you will learn all how to deploy a Microsoft Copilot Connector and use the connector in Trey Genie declarative agent. </p> <p>In this lab you will learn to:</p> <ul> <li>deploy a Microsoft Copilot Connector of your own data into Microsoft Graph and have it power various Microsoft 365 experiences</li> <li>customise the trey genie declarative agent to use the Copilot Connector as a capability to extend its knowledge</li> <li>learn how to run and test your app </li> </ul>              \ud83d\udcd8 Note:       This lab builds on the Lab E4. You should be able to continue working in the same folder for labs E2-E6, but solution folders have been provided for your reference.     The finished Trey Genie declarative solution for this lab is in the /src/extend-m365-copilot/path-e-bonus-gc-lab/trey-research-labEB-END folder.     The Microsoft Copilot Connector source code is in /src/extend-m365-copilot/path-e-bonus-gc-lab/trey-feedback-connector folder.          <p>Prerequisites: Tenant Admin Access</p> <p>Additonal prerequisites are needed to run this lab. You will need tenant administrator privileges as Microsoft Copilot Connectors use app-only authentication to access the connector APIs.</p> <p>Prerequisites: Azure Functions Visual Studio Code extension</p> <ul> <li>Azure Functions Visual Studio Code extension</li> </ul>"},{"location":"pages/extend-m365-copilot/07-add-graphconnector/#exercise-1-deploy-copilot-connector","title":"Exercise 1 : Deploy Copilot Connector","text":""},{"location":"pages/extend-m365-copilot/07-add-graphconnector/#step-1-download-sample-project","title":"Step 1: Download sample project","text":"<ul> <li>In your browser, go to this link</li> <li>Extract the trey-feedback-connector.zip file</li> </ul> <p>Note</p> <p>The extracted folder of the sample project is trey-feedback-connector. It has a folder called content which consist of feedback files from various clients for consultants at Trey Research. The files are all created by AI and are for demo purposes only.  The aim is to deploy these external files into Microsoft 365 data to be available as knowledge base for our declarative agent Trey Genie. </p> <p></p>"},{"location":"pages/extend-m365-copilot/07-add-graphconnector/#step-2-create-external-connection","title":"Step 2: Create external connection","text":"<ul> <li>Open the folder trey-feedback-connector in Visual Studio Code</li> <li>In the Activity Bar of Visual Studio Code, open the Agents Toolkit extension</li> <li>Create a file .env.local in the env folder of the root folder trey-feedback-connector</li> <li>Paste below contents in the newly created file</li> </ul> <pre><code>APP_NAME=TreyFeedbackConnectorApp\nCONNECTOR_ID=tfcfeedback\nCONNECTOR_NAME=Trey Feedback Connector\nCONNECTOR_DESCRIPTION=The Trey Feedback Connector seamlessly integrate feedback data from various clients about consultants in Trey Research.\nCONNECTOR_BASE_URL=https://localhost:3000/\n\n</code></pre> <ul> <li>Select F5, which will then kick off the creation of the Entra ID app registration needed for your connector API to authenicate and load data into Microsoft Graph </li> <li>In the <code>Terminal</code> window, for the <code>func:host start</code> Task, you will notice below link provided. Using this link you can grant the app-only permission for the Entra ID app</li> </ul> <ul> <li>Copy the link and open in a browser where you are logged in as the tenant admin for the Microsoft 365 tenant. </li> <li>Grant the required permissions to the app using the Grant admin consent button.</li> </ul> <ul> <li>Once granted, the connector creates an external connection, provisions the schema and ingests the sample contents in the content folder to your Microsoft 365 tenant. This takes a while, so keep the project running. </li> <li>Once all files in the content folder are loaded, the debugger can be stopped. </li> <li>You can also close this connector project folder.</li> </ul>"},{"location":"pages/extend-m365-copilot/07-add-graphconnector/#step-3-test-the-connector-data-in-microsoft365-app","title":"Step 3: Test the connector data in Microsoft365 app","text":"<p>Now that your data is loaded into Microsoft 365 tenant, let's test if a regular search is picking up the contents in Microsoft365.com.</p> <p>Go to https://www.microsoft365.com/ and in the search box above, type <code>thanks Avery</code>.</p> <p>You will see the results as below from the external connection which are basically the clients' feedback for consultant Avery Howard.</p> <p></p> <p>Now that your data is part of Microsoft 365 data or Microsoft Graph, let's go ahead and add this connector data as focused knowledge for our declarative agent for Trey Research called Trey Genie.</p> <p></p>"},{"location":"pages/extend-m365-copilot/07-add-graphconnector/#exercise-2-add-copilot-connector-to-declarative-agent","title":"Exercise 2 : Add Copilot Connector to Declarative Agent","text":"<p>In the previous exercise, we established a new external connection to load our data into the Microsoft 365 tenant. Next, we will integrate this connector into our declarative agent to provide focused knowledge on Trey Research consultants.</p>"},{"location":"pages/extend-m365-copilot/07-add-graphconnector/#step-1-get-the-connection-id-of-the-microsoft-copilot-connector","title":"Step 1: Get the connection id of the Microsoft Copilot Connector","text":"<p>In exercise 1, we added the environment variable in the .env.local file which has the configuration values for the Copilot Connector.  The connection id value we gave is <code>tfcfeedback</code>. When Agents Toolkit deploys this connector it will add a suffix of its environment value like <code>local</code> to the connection id. Hence we can infer the connection id is <code>tfcfeedbacklocal</code>. But the most straightforward way to get the Copilot Connector id is to use Graph Explorer.</p> <ul> <li>Browse to Microsoft Graph Explorer and sign in with your admin account.</li> <li>Select your user avatar in the upper right corner and select Consent to permissions.</li> <li>Search for <code>ExternalConnection.Read.All</code> and select Consent for that permission. Follow the prompts to grant consent.</li> <li>Enter <code>https://graph.microsoft.com/v1.0/external/connections?$select=id,name</code> in the request field and select Run query.</li> <li>Locate the connector you want and copy its id property.</li> </ul> <p></p> <p></p>"},{"location":"pages/extend-m365-copilot/07-add-graphconnector/#step-2-update-declarative-agent-manifest","title":"Step 2: Update declarative agent manifest","text":"<p>Let's now resume with our declarative agent from Lab 4. If you have it open, then continue or go to the finished lab 4 solution in this folder /src/extend-m365-copilot/path-e-lab04-enhance-api-plugin/trey-research-lab04-END.</p> <ul> <li>Open the lab 4 solution for Trey Genie declarative agent.</li> <li>Go to appPackage\\trey-declarative-agent.json</li> <li>Add a new item into the <code>capabilities</code> array as below and save</li> </ul> <pre><code> {\n            \"name\": \"GraphConnectors\",\n            \"connections\": [\n                {\n                    \"connection_id\": \"tfcfeedbacklocal\"\n                }\n            ]\n}\n</code></pre> <p>Now the capability is added, it's time to test.</p> <p></p>"},{"location":"pages/extend-m365-copilot/07-add-graphconnector/#exercise-3-test-the-agent-in-copilot","title":"Exercise 3: Test the agent in Copilot","text":"<p>Before you test the application, update the manifest version of your app package in the <code>appPackage\\manifest.json</code> file, follow these steps:</p> <ol> <li> <p>Open the <code>manifest.json</code> file located in the <code>appPackage</code> folder of your project.</p> </li> <li> <p>Locate the <code>version</code> field in the JSON file. It should look something like this: <code>json    \"version\": \"1.0.0\"</code></p> </li> <li> <p>Increment the version number to a small increment. For example, change it to: <code>json    \"version\": \"1.0.1\"</code></p> </li> <li> <p>Save the file after making the change.</p> </li> </ol>"},{"location":"pages/extend-m365-copilot/07-add-graphconnector/#step-1-start-the-application","title":"Step 1: Start the application","text":"<p>This update ensures that the platform detects the changes and properly applies the latest version of your app.</p> <p>Start your project to force it to re-deploy the application package by selecting F5. You will be brought into Microsoft Teams. Once you're back in Copilot, open the right flyout 1\ufe0f\u20e3 to show your previous chats and agents and select the Trey Genie Local agent 2\ufe0f\u20e3.</p> <p></p> <p></p>"},{"location":"pages/extend-m365-copilot/07-add-graphconnector/#step-2-test-knowledge-in-copilot","title":"Step 2: Test knowledge in Copilot","text":"<p>In the immersive experience of Trey Genie, use below prompts and test them</p> <ul> <li>Can you check for any feedback from clients for consultants Trey Research</li> <li>How did Avery's guidance specifically streamline the product development process?</li> </ul> <p></p> <p></p> <p>CONGRATULATIONS!</p> <p>You have completed lab Add Copilot Connector, Well done!</p> <p></p>"},{"location":"pages/extend-m365-copilot/auth/","title":"Shortcut to Declarative Agent Authentication","text":"<p>Do you already know how to build a declarative agent and API plugin, and want to learn how to secure your API? Well you've come to the right place! You can skip the regular labs (E1-E5) and jump right to your choice of DA Authentication lab!</p> <p>Begin by completing Lab E0 to get up your development environment. Then choose an auth lab from these choices:</p>"},{"location":"pages/extend-m365-copilot/auth/#lab-e6a-add-oauth-authentication-with-agents-toolkit","title":"Lab E6a - Add OAuth authentication with Agents Toolkit","text":"<p>In this lab, the student:</p> <ul> <li>adds Agents Toolkit directives to register an Entra ID application</li> <li>updates the app packaging so Copilot uses OAuth when calling the API</li> <li>updates the code to validate the access token</li> <li>tests the declarative agent</li> </ul> <p>Test procedure:</p> <ol> <li>copy the Lab E5 solution files to a folder on your computer</li> <li>open in VS Code such that the solution is at the root of your open folder (you should see .vscode, appPackage, etc. at the root level)</li> <li>copy /env/.env.local.sample to /env/.env.local and change the SHAREPOINT_DOCS_URL to a valid SharePoint site URL in your tenant (if you want all the features to work, upload the contents of the sampleDocs folder to this SharePoint location)</li> <li>copy /env/.env.local.user.sample to /env/.env.local.user</li> <li>(optional) edit /appPackage/trey-declarative-agent.json and rename the agent so you know which instance you're testing</li> <li>press F5. You should get a declarative agent for Trey Research.</li> <li>click the green button to open the instructions   </li> </ol>"},{"location":"pages/extend-m365-copilot/auth/#lab-e6b-add-oauth-authentication-with-manual-setup","title":"Lab E6b - Add OAuth authentication with Manual Setup","text":"<p>In this lab, the student:</p> <ul> <li>registers an app with Entra ID and configures it to work with Copilot</li> <li>registers the app in the Teams Developer Portal \"vault\" so Copilot can access secure Entra ID information such as the client secret</li> <li>updates the app packaging so Copilot uses OAuth when calling the API</li> <li>updates the code to validate the access token</li> <li>tests the declarative agent</li> </ul> <p>Test procedure:</p> <ol> <li>copy the Lab E5 solution files to a folder on your computer</li> <li>open in VS Code such that the solution is at the root of your open folder (you should see .vscode, appPackage, etc. at the root level)</li> <li>copy /env/.env.local.sample to /env/.env.local and change the SHAREPOINT_DOCS_URL to a valid SharePoint site URL in your tenant (if you want all the features to work, upload the contents of the sampleDocs folder to this SharePoint location)</li> <li>copy /env/.env.local.user.sample to /env/.env.local.user</li> <li>(optional) edit /appPackage/trey-declarative-agent.json and rename the agent so you know which instance you're testing</li> <li>press F5. You should get a declarative agent for Trey Research.</li> <li>click the green button to open the instructions   </li> </ol>"},{"location":"pages/extend-m365-copilot/auth/#lab-e6c-add-single-sign-on-authentication-with-manual-steps-for-teams-developer-portal","title":"Lab E6c - Add Single Sign-on authentication with manual steps for Teams Developer Portal","text":"<p>In this lab, the student:</p> <ul> <li>registers an app with Entra ID and configures it to work with Single Sign-on in Copilot</li> <li>registers the app in the Teams Developer Portal \"vault\"</li> <li>udates the app packaging for SSO</li> <li>updates the code to validate the access token</li> <li>tests the declarative agent</li> </ul> <p>Test procedure:</p> <ol> <li>copy the Lab E5 solution files to a folder on your computer</li> <li>open in VS Code such that the solution is at the root of your open folder (you should see .vscode, appPackage, etc. at the root level)</li> <li>copy /env/.env.local to /env/.env.local and change the SHAREPOINT_DOCS_URL to a valid SharePoint site URL in your tenant (if you want all the features to work, upload the contents of the sampleDocs folder to this SharePoint location)</li> <li>copy /env/.env.local.user.sample to /env/.env.local.user</li> <li>(optional) edit /appPackage/trey-declarative-agent.json and rename the agent so you know which instance you're testing</li> <li>press F5. You should get a declarative agent for Trey Research.</li> <li>click the green button to open the instructions      </li> </ol> <p></p>"},{"location":"pages/extend-message-ext/","title":"Extend Teams Message Extension as a plugin","text":"<p>Disclaimer</p> <p>These samples and labs are intended for instructive and demonstration purposes and are not intended for use in production. Do not put them into production without upgrading them to production quality.</p> <p>In this path of Extend, you will learn how to use Teams Message Extensions as plugins in Microsoft 365 Copilot. You will start with a working message extension sample available in the sample source code and run it as a plugin in Microsoft 365 Copilot. You will also enhance the code to add some extra features. The source code utilizes the Northwind Database, providing you with the necessary enterprise data to test your plugin like in a real world scenario.</p> <p>In this lab, Northwind operates as a specialty foods e-commerce business located in Walla Walla, Washington. You will be working with the Northwind Inventory application, which provides access to product inventory and financial data.</p> <p>Here are the labs</p> <ul> <li>Lab M0 - Prerequisites Set up your development environment</li> <li>Lab M1 - Get to know Northwind message extension Get to know Northwind message extension</li> <li>Lab M2 - Run app in Microsoft 365 Copilot Run Northwind message extension as a plugin in Microsoft 365 Copilot</li> <li>Lab M3 - Enhance plugin with new search command Enhance the plugin with a new search command</li> <li>Lab M4 - Add authentication Secure your plugin in Authentication</li> <li>Lab M5 - Enhance plugin with an action command Enhance the plugin with a new action command</li> </ul>"},{"location":"pages/extend-message-ext/#start-here-with-lab-m0-where-youll-set-up-development-your-environment","title":"Start here with Lab M0, where you'll set up development your environment.","text":""},{"location":"pages/extend-message-ext/00-prerequisites/","title":"Lab M0 - Prerequisites","text":"<p>In this lab, you will set up the development environment to build, test, and deploy the plugins that will extend the capabilities of Microsoft 365 Copilot.</p> Navigating the Extend Teams Message Extension labs (Extend Path) <ul> <li>Lab M0 - Prerequisites (\ud83d\udccdYou are here)</li> <li>Lab M1 - Get to know Northwind message extension </li> <li>Lab M2 - Run app in Microsoft 365 Copilot </li> <li>Lab M3 - Enhance plugin with new search command</li> <li>Lab M4 - Add authentication </li> <li>Lab M5 - Enhance plugin with an action command </li> </ul> <p>In this lab you will learn:</p> <ul> <li>How to set up your developer tenant for the entire lab exercises</li> <li>How to install and configure Agents Toolkit for Visual Studio Code and other tools</li> <li>How to set up your development environment with a base project</li> </ul> <p>Attention</p> <p>To extend Microsoft 365 Copilot, you must ensure that your development environment meets the requirements.</p>"},{"location":"pages/extend-message-ext/00-prerequisites/#exercise-1-enable-teams-application-uploads","title":"Exercise 1: Enable Teams application uploads","text":"<p>You will need a Microsoft work or school account with permissions to upload custom Teams applications. </p> <p>By default, end users can't upload applications directly; instead an administrator needs to upload them into the enterprise app catalog. In this step you will ensure your tenant is set up for direct uploads by Microsoft 365 Agents Toolkit.</p> <ul> <li>Sign in to Microsoft Teams admin center with your admin credentials.</li> <li>Go to Teams apps &gt; Setup Policies &gt; Global.</li> <li>Toggle Upload custom apps to the \"On\" position.</li> <li>Select \"Save\". Your test tenant can permit custom app upload.</li> </ul> <p>The change can take up to 24 hours to take effect, but usually it's much faster.</p>"},{"location":"pages/extend-message-ext/00-prerequisites/#exercise-2-install-agents-toolkit-and-prerequisites","title":"Exercise 2: Install Agents Toolkit and prerequisites","text":"<p>You can complete these labs on a Windows, Mac, or Linux machine, but you do need the ability to install the prerequisites. If you are not permitted to install applications on your computer, you'll need to find another machine (or virtual machine) to use throughout the workshop.</p>"},{"location":"pages/extend-message-ext/00-prerequisites/#step-1-install-visual-studio-code","title":"Step 1: Install Visual Studio Code","text":"<p>It should be no surprise that Agents Toolkit for Visual Studio Code requires Visual Studio Code! You can download it here: Visual Studio Code.</p>"},{"location":"pages/extend-message-ext/00-prerequisites/#step-2-install-nodejs","title":"Step 2: Install NodeJS","text":"<p>Node.js is a runtime that allows you to run JavaScript on your computer. It uses the open-source V8 engine, which is used in popular web browsers like Google Chrome (and the Chromium-based version of Microsoft Edge). You will need Node.js to run the web server code used throughout this workshop.</p> <p>Browse to https://nodejs.org/en/download/ and install version 18 or 16 for your operating system. This lab has been tested using NodeJS version 18.16.0. If you already have another version of NodeJS installed, you may want to set up the Node Version Manager (or this variation for Microsoft Windows), which allows you to easily switch Node versions on the same computer.</p>"},{"location":"pages/extend-message-ext/00-prerequisites/#step-3-install-tools","title":"Step 3: Install Tools","text":"<p>These labs are based on the latest general available version of Agents Toolkit. Follow the steps as shown in the screen shot below.</p> <p>1\ufe0f\u20e3 Open Visual Studio Code and click on the Extensions toolbar button</p> <p>2\ufe0f\u20e3 Search for \"Teams\" and locate Agents Toolkit</p> <p>3\ufe0f\u20e3 Click \"Install\"</p> <p></p> <p>If you have Agents Toolkit installed but hidden</p> <p>If you previously installed Agents Toolkit, and then hid it on the Visual Studio sidebar, you might wonder why you can't see it. Right-click on the left sidebar and check off Agents Toolkit to bring it back into view.</p> <p>Azure Storage Explorer</p> <p>Azure Storage Explorer (OPTIONAL) - Download this if you want to view and edit the Northwind database used in this sample</p>"},{"location":"pages/extend-message-ext/00-prerequisites/#exercise-3-set-up-your-project-and-developer-tenant-data","title":"Exercise 3 - Set up your project and developer tenant data","text":""},{"location":"pages/extend-message-ext/00-prerequisites/#step-1-download-the-sample-code","title":"Step 1 - Download the sample code","text":"<p>In a web browser navigate to this link. You will get a prompt to download a ZIP file called Northwind.zip. </p> <ul> <li> <p>Save the ZIP file on your computer. </p> </li> <li> <p>Extract the ZIP file contents, it will extract into a folder called Northwind . </p> </li> <li> <p>Open Visual Studio Code. </p> </li> </ul> <p>In Visual Studio Code: </p> <ul> <li> <p>From the \"File\" menu choose the \"Open folder\"... option </p> </li> <li> <p>Open the folder Northwind.</p> </li> </ul> <p>These labs will refer to this Northwind folder as your \"root folder\" or \"working folder\" since this is where you'll be working.</p>"},{"location":"pages/extend-message-ext/00-prerequisites/#step-2-set-up-accounts-in-agents-toolkit","title":"Step 2 - Set up accounts in Agents Toolkit","text":"<p>Now select the Agents Toolkit icon in the left 1\ufe0f\u20e3 . If it offers options to create a new project, you're probably in the wrong folder. In the Visual Studio Code file menu select \"Open Folder\" and directly open the Northwind folder. You should see sections for Accounts, Environment, etc. as shown below.</p> <p>Under \"Accounts\" click \"Sign in to Microsoft 365\" 2\ufe0f\u20e3 and log in with your own Microsoft 365 account.</p> <p></p> <p>A browser window will pop up and offer to log into Microsoft 365. When it says \"You are signed in now and close this page\", please do so.</p> <p>Now verify that the \"Custom App Upload Enabled\" checker has a green checkmark. If it doesn't, that means that your user account doesn't have permission to upload Teams applications. Follow steps in Exercise 1 of this lab. </p> <p>Now verify that the \"Copilot Access Enabled\" checker has a green checkmark. If it doesn't, that means that your user account license for Copilot. This is required to continue the labs.</p> <p></p>"},{"location":"pages/extend-message-ext/00-prerequisites/#step-3-copy-sample-documents-to-your-test-users-onedrive","title":"Step 3 - Copy sample documents to your test user's OneDrive","text":"<p>The sample application includes some documents for Copilot to reference during the labs. In this step you will copy these files to your user's OneDrive so Copilot can find them. Depending on how the tenant is set up, you may be asked to set up multi-factor authentication as part of this process.</p> <p>Open your browser and browse to Microsoft 365 (https://www.office.com/). Log in using the Microsoft 365 account you will be using throughout the lab. You may be asked to set up multi-factor authentication.</p> <p>Using the \"waffle\" menu in the upper left corner of the page 1\ufe0f\u20e3 , navigate to the OneDrive application within Microsoft 365 2\ufe0f\u20e3 .</p> <p></p> <p>Within OneDrive, navigate to \"My Files\" 1\ufe0f\u20e3 . If there's a documents folder, click into that as well. If not, you can work directly within the \"My Files\" location.</p> <p></p> <p>Now click \"Add new\" 1\ufe0f\u20e3 and \"Folder\" 2\ufe0f\u20e3 to create a new folder.</p> <p></p> <p>Name the folder \"Northwind contracts\" and click \"Create\".</p> <p></p> <p>Now, from within this new folder, click \"Add new\" 1\ufe0f\u20e3  again but this time click \"Files upload\" 2\ufe0f\u20e3 .</p> <p></p> <p>Now browse to the sampleDocs folder within your working folder. Highlight all the files 1\ufe0f\u20e3 and click \"OK\" 2\ufe0f\u20e3  to upload them all.</p> <p></p> <p>By doing this step early, there's a good chance that the Microsoft 365 search engine will have discovered them by the time you're ready for them.</p>"},{"location":"pages/extend-message-ext/00-prerequisites/#congratulations","title":"Congratulations","text":"<p>You have completed the prerequisites lab. You are now ready to proceed to run your app. Select \"Next\" button below.</p> <p></p> <p></p>"},{"location":"pages/extend-message-ext/01-nw-teams-app/","title":"Lab M1 - Get to know Northwind message extension","text":"<p>In this lab, you\u2019ll run the Northwind message extension, your base app. The initial exercises will make you familiar with the source code. Finally, you\u2019ll run the application in Teams.</p> Navigating the Extend Teams Message Extension labs (Extend Path) <ul> <li>Lab M0 - Prerequisites </li> <li>Lab M1 - Get to know Northwind message extension (\ud83d\udccdYou are here)</li> <li>Lab M2 - Run app in Microsoft 365 Copilot </li> <li>Lab M3 - Enhance plugin with new search command</li> <li>Lab M4 - Add authentication </li> <li>Lab M5 - Enhance plugin with an action command </li> </ul> <p>In this lab you will:</p> <ul> <li>Do a quick code tour of the Northwind Message extension</li> <li>Run the application on Teams</li> </ul>"},{"location":"pages/extend-message-ext/01-nw-teams-app/#exercise-1-code-tour","title":"Exercise 1 - Code tour","text":"<p>Let's examine the code in the base app called Northwind. </p>"},{"location":"pages/extend-message-ext/01-nw-teams-app/#step-1-examine-the-manifest","title":"Step 1 - Examine the manifest","text":"<p>The core of any Microsoft 365 application is its application manifest. This is where you provide the information Microsoft 365 needs to access your application.</p> <p>In your working directory called Northwind from previous lab , open the manifest.json file in the appPackage folder. This JSON file is placed in a zip archive with icon files to create the application package. The \"icons\" property includes paths to these icons.</p> <pre><code>\"icons\": {\n    \"color\": \"Northwind-Logo3-192-${{TEAMSFX_ENV}}.png\",\n    \"outline\": \"Northwind-Logo3-32.png\"\n},\n</code></pre> <p>Notice the token <code>${{TEAMSFX_ENV}}</code> in one of the icon names. Agents Toolkit will replace this token with your environment name, such as \"local\" or \"dev\" (for an Azure deployment in development). Thus, the icon color will change depending on the environment.</p> <p>Now have a look at the \"name\" and \"description\". Notice that the description is quite long! This is important so both users and Copilot can learn what your application does and when to use it.</p> <pre><code>    \"name\": {\n        \"short\": \"Northwind Inventory\",\n        \"full\": \"Northwind Inventory App\"\n    },\n    \"description\": {\n        \"short\": \"App allows you to find and update product inventory information\",\n        \"full\": \"Northwind Inventory is the ultimate tool for managing your product inventory. With its intuitive interface and powerful features, you'll be able to easily find your products by name, category, inventory status, and supplier city. You can also update inventory information with the app. \\n\\n **Why Choose Northwind Inventory:** \\n\\n Northwind Inventory is the perfect solution for businesses of all sizes that need to keep track of their inventory. Whether you're a small business owner or a large corporation, Northwind Inventory can help you stay on top of your inventory management needs. \\n\\n **Features and Benefits:** \\n\\n - Easy Product Search through Microsoft Copilot. Simply start by saying, 'Find northwind dairy products that are low on stock' \\r - Real-Time Inventory Updates: Keep track of inventory levels in real-time and update them as needed \\r  - User-Friendly Interface: Northwind Inventory's intuitive interface makes it easy to navigate and use \\n\\n **Availability:** \\n\\n To use Northwind Inventory, you'll need an active Microsoft 365 account . Ensure that your administrator enables the app for your Microsoft 365 account.\"\n    },\n</code></pre> <p>Scroll down a bit to \"composeExtensions\". Compose extension is the historical term for message extension; this is where the app's message extensions are defined.</p> <p>Within this is a bot, with the ID supplied by Agents Toolkit.</p> <pre><code>    \"composeExtensions\": [\n        {\n            \"botId\": \"${{BOT_ID}}\",\n            \"commands\": [\n                {\n                    ...\n</code></pre> <p>Message extensions communicate using the Azure Bot Framework; this provides a fast and secure communication channel between Microsoft 365 and your application. When you first ran your project, Agents Toolkit registered a bot, and will place its bot ID here.</p> <p>This message extension has two commands, which are defined in the <code>commands</code> array. Let's pick one command and see the structure. </p> <pre><code>{\n    \"id\": \"discountSearch\",\n    \"context\": [\n        \"compose\",\n        \"commandBox\"\n    ],\n    \"description\": \"Search for discounted products by category\",\n    \"title\": \"Discounts\",\n    \"type\": \"query\",\n    \"parameters\": [\n        {\n            \"name\": \"categoryName\",\n            \"title\": \"Category name\",\n            \"description\": \"Enter the category to find discounted products\",\n            \"inputType\": \"text\"\n        }\n    ]\n},\n</code></pre> <p>This allows user to search for discounted products within a Northwind category. This command accepts a single parameter, \"categoryName\". </p> <p>OK now let's move back to the first command, \"inventorySearch\". It has 5 parameters, which allows for much more sophisticated queries.</p> <pre><code>{\n    \"id\": \"inventorySearch\",\n    \"context\": [\n        \"compose\",\n        \"commandBox\"\n    ],\n    \"description\": \"Search products by name, category, inventory status, supplier location, stock level\",\n    \"title\": \"Product inventory\",\n    \"type\": \"query\",\n    \"parameters\": [\n        {\n            \"name\": \"productName\",\n            \"title\": \"Product name\",\n            \"description\": \"Enter a product name here\",\n            \"inputType\": \"text\"\n        },\n        {\n            \"name\": \"categoryName\",\n            \"title\": \"Category name\",\n            \"description\": \"Enter the category of the product\",\n            \"inputType\": \"text\"\n        },\n        {\n            \"name\": \"inventoryStatus\",\n            \"title\": \"Inventory status\",\n            \"description\": \"Enter what status of the product inventory. Possible values are 'in stock', 'low stock', 'on order', or 'out of stock'\",\n            \"inputType\": \"text\"\n        },\n        {\n            \"name\": \"supplierCity\",\n            \"title\": \"Supplier city\",\n            \"description\": \"Enter the supplier city of product\",\n            \"inputType\": \"text\"\n        },\n        {\n            \"name\": \"stockQuery\",\n            \"title\": \"Stock level\",\n            \"description\": \"Enter a range of integers such as 0-42 or 100- (for &gt;100 items). Only use if you need an exact numeric range.\",\n            \"inputType\": \"text\"\n        }\n    ]\n},\n</code></pre>"},{"location":"pages/extend-message-ext/01-nw-teams-app/#step-2-examine-the-bot-code","title":"Step 2 - Examine the \"Bot\" code","text":"<p>Now open the file searchApp.ts in folder src in the root folder. This application contains the \"bot\" code, which communicates with the Azure Bot Framework using the Bot Builder SDK.</p> <p>Notice that the bot extends an SDK class TeamsActivityHandler.</p> <pre><code>export class SearchApp extends TeamsActivityHandler {\n  constructor() {\n    super();\n  }\n\n  ...\n</code></pre> <p>By overriding the methods of the TeamsActivityHandler, the application is able to handle messages (called \"activities\") coming from Microsoft 365.</p> <p>The first of these is a Messaging Extension Query activity (\"messaging extension\" is another historical name for a message extension). This function is called when a user types into a message extension or when Copilot calls it.</p> <pre><code>  // Handle search message extension\n  public async handleTeamsMessagingExtensionQuery(\n    context: TurnContext,\n    query: MessagingExtensionQuery\n  ): Promise&lt;MessagingExtensionResponse&gt; {\n\n    switch (query.commandId) {\n      case productSearchCommand.COMMAND_ID: {\n        return productSearchCommand.handleTeamsMessagingExtensionQuery(context, query);\n      }\n      case discountedSearchCommand.COMMAND_ID: {\n        return discountedSearchCommand.handleTeamsMessagingExtensionQuery(context, query);\n      }\n    }\n  }\n</code></pre> <p>All it's doing is dispatching the query to the based on the command ID. These are the same command ID's used in the manifest above.</p> <p>The other type of activity our app needs to handle is the adaptive card actions, such as when a user clicks on \"Update stock\" or \"Reorder\" on an adaptive card. Since there is no specific method for an adaptive card action, the code overrides <code>onInvokeActivity()</code>, which is a much broader class of activity that includes message extension queries. For that reason, the code manually checks the activity name, and dispatches to the appropriate handler. If the activity name isn't for an adaptive card action, the <code>else</code> clause runs the base implementation of <code>onInvokeActivity()</code> which, among other things, will call our <code>handleTeamsMessagingExtensionQuery()</code> method if the Invoke activity is a query.</p> <pre><code>import {\n  TeamsActivityHandler,\n  TurnContext,\n  MessagingExtensionQuery,\n  MessagingExtensionResponse,\n  InvokeResponse\n} from \"botbuilder\";\nimport productSearchCommand from \"./messageExtensions/productSearchCommand\";\nimport discountedSearchCommand from \"./messageExtensions/discountSearchCommand\";\nimport revenueSearchCommand from \"./messageExtensions/revenueSearchCommand\";\nimport actionHandler from \"./adaptiveCards/cardHandler\";\n\nexport class SearchApp extends TeamsActivityHandler {\n  constructor() {\n    super();\n  }\n\n  // Handle search message extension\n  public async handleTeamsMessagingExtensionQuery(\n    context: TurnContext,\n    query: MessagingExtensionQuery\n  ): Promise&lt;MessagingExtensionResponse&gt; {\n\n    switch (query.commandId) {\n      case productSearchCommand.COMMAND_ID: {\n        return productSearchCommand.handleTeamsMessagingExtensionQuery(context, query);\n      }\n      case discountedSearchCommand.COMMAND_ID: {\n        return discountedSearchCommand.handleTeamsMessagingExtensionQuery(context, query);\n      }\n    }\n\n  }\n\n  // Handle adaptive card actions\n  public async onInvokeActivity(context: TurnContext): Promise&lt;InvokeResponse&gt; {\n    let runEvents = true;\n    // console.log (`\ud83c\udfac Invoke activity received: ${context.activity.name}`);\n    try {\n      if(context.activity.name==='adaptiveCard/action'){\n        switch (context.activity.value.action.verb) {\n          case 'ok': {\n            return actionHandler.handleTeamsCardActionUpdateStock(context);\n          }\n          case 'restock': {\n            return actionHandler.handleTeamsCardActionRestock(context);\n          }\n          case 'cancel': {\n            return actionHandler.handleTeamsCardActionCancelRestock(context);\n          }\n          default:\n            runEvents = false;\n            return super.onInvokeActivity(context);\n        }\n      } else {\n          runEvents = false;\n          return super.onInvokeActivity(context);\n      }\n    } ...\n</code></pre>"},{"location":"pages/extend-message-ext/01-nw-teams-app/#step-3-examine-the-message-extension-command-code","title":"Step 3 - Examine the message extension command code","text":"<p>In an effort to make the code more modular, readable, and reusable, each message extension command has been placed in its own TypeScript module. Have a look at src/messageExtensions/discountSearchCommand.ts as an example.</p> <p>First, note that the module exports a constant <code>COMMAND_ID</code>, which contains the same command ID found in the app manifest, and allows the switch statement in searchApp.ts to work properly.</p> <p>Then it provides a function, <code>handleTeamsMessagingExtensionQuery()</code>, to handle incoming queries for discounted products by category.</p> <pre><code>async function handleTeamsMessagingExtensionQuery(\n    context: TurnContext,\n    query: MessagingExtensionQuery\n): Promise&lt;MessagingExtensionResponse&gt; {\n\n    // Seek the parameter by name, don't assume it's in element 0 of the array\n    let categoryName = cleanupParam(query.parameters.find((element) =&gt; element.name === \"categoryName\")?.value);\n    console.log(`\ud83d\udcb0 Discount query #${++queryCount}: Discounted products with categoryName=${categoryName}`);\n\n    const products = await getDiscountedProductsByCategory(categoryName);\n\n    console.log(`Found ${products.length} products in the Northwind database`)\n    const attachments = [];\n    products.forEach((product) =&gt; {\n        const preview = CardFactory.heroCard(product.ProductName,\n            `Avg discount ${product.AverageDiscount}%&lt;br /&gt;Supplied by ${product.SupplierName} of ${product.SupplierCity}`,\n            [product.ImageUrl]);\n\n        const resultCard = cardHandler.getEditCard(product);\n        const attachment = { ...resultCard, preview };\n        attachments.push(attachment);\n    });\n    return {\n        composeExtension: {\n            type: \"result\",\n            attachmentLayout: \"list\",\n            attachments: attachments,\n        },\n    };\n}\n</code></pre> <p>Notice that the index in the <code>query.parameters</code> array may not correspond to the parameter's position in the manifest. While this is generally only an issue for a multi-parameter command, the code will still get the value based on the parameter name rather than hard coding an index. After cleaning up the parameter (trimming it, and handling the fact that sometimes Copilot assumes \"*\" is a wildcard that matches everything), the code calls the Northwind data access layer to <code>getDiscountedProductsByCategory()</code>.</p> <p>Then it iterates through the products and creates two cards for each:</p> <ul> <li>a preview card, which is implemented as a \"hero\" card (these predate adaptive cards and are very simple). This is what's displayed in the search results in the user interface and in some citations in Copilot.</li> <li>a result card, which is implemented as an \"adaptive\" card that includes all the details.</li> </ul> <p>In the next step, we'll review the adaptive card code and check out the Adaptive Card designer.</p>"},{"location":"pages/extend-message-ext/01-nw-teams-app/#step-4-examine-the-adaptive-cards-and-related-code","title":"Step 4 - Examine the adaptive cards and related code","text":"<p>The project's adaptive cards are in the src/adaptiveCards folder. There are 3 cards, each implemented as a JSON file.</p> <ul> <li>editCard.json - This is the initial card that's displayed by the message extension or a Copilot reference</li> <li>successCard.json - When a user takes action, this card is displayed to indicate success. It's mostly the same as the edit card except it includes a message to the user.</li> <li>errorCard.json - If an action fails, this card is displayed.</li> </ul> <p>Let's take a look at the edit card in the Adaptive Card Designer. Open your web browser to https://adaptivecards.io and click the \"Designer\" option at the top.</p> <p></p> <p>Notice the data binding expressions such as <code>\"text\": \"\ud83d\udce6 ${productName}\",</code>. This binds the <code>productName</code> property in the data to the text on the card.</p> <p>Now select \"Microsoft Teams\" as the host application 1\ufe0f\u20e3 . Paste the entire contents of editCard.json into the Card Payload Editor 2\ufe0f\u20e3 , and the contents of sampleData.json into the Sample Data Editor 3\ufe0f\u20e3 . The sample data is identical to a product as provided in the code.</p> <p></p> <p>You should see the card as rendered, except for a small error which arises due to the designer's inability to display one of the adaptive card formats.</p> <p>Near the top of the page, try changing the Theme and Emulated Device to see how the card would look in dark theme or on a mobile device. This is the tool that was used to build adaptive cards for the sample application.</p> <p>Now, back in Visual Studio Code, open cardHandler.ts. The function <code>getEditCard()</code> is called from each of the message extension commands to obtain a result card. The code reads the adaptive card JSON - which is considered a template - and then binds it to product data. The result is more JSON - the same card as the template, with the data binding expressions all filled in. Finally, the <code>CardFactory</code> module is used to convert the final JSON into an adaptive card object for rendering.</p> <pre><code>function getEditCard(product: ProductEx): any {\n\n    var template = new ACData.Template(editCard);\n    var card = template.expand({\n        $root: {\n            productName: product.ProductName,\n            unitsInStock: product.UnitsInStock,\n            productId: product.ProductID,\n            categoryId: product.CategoryID,\n            imageUrl: product.ImageUrl,\n            supplierName: product.SupplierName,\n            supplierCity: product.SupplierCity,\n            categoryName: product.CategoryName,\n            inventoryStatus: product.InventoryStatus,\n            unitPrice: product.UnitPrice,\n            quantityPerUnit: product.QuantityPerUnit,\n            unitsOnOrder: product.UnitsOnOrder,\n            reorderLevel: product.ReorderLevel,\n            unitSales: product.UnitSales,\n            inventoryValue: product.InventoryValue,\n            revenue: product.Revenue,\n            averageDiscount: product.AverageDiscount\n        }\n    });\n    return CardFactory.adaptiveCard(card);\n}\n</code></pre> <p>Scrolling down, you'll see the handler for each of the action buttons on the card. The card submits data when an action button is clicked - specifically <code>data.txtStock</code>, which is the \"Quantity\" input box on the card, and <code>data.productId</code>, which is sent in each card action to let the code know what product to update.</p> <pre><code>async function handleTeamsCardActionUpdateStock(context: TurnContext) {\n\n    const request = context.activity.value;\n    const data = request.action.data;\n    console.log(`\ud83c\udfac Handling update stock action, quantity=${data.txtStock}`);\n\n    if (data.txtStock &amp;&amp; data.productId) {\n\n        const product = await getProductEx(data.productId);\n        product.UnitsInStock = Number(data.txtStock);\n        await updateProduct(product);\n\n        var template = new ACData.Template(successCard);\n        var card = template.expand({\n            $root: {\n                productName: product.ProductName,\n                unitsInStock: product.UnitsInStock,\n                productId: product.ProductID,\n                categoryId: product.CategoryID,\n                imageUrl: product.ImageUrl,\n                ...\n</code></pre> <p>As you can see, the code obtains these two values, updates the database, and then sends a new card that contains a message and the updated data.</p>"},{"location":"pages/extend-message-ext/01-nw-teams-app/#exercise-2-run-the-sample-as-a-message-extension","title":"Exercise 2 - Run the sample as a Message Extension","text":""},{"location":"pages/extend-message-ext/01-nw-teams-app/#step-1-set-up-the-project-for-first-use","title":"Step 1 - Set up the project for first use","text":"<p>Open your working folder in Visual Studio Code. If you have already opened it for the code tour, you can continue from there.</p> <p>Agents Toolkit stores environment variables in the env folder, and it will fill in all the values automatically when you start your project the first time. However there's one value that's specific to the sample application, and that's the connection string for accessing the Northwind database.</p> <p>In this project, the Northwind database is stored in Azure Table Storage; when you're debugging locally, it uses the Azurite storage emulator. That's mostly built into the project, but the project won't build unless you provide the connection string.</p> <p>The necessary setting is provided in a file env/.env.local.user.sample. Make a copy of this file in the env folder, and call it .env.local.user. This is where secret or sensitive settings are stored.</p> <p>If you're not sure how to do this, here are the steps in Visual Studio Code. Expand the env folder and right click on .env.local.user.sample. Select \"Copy\". Then right click anywhere in the env folder and select \"Paste\". You will have a new file called .env.local.user copy.sample. Use the same context menu to rename the file to .env.local.user and you're done.</p> <p></p> <p>The resulting .env.local.user file should contain this line:</p> <pre><code>SECRET_STORAGE_ACCOUNT_CONNECTION_STRING=UseDevelopmentStorage=true\n</code></pre> <p>(OK it's not a secret! But it could be; if you deploy the project to Azure it will be!)</p>"},{"location":"pages/extend-message-ext/01-nw-teams-app/#step-2-run-the-application-locally","title":"Step 2 - Run the application locally","text":"<p>Click F5 to start debugging, or click the start button 1\ufe0f\u20e3. You will have an opportunity to select a debugging profile; select Debug in Teams (Edge) 2\ufe0f\u20e3 or choose another profile.</p> <p></p> <p>If you see this screen, you need to fix your env/.env.local.user file; this is explained in the previous step.</p> <p></p> <p>The first time your app runs, you may be prompted to allow NodeJS to go through your firewall; this is necessary to allow the application to communicate.</p> <p>It may take a while the first time as it's loading all the npm packages. Eventually, a browser window will open and invite you to log in.</p> <p>The debugging will open teams in a browser window. Make sure you login using the same credentials you signed into Agents Toolkit. Once you're in, Microsoft Teams should open up and display a dialog offering to open your application. </p> <p></p> <p>Once opened it immediately ask you where you want to open the app in. By default it's personal chat. You could also select it in a channel or group chat as shown. Select \"Open\".</p> <p></p> <p>Now you are in a personal chat with the app.</p>"},{"location":"pages/extend-message-ext/01-nw-teams-app/#step-3-test-in-microsoft-teams","title":"Step 3 - Test in Microsoft Teams","text":"<p>To test the app on the teams, select the \"+\" sign in the chat message compose area. And select \"+ Get more apps\" button to open the dialog to search apps. Choose \"Northwind Inventory\" app with a blue background. See the process below.</p> <p></p> <p>Once the app is opened from the compose area, you will see a search box in the default tab \"Products Inventory\". You will also find the \"Discount\" search tab greyed out. Continue searching for a product, type in \"Chai\" which is a product available in Northwind database to see if the item is displayed as shown below.</p> <p></p> <p>You can select the card for Chai and send it in the conversation. </p> <p>You could also test the button actions in the adaptive card as demonstrated below. </p> <p></p> <p>This will confirm that the message extension is working and ready to be used as a plugin, which we will see in the next lab.</p> <p>NOTE: This is really only useful in conversations with other users; the chat in the Northwind Inventory app is just for testing.</p>"},{"location":"pages/extend-message-ext/01-nw-teams-app/#step-4-advanced-queries","title":"Step 4 - Advanced queries","text":"<p>Back in Visual Studio Code, have a look at the app manifest, which is in a file called manifest.json in the appPackage directory. You'll notice that the app information that was displayed when you installed the app is all here.</p> <p>Scroll down a bit to <code>composeExtensions:</code>. Compose extensions is the historical name for a message extension; the Northwind Inventory message extension is defined here.</p> <p>Here's an abbreviated version of that JSON for easy reference.</p> <pre><code>\"composeExtensions\": [\n    {\n        \"botId\": \"${{BOT_ID}}\",\n        \"commands\": [\n            {\n                \"id\": \"inventorySearch\",\n                ...\n                \"description\": \"Search products by name, category, inventory status, supplier location, stock level\",\n                \"title\": \"Product inventory\",\n                \"type\": \"query\",\n                \"parameters\": [ ... ]\n            },\n            {\n                \"id\": \"discountSearch\",\n                ...\n                \"description\": \"Search for discounted products by category\",\n                \"title\": \"Discounts\",\n                \"type\": \"query\",\n                \"parameters\": [ ...]\n            }\n        ]\n    }\n],\n</code></pre> <p>Notice first that there's a bot ID. That's because Microsoft Teams uses the Azure bot channel to exchange secure, real-time messages with your application. Agents Toolkit will register the bot and fill in the ID for you.</p> <p>Then there's a collection of commands. These correspond to the tabs in the search dialog in Teams. In this application, the commands are really intended for Copilot more than regular users!</p> <p>You already ran the first command when you searched for a product by name. You can try the other one now.</p> <p>Enter \"Beverages\", \"Dairy\", or \"Produce\" into the \"Discounts\" tab, and you'll see the products within those categories that are discounted. Copilot will use this to answer questions about discounted products.</p> <p></p> <p>Now examine the first command again. You'll notice it has 5 parameters!</p> <pre><code>\"parameters\": [\n    {\n        \"name\": \"productName\",\n        \"title\": \"Product name\",\n        \"description\": \"Enter a product name here\",\n        \"inputType\": \"text\"\n    },\n    {\n        \"name\": \"categoryName\",\n        \"title\": \"Category name\",\n        \"description\": \"Enter the category of the product\",\n        \"inputType\": \"text\"\n    },\n    {\n        \"name\": \"inventoryStatus\",\n        \"title\": \"Inventory status\",\n        \"description\": \"Enter what status of the product inventory. Possible values are 'in stock', 'low stock', 'on order', or 'out of stock'\",\n        \"inputType\": \"text\"\n    },\n    {\n        \"name\": \"supplierCity\",\n        \"title\": \"Supplier city\",\n        \"description\": \"Enter the supplier city of product\",\n        \"inputType\": \"text\"\n    },\n    {\n        \"name\": \"stockQuery\",\n        \"title\": \"Stock level\",\n        \"description\": \"Enter a range of integers such as 0-42 or 100- (for &gt;100 items). Only use if you need an exact numeric range.\",\n        \"inputType\": \"text\"\n    }\n]\n</code></pre> <p>Unfortunately, Teams can only display the first parameter, but Copilot can use all 5. This will allow it to do more advanced queries of the Northwind inventory data.</p> <p>As a work-around to the Teams UI limitation, in the \"Northwind Inventory\" tab, the application will accept up to 5 parameters comma separated, using the format:</p> <pre><code>name,category,inventoryStatus,supplierCity,supplierName\n</code></pre> <p></p> <p>Read the descriptions in the JSON above carefully when entering a query. Try entering these, and as you do, keep an eye on the debug console tab in Visual Studio Code, where you'll see each query as it's run.</p> <ul> <li>\"chai\" - find products with names that begin with \"chai</li> <li>\"c,bev\" - find products in categories beginning with \"bev\" and names that begin with \"c</li> <li>\",,out\" - find products that are out of stock</li> <li>\",,on,london\" - find products that are on order from suppliers in London</li> <li>\"tofu,produce,,osaka\" - find products in the \"produce\" category with suppliers in Osaka and names that begin with \"tofu\"</li> </ul> <p>Each query term filters the list of products down. The format of each query term is arbitrary - just be sure to explain it to Copilot in the description of each parameter.</p>"},{"location":"pages/extend-message-ext/01-nw-teams-app/#step-6-optional-view-northwind-database-in-azure-storage-explorer","title":"Step 6 (optional) - View Northwind database in Azure Storage Explorer","text":"<p>The Northwind Database isn't fancy but it's real! If you want to peek at or even modify the data, open the Azure Storage Explorer while Azurite is running. </p> <p>Note</p> <p>Running the app starts Azurite automatically. For more information check the Azurite documention here. As long as your project is started successfully you can view the storage.</p> <p>To view the Northwind data, open \"Emulator &amp; Attached\", \"Storage Accounts\", \"Emulator - Default Ports\", and \"Tables\". There you'll see the old Northwind database tables, which aren't nearly as handy in a NO SQL environment, but there they are!</p> <p></p> <p>The code reads the Products table on each query, but the other tables are only accessed when the app starts. So if you want to add a new category, you'll need to restart the app for it to appear.</p> <p></p>"},{"location":"pages/extend-message-ext/01-nw-teams-app/#congratulations","title":"Congratulations","text":"<p>You have mastered running the Northwind message extension. Now it's time to test it as plugin in Microsoft 365 Copilot  in the next lab. Select Next.</p> <p></p>"},{"location":"pages/extend-message-ext/02-nw-plugin/","title":"Lab M2 - Run app in Microsoft Microsoft 365 Copilot","text":"<p>In this lab, you\u2019ll run the Northwind app as a plugin in Microsoft 365 Copilot. </p> Navigating the Extend Teams Message Extension labs (Extend Path) <ul> <li>Lab M0 - Prerequisites </li> <li>Lab M1 - Get to know Northwind message extension </li> <li>Lab M2 - Run app in Microsoft 365 Copilot (\ud83d\udccdYou are here)</li> <li>Lab M3 - Enhance plugin with new search command</li> <li>Lab M4 - Add authentication </li> <li>Lab M5 - Enhance plugin with an action command </li> </ul> <p>NOTE</p> <p>The completed exercise with all of the code changes can be downloaded from here. This can be useful for troubleshooting purposes. If you ever need to reset your edits, you can clone again the repository and start over.</p> <p>In this lab you will:</p> <ul> <li>Run the message extension you ran on Microsoft Teams on Microsoft Copilot </li> <li>You will learn how to use natural language prompts to search and find items in the Northwind database </li> </ul>"},{"location":"pages/extend-message-ext/02-nw-plugin/#exercise-1-run-the-sample-as-a-copilot-plugin","title":"Exercise 1 - Run the sample as a Copilot plugin","text":"<p>If you are coming from previous lab, you can keep the debugger running and skip Step 1 and go to Step 2 or if it had stopped, go to Step 1. </p>"},{"location":"pages/extend-message-ext/02-nw-plugin/#step-1-run-the-app-locally","title":"Step 1 : Run the app locally","text":"<p>Restart by clicking F5 to start debugging, or click the start button 1\ufe0f\u20e3. You will have an opportunity to select a debugging profile; select Debug in Teams (Edge) 2\ufe0f\u20e3 or choose another profile.</p> <p></p> <p>The debugging will open teams in a browser window. Make sure you login using the same credentials you signed into Agents Toolkit. Once you're in, Microsoft Teams should open up and display a dialog offering to open your application. </p> <p></p> <p>Once opened it immediately ask you where you want to open the app in. By default it's personal chat. You could also select it in a channel or group chat as shown. Select \"Open\".</p> <p></p> <p>Now you are in a personal chat with the app.</p>"},{"location":"pages/extend-message-ext/02-nw-plugin/#step-2-test-in-microsoft-365-copilot-single-parameter","title":"Step 2 - Test in Microsoft 365 Copilot (single parameter)","text":"<p>Reminder</p> <p>To perform the following exercise, your account must have a valid license for Microsoft 365 Copilot.</p> <p>Go to Teams in browser https://teams.microsoft.com/v2/ logged into your developer tenant. If you have a Microsoft 365 Copilot, the new app will be automatically pinned above your chats. Just open Teams, select \u201cchats\u201d and you\u2019ll see Copilot.</p> <p>Once in the Copilot app experience, Check the lower left of the chat user interface, below the compose box. You should see a plugin icon 1\ufe0f\u20e3 . Click this and enable the Northwind Inventory plugin 2\ufe0f\u20e3 .</p> <p></p> <p>For best results, start a new chat by typing \"New chat\" or by clicking on the New chat icon at the top right before each prompt or set of related prompts.</p> <p></p> <p>Here are some prompts to try that use only a single parameter of the message extension:</p> <ul> <li> <p>Find information about Chai in Northwind Inventory</p> </li> <li> <p>Find discounted seafood in Northwind. Show a table with the products, supplier names, average discount rate, and revenue per period.</p> </li> </ul> <p>Let's try the first one.  Find information about Chai in Northwind Inventory</p> <p></p> <p>Try using these adaptive cards to take action on the products. If there's a single item returned back, Copilot may show the whole card as above. For multiple response  Copilot may show a small number next to each. You can hover over these numbers to display the adaptive card. References will also be listed below the response.</p> <p>Here is an example of multiple items returned with references.</p> <p></p> <p>Next, try  Find discounted seafood in Northwind. Show a table with the products, supplier names, average discount rate, and revenue per period.</p> <p></p> <p>As you're testing, watch the log messages within your application. - Go to Visual Studio Code where you project is runnning. - Find the terminal that has the \"Start application\" task running.</p> <p>You should be able to see when Copilot calls your plugin. For example, after the previous prompt you should see below log</p> <p></p>"},{"location":"pages/extend-message-ext/02-nw-plugin/#step-3-test-in-microsoft-365-copilot-multiple-parameters","title":"Step 3 - Test in Microsoft 365 Copilot (multiple parameters)","text":"<p>In this exercise, you'll try some prompts that exercise the multi-parameter feature in the sample plugin. These prompts will request data that can be retrieved by name, category, inventory status, supplier city, and stock level, as defined in the manifest.</p> <p>For example, try prompting Find Northwind beverages with more than 100 items in stock. To respond, Copilot must identify products:</p> <ul> <li>where the category is beverages</li> <li>where inventory status is in stock</li> <li>where the stock level is more than 100</li> </ul> <p></p> <p>The plugin code applies all three filters, providing a result set.</p> <p>If you look at the log messages in your terminal in VS Code, you can see that Copilot was able to understand this requirement and fill in 3 of the parameters in the first message extension command.</p> <p></p> <p>By using this prompt, Copilot might look also in your OneDrive files to find the payment terms with each supplier's contract. In this case, you will notice that some of the references won't have the Northwind Inventory icon, but the Word one.</p> <p>Here is an example:</p> <p></p> <p>Here are some more prompts to try:</p> <ul> <li> <p>Find Northwind dairy products that are low on stock. Show me a table with the product, supplier, units in stock and on order.</p> </li> <li> <p>We\u2019ve been receiving partial orders for Tofu. Find the supplier in Northwind and draft an email summarizing our inventory and reminding them they should stop sending partial orders per our MOQ policy.</p> </li> <li> <p>Northwind will have a booth at Microsoft Community Days  in London. Find products with local suppliers and write a LinkedIn post to promote the booth and products.</p> </li> <li> <p>What beverage is high in demand due to social media that is low stock in Northwind in London. Reference the product details to update stock.</p> </li> </ul> <p>Which prompts work best for you? Try making up your own prompts and observe your log messages to see how Copilot accesses your plugin.</p> <p></p>"},{"location":"pages/extend-message-ext/02-nw-plugin/#congratulations","title":"Congratulations","text":"<p>You\u2019ve done an excellent job testing the plugin in Microsoft 365 Copilot. Now, proceed to the next lab to add code for another search criterion. Select Next.</p> <p></p>"},{"location":"pages/extend-message-ext/03-enhance-nw-plugin/","title":"Lab M3 - Enhance plugin with new search command","text":"<p>In this lab, you will enhance the Northwind plugin by adding a new command. While the current message extension effectively provides information about products within the Northwind inventory database, it does not provide information related to Northwind\u2019s customers. Your task is to introduce a new command associated with an API call that retrieves products ordered by a customer name specified by the user. </p> Navigating the Extend Teams Message Extension labs (Extend Path) <ul> <li>Lab M0 - Prerequisites </li> <li>Lab M1 - Get to know Northwind message extension </li> <li>Lab M2 - Run app in Microsoft 365 Copilot </li> <li>Lab M3 - Enhance plugin with new search command(\ud83d\udccdYou are here)</li> <li>Lab M4 - Add authentication </li> <li>Lab M5 - Enhance plugin with an action command </li> </ul> <p>NOTE</p> <p>The completed exercise with all of the code changes can be downloaded from here. This can be useful for troubleshooting purposes. If you ever need to reset your edits, you can clone again the repository and start over.</p>"},{"location":"pages/extend-message-ext/03-enhance-nw-plugin/#exercise-1-code-changes","title":"Exercise 1 - Code changes","text":""},{"location":"pages/extend-message-ext/03-enhance-nw-plugin/#step-1-extend-the-message-extension-plugin-user-interface","title":"Step 1 -  Extend the Message Extension / plugin User Interface","text":"<p>In your working directory called Northwind from previous lab , open manifest.json in the  appPackage folder. Look for discountSearch in the commands array. After the closing braces of the discountSearch command, add a comma ,. Then, copy the companySearch command snippet and add it to the commands array.</p> <pre><code>{\n    \"id\": \"companySearch\",\n    \"context\": [\n        \"compose\",\n        \"commandBox\"\n    ],\n    \"description\": \"Given a company name, search for products ordered by that company\",\n    \"title\": \"Customer\",\n    \"type\": \"query\",\n    \"parameters\": [\n        {\n            \"name\": \"companyName\",\n            \"title\": \"Company name\",\n            \"description\": \"The company name to find products ordered by that company\",\n            \"inputType\": \"text\"\n        }\n    ]\n}\n</code></pre> <p>COMMAND_ID</p> <p>The \"id\" is the connection between the UI and the code. This value is defined as COMMAND_ID in the discount/product/SearchCommand.ts files. See how each of these files has a unique COMMAND_ID that corresponds to the value of \"id\".</p>"},{"location":"pages/extend-message-ext/03-enhance-nw-plugin/#step-2-implement-product-search-by-company","title":"Step 2 - Implement Product Search by Company","text":"<p>You will implement a product search by Company name and return a list of the company's ordered products. Find this information using the tables below:</p> Table Find Look Up By Customer Customer Id Customer Name Orders Order Id Customer Id OrderDetail Product Order Id <p>Here's how it works:  Use the Customer table to find the Customer Id with the Customer Name. Query the Orders table with the Customer Id to retrieve the associated Order Ids. For each Order Id, find the associated products in the OrderDetail table. Finally, return a list of products ordered by the specified company name.</p> <p>Open .\\src\\northwindDB\\products.ts</p> <p>Update the <code>import</code> statement on line 1 to include OrderDetail, Order and Customer. It should look as follows</p> <pre><code>import {\n    TABLE_NAME, Product, ProductEx, Supplier, Category, OrderDetail,\n    Order, Customer\n} from './model';\n</code></pre> <p>Add the new function <code>searchProductsByCustomer()</code> as in the below snippet, right after the <code>import { getInventoryStatus } from '../adaptiveCards/utils';</code>import statement.</p> <pre><code>export async function searchProductsByCustomer(companyName: string): Promise&lt;ProductEx[]&gt; {\n\n    let result = await getAllProductsEx();\n\n    let customers = await loadReferenceData&lt;Customer&gt;(TABLE_NAME.CUSTOMER);\n    let customerId=\"\";\n    for (const c in customers) {\n        if (customers[c].CompanyName.toLowerCase().includes(companyName.toLowerCase())) {\n            customerId = customers[c].CustomerID;\n            break;\n        }\n    }\n\n    if (customerId === \"\") \n        return [];\n\n    let orders = await loadReferenceData&lt;Order&gt;(TABLE_NAME.ORDER);\n    let orderdetails = await loadReferenceData&lt;OrderDetail&gt;(TABLE_NAME.ORDER_DETAIL);\n    // build an array orders by customer id\n    let customerOrders = [];\n    for (const o in orders) {\n        if (customerId === orders[o].CustomerID) {\n            customerOrders.push(orders[o]);\n        }\n    }\n\n    let customerOrdersDetails = [];\n    // build an array order details customerOrders array\n    for (const od in orderdetails) {\n        for (const co in customerOrders) {\n            if (customerOrders[co].OrderID === orderdetails[od].OrderID) {\n                customerOrdersDetails.push(orderdetails[od]);\n            }\n        }\n    }\n\n    // Filter products by the ProductID in the customerOrdersDetails array\n    result = result.filter(product =&gt; \n        customerOrdersDetails.some(order =&gt; order.ProductID === product.ProductID)\n    );\n\n    return result;\n}\n</code></pre>"},{"location":"pages/extend-message-ext/03-enhance-nw-plugin/#step-3-create-a-handler-for-the-new-command","title":"Step 3: Create a handler for the new command","text":"<p>In VS Code, duplicate the productSearchCommand.ts file located in the src/messageExtensions folder. Then, rename the copied file to \"customerSearchCommand.ts\"</p> <p>Change value of COMMAND_ID constant to:</p> <pre><code>const COMMAND_ID = \"companySearch\";\n</code></pre> <p>Replace below import statement from: </p> <pre><code>import { searchProducts } from \"../northwindDB/products\";`\n</code></pre> <p>to </p> <pre><code>import { searchProductsByCustomer } from \"../northwindDB/products\";\n</code></pre> <p>Inside the existing brackets of handleTeamsMessagingExtensionQuery , replace exisiting code with below snippet:</p> <pre><code>\n    let companyName;\n\n    // Validate the incoming query, making sure it's the 'companySearch' command\n    // The value of the 'companyName' parameter is the company name to search for\n    if (query.parameters.length === 1 &amp;&amp; query.parameters[0]?.name === \"companyName\") {\n        [companyName] = (query.parameters[0]?.value.split(','));\n    } else { \n        companyName = cleanupParam(query.parameters.find((element) =&gt; element.name === \"companyName\")?.value);\n    }\n    console.log(`\ud83c\udf7d\ufe0f Query #${++queryCount}:\\ncompanyName=${companyName}`);    \n\n    const products = await searchProductsByCustomer(companyName);\n\n    console.log(`Found ${products.length} products in the Northwind database`)\n    const attachments = [];\n    products.forEach((product) =&gt; {\n        const preview = CardFactory.heroCard(product.ProductName,\n            `Customer: ${companyName}`, [product.ImageUrl]);\n\n        const resultCard = cardHandler.getEditCard(product);\n        const attachment = { ...resultCard, preview };\n        attachments.push(attachment);\n    });\n    return {\n        composeExtension: {\n            type: \"result\",\n            attachmentLayout: \"list\",\n            attachments: attachments,\n        },\n    };\n\n</code></pre>"},{"location":"pages/extend-message-ext/03-enhance-nw-plugin/#step-4-update-the-command-routing","title":"Step 4 - Update the command routing","text":"<p>In this step you will route the <code>companySearch</code> command to the handler you implemented in the previous step.</p> <p>Open searchApp.ts in the src folder and add the following import statement: </p> <pre><code>import customerSearchCommand from \"./messageExtensions/customerSearchCommand\";\n</code></pre> <p>In the switch statement of the handler function <code>handleTeamsMessagingExtensionQuery</code> add another case statement as below:</p> <pre><code>      case customerSearchCommand.COMMAND_ID: {\n        return customerSearchCommand.handleTeamsMessagingExtensionQuery(context, query);\n      }\n</code></pre> <p>Note</p> <p>in the UI-based operation of the Message Extension / plugin, this command is explicitly called. However, when invoked by Microsoft 365 Copilot, the command is triggered by the Copilot orchestrator.</p>"},{"location":"pages/extend-message-ext/03-enhance-nw-plugin/#exercise-2-run-the-app-search-for-product-by-company-name","title":"Exercise 2 - Run the App! Search for product by company name","text":"<p>Now you're ready to test the sample as a plugin for Microsoft 365 Copilot.</p>"},{"location":"pages/extend-message-ext/03-enhance-nw-plugin/#step-1-run-the-updated-app-locally","title":"Step 1: Run the updated app locally","text":"<p>Stop the local debugger if it is kept running. Since you have updated the manifest with a new command, you will want to re install the app with the new package.  Update the manifest version in the manifest.json file inside the appPackage folder from \"1.0.9\" to \"1.0.10\". This ensurers the new changes of the app is refelected. </p> <p>Restart debugger by clicking F5, or click the start button 1\ufe0f\u20e3. You will have an opportunity to select a debugging profile; select Debug in Teams (Edge) 2\ufe0f\u20e3 or choose another profile.</p> <p></p> <p>The debugging will open teams in a browser window. Make sure you login using the same credentials you signed into Agents Toolkit. Once you're in, Microsoft Teams should open up and display a dialog offering to open your application. </p> <p></p> <p>Once opened it immediately ask you where you want to open the app in. By default it's personal chat. You could also select it in a channel or group chat as shown. Select \"Open\".</p> <p></p> <p>Now you are in a personal chat with the app. But we are testing in Copilt so follow next instruction. </p> <p>In Teams click on Chat and then Copilot. Copilot should be the top-most option. Click on the Plugin icon and select Northwind Inventory to enable the plugin.</p>"},{"location":"pages/extend-message-ext/03-enhance-nw-plugin/#step-2-test-with-new-command-in-copilot","title":"Step 2: Test with new command in Copilot","text":"<p>Enter the prompt: </p> <p>What are the products ordered by 'Consolidated Holdings' in Northwind Inventory?</p> <p>The Terminal output shows Copilot understood the query and executed the <code>companySearch</code> command, passing company name extracted by Copilot. </p> <p>Here's the output in Copilot: </p> <p>Here is another prompt to try:</p> <p>What are the products ordered by 'Consolidated Holdings' in Northwind Inventory? Please list the product name, price and supplier in a table.</p>"},{"location":"pages/extend-message-ext/03-enhance-nw-plugin/#step-3-test-the-command-as-message-extension-optional","title":"Step 3: Test the command as Message extension (Optional)","text":"<p>Of course, you can test this new command also by using the sample as a Message Extension, like we did in previous lab.</p> <ol> <li>In the Teams sidebar, move to the Chats section and pick any chat or start a new chat with a colleague.</li> <li>Click on the + sign to access to the Apps section.</li> <li>Pick the Northwind Inventory app.</li> <li>Notice how now you can see a new tab called Customer.</li> <li>Search for Consolidated Holdings and see the products ordered by this company. They will match the ones that Copilot returned you in the previous step.</li> </ol> <p></p> <p></p>"},{"location":"pages/extend-message-ext/03-enhance-nw-plugin/#congratulations","title":"Congratulations","text":"<p>You are now a plugin champion. You are now ready to secure your plugin with authentication. Proceed to the next lab. Select \"Next\"</p> <p></p>"},{"location":"pages/extend-message-ext/04-add-authentication/","title":"Lab M4 - Add authentication","text":"<p>In this lab you will secure your Northwind plugin from the previous lab with authentication using Entra ID SSO (single sign-on) to search and find your own contacts like suppliers information from Outlook.  </p> Navigating the Extend Teams Message Extension labs (Extend Path) <ul> <li>Lab M0 - Prerequisites </li> <li>Lab M1 - Get to know Northwind message extension </li> <li>Lab M2 - Run app in Microsoft 365 Copilot </li> <li>Lab M3 - Enhance plugin with new search command</li> <li>Lab M4 - Add authentication (\ud83d\udccdYou are here)</li> <li>Lab M5 - Enhance plugin with an action command </li> </ul> <p>Attention</p> <p>This lab requires you to have an Azure Subscripton to provision bot services.</p> <p>NOTE</p> <p>The completed exercise with all of the code changes can be downloaded from here. This can be useful for troubleshooting purposes. If you ever need to reset your edits, you can clone again the repository and start over.</p> <p>In this lab you will learn to:</p> <ul> <li> <p>how to add Entra ID single sign-on (SSO) to your plugin so users can seamlessly log into your app with the same account they use in Microsoft Teams</p> </li> <li> <p>Access the Microsoft Graph API to access user data in Microsoft 365. Your app will act on behalf of the logged-in user so they can securely access their own content within your application like contacts from Outlook in this lab.</p> </li> </ul>"},{"location":"pages/extend-message-ext/04-add-authentication/#introduction-tasks-involved-to-implement-sso-brief","title":"Introduction : Tasks involved to implement SSO (brief)","text":"<p>Implementing SSO for your plugin (Message extension app) involves several steps. Here is a high level over view of the process:</p>"},{"location":"pages/extend-message-ext/04-add-authentication/#register-your-app-in-microsoft-entra-id-configure-your-bot-in-azure-bot-service","title":"Register Your App in Microsoft Entra ID &amp; Configure Your Bot in Azure Bot Service","text":"<ul> <li>Create a new app registration in the Azure portal.</li> <li>Configure the app with necessary permissions and scopes.</li> <li>Generate a client secret for your app.</li> <li>Create a bot in the Azure Bot Service.</li> <li>Add the Microsoft 365 channel to your bot.</li> <li>Set up OAuth connection settings in the Azure portal.</li> </ul>"},{"location":"pages/extend-message-ext/04-add-authentication/#enable-sso-in-your-teams-app","title":"Enable SSO in Your Teams App","text":"<ul> <li>Update your message extension's bot code to handle authentication and token exchange.</li> <li>Use the Bot Framework SDK to integrate SSO capabilities.</li> <li>Implement the OAuth flow to obtain access tokens for the user.</li> </ul>"},{"location":"pages/extend-message-ext/04-add-authentication/#configure-authentication-in-teams","title":"Configure Authentication in Teams","text":"<ul> <li>Add the necessary permissions in the Teams app manifest.</li> </ul>"},{"location":"pages/extend-message-ext/04-add-authentication/#exercise-1-register-your-app-in-microsoft-entra-id-and-configure-your-bot-in-azure-bot-service","title":"Exercise 1: Register Your App in Microsoft Entra ID and Configure Your Bot in Azure Bot Service","text":"<p>Luckily for you, we\u2019ve streamlined everything so that it\u2019s ready to go as soon as you hit F5. However, let\u2019s go over the specific changes you\u2019ll need to make in the project for registering and configuring these resources. </p>"},{"location":"pages/extend-message-ext/04-add-authentication/#step-1-copy-files-and-folders","title":"Step 1: Copy files and folders","text":"<p>Create a new folder called entra inside folder infra in your root folder. </p> <p>Create two new files in the entra folder called entra.bot.manifest.json and entra.graph.manifest.json </p> <p>Copy code from this file into entra.bot.manifest.json and same for entra.graph.manifest.json from this file.</p> <p>These files are needed to provision the Entra ID app registrations (previously know as Azure Active Directory app registrations) needed for the bot as well as the one for graph for token exchange between them. </p> <p>Next in the infra folder create files azure.local.bicep and copy code from this file and create file azure.parameters.local.json in the same folder infra and copy code from this file</p> <p>These file help with the bot registration. This will ensure the bot service is provisioned in Azure even when you run app locally. This is required for this authentication flow.</p> <p>What is happening with these files?</p> <p>When Agents Toolkit runs the app locally, it will provision a new Azure AI Bot Service into the resource group which uses the F0 SKU which grants unlimited messages to be sent to standard channels, this includes Microsoft Teams and Microsoft 365 channel (Outlook and Copilot) and does not incur a cost.</p>"},{"location":"pages/extend-message-ext/04-add-authentication/#step-2-update-existing-code","title":"Step 2: Update existing code","text":"<p>Next, open file azurebot.bicep under botRegistration folder which is under infra folder and add below code snippet after declaration of \"param botAppDomain\"</p> <pre><code>param graphAadAppClientId string\n@secure()\nparam graphAadAppClientSecret string\n\nparam connectionName string\n</code></pre> <p>Next add below snippet to provision bot service into the same file at end of line.</p> <pre><code>resource botServicesMicrosoftGraphConnection 'Microsoft.BotService/botServices/connections@2022-09-15' = {\n  parent: botService\n  name: connectionName\n  location: 'global'\n  properties: {\n    serviceProviderDisplayName: 'Azure Active Directory v2'\n    serviceProviderId: '30dd229c-58e3-4a48-bdfd-91ec48eb906c'\n    clientId: graphAadAppClientId\n    clientSecret: graphAadAppClientSecret\n    scopes: 'email offline_access openid profile Contacts.Read'\n    parameters: [\n      {\n        key: 'tenantID'\n        value: 'common'\n      }\n      {\n        key: 'tokenExchangeUrl'\n        value: 'api://${botAppDomain}/botid-${botAadAppClientId}'\n      }\n    ]\n  }\n}\n\n</code></pre> <p>This will create a new OAUTH connection for token exchange between bot service and the graph entra ID app.</p> <p>Changes to infrastructure for plugin</p> <p>We require a different infrastructure to run this setup compared to the non-authenticated plugins we've previously built in this path and hence we need to rewire. Next steps will help you with this. </p> <p>Next, open the teamsapp.local.yml file and replace its content with the code snippet below. This will rewire parts of the infrastructure, including deploying a bot service in Azure for our lab. </p> <pre><code># yaml-language-server: $schema=https://aka.ms/teams-toolkit/1.0.0/yaml.schema.json\n# Visit https://aka.ms/teamsfx-v5.0-guide for details on this file\n# Visit https://aka.ms/teamsfx-actions for details on actions\nversion: 1.0.0\n\nprovision:\n\n  - uses: script\n    name: Ensure database\n    with:\n      run: node db-setup.js\n      workingDirectory: scripts\n\n  # Creates a Teams app\n  - uses: teamsApp/create\n    with:\n      # Teams app name\n      name: NorthwindProducts-${{TEAMSFX_ENV}}\n    # Write the information of created resources into environment file for\n    # the specified environment variable(s).\n    writeToEnvironmentFile:\n      teamsAppId: TEAMS_APP_ID\n\n  - uses: aadApp/create\n    with:\n      name: ${{APP_INTERNAL_NAME}}-bot-${{TEAMSFX_ENV}}\n      generateClientSecret: true\n      signInAudience: AzureADMultipleOrgs\n    writeToEnvironmentFile:\n      clientId: BOT_ID\n      clientSecret: SECRET_BOT_PASSWORD\n      objectId: BOT_AAD_APP_OBJECT_ID\n      tenantId: BOT_AAD_APP_TENANT_ID\n      authority: BOT_AAD_APP_OAUTH_AUTHORITY\n      authorityHost: BOT_AAD_APP_OAUTH_AUTHORITY_HOST\n\n  - uses: aadApp/update\n    with:\n      manifestPath: \"./infra/entra/entra.bot.manifest.json\"\n      outputFilePath : \"./build/entra.bot.manifest.${{TEAMSFX_ENV}}.json\"\n  - uses: aadApp/create\n    with:\n      name: ${{APP_INTERNAL_NAME}}-graph-${{TEAMSFX_ENV}}\n      generateClientSecret: true\n      signInAudience: AzureADMultipleOrgs\n    writeToEnvironmentFile:\n      clientId: GRAPH_AAD_APP_ID\n      clientSecret: SECRET_GRAPH_AAD_APP_CLIENT_SECRET\n      objectId: GRAPH_AAD_APP_OBJECT_ID\n      tenantId: GRAPH_AAD_APP_TENANT_ID\n      authority: GRAPH_AAD_APP_OAUTH_AUTHORITY\n      authorityHost: GRAPH_AAD_APP_OAUTH_AUTHORITY_HOST\n\n  - uses: aadApp/update\n    with:\n      manifestPath: \"./infra/entra/entra.graph.manifest.json\"\n      outputFilePath : \"./build/entra.graph.manifest.${{TEAMSFX_ENV}}.json\"\n\n  - uses: arm/deploy\n    with:\n      subscriptionId: ${{AZURE_SUBSCRIPTION_ID}}\n      resourceGroupName: ${{AZURE_RESOURCE_GROUP_NAME}}\n      templates:\n        - path: ./infra/azure.local.bicep\n          parameters: ./infra/azure.parameters.local.json\n          deploymentName: Create-resources-for-${{APP_INTERNAL_NAME}}-${{TEAMSFX_ENV}}\n      bicepCliVersion: v0.9.1\n\n  # Validate using manifest schema\n  - uses: teamsApp/validateManifest\n    with:\n      # Path to manifest template\n      manifestPath: ./appPackage/manifest.json\n\n  # Build Teams app package with latest env value\n  - uses: teamsApp/zipAppPackage\n    with:\n      # Path to manifest template\n      manifestPath: ./appPackage/manifest.json\n      outputZipPath: ./appPackage/build/appPackage.${{TEAMSFX_ENV}}.zip\n      outputJsonPath: ./appPackage/build/manifest.${{TEAMSFX_ENV}}.json\n  # Validate app package using validation rules\n  - uses: teamsApp/validateAppPackage\n    with:\n      # Relative path to this file. This is the path for built zip file.\n      appPackagePath: ./appPackage/build/appPackage.${{TEAMSFX_ENV}}.zip\n\n  # Apply the Teams app manifest to an existing Teams app in\n  # Teams Developer Portal.\n  # Will use the app id in manifest file to determine which Teams app to update.\n  - uses: teamsApp/update\n    with:\n      # Relative path to this file. This is the path for built zip file.\n      appPackagePath: ./appPackage/build/appPackage.${{TEAMSFX_ENV}}.zip\n\n  # Extend your Teams app to Outlook and the Microsoft 365 app\n  - uses: teamsApp/extendToM365\n    with:\n      # Relative path to the build app package.\n      appPackagePath: ./appPackage/build/appPackage.${{TEAMSFX_ENV}}.zip\n    # Write the information of created resources into environment file for\n    # the specified environment variable(s).\n    writeToEnvironmentFile:\n      titleId: M365_TITLE_ID\n      appId: M365_APP_ID\n\ndeploy:\n# Run npm command\n  - uses: cli/runNpmCommand\n    name: install dependencies\n    with:\n      args: install --no-audit\n\n  # Generate runtime environment variables\n  - uses: file/createOrUpdateEnvironmentFile\n    with:\n      target: ./.localConfigs\n      envs:\n        BOT_ID: ${{BOT_ID}}\n        BOT_PASSWORD: ${{SECRET_BOT_PASSWORD}}\n        STORAGE_ACCOUNT_CONNECTION_STRING: ${{SECRET_STORAGE_ACCOUNT_CONNECTION_STRING}}\n        CONNECTION_NAME: ${{CONNECTION_NAME}}\n\n</code></pre> <p>Open .env.local file under env folder and completely remove all variable and add below for a fresh start. </p> <pre><code>APP_INTERNAL_NAME=Northwind\nAPP_DISPLAY_NAME=Northwind\nCONNECTION_NAME=MicrosoftGraph\n\n</code></pre> <p>Open .env.local.user file under env folder and completely remove all variable and add below for a fresh start. </p> <pre><code>SECRET_BOT_PASSWORD=\nSECRET_GRAPH_AAD_APP_CLIENT_SECRET=\nSECRET_STORAGE_ACCOUNT_CONNECTION_STRING=UseDevelopmentStorage=true\n</code></pre>"},{"location":"pages/extend-message-ext/04-add-authentication/#exercise-2-new-search-command-for-contacts","title":"Exercise 2: New search command for Contacts","text":""},{"location":"pages/extend-message-ext/04-add-authentication/#step-1-add-a-command-to-search-contacts-suppliers","title":"Step 1: Add a command to search contacts (suppliers)","text":"<p>To start, add a new command for searching contacts. We\u2019ll eventually retrieve contact details from Microsoft Graph, but for now, we\u2019ll use mock data to ensure the message extension command functions correctly. Go to src folder &gt; messageExtensions and add an new file supplierContactSearchCommand.ts in it.</p> <p>Copy the content from below into the new file.</p> <pre><code>import {\n    CardFactory,\n    TurnContext\n} from \"botbuilder\";\n\n\nconst COMMAND_ID = \"supplierContactSearch\";\n\nlet queryCount = 0;\nasync function handleTeamsMessagingExtensionQuery(context: TurnContext, query: any): Promise&lt;any&gt; {\n\n    let name = '';\n    if (query.parameters.length === 1 &amp;&amp; query.parameters[0]?.name === \"name\") {\n        [name] = (query.parameters[0]?.value.split(','));\n    } else {\n        name = cleanupParam(query.parameters.find((element) =&gt; element.name === \"name\")?.value);\n    }\n    console.log(`\ud83c\udf7d\ufe0f Query #${++queryCount}:\\name of contact=${name}`);\n    const filteredProfile = [];\n    const attachments = [];\n\n    const allContacts = [\n    {\n        displayName: \"John Doe\",\n        emailAddresses: [\n        { address: \"john.doe@example.com\" }\n        ]\n    },\n    {\n        displayName: \"Jane Smith\",\n        emailAddresses: [\n        { address: \"jane.smith@example.com\" }\n        ]\n    },\n    {\n        displayName: \"Alice Johnson\",\n        emailAddresses: [\n        { address: \"alice.johnson@example.com\" }\n        ]\n    }\n];\n\n    allContacts.forEach((contact) =&gt; {\n        if (contact.displayName.toLowerCase().includes(name.toLowerCase()) || contact.emailAddresses[0]?.address.toLowerCase().includes(name.toLowerCase())) {\n            filteredProfile.push(contact);\n        }\n    });\n\n    filteredProfile.forEach((prof) =&gt; {\n        const preview = CardFactory.heroCard(prof.displayName,\n            `with email ${prof.emailAddresses[0]?.address}`);\n\n        const resultCard = CardFactory.heroCard(prof.displayName,\n            `with email ${prof.emailAddresses[0]?.address}`);\n        const attachment = { ...resultCard, preview };\n        attachments.push(attachment);\n    });\n    return {\n        composeExtension: {\n            type: \"result\",\n            attachmentLayout: \"list\",\n            attachments: attachments,\n        },\n    };\n\n}\nfunction cleanupParam(value: string): string {\n\n    if (!value) {\n        return \"\";\n    } else {\n        let result = value.trim();\n        result = result.split(',')[0];          // Remove extra data\n        result = result.replace(\"*\", \"\");       // Remove wildcard characters from Copilot\n        return result;\n    }\n}\n\nexport default { COMMAND_ID, handleTeamsMessagingExtensionQuery }\n</code></pre> <p>Go to src folder &gt; searchApp.ts file and import the newly created command.</p> <pre><code>import supplierContactSearchCommand from \"./messageExtensions/supplierContactSearchCommand\";\n</code></pre> <p>And add another case in the handleTeamsMessagingExtensionQuery for the newly added command after case customerSearchCommand.COMMAND_ID:</p> <pre><code>  case supplierContactSearchCommand.COMMAND_ID: {\n        return supplierContactSearchCommand.handleTeamsMessagingExtensionQuery(context, query);\n      } \n</code></pre> <p>Now to go appPackage &gt; manifest.json and add the command inside the commands array under the node composeExtensions.</p> <pre><code> {\n                    \"id\": \"supplierContactSearch\",\n                    \"context\": [\n                        \"compose\",\n                        \"commandBox\"\n                    ],\n                    \"description\": \"Search for a contact in the user's Outlook contacts list for Northwind\",\n                    \"title\": \"Contact search\",\n                    \"type\": \"query\",\n                    \"parameters\": [\n                        {\n                            \"name\": \"name\",\n                            \"title\": \"Contact search\",\n                            \"description\": \"Type name of the contact or company which forms the domain for email address of the contact, to search my Outlook contacts list\",\n                            \"inputType\": \"text\"\n                        }\n                    ] \n         } \n</code></pre> <p>So you have now added a new non authenticated command to search contacts from a mock list. </p>"},{"location":"pages/extend-message-ext/04-add-authentication/#step-2-sign-in-to-azure-in-agents-toolkit","title":"Step 2: Sign in to Azure in Agents Toolkit","text":"<p>Agents Toolkit requires you to sign in to an Azure account and have a subscription before you can provision the resource instances. You'll then use these resources to deploy your app to host it in Azure.</p> <p>On the Activity Bar of your project editor, select the Microsoft Teams icon 1\ufe0f\u20e3. This will open the Agents Toolkit extension panel.</p> <p>On the Agents Toolkit panel, under Accounts, select \"Sign in to Azure\" 2\ufe0f\u20e3.</p> <p></p> <p>In the dialog that appears, select \"Sign in\".</p> <p></p>"},{"location":"pages/extend-message-ext/04-add-authentication/#step-3-run-the-application-in-teams-to-test-new-command","title":"Step 3: Run the application in Teams to test new command","text":"<p>To test the new command you need to run the app locally.</p> <p>Click F5 to start debugging, or click the start button 1\ufe0f\u20e3. You will have an opportunity to select a debugging profile; select Debug in Teams (Edge) 2\ufe0f\u20e3 or choose another profile.</p> <p></p> <p>F5 in this lab</p> <p>When you press F5 to run the application, it will also provision all the necessary resources for the authenticated flow, as we configured everything using the Team Toolkit's actions in Exercise 1. </p> <p>Since you cleared the environments variable, you will install all Entra ID apps and bot services in Azure. During the first run, you'll need to select a resource group in your Azure subscription, which you logged into via the Agents Toolkit, for provisioning resources.</p> <p></p> <p>Choose + New resource group to keep things tidy.And choose the default name Agents Toolkit has suggested and select Enter.</p> <p>Next, choose a Location. For this lab just choose Central US</p> <p></p> <p>Next Agents Toolkit will go ahead and provision the resources but will also ask you a confirmation before doing so.</p> <p></p> <p>Select Provision.</p> <p>Once it's provisioned all the resources, you will get the Northwind app install dialog in a browser, select Add.</p> <p></p> <p>Once installed, you will be given another dialog to open the app. This will open the app as a message extension in a personal chat. Select Open.</p> <p></p> <p>Since we only need to test if the command works or not, we will only test the app in Teams chat. In the personal chat with the app, select the Contacrt search and type a. </p> <p></p> <p>If it lists the contacts as shown above, the command is working, but with mock data. We will fix this in the next exercise.</p>"},{"location":"pages/extend-message-ext/04-add-authentication/#exercise-3-enable-authentication-for-new-command","title":"Exercise 3 : Enable authentication for new command","text":"<p>In the previous step, you have laid the foundation for the new command. Next you will add authentication on top of the command, replace the mock contact list and replace it with actual contact list from the logged in user's Outlook contacts.</p> <p>You will first install some npm packages needed for the plugin. Create a new terminal window in the project.</p> <p>Run below script in the terminal :</p> <pre><code>npm i @microsoft/microsoft-graph-client @microsoft/microsoft-graph-types\n</code></pre> <p>Locate config.ts file in the src folder. Add a \",\" after <code>storageAccountConnectionString: process.env.STORAGE_ACCOUNT_CONNECTION_STRING</code> and add the new property and value for <code>connectionName</code> as below.</p> <pre>\n const config = {\n  botId: process.env.BOT_ID,\n  botPassword: process.env.BOT_PASSWORD,\n  storageAccountConnectionString: process.env.STORAGE_ACCOUNT_CONNECTION_STRING,\n  connectionName: process.env.CONNECTION_NAME\n};\n</pre> <p>Now create a folder called services under src folder of your base project. Create two files AuthService.ts and GraphService.ts in the services folder. </p> <ul> <li> <p>AuthService : contains a class that provides authentication services. It includes a method getSignInLink which asynchronously retrieves a sign-in URL from a client using specific connection details and returns this URL.</p> </li> <li> <p>GraphService : defines a class that interacts with the Microsoft Graph API. It initializes a Graph client using an authentication token and provides a method getContacts to fetch the user's contacts, selecting specific fields (displayName and emailAddresses).</p> </li> </ul> <p>Next, copy paste below code into AuthService.ts</p> <pre><code>import {\n  AdaptiveCardInvokeResponse,\n  CloudAdapter,\n  MessagingExtensionQuery,\n  MessagingExtensionResponse,\n  TurnContext,\n} from 'botbuilder';\nimport { UserTokenClient } from 'botframework-connector';\nimport { Activity } from 'botframework-schema';\nimport config from '../config';\n\nexport class AuthService {\n  private client: UserTokenClient;\n  private activity: Activity;\n  private connectionName: string;\n\n  constructor(context: TurnContext) {\n    const adapter = context.adapter as CloudAdapter;\n    this.client = context.turnState.get&lt;UserTokenClient&gt;(\n      adapter.UserTokenClientKey\n    );\n    this.activity = context.activity;\n    this.connectionName = config.connectionName;\n  }\n\n  async getUserToken(\n    query?: MessagingExtensionQuery\n  ): Promise&lt;string | undefined&gt; {\n    const magicCode =\n      query?.state &amp;&amp; Number.isInteger(Number(query.state)) ? query.state : '';\n\n    const tokenResponse = await this.client.getUserToken(\n      this.activity.from.id,\n      this.connectionName,\n      this.activity.channelId,\n      magicCode\n    );\n\n    return tokenResponse?.token;\n  }\n\n  async getSignInComposeExtension(): Promise&lt;MessagingExtensionResponse&gt; {\n    const signInLink = await this.getSignInLink();\n\n    return {\n      composeExtension: {\n        type: 'auth',\n        suggestedActions: {\n          actions: [\n            {\n              type: 'openUrl',\n              value: signInLink,\n              title: 'SignIn',\n            },\n          ],\n        },\n      },\n    };\n  }\n\n  async getSignInAdaptiveCardInvokeResponse(): Promise&lt;AdaptiveCardInvokeResponse&gt; {\n    const signInLink = await this.getSignInLink();\n\n    return {\n      statusCode: 401,\n      type: 'application/vnd.microsoft.card.signin',\n\n      value: {\n        signinurl: signInLink,\n      },\n    };\n  }\n\n  async getSignInLink(): Promise&lt;string&gt; {\n    const { signInLink } = await this.client.getSignInResource(\n      this.connectionName,\n      this.activity,\n      ''\n    );\n\n    return signInLink;\n  }\n}\n\n</code></pre> <p>Next, copy paste below code into GraphService.ts</p> <pre><code>import { Client } from '@microsoft/microsoft-graph-client';\n\n\nexport class GraphService {\n  private _token: string;\n  private graphClient: Client;\n\n  constructor(token: string) {\n    if (!token || !token.trim()) {\n      throw new Error('SimpleGraphClient: Invalid token received.');\n    }\n    this._token = token;\n\n    this.graphClient = Client.init({\n      authProvider: done =&gt; {\n        done(null, this._token);\n      },\n    });\n  }\n  async getContacts(): Promise&lt;any&gt; {\n    const response = await this.graphClient\n      .api(`me/contacts`)\n      .select('displayName,emailAddresses')\n      .get();\n\n    return response.value;\n  }\n}\n\n</code></pre> <p>Now, go back to the supplierContactSearchCommand.ts file and import these two services we just added.</p> <pre><code>import { AuthService } from \"../services/AuthService\";\nimport { GraphService } from \"../services/GraphService\";\n</code></pre> <p>Next, add the code that initializes authentication, retrieves a user token, checks its validity, and then sets up a service to interact with the Microsoft Graph API if the token is valid. If the token is invalid, it prompts the user to sign in.</p> <p>Copy below code into the handleTeamsMessagingExtensionQuery function above the mock definition of allContacts constant.</p> <pre><code>  const credentials = new AuthService(context);\n  const token = await credentials.getUserToken(query);\n  if (!token) {\n    return credentials.getSignInComposeExtension();\n  }\n  const graphService = new GraphService(token);\n</code></pre> <p>Next, replace the mock definition of allContacts constant with below code:</p> <pre><code>const allContacts = await graphService.getContacts();\n</code></pre> <p>Next go to appPackage/manifest.json file and update the node validDomains as below</p> <pre><code>\"validDomains\": [\n        \"token.botframework.com\",\n        \"${{BOT_DOMAIN}}\"\n    ]\n</code></pre> <p>Also add comma \",\" after <code>validDomains</code> array and add a node for webApplicationInfo and update it with below value</p> <pre><code>    \"webApplicationInfo\": {\n        \"id\": \"${{BOT_ID}}\",\n        \"resource\": \"api://${{BOT_DOMAIN}}/botid-${{BOT_ID}}\"\n    },\n</code></pre> <p>Next, upgrade the manifest version from \"1.0.10\" to \"1.0.11\" so the changes are reflected. </p> <p>These manifest changes will make sure the sign-in url is correctly formed and sent to the user for consent.</p>"},{"location":"pages/extend-message-ext/04-add-authentication/#exercise-4-test-authentication","title":"Exercise 4:  Test authentication","text":""},{"location":"pages/extend-message-ext/04-add-authentication/#step-1-run-app-locally","title":"Step 1: Run app locally","text":"<p>Stop the local debugger if it is kept running. Since you have updated the manifest with a new command, you will want to re install the app with the new package. </p> <p>Restart debugger by clicking F5, or click the start button 1\ufe0f\u20e3. You will have an opportunity to select a debugging profile; select Debug in Teams (Edge) 2\ufe0f\u20e3 or choose another profile.</p> <p></p> <p>Provision</p> <p>Here you will again get a dialog confirming if you want to provision the resources. Select \"Provision\". This is not actually provisioning new resources just overwriting existing resources. </p> <p>The debugging will open teams in a browser window. Make sure you login using the same credentials you signed into Agents Toolkit. Once you're in, Microsoft Teams should open up and display a dialog offering to open your application. </p> <p></p> <p>Once opened it immediately ask you where you want to open the app in. By default it's personal chat. You could also select it in a channel or group chat as shown. Select \"Open\".</p> <p></p> <p>Now you are in a personal chat with the app. But we are testing in Copilt so follow next instruction. </p> <p>In Teams click on Chat and then Copilot. Copilot should be the top-most option. Click on the Plugin icon and select Northwind Inventory to enable the plugin.</p>"},{"location":"pages/extend-message-ext/04-add-authentication/#step-2-enter-test-data","title":"Step 2 : Enter test data","text":"<p>Before we test the plugin to bring actual contacts, we'll need to add some contact information. So let us first ensure we have some contacts in Microsoft 365.</p> <p>1\ufe0f\u20e3 From Microsoft Teams, click the \"waffle\" menu</p> <p>2\ufe0f\u20e3 Select Microsoft Outlook</p> <p></p> <p>1\ufe0f\u20e3 Within Outlook, click the \"Contacts\" button</p> <p>2\ufe0f\u20e3 Enter some new contacts</p> <p>The app is simple, and will only display the person or company name and email address. If you want to play along with the business scenario, make them sound like suppliers.</p> <p></p>"},{"location":"pages/extend-message-ext/04-add-authentication/#step-2-test-in-copilot","title":"Step 2: Test in Copilot","text":"<p>Ask Copilot for contacts by using this prompt- Find my conacts with name {first name} in Northwind (Replace {first name} with what name you have given for your contacts in Exercise 4, Step 1)</p> <p>You will get a sign-in button to authenticate (one time only) as shown in the screen. </p> <p></p> <p>This is the indication that you have an some sort of an authentication set in place to call this feature of the plugin. Select Sign in to Northwind Inventory</p> <p>You will now get a dialog to interact and provide consent as show in the GIF below. Once consented you should be able to get back results form Microsoft 365 Copilot. </p>"},{"location":"pages/extend-message-ext/04-add-authentication/#congratulations","title":"Congratulations","text":"<p>This was a hard one, but you ACED it! Thanks for doing the Message Extension agent track!</p> <p></p> <p></p>"},{"location":"pages/extend-message-ext/05-add-action/","title":"Lab M5 - Enhance plugin with an action command","text":""},{"location":"pages/in-a-box/","title":"Copilot Developer Camp In a Box","text":"<p>Here are presentation materials for running your own Copilot Developer Camp workshop!!</p> title deck with video demos deck for sharing 20 min CC01: Keynote download download 40 min CC02: Introducing Declarative Agents download download 40 min CC03: Introducing Custom Engine Agents part 1, part 2 download <p></p>"},{"location":"pages/internal/labFormat/","title":"Guide to formatting lab content","text":""},{"location":"pages/internal/labFormat/#formatting-text-elements","title":"Formatting text elements","text":"<p>These text elements are embedded into the lab instructions, so the formatting is always in-line</p> Element Treatment Example Function names monospaced with parenthesis Then, call <code>myFunction()</code> to do something ... Language keywords monospaced ... insert at the top of the <code>try</code> block ... Symbols in code (variable, object names etc.) monospaced ... the <code>foo</code> object contains something random ... File and folder names bold Copy the contents of foo.js into the bar folder Text on screen enclose in double quotes Now click on the \"foo\" button"},{"location":"pages/internal/labFormat/#includes","title":"Includes","text":"<p>Content that will be used on multiple pages should be placed in include files in the /docs/includes folder.</p> <p>Here is the syntax:</p> --8&lt;-- \"all-labs-toc.md\" <p>Here is an example::</p> <p>Do these labs if you want to build a Declarative agent where Microsoft 365 provides the AI model and             orchestration</p> <ul> <li>\ud83c\udfc1 Welcome</li> <li>\ud83d\udd27 Set up <ul> <li>Lab E0 - Setup</li> </ul> </li> <li>\ud83e\uddf0 Declarative agent fundamentals <ul> <li> Lab E1 - Build a Detailed Declarative Agent </li> <li> Lab E1a - Geo locator game</li> </ul> </li> <li>\ud83d\udee0\ufe0f Build and integrate API from scratch <ul> <li>Lab E2 - Build an API</li> <li> Lab E3 - Add Declarative Agent + API</li> <li> Lab E4 - Enhance API + Plugin</li> <li>Lab E5 - Add Adaptive Cards</li> </ul> </li> <li>\ud83d\udd10 Authentication <ul> <li> Lab E6a - Toolkit</li> <li> Lab E6b - Manual</li> <li> Lab E6c - SSO</li> </ul> </li> <li>\ud83d\udd0c Integration <ul> <li> Lab EB - Add Graph Connector</li> </ul> </li> </ul> <p>Do these labs if you want to build a Custom engine agent with custom AI model and orchestration using Azure OpenAI and Teams AI library</p> <ul> <li>BTA0 - Setup</li> <li>BTA1 - First custom engine agent</li> <li>BTA2 - Index your data in Azure AI Search</li> <li>BTA3 - Enhance the user experience</li> <li>BTA4 - Add single sign on authentication</li> <li>BTA5 - Add actions to handle complex tasks</li> </ul> <p>Do these labs if you want to build a Declarative agent with Copilot Studio Lite</p> <ul> <li>MAB1 - Build your first agent</li> </ul> <p>Do these labs if you want to build agents with Microsoft Copilot Studio</p> <ul> <li>MCS0 - Setup</li> <li>MCS1 - First agent</li> <li>MCS2 - Defining Topics</li> <li>MCS3 - Defining Tools</li> <li>MCS4 - Extending Microsoft 365 Copilot</li> <li>MCS5 - Consuming a custom connector</li> <li>MCS6 - Consuming an MCP server</li> <li>MCS7 - Creating Autonomous Agents</li> <li>MCS8 - Integrating Azure AI Search for RAG</li> </ul>"},{"location":"pages/internal/labFormat/#lab-steps","title":"Lab steps","text":"<p>Copilot Developer Camp labs use custom web controls to help students track their progress. You will want to include a <code>&lt;cc-end-step /&gt;</code> element at the end of each lab step. See this test page for details.</p>"},{"location":"pages/internal/labFormat/#hyperlinks","title":"Hyperlinks","text":"<p>Links within the labs can be relative and should open within the current window like this.</p> <p>Links that go outside the labs, including links to source code in the same repo, should open a new window like this</p>"},{"location":"pages/internal/labFormat/#admonitions","title":"Admonitions","text":"<p>The documentation for admonitions is here. Here's how to use them in Copilot Developer Camp:</p> <p>Challenge</p> <p>Here's something to try on your own</p> <p>Note</p> <p>Use this format to emphasize or clarify the instructions</p> <p>Tip</p> <p>Use this format to show tips and best practices</p> <p>Warning</p> <p>Use this format to warn the student about a common pitfall in completing the labs</p> <p>Danger</p> <p>Use this format to warn the student about security issues or stability issues that may arise in a production application</p> Video briefing <p> Caption </p> Video briefing <p> Caption </p> More information <p> Caption 1 Caption 2 Caption 3 </p> TL;DR <p>Use this format to provide ancillary details that may be of interest but are not essential</p>"},{"location":"pages/internal/testGuide/","title":"testGuide","text":""},{"location":"pages/internal/testGuide/#thank-you-for-testing-code-camp","title":"Thank you for testing Code Camp","text":"<p>The key to successful labs is testing; the more people who try it, the more we'll find any missing steps or assumed knowledge.</p> <p>The following labs are in need of testing. Please send questions and issues to the lab owner, or bring it up in the Copilot Camp Testers chat. If you add Github issues or Pull requests please mention or assign the owner.</p> <p>Auth labs are now published</p> <p>If you'd like to try the new Declarative Agent auth labs, skip to them here</p>"},{"location":"pages/internal/testGuide/#here-are-the-new-labs","title":"Here are the new labs!","text":"<p>New Maker Path</p> <p>Owner: Paolo Pialorsi</p> <p>In this new path, the student finds content about:</p> <ul> <li>Copilot Studio Lite</li> <li>Microsoft Copilot Studio</li> <li>SharePoint agents</li> </ul> <p>Test procedure:</p> <ol> <li>Just read the initial introductions for each branch, starting from here.</li> </ol> <p>Lab MAB1 - Copilot Studio Lite</p> <p>Owner: Paolo Pialorsi</p> <p>In this lab, the student:</p> <ul> <li>learns what is a declarative agent for Microsoft 365 Copilot</li> <li>makes a declarative agent using Copilot Studio Lite</li> <li>customises the agent to create a game using specific instructions</li> <li>configures the agent to rely on a set of documents stored in SharePoint Online</li> <li>enables the agent to generate images</li> <li>shares the agent with other people</li> <li>learns how to share the agent with other people</li> </ul> <p>To test you will need a tenant with Microsoft 365 Copilot.</p> <p>Test procedure:</p> <ol> <li>Just follow the lab instructions</li> </ol> <p>Lab MCS0 - Setup</p> <p>Owner: Paolo Pialorsi</p> <p>In this lab, the student:</p> <ul> <li>How to create a dedicated environment for your labs</li> <li>How to setup and configure Microsoft Copilot Studio</li> </ul> <p>To test you will need a tenant with Microsoft 365 Copilot and Microsoft Copilot Studio (a trial license is enough).</p> <p>Test procedure:</p> <ol> <li>Just follow the lab instructions</li> </ol> <p>Lab MCS1 - First agent</p> <p>Owner: Paolo Pialorsi</p> <p>In this lab, the student:</p> <ul> <li>How to create an agent with Copilot Studio</li> <li>How to configure a custom icon for your agent</li> <li>How to configure knowledge sources for your agent</li> <li>How to publish your agent in Microsoft Teams</li> </ul> <p>To test you will need a tenant with Microsoft 365 Copilot and Microsoft Copilot Studio (a trial license is enough).</p> <p>Test procedure:</p> <ol> <li>Just follow the lab instructions</li> </ol> <p>Lab MCS2 - Defining Topics</p> <p>Owner: Paolo Pialorsi</p> <p>In this lab, the student:</p> <ul> <li>How to rely on Orchestration based on generative AI</li> <li>How to create a single-turn topic</li> <li>How to create a multi-turn topic</li> <li>How to use adaptive cards to interact with users</li> </ul> <p>To test you will need a tenant with Microsoft 365 Copilot and Microsoft Copilot Studio (a trial license is enough).</p> <p>Test procedure:</p> <ol> <li>Just follow the lab instructions</li> </ol> <p>Lab MCS3 - Defining Actions</p> <p>Owner: Paolo Pialorsi</p> <p>In this lab, the student:</p> <ul> <li>How to create an action to invoke a Power Platform connector</li> <li>How to create an action to invoke a Power Automate flow</li> <li>How to invoke actions from topics</li> </ul> <p>To test you will need a tenant with Microsoft 365 Copilot and Microsoft Copilot Studio (a trial license is enough).</p> <p>Test procedure:</p> <ol> <li>Just follow the lab instructions</li> </ol> <p>Lab MCS4 - Extending Microsoft 365 Copilot</p> <p>Owner: Paolo Pialorsi</p> <p>In this lab, the student:</p> <ul> <li>How to create an agent for Microsoft 365 Copilot Chat</li> <li>How to configure a custom icon for your agent</li> <li>How to configure knowledge sources for your agent</li> <li>How to publish the agent in Microsoft 365 Copilot Chat</li> <li>How to create an action for Microsoft 365 Copilot Chat</li> </ul> <p>To test you will need a tenant with Microsoft 365 Copilot and Microsoft Copilot Studio (a trial license is enough).</p> <p>Test procedure:</p> <ol> <li>Just follow the lab instructions</li> </ol> <p>Lab MCS5 - Power Platform custom connector</p> <p>Owner: Paolo Pialorsi</p> <p>In this lab, the student:</p> <ul> <li>How to expose a REST API through a Power Platform custom connector</li> <li>How to secure communication to an external REST API in the Power Platform</li> <li>How to consume a custom connector from an agent</li> </ul> <p>To test you will need a tenant with Microsoft 365 Copilot and Microsoft Copilot Studio (a trial license is enough).</p> <p>Test procedure:</p> <ol> <li>Just follow the lab instructions</li> </ol> <p># Thank you!</p>"},{"location":"pages/make/","title":"Make agents for Microsoft 365 Copilot","text":"<p>Welcome to Copilot Developer Camp's Maker Path! In this lab, you will design customised assistants to improve the overall experience of using Microsoft 365 Copilot. The process will begin with the creation of a basic agent using either the Copilot Studio Lite, or the SharePoint agent capability in SharePoint Online, or Copilot Studio.</p> <p>In order to better understand the available options and when you should use what, here you can find a helpful table with a brief explanation of each of the options.</p>        Copilot Studio Lite      <ul> <li>Easy, simple, and interactive experience</li> <li>Web based, integrated with Microsoft 365 Copilot Chat and Microsoft 365 Copilot</li> <li>Content from SharePoint Online, public web, and Microsoft Copilot Connectors</li> <li>Available in Microsoft 365 Copilot Chat</li> <ul> Start here  Copilot Studio Full              <ul> <li>Maximum level of flexibility</li> <li>Almost any data source or knowledge base</li> <li>Support for various publishing channels</li> <li>Support for actions</li> <li>Support for Power Platform connectors, Dataverse, REST API, and more</li> <li>Per user + per tenant license or Pay-As-You-Go</li> <ul> Start here  SharePoint Agent              <ul> <li>Integrated with SharePoint Online user experience</li> <li>SharePoint Online content only</li> <li>Supported in Microsoft Teams chat</li> <li>Microsoft 365 Copilot license or Microsoft Copilot Studio capacity or Pay-As-You-Go</li> <ul> Start here <p></p>"},{"location":"pages/make/agent-builder/","title":"Lab MAB - Making agents with Copilot Studio Lite","text":"<p>This is the easiest way of making a personal agent for Microsoft 365 Copilot. In fact, it is integrated with the native UI of Microsoft 365 Copilot Chat and Microsoft 365 Copilot. You can start from a set of Microsoft provided templates, or you can start from scratch. You can define the agent simply describing in natural language what you are looking for and relying on Copilot Studio Lite capability to understand natural language. It will create an agent for you, based on your prompt. Or you can configure the agent using a configuration page. By default, the agent is for personal use only. However, you can share it with specific people in your organization, or even with all the users in your organization, if needed.</p> <p></p> <p>An agent built with Copilot Studio Lite can use knowledge bases like:</p> <ul> <li>Generic web content</li> <li>Content of documents stored in SharePoint Online</li> <li>Microsoft Copilot Connectors</li> </ul> <p>It can also generate images on the fly or convert natural language into code.</p> <p>It is available in Microsoft 365 Copilot Chat and to any licensed user of Microsoft 365 Copilot.  Depending on the target knowledge base and on your users' license, your organization might have to pay for metered services.</p> <p>Do these labs if you want to build a Declarative agent with Copilot Studio Lite</p> <ul> <li>MAB1 - Build your first agent</li> </ul> <p>Start here with Lab MAB1, where you'll make your first agent with Copilot Studio Lite. </p> <p></p>"},{"location":"pages/make/agent-builder/01-first-agent/","title":"Lab MAB1 - Build your first agent","text":"<p>Do these labs if you want to build a Declarative agent with Copilot Studio Lite</p> <ul> <li>MAB1 - Build your first agent</li> </ul> Table of Contents <p>In this lab, you'll create a simple declarative agent using Copilot Studio Lite. Your agent is designed to help users to maintain and improve a home garden. The knowledge base of the agent is based on a set of documents stored in SharePoint Online and on the public web content. The agent can also engage the user in a nice game to guess the name of plants or flowers based on a set of clues.</p> <p>In this lab you will learn:</p> <ul> <li>What is a declarative agent for Microsoft 365 Copilot</li> <li>Make a declarative agent using Copilot Studio Lite</li> <li>Customise the agent to create a game using specific instructions </li> <li>Configure the agent to rely on a set of documents stored in SharePoint Online</li> <li>Enable the agent to generate images</li> <li>Share the agent with other people</li> <li>Learn how to share the agent with other people </li> </ul>"},{"location":"pages/make/agent-builder/01-first-agent/#introduction","title":"Introduction","text":"<p>Declarative agents leverage the same scalable infrastructure and platform of Microsoft 365 Copilot, tailored specifically to meet focus on a special area of your needs. They function as subject matter experts in a specific area or business need, allowing you to use the same interface as a standard Microsoft 365 Copilot chat, while ensuring they focus exclusively on the specific task at hand. </p> <p>Welcome on board to making your own declarative agent \u263a\ufe0f! Let's dive in and make your Copilot work magic!</p> <p>In this lab you will start out building a declarative agent using Copilot Studio Lite and providing a sample set of instructions. This is to help you get started with something. </p> <p>Next, you will modify your agent to be focused on a guess the plant or flower name game. </p> <p>You will also give your agent some files, stored in SharePoint Online, to refer to an hypothetical knowledge base. </p> <p>Lastly you will share the agent with other people in your organization.</p> <p></p>"},{"location":"pages/make/agent-builder/01-first-agent/#exercise-1-creating-the-declarative-agent","title":"Exercise 1: Creating the Declarative agent","text":"<p>Let's get started! \ud83d\udcaa\ud83c\udffc Let's make the agent from scratch using Copilot Studio Lite.</p>"},{"location":"pages/make/agent-builder/01-first-agent/#step-1-describe-your-agent","title":"Step 1: Describe your agent","text":"<p>To create a declarative agent with Copilot Studio Lite, open the Microsoft 365 Copilot chat home page and select Create an agent in the right side panel, where there is the list of available agents, like illustrated in the following picture.</p> <p></p> <p>The Copilot Studio Lite pops up and you can start defining the custom agent. You can choose a template to start from, or you can simply describe the agent by providing a description in natural language. You can also choose to manually configure the agent, selecting the Configure option, but you will get there later. Let's provide the following initial description:</p> <pre><code>You are an expert gardener and you help users to maintain and improve their home garden\nproviding detailed instructions and advice about the best practices for home gardening.\n</code></pre> <p></p> <p>Once you have provided the instructions, the agent builder will ask you about the name for the new agent. Provide the name: Gardener. While you interact with the agent builder, on the right side of the dialog you can see there is a preview of the agent itself, including some suggested conversation starters. If the agent builder asks you about refining instructions further, provide the following sentence.</p> <pre><code>Suggest ways to keep plants and flowers shining and gorgeous\n</code></pre> <p></p> <p>Keep on interacting with the agent builder until it does have all the information needed to create the agent. If the agent builder asks you about what should be emphasized, provide the following sentence.</p> <pre><code>Highlight the importance of nature and plants/flowers to be present in every house!\n</code></pre> <p>When the agent builder asks you about how the agent should talk, answer with the following sentence.</p> <pre><code>Use a professional, yet friendly, tone.\n</code></pre> <p>Lastly, say that you don't have any further refinements and select the Create button in the upper right corner of the screen. </p> <p></p> <p>The Copilot Studio Lite will create a new agent for you, based on the provided instructions. </p> <p></p>"},{"location":"pages/make/agent-builder/01-first-agent/#step-2-test-the-agent","title":"Step 2: Test the agent","text":"<p>Once the agent is ready, you will see a popup dialog with a link to the agent and a link to share it with other people in your organization.</p> <p></p> <p>Select the Go to agent button. You will be brought to the actual user experience of the new agent that you've just made.</p> <p></p> <p>To start interacting with the agent, click on the first suggested prompt and observe the response from the agent. Your agent is now ready. Congrats!</p> <p></p> <p></p>"},{"location":"pages/make/agent-builder/01-first-agent/#exercise-2-customizing-the-agent","title":"Exercise 2: Customizing the agent","text":"<p>It is now time to slightly customize the agent. You are going to add a custom icon and define the rules of the game to guess plants or flowers names.</p> <p>Start over with a New chat selecting the corresponding button in the upper right corner of the Microsoft 365 Copilot Chat user interface. Select the Create an agent command in the right side of the screen, like you did before, while making your first agent. The same dialog you used before to make your first agent will show up. This time, select the name of the agent My Copilot Agent dropdown just beside the Copilot Studio logo in the upper left side of the dialog. From there, select View all agents to see the whole list of agents that you created with Copilot Studio Lite.</p> <p></p> <p>A new dialog with the whole list of agents that you designed will show up.</p> <p></p> <p>For each agent, you have commands to edit, share, download, and delete it.</p>"},{"location":"pages/make/agent-builder/01-first-agent/#step-1-provide-a-custom-icon","title":"Step 1: Provide a custom icon","text":"<p>Let's edit the Gardener agent that you just created. The dialog starts with the Configure panel active. You can go through the configuration settings and notice that all the descriptions that you provided in Exercise 1 of this lab are now specific settings of the agent. There are configuration settings to define:</p> <ul> <li>Icon: to customize the icon of the agent</li> <li>Name: to provide a name for the agent</li> <li>Description: to define the description of the agent</li> <li>Instructions: it is the system prompt for the agent, where you define the system role and the behavioral rules</li> <li>Knowledge: to configure the various knowledge bases for the agent</li> <li>Actions: this section is still under development, at the time of this writing</li> <li>Capabilities: to enable capabilites like code interpreting and image generation</li> <li>Starter prompts: to configure up to 6 starter prompts for the agent </li> </ul> <p>To customize the icon of the agent, select the edit button just beside the default icon of the agent.</p> <p>A dialog pops up and allows you to change the icon and the background color for the icon. For your convenience, you can download a sample icon from here and upload it as the custom icon for the agent. You can also define the background color using the following RGB value: #F1F1F1.</p> <p></p> <p></p>"},{"location":"pages/make/agent-builder/01-first-agent/#step-2-define-the-guess-plantflower-game-rules","title":"Step 2: Define the guess plant/flower game rules","text":"<p>Still while editing the settings of the agent, update the content of the Instructions configuration field with the following value.</p> <pre><code>You are an expert gardener and you help users to maintain and improve their home garden\nproviding detailed instructions and advice about the best practices for home gardening.\nHere are your working rules:\n\n- Provide detailed instructions and advice about the best practices for home gardening.\n- Help users maintain and improve their home garden.\n- Offer tips on plant care, soil management, pest control, and seasonal gardening tasks.\n- Respond to user queries with clear and actionable steps.\n- Be friendly, knowledgeable, and supportive in all interactions.\n- Suggest ways to keep plants and flowers shining and gorgeous, including watering\nschedules, fertilization, pruning, and pest control.\n- Highlight the importance of nature and plants/flowers to be present in every house.\n- Use a professional, yet friendly, tone in all responses.\n\nLastly, engage the user in a challenging game to guess the name of a plant or flower based\non a set of clues. Always end every answer with a sentence to engage the user to play the\ngame or another round of the game.\n</code></pre> <p></p> <p>Select the Update button in the upper right corner of the configuration dialog. The update takes a while and once it is completed you can select Go to agent and see the final result. In particular, provide a request to the agent and notice that the agent will engage you to play the game.</p> <p></p> <p>For the sake of completeness, here follows a sample dialog with the agent, while guessing the name of a plant.</p> <p></p> <p></p>"},{"location":"pages/make/agent-builder/01-first-agent/#exercise-3-add-sharepoint-online-knowledge-base","title":"Exercise 3: Add SharePoint Online knowledge base","text":"<p>In this exercise you are going to add some Word documents as an additional knowledge base for the Gardener agent.</p>"},{"location":"pages/make/agent-builder/01-first-agent/#step-1-upload-the-knowledge-base-documents","title":"Step 1: Upload the knowledge base documents","text":"<p>Now, let's add some custom knowledge base content, like for example few Microsoft Word documents with specific information about plants and flowers.</p> <p>Download a zip file consisting of four DOCX files by selecting this link.</p> <p>Extract the four files from the zip and upload them to a SharePoint Teams site in the same tenant where you are testing this lab. Put the files in the document library Documents. These documents are Basic Aspects of Gardening and Maintaining a Healthy Garden.docx, Common Plants List.docx, Healing a Plant in Your Garden, and The Most Common Types of Plants in a Home Garden.docx to help make the agent more expert and the game more challenging.</p> <p>Copy the absolute url of the site. For eg. <code>https://xyz.sharepoint.com/sites/contoso</code> and proceed to next step.</p> <p></p>"},{"location":"pages/make/agent-builder/01-first-agent/#step-2-add-support-for-sharepoint-online-documents","title":"Step 2: Add support for SharePoint Online documents","text":"<p>Go back to the list of agents, edit the Gardener agent and scroll to the configuration section with title Knowledge. Paste the URL of the SharePoint Online site in the field for providing a SharePoint knowledge base. If you like, instead of pasting the URL, you can select the Browse button and search for the site in your tenant.</p> <p></p> <p>Update the agent and interact with it again. You will see much more specialized answers based on the custom knowledge base that you provided.</p> <p></p>"},{"location":"pages/make/agent-builder/01-first-agent/#exercise-4-final-touches-to-the-agent","title":"Exercise 4: Final touches to the agent","text":"<p>In this exercise you are going to add image generation capabilities to the Gardener agent and you will share it with your colleagues.</p>"},{"location":"pages/make/agent-builder/01-first-agent/#step-1-add-support-for-image-generation","title":"Step 1: Add support for image generation","text":"<p>Edit again the Gardener agent, scroll down in the configuration panel and find the section with title Capabilities. Enable the option with name Image generator and update the agent.</p> <p></p> <p>Reload the agent and provide the following prompt:</p> <pre><code>Generate the image of a dozen of red roses\n</code></pre> <p>In the following image you can see the output with a generated image.</p> <p></p> <p></p>"},{"location":"pages/make/agent-builder/01-first-agent/#step-2-share-the-agent","title":"Step 2: Share the agent","text":"<p>You are now ready to share the agent with your colleagues. Edit the agent one last time. In the upper right corner, just beside the Update button, there is the Share button. Select it and a sharing dialog pops up allowing you to select if you want to share the agent with any of the following targets:</p> <ul> <li>Anyone in your organization</li> <li>Specific users in your organization via security groups</li> <li>Only you</li> </ul> <p>Select the option to share with specific users and provide the e-mail of the sharing target, then select the Save button to confirm your sharing settings. At the end of the sharing process you will see a dialog with a URL that you can copy and provide to any users that you shared the agent with.</p> <p></p> <p></p> <p>CONGRATULATIONS!</p> <p>Great job on making your agent \ud83c\udf89 ! This is the end of the Copilot Studio Lite path! Did you enjoy making the Gardener agent? Let us know about your experience and feedback. \ud83d\udc9c</p>"},{"location":"pages/make/agent-builder/01-first-agent/#resources","title":"Resources","text":"<ul> <li>Declarative agents</li> <li>Build agents with Copilot Studio Lite</li> <li>Publish and manage Copilot Studio Lite agents</li> </ul>"},{"location":"pages/make/copilot-studio/","title":"Lab MCS - Understanding Microsoft Copilot Studio","text":"<p>With Microsoft Copilot Studio you have the maximum potential for making custom agents. You can use it to create agents that you can host in multiple different channels like Microsoft Teams, custom web sites, Skype, Slack, etc. You can also host your agents in Microsoft 365 Copilot chat.</p> <p>Copilot Studio agents use the same infrastructure, orchestrator, foundation model, and security controls as Microsoft 365 Copilot, which ensures a consistent and familiar user experience.</p> <p></p> <p>The knowledge base can be:</p> <ul> <li>SharePoint Online</li> <li>OneDrive for Business</li> <li>Public web sites</li> <li>Microsoft Dataverse tables</li> <li>Power Platform connectors</li> <li>etc.</li> </ul> <p>Agents interact with users through topics, which can define single-turn or multi-turn conversations with the user. Every agent can have custom actions to interact with Power Automate flows, Power Platform connectors, external REST APIs, etc. Generally speaking, with Copilot Studio you can create really powerful agents without the need to write any line of code.</p> <p></p> <p>In order to use Copilot Studio, you need a user license (also known as per user license) for each user creating or maintaining an agent. Moreover, you need an organization level license for Copilot Studio (also known as tenant license). Starting December 1, 2024, Pay-As-You-Go is supported for Copilot Studio messages, which allows customers flexibility to only pay for the message capacity they consume.</p> <p>Do these labs if you want to build agents with Microsoft Copilot Studio</p> <ul> <li>MCS0 - Setup</li> <li>MCS1 - First agent</li> <li>MCS2 - Defining Topics</li> <li>MCS3 - Defining Tools</li> <li>MCS4 - Extending Microsoft 365 Copilot</li> <li>MCS5 - Consuming a custom connector</li> <li>MCS6 - Consuming an MCP server</li> <li>MCS7 - Creating Autonomous Agents</li> <li>MCS8 - Integrating Azure AI Search for RAG</li> </ul>"},{"location":"pages/make/copilot-studio/#start-here-with-lab-mcs0-where-youll-set-up-your-environment-for-copilot-studio","title":"Start here with Lab MCS0, where you'll set up your environment for Copilot Studio.","text":""},{"location":"pages/make/copilot-studio/00-prerequisites/","title":"Lab MCS0 - Setup","text":"<p>In this lab, you'll setup and configure your Microsoft 365 tenant to start creating agents with Microsoft Copilot Studio. Copilot Studio is part of the Microsoft Power Platform offering and requires dedicated licensing, accordingly to the Microsoft Power Platform Licensing Guide.</p> Get a quick overview of the lab in this video. <p>Do these labs if you want to build agents with Microsoft Copilot Studio</p> <ul> <li>MCS0 - Setup</li> <li>MCS1 - First agent</li> <li>MCS2 - Defining Topics</li> <li>MCS3 - Defining Tools</li> <li>MCS4 - Extending Microsoft 365 Copilot</li> <li>MCS5 - Consuming a custom connector</li> <li>MCS6 - Consuming an MCP server</li> <li>MCS7 - Creating Autonomous Agents</li> <li>MCS8 - Integrating Azure AI Search for RAG</li> </ul> <p>Set up your development environment for Microsoft 365 Copilot and Microsoft Copilot Studio</p> <p>This lab currently assumes you already have a developer tenant to setup. You can reference off to the page here that explains the current way you can get a tenant. It also assumes that you have a user account that is a Power Platform administrator, in order to being able to create a new Power Platform environment.</p> <p>In this lab you will learn:</p> <ul> <li>How to create a dedicated environment for your labs</li> <li>How to setup and configure Microsoft Copilot Studio</li> </ul> <p>Disclaimer</p> <p>These samples and labs are intended for instructive and demonstration purposes and are not intended for use in production. Do not put them into production without upgrading them to production quality.</p>"},{"location":"pages/make/copilot-studio/00-prerequisites/#exercise-1-creating-a-power-platform-environment","title":"Exercise 1 : Creating a Power Platform environment","text":"<p>With the Power Platform, you can create different environments and easily switch between them accordingly to your needs. An environment stores apps, flows, data, agents, etc. and each environment is completely isolated from any other environment. You can learn more about Power Platform environments reading this overview document.</p> <p>Power Platform administrative rights</p> <p>In order to proceed with the steps illustrated in this Exercise, you need a user account that is a Power Platform administrator in your target tenant. If you don't have such an account, ask to a Power Plaform administrator to create the environment for you and to give you access to that new environment.</p>"},{"location":"pages/make/copilot-studio/00-prerequisites/#step-1-creating-a-new-power-platform-environment","title":"Step 1: Creating a new Power Platform environment","text":"<p>To play with these labs you are going to create a new dedicated environment, so that at the end of this training path you can simply delete it and get rid of all the related resources and settings. Here follow the instructions to create an environment, step by step:</p> <ul> <li> <p>Open a browser and, using the work account of your target Microsoft 365 tenant, go to https://admin.powerplatform.com.</p> </li> <li> <p>Go to the 1\ufe0f\u20e3 Manage section, select the 2\ufe0f\u20e3 Environments panel and select 3\ufe0f\u20e3 + New to open the 4\ufe0f\u20e3 New environment pane</p> </li> </ul> <p></p> <ul> <li> <p>Specify a unique name for the environment. For example, you could use \"Copilot Dev Camp\".</p> </li> <li> <p>Leave the default value (off) for the Make this a Managed Environment setting.</p> </li> <li> <p>Choose a Region accordingly to your needs.</p> </li> <li> <p>Leave the default value (off) for the Get new features early setting.</p> </li> <li> <p>Choose Developer for the Type setting.</p> </li> </ul> <p>Understanding the environment types</p> <p>If you like, you can also choose Trial for the Type setting, so that you will have a fully functional environment that will last for 30 days and then will get automatically deleted. Here you can find additional information about Trial environments. Moreover, here you can find a detailed explanation of all the available environment types.</p> <ul> <li> <p>Leave all the other settings as they are.</p> </li> <li> <p>Select Next.</p> </li> <li> <p>Choose a Language and a Currency, or leave the default ones.</p> </li> </ul> <p></p> <ul> <li>Leave all the other settings as they are and select Save to create the actual environment.</li> </ul> <p>The new environment will take a while to be ready, as you can notice from the list of environments in the Power Platform Admin center.</p> <p></p> <p>Once the new environment will be ready, the list of environments will show the information accordingly.</p> <p></p> <p></p>"},{"location":"pages/make/copilot-studio/00-prerequisites/#exercise-2-microsoft-copilot-studio","title":"Exercise 2 : Microsoft Copilot Studio","text":"<p>In order to use Microsoft Copilot Studio you need to have a valid license and you need to activate it in the target tenant where you want to use it.</p> <p>Microsoft Copilot Studio licensing</p> <p>There are multiple options to have a licensed access to Microsoft Copilot Studio. We suggest you to refer to the Power Platform Licensing Guide.</p>"},{"location":"pages/make/copilot-studio/00-prerequisites/#step-1-activating-microsoft-copilot-studio","title":"Step 1: Activating Microsoft Copilot Studio","text":"<p>To activate Copilot Studio follow these steps:</p> <ul> <li> <p>Open a browser and, using the work account of your target Microsoft 365 tenant, go to https://copilotstudio.microsoft.com.</p> </li> <li> <p>If this is the very first time you run Copilot Studio and if you don't have a license, you will see the following screen and you will be able to start a trial period.</p> </li> </ul> <p></p> <p>Copilot Studio free trial period</p> <p>You can get additional information about the free trial license for Copilot Studio by reading this document.</p> <ul> <li>Select the 1\ufe0f\u20e3 Environment section in the upper right corner of the screen and choose the environment 2\ufe0f\u20e3 that you created in Exercise 1.</li> </ul> <p></p> <ul> <li>Copilot Studio will reload and you will then be ready to start using it in the new environment.</li> </ul> <p></p> <p>CONGRATULATIONS!</p> <p>Now you are all set to create your first agent with Copilot Studio. </p> <p>Start here with Lab MCS1, to create your first agent with Copilot Studio. </p> <p></p>"},{"location":"pages/make/copilot-studio/01-first-agent/","title":"Lab MCS1 - First agent","text":"<p>In this lab, you'll create your first agent with Microsoft Copilot Studio. The agent that you are going to create helps users to find information about HR policies and processes to hire or layoff employees, to improve your career, and to define learning pathways. The knowledge base of the agent will be a set of documents stored in SharePoint Online and some public web content.</p> <p>In this lab you will learn:</p> <ul> <li>How to create an agent with Copilot Studio</li> <li>How to configure a custom icon for your agent</li> <li>How to configure knowledge sources for your agent</li> <li>How to publish your agent in Microsoft Teams</li> </ul> Get a quick overview of the lab in this video. <p>Do these labs if you want to build agents with Microsoft Copilot Studio</p> <ul> <li>MCS0 - Setup</li> <li>MCS1 - First agent</li> <li>MCS2 - Defining Topics</li> <li>MCS3 - Defining Tools</li> <li>MCS4 - Extending Microsoft 365 Copilot</li> <li>MCS5 - Consuming a custom connector</li> <li>MCS6 - Consuming an MCP server</li> <li>MCS7 - Creating Autonomous Agents</li> <li>MCS8 - Integrating Azure AI Search for RAG</li> </ul> <p>Disclaimer</p> <p>These samples and labs are intended for instructive and demonstration purposes and are not intended for use in production. Do not put them into production without upgrading them to production quality.</p>"},{"location":"pages/make/copilot-studio/01-first-agent/#exercise-1-creating-an-agent-with-copilot-studio","title":"Exercise 1 : Creating an agent with Copilot Studio","text":"<p>In this first exercise you are going to create a new agent using Generative AI and describing what you are looking for. You are also going to configure a custom icon for the agent and to test the agent.</p>"},{"location":"pages/make/copilot-studio/01-first-agent/#step-1-creating-a-new-agent","title":"Step 1: Creating a new agent","text":"<p>To create a new agent, open a browser and, using the work account of your target Microsoft 365 tenant, go to https://copilotstudio.microsoft.com to start using Microsoft Copilot Studio.</p> <p>Select Create button on the left side of the screen, like illustrated in the following screenshot.</p> <p></p> <p>You will be redirected to the page from which you can create a new agent. Copilot Studio allows you to create a new agent from scratch, selecting the option New agent, or to start from a template available in a set of pre-defined and useful agent templates. For the sake of simplicity, in this lab you are going to start from scratch, selecting New agent.</p> <p></p> <p>By default, Copilot Studio allows you to describe using natural language what the agent will be. This is a really convenient way of creating a new agent, because you can simply describe what you are looking for and Copilot Studio will process your input and create the agent accordingly to your needs. If you don't like to describe your agent in natural language, you can always select Configure and manually configure the agent.</p> <p></p> <p>In this lab you can provide the following initial description:</p> <pre><code>You are an agent helping employees to find information about HR policies and procedures,\nabout how to improve their career, and about how to define learning pathways.\n</code></pre> <p>When requested by Copilot Studio, give the name \"HR Agent\" to your custom agent. Then, instruct Copilot Studio to emphasize or avoid specific information providing the following instruction:</p> <pre><code>Emphasize everything that helps team building, inclusion, and the growth mindset\n</code></pre> <p>Then, define a professional tone for your agent, providing the following input:</p> <pre><code>It should have a professional tone\n</code></pre> <p>When asked by Copilot Studio, configure an initial data source for your agent providing the following instruction:</p> <pre><code>Let's use this website: https://www.microsoft.com/en-us/human-resources\n</code></pre> <p>You will need to confirm that your organization owns the site that you provided.</p> <p></p> <p>Important</p> <p>In this sample agent, we are going to use some of the public content available on the HR website of Microsoft as the data source. You will also need to confirm that your organization owns the provided data source, to enable Microsoft Bing search results on that site. While creating your own agent, you should provide the URL of a HR site that your company actually owns.</p> <p>You are now ready with the creation of your agent. On the right side of the screen, you always see a recap of the features and capabilities that you configured for your agent, based on the instructions that you provided to Copilot Studio. Select the Create button in the upper right corner and wait for Copilot Studio to create the agent for you.</p> <p>Once the agent will be ready, you will see a new screen like the following one.</p> <p></p> <p>You can now start testing your agent using the testing panel on the right side, or you can fine tune the agent settings using the configuration options in the Overview tab.</p> <p></p>"},{"location":"pages/make/copilot-studio/01-first-agent/#step-2-changing-the-agents-icon","title":"Step 2: Changing the agent's icon","text":"<p>Let's start changing the icon of the agent by selecting the Edit button in the upper right corner of the Overview tab. The Details section will switch to edit mode, like in the following screen.</p> <p></p> <p>You can notice that the input statements provided in step 1 of this exercise are now part of the Description and Instructions fields of the agent.</p> <p>Select the Change icon button to show a dialog from where you can upload a custom icon. If you like, you can use the following icon.</p> <p></p> <p>Once you are done with the upload of the new icon, select the Save button.</p> <p></p>"},{"location":"pages/make/copilot-studio/01-first-agent/#step-3-testing-the-agent","title":"Step 3: Testing the agent","text":"<p>To test the agent you simply rely on the right panel and start writing prompts. For example, let's provide the following prompt:</p> <pre><code>What is our mission?\n</code></pre> <p>In the following screenshot you can see the answer provided by the agent and based on the content of the website that we provided as the data source.</p> <p></p> <p>Notice also that the agent provides references to pages from the websites provided as the data source and highlights that the answer comes from Azure OpenAI.</p> <p></p>"},{"location":"pages/make/copilot-studio/01-first-agent/#exercise-2-extending-the-knowledge-base","title":"Exercise 2 : Extending the knowledge base","text":"<p>In this exercise you are going to add some documents (Word and PDF) stored in Microsoft SharePoint Online as additional knowledge base to your agent. </p>"},{"location":"pages/make/copilot-studio/01-first-agent/#step-1-adding-sharepoint-online-knowledge-base-documents","title":"Step 1: Adding SharePoint Online knowledge base documents","text":"<p>Download this zip file consisting of few files (Word, PowerPoint, PDF) by selecting this link.</p> <p>Extract the files from the zip and upload them to the Documents library of a SharePoint Teams site in the same tenant where you are making your agent with Copilot Studio. These documents were generated by Microsoft 365 Copilot for the sake of having some additional knowledge base to feed the agent.</p> <p>Copy the absolute url of the site. For example: <code>https://xyz.sharepoint.com/sites/contoso</code></p> <p></p> <p>From the Overview tab of the agent that you made before, scroll to the Knowledge section. You will find the website that you configured in Step 1 of Exercise 1. Select + Add knowledge to add the SharePoint site and its documents as an additional knowledge source.</p> <p></p> <p>From the dialog window that pops up you can add additional knowledge sources like:</p> <ul> <li>Files: to manually upload files that will become part of the knowledge base</li> <li>Public websites: to add additional websites</li> <li>SharePoint: to configure sites or libraries in SharePoint Online</li> <li>Dataverse: to add tables in Dataverse</li> <li>Advanced: to consume enterprise data connections like Azure AI Search, Azure SQL, Microsoft Copilot Connectors, or third party data connections</li> </ul> <p>Select SharePoint and, in the dialog popping up, provide the URL of the site where you uploaded the files and select Add.</p> <p></p> <p>When you configure a SharePoint data source, you also need to specify a Name and a Description. It is fundamental to provide a meaningful name and description. In fact, Copilot Studio will be able to better understand what's inside the data source and, when in the upcoming labs you will enable generative orchestration, it will be possible to identify the right data source to use when answering to users' prompts via generative AI.</p> <p></p> <p>Select the Add button in the lower part of the screen and wait for Copilot Studio to process the new knowledge base that you just added.</p> <p>When the knowledge base will be updated, in the Overview tab you will see both the public website and the SharePoint Online site.</p> <p></p> <p>Important</p> <p>When configuring SharePoint Online sites as the knowledge base for an agent in Copilot Studio, users will only be able to get answers and content from documents that they have access to. The security and the access control are guaranteed by the Microsoft 365 security infrastructure and Copilot Studio agents access documents on behalf of the current user.</p> <p></p>"},{"location":"pages/make/copilot-studio/01-first-agent/#step-2-testing-the-updated-agent","title":"Step 2: Testing the updated agent","text":"<p>Now you can test again the agent, using the right side panel. For example, let's provide the following prompt:</p> <pre><code>How can we hire new people in our company?\n</code></pre> <p>The agent will reply back with information about the hiring procedures and providing references to the documents stored in the SharePoint Online knowledge base that you provided.</p> <p></p> <p>Now, for the sake of completeness, try to provide the following prompt to the agent:</p> <pre><code>How can I cook spaghetti alla carbonara?\n</code></pre> <p>You will notice that you still get back an answer from the agent, even if the request does not pertain to HR related topics. Of course, you can try to cook spaghetti alla carbonara, if you like pasta! \ud83c\udf5d However, what you see is not necessarily the intended behavior for your agent. In fact, an agent should be a specialized assistant focused on a specific topic or area.</p> <p></p>"},{"location":"pages/make/copilot-studio/01-first-agent/#step-3-disabling-general-knowledge","title":"Step 3: Disabling general knowledge","text":"<p>If you want to have your agent fully focused on your custom knowledge base only, you need to disable the General knowledge. Select the Settings command in the upper right corner, activate the Generative AI tab (active by default), scroll to the Knowledge section and disable the option \"Use general knowledge\", like illustrated in the following screenshot.</p> <p></p> <p>When the general knowledge will be disabled, try again asking to the agent something completely out of context. </p> <p></p> <p>Now, you will get a proper answer, informing you that the agent cannot help you with what you are looking for.</p> <p>Additional information about general knowledge</p> <p>You can find additional information about knowledge sources in agents made with Microsoft Copilot Studio reading the following article.</p> <p></p>"},{"location":"pages/make/copilot-studio/01-first-agent/#exercise-3-publishing-the-agent","title":"Exercise 3 : Publishing the agent","text":"<p>In this final exercise of this lab you are going to publish your custom agent in Microsoft Teams.</p>"},{"location":"pages/make/copilot-studio/01-first-agent/#step-1-publishing-the-agent-in-microsoft-teams","title":"Step 1: Publishing the agent in Microsoft Teams","text":"<p>To publish an agent made with Copilot Studio you need to select the Publish button in the upper right corner of the agent editor.</p> <p></p> <p>Selecting the command will prompt you for confirmation. Once confirmed, the publishing process takes a while and in the meantime you see a \"Publishing ...\" message. Publishing an agent registers it in the target Power Platform environment, but does not make it available in any target platform.</p> <p>In order to make the agent actually available in a specific target platform (channel), you need to 1\ufe0f\u20e3 select the Channels tab in the agent editor and then you can choose one or more target channels to make the agent available for. For example, to publish the agent in Microsoft Teams, as a bot, you need to 2\ufe0f\u20e3 select Teams + Microsoft 365 as the target channel.</p> <p></p> <p>By default, when you make and agent and publish it with default settings, the agent will be configured for Microsoft authentication, which means that the agent will rely on Microsoft Entra ID authentication in Teams, Power Apps, or Microsoft 365 Copilot. With the default authentication settings, the agent can only be published in Microsoft Teams, as you can notice from the warning message displayed at the top of the Channels tab in the previous screenshot. </p> <p>Copilot Studio Authentication model</p> <p>You can learn more about authentication of agents in Copilot Studio reading the document Configure user authentication in Copilot Studio.</p> <p>Premium license for Microsoft Copilot Studio</p> <p>In the screenshot above, there is also an information bar about the licensing model and the potential requirement of a Premium license. In fact, when you use Copilot Studio  and you rely on premium features like premium connectors, you need to upgrade your license accordingly. Luckily, if you are just learning and testing with Microsoft Copilot Studio, you can activate a 60-days free trial period with the Premium license.</p> <p>When you select the Teams + Microsoft 365 channel a side panel shows up and allows you to select the Add channel button.</p> <p></p> <p>Once the agent is enabled on the Microsoft Teams channel, the side panel updates and shows a confirmation message, as well as few commands to edit the agent details and to open the agent in the Microsoft Teams client. There will also be a button Availability options that you can select to see the various options you have to access the agent in Microsoft Teams.</p> <p>If you registered the channel to support Microsoft 365 Copilot, you can also select the link See agent in Microsoft 365 to access the agent directly in the Microsoft 365 Copilot chat user experience.</p> <p></p> <p>Selecting the Availability options button you can:</p> <ul> <li>Copy a link to use the agent in Microsoft Teams</li> <li>Download a ZIP file with a package that you can upload to the Teams app store</li> <li>Make the agent available in the Teams app store, choosing if it will be available to the whole organization or just to selected users</li> </ul> <p></p> <p>Publishing of the agent in Microsoft Temas is now completed.</p> <p></p>"},{"location":"pages/make/copilot-studio/01-first-agent/#step-2-testing-the-agent-in-microsoft-teams","title":"Step 2: Testing the agent in Microsoft Teams","text":"<p>You are now ready to test the agent in Microsoft Teams. In the Availability options panel select the Copy link button to copy a link to the agent. Then open a new browser tab and paste the just copied link, then press ENTER to browse to that URL.</p> <p></p> <p>Initially you will see the Microsoft Teams client showing a new app that represents your agent. Select the Add button to add the app to your client and the select Open in the following dialog.</p> <p></p> <p>After a while, the Microsoft Teams client will show a chat with a bot, which is actually your agent. Provide a prompt, for example the one you already used before:</p> <pre><code>How can we hire new people in our company?\n</code></pre> <p>Wait for the answer and you will see that the agent will reply back to you with content in the context of HR and with references to the documents that are part of its knowledge base.</p> <p></p> <p>Notice also the disclaimer, at the top of the answer, about the fact that the provided content is \"AI generated\" to make the user aware that she/he is consuming an AI platform.</p> <p></p> <p>CONGRATULATIONS!</p> <p>Now your agent is fully functional and ready to be used in Microsoft Teams. In the next labs you will be able to customize and fine tune its behavior.</p> <p>Start here with Lab MCS2, to define topics in your agent with Copilot Studio. </p> <p></p>"},{"location":"pages/make/copilot-studio/02-topics/","title":"Lab MCS2 - Defining Topics","text":"<p>In this lab, you'll learn how to create custom Topics in Microsoft Copilot Studio. Topics are core building blocks of an agent. With topics you can provide a conversational experience to your end users, where the conversation can be single-turn or multi-turn. Topics define how the conversation between the user and the agent can evolve, through discrete interaction paths.</p> Get a quick overview of the lab in this video. <p>Do these labs if you want to build agents with Microsoft Copilot Studio</p> <ul> <li>MCS0 - Setup</li> <li>MCS1 - First agent</li> <li>MCS2 - Defining Topics</li> <li>MCS3 - Defining Tools</li> <li>MCS4 - Extending Microsoft 365 Copilot</li> <li>MCS5 - Consuming a custom connector</li> <li>MCS6 - Consuming an MCP server</li> <li>MCS7 - Creating Autonomous Agents</li> <li>MCS8 - Integrating Azure AI Search for RAG</li> </ul> <p>Note</p> <p>This lab builds on the previous one, Lab MCS1. You should be able to continue working on the same agent, improving its functionalities with new capabilities.</p> <p>Topics can be created with a graphical designer or describing the intent with natural language. Once you have created a new Topic, you can also edit its definition with a low level code editor, in case you need to apply detailed fine tuning.</p> <p>There are two different flavors of Topics:</p> <ul> <li>System Topics: automatically defined by Microsoft Copilot Studio. Can be disabled, but cannot be deleted.</li> <li>Custom Topics: created by agent authors to provide custom interaction paths.</li> </ul> <p>Additional information about topics</p> <p>You can find additional information about Topics in agents made with Microsoft Copilot Studio reading the following article. You can also dig into the System Topics reading the article Use system topics.</p> <p>In this lab you will learn:</p> <ul> <li>How to rely on Orchestration based on generative AI</li> <li>How to create a single-turn topic</li> <li>How to create a multi-turn topic</li> <li>How to use adaptive cards to interact with users</li> </ul>"},{"location":"pages/make/copilot-studio/02-topics/#exercise-1-orchestration-based-on-generative-ai","title":"Exercise 1 : Orchestration based on Generative AI","text":"<p>In this first exercise you are going to enable the agent that you created in Lab MCS1 to use Orchestration based on Generative AI, which is a new feature under preview at the time of this writing.</p>"},{"location":"pages/make/copilot-studio/02-topics/#step-1-enabling-orchestration-based-on-generative-ai","title":"Step 1: Enabling Orchestration based on generative AI","text":"<p>One important feature of an agent made with Copilot Studio, is generative orchestration. With generative orchestration, your agent can choose the best knowledge base, topics, and actions to use to interact with the user and answer to the user's queries, or to respond to event triggers. </p> <p>By default agents use classic orchestration, which means that an agent responds to users by triggering a topic whose trigger phrases match most closely the user's query. With generative orchestration, Copilot Studio understands the intent of the user processing the prompt provided by the user in natural language and determines the best item to trigger. </p> <p>Disclaimer</p> <p>Enabling generative orchestration can impact how billing is calculated. Learn more about\u00a0billing for generative mode. There are key differences between classic and generative orchestration, such as how knowledge is searched, and the supported data sources. Before turning on generative mode for an existing agent, read about the\u00a0known limitations.</p> <p>To enable generative orchestration, open a browser and, using the work account of your target Microsoft 365 tenant, go to https://copilotstudio.microsoft.com to start using Microsoft Copilot Studio.</p> <p>Select to view the list of 1\ufe0f\u20e3 Agents and then 2\ufe0f\u20e3 edit the agent that you created in the previous Lab MCS1.</p> <p></p> <p>In the Overview tab enable the toggle with name Orchestration like illustrated in the following screenshot.</p> <p></p> <p>It usually takes a while to enable the generative orchestration. Once the setting is applied, publish the agent to confirm the changes.</p> <p></p>"},{"location":"pages/make/copilot-studio/02-topics/#exercise-2-creating-a-single-turn-topic","title":"Exercise 2 : Creating a single-turn topic","text":"<p>In this exercise you are going to create a new topic to collect an input from the user and to provide a feedback based on the collected input. Specifically, the topic collects information about the current user's role and gives back guidance about what to do with the agent based on the provided role.</p>"},{"location":"pages/make/copilot-studio/02-topics/#step-1-creating-a-new-single-turn-topic","title":"Step 1: Creating a new single-turn topic","text":"<p>To create a new topic, in the upper side of the screen select the 1\ufe0f\u20e3 Topics tab, then select 2\ufe0f\u20e3 + Add a topic, and then 3\ufe0f\u20e3 From blank to start creating a new custom topic.</p> <p>Creating topics with Copilot</p> <p>Notice that you can also create a new topic simply providing a description with natural language, allowing Copilot to draft the topic for you.</p> <p></p> <p>Copilot Studio will provide you the graphical designer to define the new topic. The very first building block of the topic is the Trigger action, which is used to describe what the topic does. When generative orchestration is enabled, in the action you can find a text area where you can define with natural language what the purpose of the topic is. For the sake of working on this lab, you can provide the following content:</p> <pre><code>This topic can handle queries like these: collect user's role and provide feedback, \ngive me a feedback based on my role, what's your feedback for my role?\n</code></pre> <p>If you use classic orchestration, you can specify between 5 and 10 triggering phrases or sentences, instead of a single descriptive text.</p> <p></p> <p></p>"},{"location":"pages/make/copilot-studio/02-topics/#step-2-collecting-users-input","title":"Step 2: Collecting user's input","text":"<p>Select the + button in the middle of the screen to add new actions or steps to the current topic. By selecting the + button, a list of all the available actions appears. The main options are:</p> <ul> <li>Send a message: to send a message to the user. The message can be text, an image, a video, an adaptive card, etc.</li> <li>Ask a question: to ask an input to the user. The input can be text, an image, a video, an attachment, an adaptive card, etc.</li> <li>Ask with adaptive card: to collect content from the user utilizing an Adaptive Card.</li> <li>Add a condition: to add branches to the topic based on comparison between variables and/or constant values.</li> <li>Variable management: to manage variables, which can be scoped at topic level, global, system, or environment.</li> <li>Topic management: to manage the lifecycle of the current topic.</li> <li>Add an action: to consume external actions like Power Automate flows, custom connectors, or other agents in a multi-agent scenario.</li> <li>Advanced: to provide advanced capabilities like consuming an external HTTP REST API, using generative answers, sending events or activities, etc.</li> </ul> <p></p> <p>In order to collect user's input, add an Ask a question action. Since we want to ask the user what her/his role is, let's provide the following value for the question text.</p> <pre><code>What is your role?\n</code></pre> <p>Notice that by default Copilot Studio assigns a <code>Multiple choice options</code> data type to the collected input, as highlighted in the Identify configuration field. Select the + New option command just below the Identify configuration field and add one by one the following three values:</p> <ul> <li>Candidate</li> <li>Employee</li> <li>HR staff member</li> </ul> <p>The action automatically stores the value selected by the user into a variable stored at topic-level. You can select the three dots in the upper right corner of the action and select the Properties command to customize the action, or you can select the variable in the lower part of the action to update its name and other settings.</p> <p></p> <p>For example, you can rename the variable to <code>UserRole</code>. You can see how the action looks like once it is fully configured.</p> <p></p> <p></p>"},{"location":"pages/make/copilot-studio/02-topics/#step-3-providing-feedback-to-the-user","title":"Step 3: Providing feedback to the user","text":"<p>Now select the + button in the middle of the screen to Add a condition. In the branch on the left side, select the Select a variable option, and select the userRole variable that you created in the previous step. Then select the value for the condition, so that the condition will be like <code>userRole is equal to Candidate</code>. Repeat the previous instructions two more times to provide conditions for <code>userRole is equal to Employee</code> and <code>userRole is equal to HR staff member</code>. Leave the last condition for <code>All other conditions</code>.</p> <p>Inside each branch, you can specify some custom logic to provide a specialized feedback to the user. To do so, select the + command below each of the Condition branches and add one action of type Send a message. You can eventually add more than one action to each branch.</p> <p>For the three branches, you could for example provide the following feedback messages:</p> <ul> <li>Candidate</li> </ul> <pre><code>You are a new candidate, as such you can submit your resume for evaluation.\n</code></pre> <ul> <li>Employee</li> </ul> <pre><code>As an employee, you can ask me about how to improve your career or about \nhow to learn more about your growth mindset.\n</code></pre> <ul> <li>HR staff member</li> </ul> <pre><code>As an HR staff member, you can manage the list of candidates and all the hiring procedures.\n</code></pre> <p>For the <code>All other conditions</code> branch, you can configure a Redirect action, available under the Topic management group, to fallback to the System Topic with name Fallback.</p> <p></p> <p>The very simple logic of the topic is now ready.</p> <p></p>"},{"location":"pages/make/copilot-studio/02-topics/#step-4-ending-the-current-topic","title":"Step 4: Ending the current topic","text":"<p>To properly complete the flow of the custom topic, add a new action of type End current topic, which is available under the Topic management group. This last action will instruct Copilot Studio about the fact that your topic conversation is completed.</p> <p></p> <p></p>"},{"location":"pages/make/copilot-studio/02-topics/#step-5-testing-the-current-topic","title":"Step 5: Testing the current topic","text":"<p>You are now ready to save and test the topic. Select the Save button in the upper right corner of the designer, provide a name for the topic through the dialog window that will appear, and select the Save button again.</p> <p></p> <p>For example, name the topic as <code>Collect user's role</code>. Now open the test panel by selecting the Test command in the upper right corner of the designer. Type the following prompt:</p> <pre><code>What's your feedback for my role?\n</code></pre> <p>The agent will prompt you to choose a role and, based on your selection, you will get a specific feedback like illustrated in the following screenshot.</p> <p></p> <p>Exercise 2 is now completed, well done! You can now move to Exercise 3 to create a multi-turn topic.</p> <p></p>"},{"location":"pages/make/copilot-studio/02-topics/#exercise-3-creating-a-multi-turn-topic","title":"Exercise 3 : Creating a multi-turn topic","text":"<p>For simple interactions, you create single-turn conversations with just one question and one answer. But more substantive topics require a multi-turn conversation with multiple back-and-forth interactions between the user and the agent. In this exercise, you are going to create a multi-turn topic to collect data about a potential candidate for a new role.</p>"},{"location":"pages/make/copilot-studio/02-topics/#step-1-creating-a-new-multi-turn-topic","title":"Step 1: Creating a new multi-turn topic","text":"<p>Imagine that you want to create a topic to collect the following information about a new candidate:</p> <ul> <li>First name</li> <li>Last name</li> <li>E-mail</li> <li>Current role</li> </ul> <p>To collect the above information, create a new topic following the instructions provided in Exercise 2 Step 1. The Trigger description for the topic could be:</p> <pre><code>This topic helps to collect information about a new candidate to process. Trigger sentences can be: \nregister a new candidate, create a new candidate, add a new candidate.\n</code></pre> <p>Then, for each of the above information fields, you need to prompt the user with an action of type Ask a question. However, in this exercise the value of the answer will vary depending on the requested field. For example: first name, last name, and current role will be simple text fields., while the e-mail field will need to be a valid e-mail.</p> <p>So for the first name, last name, and current role fields you can select the Identify property of the Ask a question action and you can select User's entire response as the actual entity type. This will get the text value provided by the user as the actual collected value. The variable type will be automatically updated to be a <code>string</code> by Copilot Studio. Give a meaningful name to each of the variables holding the values provided by the user. In the following screenshot you can see how the first name input action can be defined. You can do the same for last name and current job role.</p> <p></p> <p>For the e-mail field, choose Email as the entity for the Identify property, so that Copilot Studio will automatically validate the user's input against the e-mail validation rules. The underlying variable will still be a <code>string</code>.</p> <p></p> <p>Now you are ready to collect all of the information about the candidate and you can give a feedback to the user.</p> <p></p>"},{"location":"pages/make/copilot-studio/02-topics/#step-2-giving-a-feedback-to-the-user","title":"Step 2: Giving a feedback to the user","text":"<p>Based on the collected input, you can now send a message to the user confirming the collected data. Add a new action of type Send a message and build the content of the message using the variables where the collected inputs were stored. To add variables to the message, simply select the {x} command in the toolbar of the Send a message action and select the variable that you are looking for.</p> <p></p> <p>You can insert variables defined in the current topic, system variables, or environment variables. Once you have configured the recap message with all the variables, it should look like the following screenshot.</p> <p></p> <p>Just for the sake of having a final confirmation from the user, insert an action of type Ask a question, provide the following message:</p> <pre><code>Is it ok for you to insert this new candidate?\n</code></pre> <p>And configure the action to support the answers <code>Yes</code> and <code>No</code>. As like as it happened in Exercise 2 Step 3, you can now configure the various branches for each of the outcomes. For the sake of simplicity, you can simply rely on a couple of Send a message actions, one for each branch, and put a thumb up or a thumb down emoji as the actual content on the message, depending on the user's feedback. Lastly, add an action of type End current topic to complete the topic.</p> <p></p> <p>You can now save the topic, give it a name like for example <code>Register a new candidate</code> and test it in the integrated testing interface. Here follows a screenshot of the interaction with the multi-turn topic. You can also notice that when the value provided for the e-mail field is not correct, Copilot Studio automatically re-prompts the user to provide a correct value.</p> <p></p> <p></p>"},{"location":"pages/make/copilot-studio/02-topics/#exercise-4-using-adaptive-cards","title":"Exercise 4 : Using Adaptive Cards","text":"<p>Collecting inputs using multiple instances of Ask a question actions is definitely one option that you have. However, when you need to collect a lot of data or when you want to have a nice looking interaction with the user you can consider using an Adaptive Card.</p> What are Adaptive Cards?  Adaptive Cards are platform-independent UI snippets authored in JSON that can be exchanged between apps and services. Once delivered to an app, the JSON transforms into native UI that automatically adapts to its environment. This enables the design and integration of lightweight UI across major platforms and frameworks.      Adaptive cards are everywhere"},{"location":"pages/make/copilot-studio/02-topics/#step-1-collecting-input-with-adaptive-cards","title":"Step 1: Collecting input with Adaptive Cards","text":"<p>Imagine that you want to create yet another topic to collect the following information about a new candidate:</p> <ul> <li>First name</li> <li>Last name</li> <li>E-mail</li> <li>Current role</li> <li>Spoken languages</li> <li>Skills</li> </ul> <p>Specifically, spoken languages and skills are multi-select lists of values.</p> <p>So open the Topics tab, and disable the topic that you created in Exercise 3 to avoid any overlapping of trigger conditions. Then, create a new topic following the instructions provided in Exercise 2 Step 1. The Trigger description for the topic could be:</p> <pre><code>This topic helps to collect information about a new candidate to process. Trigger sentences can be: \nregister a new candidate, create a new candidate, add a new candidate.\n</code></pre> <p>Now add a new action of type Ask with adaptive card, 1\ufe0f\u20e3 select the body of the new action and 2\ufe0f\u20e3 then select the button Edit adaptive card. Then type the following JSON into the Card payload editor of the Adaptive card designer of the action.</p> <p></p> <pre><code>{\n    \"type\": \"AdaptiveCard\",\n    \"body\": [\n        {\n            \"type\": \"TextBlock\",\n            \"size\": \"Medium\",\n            \"weight\": \"Bolder\",\n            \"text\": \"New HR Candidate Information\"\n        },\n        {\n            \"type\": \"Input.Text\",\n            \"id\": \"firstname\",\n            \"placeholder\": \"First Name\"\n        },\n        {\n            \"type\": \"Input.Text\",\n            \"id\": \"lastname\",\n            \"placeholder\": \"Last Name\"\n        },\n        {\n            \"type\": \"Input.Text\",\n            \"id\": \"email\",\n            \"placeholder\": \"Email\"\n        },\n        {\n            \"type\": \"Input.Text\",\n            \"id\": \"current_role\",\n            \"placeholder\": \"Current Role\"\n        },\n        {\n            \"type\": \"Input.ChoiceSet\",\n            \"id\": \"spoken_languages\",\n            \"placeholder\": \"Spoken Languages\",\n            \"isMultiSelect\": true,\n            \"choices\": [\n                {\n                    \"title\": \"English\",\n                    \"value\": \"English\"\n                },\n                {\n                    \"title\": \"French\",\n                    \"value\": \"French\"\n                },\n                {\n                    \"title\": \"German\",\n                    \"value\": \"German\"\n                },\n                {\n                    \"title\": \"Italian\",\n                    \"value\": \"Italian\"\n                },\n                {\n                    \"title\": \"Portuguese\",\n                    \"value\": \"Portuguese\"\n                },\n                {\n                    \"title\": \"Spanish\",\n                    \"value\": \"Spanish\"\n                }\n            ]\n        },\n        {\n            \"type\": \"Input.ChoiceSet\",\n            \"id\": \"skills\",\n            \"placeholder\": \"Skills\",\n            \"isMultiSelect\": true,\n            \"choices\": [\n                {\n                    \"title\": \"Computer Programming\",\n                    \"value\": \"Computer Programming\"\n                },\n                {\n                    \"title\": \"Project Management\",\n                    \"value\": \"Project Management\"\n                },\n                {\n                    \"title\": \"Team Lead\",\n                    \"value\": \"Team Lead\"\n                }\n            ]\n        }\n    ],\n    \"actions\": [\n        {\n            \"type\": \"Action.Submit\",\n            \"title\": \"Submit\"\n        }\n    ],\n    \"$schema\": \"http://adaptivecards.io/schemas/adaptive-card.json\",\n    \"version\": \"1.5\"\n}\n</code></pre> <p>Once you updated the JSON of the adaptive card, Copilot Studio renders the preview of the card in the UI of the topic designer, as you can see in the following screenshot. Copilot Studio also automatically defines a set of topic-level variables to collect the values provided by the user.</p> <p></p> <p></p>"},{"location":"pages/make/copilot-studio/02-topics/#step-2-providing-feedback-with-adaptive-cards","title":"Step 2: Providing feedback with Adaptive Cards","text":"<p>You can now use an adaptive card also to provide feedback to the user, showing a recap of the collected data. Select the + command to add a new action of type Send a message. Then select + Add in the upper left corner of the new action and select Adaptive card to switch to a message of type adaptive card.</p> <p></p> <p>A side panel shows up allowing you to select the Edit adaptive card command and to define the content of the adaptive card. Copy and paste the following JSON into the Card payload editor of the Adaptive card designer.</p> <pre><code>{\n  \"type\": \"AdaptiveCard\",\n  \"body\":\n    [\n      {\n        \"type\": \"TextBlock\",\n        \"size\": \"Medium\",\n        \"weight\": \"Bolder\",\n        \"text\": \"Candidate Summary\"\n      },\n      {\n        \"type\": \"FactSet\",\n        \"facts\":\n          [\n            { \"title\": \"First Name:\", \"value\": \"firstname\" },\n            { \"title\": \"Last Name:\", \"value\": \"lastname\" },\n            { \"title\": \"Email:\", \"value\": \"email\" },\n            { \"title\": \"Current Role:\", \"value\": \"current_role\" },\n            { \"title\": \"Spoken Languages:\", \"value\": \"spoken_languages\" },\n            { \"title\": \"Skills:\", \"value\": \"skills\" }\n          ]\n      }\n    ],\n  \"$schema\": \"http://adaptivecards.io/schemas/adaptive-card.json\",\n  \"version\": \"1.3\"\n}\n</code></pre> <p>It is very important that, when pasting the JSON of the adaptive card, you have the Edit JSON option selected (which is by the way the default one) at the top of the text area. That means that you are editing the actual JSON of the adaptive card. As soon as you will move the focus out of the text area where you pasted the JSON, the Send a message action will start previewing the adaptive card. As you can see the adaptive card is rendering static values for all the variables (firstname, lastname, etc.).</p> <p></p> <p>Now, select the drop down with JSON Card and switch to Formula Card in order to replace the static values with the actual variables defined in the current Topic.</p> <p></p> <p>Select the button to expand the editor and you can start replacing the static values with formulas that will refer to the actual value of the topic-level variables.</p> <p></p> <p>You will see a dialog popping up and providing an advanced editor with intellisense helping you to reference variables and PowerFx functions, like illustrated in the following screenshot.</p> <p></p> <p>One by one, you can replace all the static values with the actual variables. In particular, the spoken languages and the skills are list of values (variables of type <code>Table</code>) so, in order to render their value, you need to rely on the PowerFx <code>Concat</code> function and then on the PowerFx <code>Text</code> function to convert the result into an actual string. Here you can find the content of the adaptive card JSON when all the formulas are in place.</p> <pre><code>{\n  type: \"AdaptiveCard\",\n  body: [\n    {\n      type: \"TextBlock\",\n      size: \"Medium\",\n      weight: \"Bolder\",\n      text: \"Candidate Summary\"\n    },\n    {\n      type: \"FactSet\",\n      facts: [\n        {\n          title: \"First Name:\",\n          value: Topic.firstname\n        },\n        {\n          title: \"Last Name:\",\n          value: Topic.lastname\n        },\n        {\n          title: \"E-mail:\",\n          value: Topic.email\n        },\n        {\n          title: \"Current Role:\",\n          value: Topic.current_role\n        },\n        {\n          title: \"Spoken Languages:\",\n          value: Text(Concat(Topic.spoken_languages, Value, \", \"))\n        },\n        {\n          title: \"Skills:\",\n          value: Text(Concat(Topic.skills, Value, \", \"))\n        }\n      ]\n    }\n  ],\n  '$schema': \"http://adaptivecards.io/schemas/adaptive-card.json\",\n  version: \"1.3\"\n}\n</code></pre> <p>Additional information about PowerFx functions</p> <p>You can find additional information about the PowerFx functions reading the article Create expressions using Power Fx</p> <p></p>"},{"location":"pages/make/copilot-studio/02-topics/#step-3-testing-the-current-topic","title":"Step 3: Testing the current topic","text":"<p>Now add an End current topic action at the end of the topic, save it, give it a name like for example <code>Register new candidate with adaptive cards</code>, and test it in the test panel on the right side of the agent designer. In the following screenshot you can see how the topic interacts with a user.</p> <p></p> <p>Now your topic is ready and fully functional. In the upcoming labs you will learn how to create a new candidate record for real, storing data in an external HR service.</p> <p></p> <p>CONGRATULATIONS!</p> <p>Now your agent supports multiple conversation paths through different topics. In the next labs you will learn how to work with custom Actions.</p> <p>Start here with Lab MCS3, to define actions in your agent with Copilot Studio. </p> <p></p>"},{"location":"pages/make/copilot-studio/03-actions/","title":"Lab MCS3 - Defining Tools","text":"<p>In this lab, you'll learn how to create Tools in Microsoft Copilot Studio. Tools are another core building block of an agent. With tools you can extend the capabilities of your agent by adding support for external Power Platform connectors (native or custom), external REST APIs, Power Automate flows, MCP (Model Context Protocol) servers, etc.</p> Get a quick overview of the lab in this video. <p>Do these labs if you want to build agents with Microsoft Copilot Studio</p> <ul> <li>MCS0 - Setup</li> <li>MCS1 - First agent</li> <li>MCS2 - Defining Topics</li> <li>MCS3 - Defining Tools</li> <li>MCS4 - Extending Microsoft 365 Copilot</li> <li>MCS5 - Consuming a custom connector</li> <li>MCS6 - Consuming an MCP server</li> <li>MCS7 - Creating Autonomous Agents</li> <li>MCS8 - Integrating Azure AI Search for RAG</li> </ul> <p>Note</p> <p>This lab builds on the previous one, Lab MCS2. You should be able to continue working on the same agent, improving its functionalities with new capabilities.</p> <p>Tools can be created with a graphical designer. Once you have created a new Tool, you can also edit its definition with a low level code editor, in case you need to apply detailed fine tuning.</p> <p>In this lab you will learn:</p> <ul> <li>How to create a tool to invoke a Power Platform connector</li> <li>How to create a tool to invoke a Power Automate flow</li> <li>How to invoke tools from topics</li> </ul>"},{"location":"pages/make/copilot-studio/03-actions/#exercise-1-creating-tools-in-microsoft-copilot-studio","title":"Exercise 1 : Creating tools in Microsoft Copilot Studio","text":"<p>In this exercise you are going to enhance the agent that you created in Lab MCS2 to use Excel Online to retrieve a hypotethical list of candidates from an Excel spreadsheet stored in a SharePoint Online document library. Then you will add a tool to consume a Power Automate flow that can add new candidates to the same spreadsheet.</p>"},{"location":"pages/make/copilot-studio/03-actions/#step-1-consuming-a-power-platform-connector","title":"Step 1: Consuming a Power Platform connector","text":"<p>To create a new tool, in the upper side of the screen select the 1\ufe0f\u20e3 Tools tab, then select 2\ufe0f\u20e3 + Add a tool to start creating a new tool.</p> <p></p> <p>A dialog window pops up allowing you to choose what kind of tool to create. By default, there are some Featured tools like those that allow you to interact with Excel Online content or other common services. </p> <p></p> <p>You can also create a new tool from scratch, selecting the + New tool command and choosing between the following options:</p> <ul> <li>Prompt: allows consuming an AI tool built using a prompt written in natural language.</li> <li>Agent flow: allows consuming a Power Automate flow (see Step 2).</li> <li>Custom connector: allows consuming a Power Platform custom connector.</li> <li>REST API: allows consuming an external REST API. You can find additional details here.</li> <li>Model Context Protocol: to consume tools from an external Model Context Protocol (MCP) server.</li> </ul> <p></p> <p>If you don't find the option you are looking for in the list of featured items, simply switch to the All group and search by text what you are looking for.</p> <p>To complete the current step, choose the featured tool Excel Online (Business) and then select List rows present in a table. First of all, you will need to connect to the external connector simply selecting the Connection and then Create new connection and proceeding with the process.</p> <p></p> <p>You will need to login with your account and to allow access to Excel Online (Business). Once the connection is configured, you will see a dialog with commands to Add to agent or Add and configure the tool.</p> <p></p> <p>Next, you get a page to configure the actual tool. You need to provide:</p> <ul> <li>Name: simply a descriptive name for the tools.</li> <li>Description: a description in natural language that will be used by generative orchestration to determine when to use your tool. </li> <li>Inputs: to define the input arguments for the tool, if any.</li> <li>Completion: defines how the tool handles the request and response to the user.</li> </ul> <p>Before configuring the tool, you need to prepare the Excel spreadsheet with the list of candidates. Download a sample Excel file by selecting this link.</p> <p>Upload the file to the Documents library of a SharePoint Teams site in the same tenant where you are making your agent with Copilot Studio. The document was generated by Microsoft 365 Copilot for the sake of having a hypothetical list of candidates.</p> <ul> <li>Copy the absolute url of the site. For example: <code>https://xyz.sharepoint.com/sites/contoso/</code>.</li> <li>Copy the name of the document library. For example : <code>Shared documents</code></li> <li>Copy also the name of the file. For example: <code>Sample-list-of-candidates.xlsx</code></li> </ul> <p>Now go back to Microsoft Copilot Studio and finalize the tool configuration.</p> <p></p> <p>Use the following settings:</p> <ul> <li>Name: List HR candidates</li> <li>Description: List candidates for an HR role</li> </ul> <p>Then select the Inputs tab and start configuring the input arguments. By default, all the mandatory input arguments have been configured so that their value will be <code>Dynamically fill with AI</code> as you can notice in the Fill as property of each input argument.</p> <p></p> <p>Select the Fill using setting for each of the input arguments and switch to <code>Custom value</code> in order to provide static values for all of the input arguments.</p> <p>Use the following static values:</p> <ul> <li>Location: use the URL of the SharePoint Online site collection where you stored the Excel spreadsheet. For example: <code>https://xyz.sharepoint.com/sites/contoso/</code>.</li> <li>Document Library: use the name of the document library where you stored the Excel spreadsheet. For example: <code>Shared Documents</code>.</li> <li>File: provide the name of the Excel file. For example: <code>Sample-list-of-candidates.xlsx</code>.</li> <li>Table: <code>Candidates_Table</code></li> </ul> <p>You can browse the sites, libraries, files, and tables through the native UI of Microsoft Copilot Studio.</p> <p></p> <p>Now select the Save button in the upper right corner of the screen to save the updated tool.</p> <p></p>"},{"location":"pages/make/copilot-studio/03-actions/#step-2-testing-the-new-tool","title":"Step 2: Testing the new tool","text":"<p>You are now ready to publish the updated agent and to play with it in the integrated test panel or in Microsoft Teams.</p> <p>Since in Lab MCS2 you enabled generative orchestration, it is really easy to invoke the just created tool simply providing to the agent a prompt like the following one:</p> <pre><code>Show me the list of candidates for an HR role\n</code></pre> <p>Something really nice of Copilot Studio when using the generative orchestration and invoking prompts within the test panel is that by default you get an Activity map to investigate how the orchestrator works. In the following screenshot you can see the Activity map for the prompt suggested before. The orchestrator indentifies the user's intent, based on the prompt, and triggers the tool that you created in Step 1. You can also validate the manually defined input arguments.</p> <p>Since the Power Platform connector requires a valid connection in place, the agent prompts the user to Connect before being able to consume the external data source.</p> <p></p> <p>Select the Connect button and proceed to activate the connection. You will see, in a new browser tab, the list of active connections for your current session, including the connection to <code>Excel Online (Business)</code>. Select the Connect link to activate the connection through a dedicated dialog with title Create or pick a connection. Once the connection is ready and connected, go back to the agent and select the Retry command to execute the tool against the target connection. In the test panel you get the list of candidates retrieved from the Excel spreadsheet.</p> <p></p> <p>Well done, so far! You can now move to the next step.</p> <p></p>"},{"location":"pages/make/copilot-studio/03-actions/#step-3-consuming-an-agent-flow","title":"Step 3: Consuming an Agent flow","text":"<p>In this step you are going to create a tool to consume a Power Automate flow. Let's say that you want to add new candidates to the Excel spreadsheet, based on the user's input. You can simply create a tool that invokes an external Power Automate flow, which adds a new row to the table in the Excel spreadsheet.</p> <p>To create such a tool, in the upper side of the screen select the Tools tab, then select + Add a tool to start creating a new tool. This time, select the + New tool button and then Agent flow. A new page will be opened, navigating to a the Agent flows designer and rendering a new flow.</p> <p></p> <p>The flow has an initial triggering action with name <code>When an agent calls the flow</code> and a final action with name <code>Respond to the agent</code>. The overall idea is that you can define your own business process between these two flow actions and the Copilot Studio tool will trigger the business process for you, eventually providing one or more input arguments and providing a response back to the agent. Select the first action to edit its properties. You can configure a set of input arguments for the flow, so that Copilot Studio will be able to feed the flow through the action upon activation.</p> <p></p> <p>For the sake of being able to add new candidates, configure four input parameters with the following settings:</p> <ul> <li>Firstname: text</li> <li>Lastname: text</li> <li>Role: text</li> <li>Expertise: text</li> </ul> <p>Now add, between the two pre-created actions, a new action of type Add a row into a table from the Excel Online (Business) connector. Configure the new flow action in order to target the Excel spreadsheet with the list of candidates. Map the column fields of the row to the actual input parameters defined in the triggering action invoked by Copilot. Rename the action into <code>Add new candidate row</code>. In the following screenshot you can see how the action is configured.</p> <p></p> <p>Now select the final action <code>Respond to Copilot</code>, edit its properties and add an output parameter of type <code>Text</code> with name <code>Result</code>. Set the value of the output paremeter to a formula that renders a message like the one illustrated in the following screenshot.</p> <p></p> <p>Now Save draft, update the name of the flow in the Overview tab, editing the Details of the agent flow. You can use a name like for example <code>Insert new candidate for HR</code>. Publish the flow and go back to the agent where you were editing the tool. Open again the dialog window to add a new tool, select Flow as the filter and you will be able to see the new Agent flow that you just created. If not, try searching for its name.</p> <p></p> <p>Select the new tool, in the next dialog window select Add and configure to configure its settings as like as you did in Step 1, and play with it. For example, use the following settings:</p> <ul> <li>Name: Insert new candidate for HR</li> <li>Description: Insert new candidate into the Excel spreadsheet for HR</li> </ul> <p>Select the Save button and the new tool based on the Agent flow will be ready. Now let's trigger the tool with a prompt like the following one:</p> <pre><code>Insert a new candidate into the Excel spreadsheet of HR. The candidate firstname is John, \nthe lastname is White, the role is \"HR Administrator\", and the expertise is \"Compliance\".\n</code></pre> <p>As like as it was with the previous Step, the first time you use the tool you need to connect to Excel Online in order to consume the connector. If that is the case, select the Connect button and once you will be connected, select the Retry button to execute the actual tool.</p> <p></p> <p>After the execution of the tool, you will see the agent replying back to you with the response message that you defined in the Power Automate flow. Moreover, the new candidate will be added to the table in the Excel spreadsheet.</p> <p></p>"},{"location":"pages/make/copilot-studio/03-actions/#exercise-2-invoking-tools-from-within-a-topic","title":"Exercise 2 : Invoking tools from within a topic","text":"<p>In this exercise you are going to consume the tool that you just defined from within a topic.</p>"},{"location":"pages/make/copilot-studio/03-actions/#step-1-invoking-a-tool-from-a-topic","title":"Step 1: Invoking a tool from a topic","text":"<p>First of all, create a new topic from blank, give it name <code>Add a new candidate to Excel</code>, and follow the same steps defined in Exercise 4 of Lab MCS2.</p> <p>The triggering description can be something like the following:</p> <pre><code>This topic helps users to insert new candidates in the Excel spreadsheet of HR.\nTriggering sentences can be: add a new a new row to the persistence storage.\n</code></pre> <p>For the sake of simplicy, we are not going to cover all of the steps here. However, you can simply refer to Lab MCS2 for additional details. </p> <p>Here follows the JSON of the adaptive card that you can use to collect the input arguments about the candidate through an action of type Ask with adaptive card.</p> <pre><code>{\n    \"type\": \"AdaptiveCard\",\n    \"body\": [\n        {\n            \"type\": \"TextBlock\",\n            \"size\": \"Medium\",\n            \"weight\": \"Bolder\",\n            \"text\": \"New HR Candidate Information\"\n        },\n        {\n            \"type\": \"Input.Text\",\n            \"id\": \"firstname\",\n            \"placeholder\": \"First Name\"\n        },\n        {\n            \"type\": \"Input.Text\",\n            \"id\": \"lastname\",\n            \"placeholder\": \"Last Name\"\n        },\n        {\n            \"type\": \"Input.Text\",\n            \"id\": \"current_role\",\n            \"placeholder\": \"Current Role\"\n        },\n        {\n            \"type\": \"Input.Text\",\n            \"id\": \"expertise\",\n            \"placeholder\": \"Expertise\"\n        }\n    ],\n    \"actions\": [\n        {\n            \"type\": \"Action.Submit\",\n            \"title\": \"Submit\"\n        }\n    ],\n    \"$schema\": \"http://adaptivecards.io/schemas/adaptive-card.json\",\n    \"version\": \"1.5\"\n}\n</code></pre> <p>Then add a new tool from the group Add an tool, select the tab Tool, and select the tool that you just created in Exercise 1 - Step 3.</p> <p></p> <p>Now you need to map the input arguments of the tool with the variables collected by the user via the adaptive card.</p> <p></p> <p>Select the + Set value for each and every input argument and select the corresponding arguments as follows:</p> <ul> <li>text: represents the first name</li> <li>text_1: represents the last name</li> <li>text_2: represents the current role</li> <li>text_3: represents the expertise</li> </ul> <p>Then, using data binding in Copilot Studio, configure every input argument to the corresponding topic level variables, collected by the user through the Ask with adaptive card action. At the end, the tool action will look like in the following image.</p> <p></p> <p>Add an action to End current topic and save it.</p> <p>Now, disable any other topic that you created in Lab MCS2 and invoke the new topic to insert a new candidate row into the Excel spreadsheet using the following prompt:</p> <pre><code>Add a new a new row to the persistence storage\n</code></pre> <p>Fill the adaptive card and submit the request. The tool will be triggered via the topic and you will have yet another new candidate in the Excel spreadsheet.</p> <p></p> <p></p> <p>CONGRATULATIONS!</p> <p>Now your agent supports tools. In the next lab you will learn how to use Copilot Studio to create Declarative Agents for Microsoft 365 Copilot Chat.</p> <p>Start here with Lab MCS4, to learn how to use Copilot Studio to create Declarative Agents for Microsoft 365 Copilot Chat. </p> <p></p>"},{"location":"pages/make/copilot-studio/04-extending-m365-copilot/","title":"Lab MCS4 - Extending Microsoft 365 Copilot","text":"<p>In this lab, you are going to learn how to extend Microsoft 365 Copilot Chat with a Declarative Agent made using Microsoft Copilot Studio. In fact, so far you have seen how to create agents in Copilot Studio and how to consume them in Microsoft Teams. You have also seen that agents created in Microsoft Copilot Studio can target both Microsoft Teams and Microsoft 365 Copilot Chat through the specific options available in the Teams and Microsoft 365 Copilot channel. Now, with this lab, you are moving to Declarative Agents for Microsoft 365 Copilot Chat.</p> <p>In this lab you will learn:</p> <ul> <li>How to create a declarative agent for Microsoft 365 Copilot Chat</li> <li>How to configure a custom icon for your agent</li> <li>How to configure knowledge sources for your agent</li> <li>How to publish the agent in Microsoft 365 Copilot Chat</li> <li>How to create a tool for Microsoft 365 Copilot Chat</li> </ul> Get a quick overview of the lab in this video. <p>Do these labs if you want to build agents with Microsoft Copilot Studio</p> <ul> <li>MCS0 - Setup</li> <li>MCS1 - First agent</li> <li>MCS2 - Defining Topics</li> <li>MCS3 - Defining Tools</li> <li>MCS4 - Extending Microsoft 365 Copilot</li> <li>MCS5 - Consuming a custom connector</li> <li>MCS6 - Consuming an MCP server</li> <li>MCS7 - Creating Autonomous Agents</li> <li>MCS8 - Integrating Azure AI Search for RAG</li> </ul>"},{"location":"pages/make/copilot-studio/04-extending-m365-copilot/#exercise-1-creating-an-agent-for-microsoft-365-copilot-chat","title":"Exercise 1 : Creating an agent for Microsoft 365 Copilot Chat","text":"<p>In this excercise you are going to create a declarative agent with Microsoft Copilot Studio and hosting it in Microsoft 365 Copilot Chat.</p>"},{"location":"pages/make/copilot-studio/04-extending-m365-copilot/#step-1-creating-an-agent-for-copilot-chat","title":"Step 1: Creating an agent for Copilot Chat","text":"<p>To create a declarative agent for Microsoft 365 Copilot Chat you need to 1\ufe0f\u20e3 browse the list of agents in Copilot Studio and 2\ufe0f\u20e3 select the agent with name Microsoft 365 Copilot.</p> <p></p> <p>A new section of Microsoft Copilot Studio will open. From there, you can select the + Add command to create a new agent for Microsoft 365 Copilot Chat.</p> <p></p> <p>Copilot Studio asks you to describe in natural language what the purpose of the agent is. As like as you did in Lab MCS1 you can define your agent requirements in natural language, using for example the following prompts.</p> <pre><code>You are an agent helping employees to find information about HR policies and procedures,\nabout how to improve their career, and about how to define learning pathways.\n</code></pre> <p>When requested by Copilot Studio, give the name \"Agentic HR\" to your custom agent. Then, instruct Copilot Studio to have specific tasks or goals with the following instruction:</p> <pre><code>Emphasize everything that helps team building, inclusion, and the growth mindset\n</code></pre> <p>Then, define a professional tone for your agent, providing the following input:</p> <pre><code>It should have a professional tone\n</code></pre> <p></p> <p>Once you are done describing your agent, select the Create command to create the actual agent. Alternatively, you can select the Skip to configure command and move to the classic configuration user interface.</p> <p>Once the agent has been created, you will see its configuration page, where you can define:</p> <ul> <li>Details: with generic information about the agent like name, icon, description, and instructions (system prompt).</li> <li>Knowledge: to define the various knowledge bases for the agent.</li> <li>Tools: to define custom tools for the agent.</li> <li>Additional settings: to configure whether the agent will rely on public web content or not.</li> <li>Starter prompts: to configure up to 6 starter prompts that will be shown in the Copilot Chat when starting a new chat.</li> <li>Publishing details: to get information about how to consume the agent, once it will be published.</li> </ul> <p></p> <p>On the right side of the screen, you can already see a preview of the agent that you can use to test its behaviour. The initial setup of the agent is now ready. Move to the next steps to fine tune its settings.</p> <p></p>"},{"location":"pages/make/copilot-studio/04-extending-m365-copilot/#step-2-updating-the-agents-icon","title":"Step 2: Updating the agent's icon","text":"<p>Now, you can edit the details selecting the Edit command in the upper right corner of the Details section. Once in edit mode, select the Change icon command to upload a custom icon and to select a background color for the icon itself. If you like, you can use the icon available at this link. In case you want to use the suggested icon, the background color could be #B9BAB5.</p> <p></p> <p>Select the Save command to save the new icon and background color, then select the Save button again to save the updated details for the agent.</p> <p></p>"},{"location":"pages/make/copilot-studio/04-extending-m365-copilot/#step-3-adding-a-knowledge-base-to-the-agent","title":"Step 3: Adding a knowledge base to the agent","text":"<p>Like you did in Lab MCS1, download this zip file consisting of few files (Word, PowerPoint, PDF) by selecting this link.</p> <p>Extract the files from the zip and upload them to the Documents library of a SharePoint Teams site in the same tenant where you are making your agent with Copilot Studio. These documents were generated by Microsoft 365 Copilot for the sake of having some additional knowledge base to feed the agent.</p> <p>Copy the absolute url of the site. For example: <code>https://xyz.sharepoint.com/sites/contoso</code></p> <p>To add a knowledge source to the agent, select the + Add knowledge command in the upper right corner of the Knowledge section. A dialog window pops up and allows you to select a data source. At the moment of this writing you can select a SharePoint data source. Select the SharePoint command and browse for a site that you want to use as the data source.</p> <p></p> <p>Paste the URL of the SharePoint Online site where you stored the documents into the dialog or select the Browse files command to search for data sources browsing the SharePoint Online sites. Once you have provided a URL or selected a data source, you need to provide a name and a meaningful description for the new knowledge base. The description will be used by Copilot to target the data source based on the user's intent defined by the user's prompt.</p> <p></p> <p>Select the Add button to add the new data source to the knowledge base of the agent.</p> <p>Important</p> <p>When configuring SharePoint Online sites as the knowledge base for an agent in Copilot Studio, users will only be able to get answers and content from documents that they have access to. The security and the access control are guaranteed by the Microsoft 365 security infrastructure and Copilot Studio agents access documents on behalf of the current user.</p> <p></p>"},{"location":"pages/make/copilot-studio/04-extending-m365-copilot/#step-4-publishing-the-agent-in-microsoft-365-copilot-chat","title":"Step 4: Publishing the agent in Microsoft 365 Copilot Chat","text":"<p>Now you can publish and test the agent in Microsoft 365 Copilot Chat. 1\ufe0f\u20e3 Select the Publish command in the upper right corner of the page to make the agent available in Copilot Chat. Then 2\ufe0f\u20e3 fill in the details for the agent. Lastly 3\ufe0f\u20e3 select the Publish command in the lower part of the publishing dialog.</p> <p></p> <p>The details for the agent are those required by a Microsoft 365 application manifest:</p> <ul> <li>Short description: short description of the agent (up to 30 characters).</li> <li>Long description: long description of the agent (up to 100 characters).</li> <li>Developer name: name of the developer (up to 32 characters).</li> <li>Website: URL of the developer's website (up to 2048 characters).</li> <li>Privacy statement: URL of the privacy statement (up to 2048 characters).</li> <li>Terms of use: URL of the terms of use (up to 2048 characters).</li> </ul> <p>Initial publishing takes quite some time, between 30 and 60 seconds. Once the agent is published, you will see a dialog with a recap of all the availability options.</p> <p></p> <p>Specifically, you can select:</p> <ul> <li>Copy command to copy a URL with a direct link to the app registered for the new agent.</li> <li>Show to my teammates and shared users to share the agent with selected groups or individuals in your organization.</li> <li>Show to everyone in my org to share the agent with the whole organization.</li> <li>Download .zip file to download a zip package of the app that you can then upload to the Microsoft 365 store.</li> </ul> <p>Show to everyone in my org</p> <p>When you choose to show the agent to the whole organization, ensure your agent is ready for release and in compliance with company standards, rules, and policies. Coordinate with your teammates. Once the agent is submitted, it can't be resubmitted by others until an admin approves or rejects it. You can find additional details about publishing an app to the whole organization reading Show to the organization.</p> <p>Select the Copy command, open a new browser tab, and paste the URL with the direct link to the agent. The company app store will show in the browser and a dialog will allow you to select the Add button, to add the agent to Microsoft 365 Copilot.</p> <p></p> <p>Once you have added the agent to Microsoft 365 Copilot Chat, you will find it in the list of agents in the right side of the Copilot chat, like illustrated in the following screenshot.</p> <p></p> <p>Select the agent and start interacting with it. For example, you can provide the following prompt:</p> <pre><code>How can we hire new people in our company?\n</code></pre> <p>The agent will provide you detailed information about the hiring procedures, based on the content retrieved from the documents defined in the knowledge base. For example, the main data source for the response will be the document <code>Hiring Procedures.docx</code> that you uploaded to SharePoint Online.</p> <p></p> <p></p>"},{"location":"pages/make/copilot-studio/04-extending-m365-copilot/#exercise-2-adding-a-tool-to-the-agent","title":"Exercise 2 : Adding a tool to the agent","text":"<p>In this excercise you are going to add a custom tool to the agent that you made in the previous exercise. In Microsoft Copilot Studio, when making agents for Microsoft 365 Copilot Chat, you can add four different types of tools:</p> <ul> <li>Prompt: allows consuming an AI tool built using a prompt written in natural language.</li> <li>Custom connector: allows consuming a Power Platform custom connector.</li> <li>REST API: allows consuming an external REST API. You can find additional details here.</li> <li>Model Context Protocol: allows consuming an MCP server and its tools.</li> </ul> <p>Tools for agents</p> <p>You can find additional information about adding tools to agents in Copilot Studio reading the article Add tools to custom agents.</p> <p>In this lab you are going to add a tool of type <code>Custom connector</code> in order to retrieve a list of candidates from an Excel spreadsheet stored in SharePoint Online.</p>"},{"location":"pages/make/copilot-studio/04-extending-m365-copilot/#step-1-adding-a-tool-to-an-agent-for-microsoft-365-copilot","title":"Step 1: Adding a tool to an agent for Microsoft 365 Copilot","text":"<p>To add a new tool, select the + Add tool command in the Tools section of the agent's configuration panel.</p> <p></p> <p>A dialog window pops up allowing you to choose what kind of tool to create. By default, there are some Featured tools like those that allow you to interact with Excel Online content or other common services. You can also create a new tool from scratch, selecting the + New tool command and choosing between the options highlighted in the previous paragraphs.</p> <p>If you don't find the option you are looking for in the list of featured items, simply switch to the All group and search by text what you are looking for.</p> <p>To complete the current step, choose the featured tool Excel Online (Business) and then select List rows present in a table. First of all, you will need to connect to the external connector simply selecting the Connection and then Create new connection and proceeding with the process.</p> <p></p> <p>You will need to login with your account and to allow access to Excel Online (Business). Once the connection is configured, you will see a dialog with commands to Add to agent or Add and configure the tool.</p> <p></p> <p>After adding the tool, you will get the list of tools in Copilot Studio. Click on the tool that you just created to edit its settings. In the configuration panel you need to provide:</p> <ul> <li>Name: simply a descriptive name for the tools.</li> <li>Display name: a display name for the tool.</li> <li>Description: a description in natural language that will be used by generative orchestration to determine when to use your tool. </li> <li>Inputs and outpus: to define the input and output arguments for the action, if any.</li> <li>Response settings: defines how the action handles the request and response to the user.</li> </ul> <p>Before configuring the tool, you need to prepare the Excel spreadsheet with the list of candidates. Download a sample Excel file by selecting this link.</p> <p>Upload the file to the Documents library of a SharePoint Teams site in the same tenant where you are making your agent with Copilot Studio. The document was generated by Microsoft 365 Copilot for the sake of having a hypothetical list of candidates.</p> <ul> <li>Copy the absolute url of the site. For example: <code>https://xyz.sharepoint.com/sites/contoso/</code>.</li> <li>Copy the name of the document library. For example : <code>Shared documents</code></li> <li>Copy also the name of the file. For example: <code>Sample-list-of-candidates.xlsx</code></li> </ul> <p>Now go back to Microsoft Copilot Studio and finalize the tool configuration. Use the following settings:</p> <ul> <li>Name: List HR candidates</li> <li>Description: List candidates for an HR role</li> </ul> <p>In the dialog for editing the tool, update the Tool name to give it a more descriptive and informative name. Then select the Inputs tab and start configuring the input arguments. By default, all the mandatory input arguments have been configured so that their value will be exctracted by the User's entire response as you can notice in the Identify as property of each input argument.</p> <p></p> <p>Select the How will the agent fill this input? setting for each of the input arguments and switch to <code>Set as a value</code> in order to provide static values for all of the input arguments. Confirm that you want to change the setting and proceed configuring a static value for each of the input arguments.</p> <p></p> <p>Use the following static values:</p> <ul> <li>Location: use the URL of the SharePoint Online site collection where you stored the Excel spreadsheet. For example: <code>https://xyz.sharepoint.com/sites/contoso/</code>.</li> <li>Document Library: use the name of the document library where you stored the Excel spreadsheet. For example: <code>Shared Documents</code>.</li> <li>File: provide the name of the Excel file. For example: <code>Sample-list-of-candidates.xlsx</code>.</li> <li>Table: <code>Candidates_Table</code></li> </ul> <p></p> <p>Now select the Save button in the upper right corner of the screen to save the updated action.</p> <p></p>"},{"location":"pages/make/copilot-studio/04-extending-m365-copilot/#step-2-testing-the-new-tool","title":"Step 2: Testing the new tool","text":"<p>You are now ready to publish the updated agent and to play with it in the integrated test panel or in Microsoft Teams. Select the Publish button again, to update the publishing of the agent. Wait for the publishing to complete and then open again the direct link to the agent's app. You will see an Update now command instead of the Add that you saw in Exercise 1 - Step 4. Select the Update now command and wait. Once ready, go to Microsoft 365 Copilot Chat, refresh the page and start interacting with the updated agent.</p> <p>It is really easy to invoke the just created tool simply providing to the agent a prompt like the following one:</p> <pre><code>Show me the list of candidates for HR with role \"HR Director\" or \"HR Manager\"\n</code></pre> <p>Microsoft 365 Copilot Chat will ask you the permission to consume an external API (Excel Online) and you will have to select the option to Always allow or Allow once. For the sake of testing purposes, choose Allow once so that you will be able to test the authorization process again in the future.</p> <p></p> <p>Since the Power Platform connector requires a valid connection in place, the agent prompts the user to Sign in to Agentic HR before being able to consume the external data source. </p> <p></p> <p>Connect to the external connector and run again the prompt. The agent will reply back providing the list of candidates retrieved from the Excel spreadsheet and matching the criteria that you provided in the prompt.</p> <p></p> <p>Well done! You were able to consume an external connector from a Copilot Studio agent made for Microsoft 365 Copilot!</p> <p></p> <p>CONGRATULATIONS!</p> <p>Start here with Lab MCS5, to learn how to use custom connectors in Copilot Studio. </p> <p></p>"},{"location":"pages/make/copilot-studio/05-connectors/","title":"Lab MCS5 - Power Platform custom connector","text":"<p>In this lab, you are going to understand how to extend an agent made with Microsoft Copilot Studio using a Power Platform custom connector. Specifically, you are going to consume a custom REST API to manage a hypotethical list of candidates for a job role. The API offers functionalities to:</p> <ul> <li>List candidates</li> <li>Get a specific candidate</li> <li>Add a new candidate</li> <li>Remove a candidate</li> </ul> Get a quick overview of the lab in this video. <p>Do these labs if you want to build agents with Microsoft Copilot Studio</p> <ul> <li>MCS0 - Setup</li> <li>MCS1 - First agent</li> <li>MCS2 - Defining Topics</li> <li>MCS3 - Defining Tools</li> <li>MCS4 - Extending Microsoft 365 Copilot</li> <li>MCS5 - Consuming a custom connector</li> <li>MCS6 - Consuming an MCP server</li> <li>MCS7 - Creating Autonomous Agents</li> <li>MCS8 - Integrating Azure AI Search for RAG</li> </ul> <p>In Microsoft 365 Copilot, within Copilot Studio you will be able to rely on these functionalities and enhance the potential of the custom agent that you created in the previous Lab MCS4.</p> <p>Note</p> <p>This lab builds on the previous one, Lab MCS4. You should be able to continue working on the same agent, improving its functionalities with new capabilities.</p> <p>In this lab you will learn:</p> <ul> <li>How to expose a REST API through a Power Platform custom connector</li> <li>How to secure communication to an external REST API in the Power Platform</li> <li>How to consume a custom connector from an agent</li> </ul> <p>Before starting, make sure you have:</p> <ul> <li>Visual Studio Code</li> <li>REST Client extension for Visual Studio Code</li> <li>Node.js v.22 or higher</li> <li>Dev tunnel</li> </ul>"},{"location":"pages/make/copilot-studio/05-connectors/#exercise-1-creating-the-rest-api","title":"Exercise 1 : Creating the REST API","text":"<p>For the sake of simplicity in this Lab you are going to use a pre-built REST API. In this exercise you are going to download and configure it, so that you can run it locally.</p>"},{"location":"pages/make/copilot-studio/05-connectors/#step-1-downloading-and-testing-the-rest-api","title":"Step 1: Downloading and testing the REST API","text":"<p>The sample REST API is an Azure Function built with TypeScript and Node.js, named <code>HR Service</code> and you can download its source code from here.</p> <p>Extract the files from the zip and open the target folder with Visual Studio Code. In the following screenshot you can have an overview of the project structure.</p> <p></p> <p>The main elements of the project outline are:</p> <ul> <li><code>http</code>: in this folder you can find a couple of .http files useful for testing the REST API in Visual Studio Code.</li> <li><code>src/data/candidates.json</code>: a JSON file with an hypothetical list of candidates, used as the initial data source for the service.</li> <li><code>src/functions/candidatesFunction.ts</code>: the actual implementation of the Azure Function.</li> <li><code>src/openapi.json</code>: the Open API specification file for the Azure Function, stored in JSON format.</li> <li><code>src/openapi.yaml</code>: the Open API specification file for the Azure Function, stored in Yaml format.</li> <li><code>askCandidateData.json</code>: the JSON of an adaptive card to collect data for a new candidate.</li> <li><code>dev-tunnel-steps.md</code>: brief set of instructions to build a Dev Tunnel to have a reverse proxy for the REST API running locally.</li> <li><code>local.settings.json.sample</code>: a sample configuration file that will be used later in this lab.</li> </ul> <p>Rename the file <code>local.settings.json.sample</code> into <code>local.settings.json</code> and press F5 to start the project. In Visual Studio Code, open the file <code>http/ht-service.http</code> and trigger a new request to get the list of candidates by selecting the Send request command near the GET request for <code>http://localhost:7071/api/candidates</code>. On the right side of the screen you will see the output of the request, providing you with few response headers and the JSON list of candidates.</p> <p></p> <p>Notice that in the Terminal window, in the lower part of the screen, there is the tracing of the API call that you just triggered and a message stating that <code>OAuth is disabled. Skipping token validation</code>. In fact, right now the API is accessible anonymously.</p> <p></p>"},{"location":"pages/make/copilot-studio/05-connectors/#step-2-registering-the-api-in-entra-id","title":"Step 2: Registering the API in Entra ID","text":"<p>Let's now secure access to the API. First of all, you need to open a browser and, using the work account of your target Microsoft 365 tenant, go to https://entra.microsoft.com to access the Microsoft Entra admin center. Sign in to the admin center, if asked for authentication. Then 1\ufe0f\u20e3 select App registrations in the menu bar on the left, and then 2\ufe0f\u20e3 select the + New registration command to register a new application in the target tenant.</p> <p></p> <p>The <code>Register an application</code> page will show up. Provide a name for the application, for example <code>HR-Service-API</code>. Choose to support authentication only in your target tenant, and select the Register button in the lower part of the screen.</p> <p></p> <p>Microsoft Entra will register the application for you and show the Overview page with information about the newly registered application. Copy the value of Client ID and Tenant ID, because you will need them soon.</p> <p>Select the 1\ufe0f\u20e3 Expose an API menu item on the left menu, then 2\ufe0f\u20e3 select + Add a scope to add a new permission scope for consuming the custom API. The very first time you add a new scope, you have to configure an Application ID URI. By default, the value will be <code>api://&lt;Client-Id&gt;</code>. Select Save and continue to save the unique URI for the application. Then, 3\ufe0f\u20e3 configure the scope settings using the panel that appears on the righ and 4\ufe0f\u20e3 select Add scope to confirm the operation.</p> <p>Creating a scope allows you to define a custom delegated permission scope for you API. Consumers of your API will need to provide OAuth 2.0 tokens with that permission scope in order to being able to consume your API.</p> <p></p> <p>Here you can see some suggested values for the permission scope configuration:</p> <ul> <li>Scope name: the actual name of the scope. For example: <code>HR.Consume</code>.</li> <li>Who can consent?: defines whether the scope can be consented by admins only, or both by admins and regular users. Choose <code>Admins and users</code>.</li> <li>Admin consent display name: the short display name of the scope for admin consent. For example: <code>HR.Consume</code>.</li> <li>Admin consent description: the description of the scope for admin consent. For example:  <code>Allows consuming the HR Service</code>.</li> <li>User consent display name: the short display name of the scope for user consent. For example: <code>HR.Consume</code>.</li> <li>User consent description: the description of the scope for user consent. For example: <code>Allows consuming the HR Service</code>.</li> <li>State: defines whether the scope is Enabled or Disabled. Let's keep it enabled.</li> </ul> <p>Once the permission scope is configured, you will see the new scope in the list of scopes defined for the application.</p> <p></p> <p>Now, 1\ufe0f\u20e3 select the Manifest menu item on the left menu, 2\ufe0f\u20e3 edit the content of the manifest file using the Microsoft Graph App Manifest (new), and 3\ufe0f\u20e3 update the <code>requestedAccessTokenVersion</code> property to the value <code>2</code>. This specifies that the API expects a JWT token of type v2.0.</p> <p>Note</p> <p>You can find additional information about the Microsoft Graph App Manifest and the token v2.0 in the article Understand the app manifest (Microsoft Graph format).</p> <p></p> <p>Now you can go back to Visual Studio Code and configure the <code>local.settings.json</code> file accordingly to the settings of the just registered application. Replace the <code>&lt;Client-ID&gt;</code> and the <code>&lt;Tenant-ID&gt;</code> placeholders with the actual values and turn the <code>UseOAuth</code> property to <code>true</code>.</p> <pre><code>{\n  \"IsEncrypted\": false,\n  \"Values\": {\n    \"AzureWebJobsStorage\": \"UseDevelopmentStorage=true\",\n    \"FUNCTIONS_WORKER_RUNTIME\": \"node\",\n    \"AAD_APP_CLIENT_ID\": \"&lt;Client-ID&gt;\",\n    \"AAD_APP_TENANT_ID\": \"&lt;Tenant-ID&gt;\",\n    \"AAD_APP_OAUTH_AUTHORITY\": \"https://login.microsoftonline.com/&lt;Tenant-ID&gt;\",\n    \"UseOAuth\": \"true\"\n  }\n}\n</code></pre> <p>Restart the REST API project and now the API will be secured and will be looking for an OAuth 2.0 token in the Authorization header. If the token will not be provided, or if an invalid token will be provided, the API will respond with a HTTP status 401 (Unauthorized).</p> <p></p>"},{"location":"pages/make/copilot-studio/05-connectors/#step-3-configure-the-dev-tunnel","title":"Step 3: Configure the dev tunnel","text":"<p>Now, you need to expose the REST API with a public URL. Since you are running the API project locally on your development machine, you need to rely on a reverse proxy tool to expose your <code>localhost</code> via a public URL. For the sake of simplicity, you can use the dev tunnel tool provided by Microsoft, following these steps:</p> <ul> <li>Install dev tunnel on your environment following these instructions</li> <li>Login with dev tunnel, executing the following command:</li> </ul> <pre><code>devtunnel user login\n</code></pre> <ul> <li>Host your dev tunnel, executing the following commands:</li> </ul> <pre><code>devtunnel create hr-service -a --host-header unchanged\ndevtunnel port create hr-service -p 7071\ndevtunnel host hr-service\n</code></pre> <p>The command line will display the connection information, such as:</p> <p></p> <p>Copy the \"Connect via browser\" URL and save it in a safe place.</p> <p>Be sure to leave the dev tunnel command running as you do the exercises in this lab. If you need to restart it, just repeat the last command <code>devtunnel host hr-service</code>.</p> <p></p>"},{"location":"pages/make/copilot-studio/05-connectors/#step-4-registering-the-consumer-in-entra-id","title":"Step 4: Registering the Consumer in Entra ID","text":"<p>In order to consume the API from the Power Platform using a custom connector, you also need to register a consumer application in Microsoft Entra ID. Go back to the Microsoft Entra admin center and select again App registrations in the menu bar on the left, and then select the + New registration command to register a new application in the target tenant. This time, name the new application as <code>HR-Service-Consumer</code>. As like as in Step 1, configure the new application for single tenant authentication and register it.</p> <p>Microsoft Entra will register the application for you and show the Overview page with information about the newly registered application. Copy the value of Client ID and Tenant ID, because you will need them soon.</p> <p></p> <p>Select the 1\ufe0f\u20e3 Certificates &amp; Secrets menu item on the left menu, then 2\ufe0f\u20e3 select + New secret to add a new client secret. Then, 3\ufe0f\u20e3 configure a name and a duration for the secret and 4\ufe0f\u20e3 select the Add command to create the new secret. Copy the value of the new secret in a safe place, together with the Client ID and Tenant ID that you copied before.</p> <p>Switch to the permissions page, 1\ufe0f\u20e3 select the API permissions menu item on the left menu, then 2\ufe0f\u20e3 select + Add a permission. In the panel that shows up on the right side, 3\ufe0f\u20e3 select APIs my organization uses, search and 4\ufe0f\u20e3 select <code>HR-Service-API</code>.</p> <p></p> <p>Once you select the targe API, the side panel updates and allows you to select the delegated permission of type <code>HR.Consume</code> that you configured before. Once you picked the permission, select the Add permission command to add it to the consumer application. When the permission has been added, select the Grand admin consent for ... command to grant the permission to the application.</p> <p></p> <p>At the end of this process, the consumer application will be configured with the permissions highlighted in the following screenshot.</p> <p></p> <p>Keep the consumer application tab open, because you will need to update its configuration in the upcoming steps.</p> <p></p>"},{"location":"pages/make/copilot-studio/05-connectors/#exercise-2-creating-the-custom-connector","title":"Exercise 2 : Creating the custom connector","text":"<p>In this excercise you are going to create the Power Platform custom connector to consume the HR Service API.</p>"},{"location":"pages/make/copilot-studio/05-connectors/#step-1-creating-the-custom-connector","title":"Step 1: Creating the custom connector","text":"<p>To create a new custom connector, open a browser and, using the work account of your target Microsoft 365 tenant, go to https://make.powerautomate.com to access Power Automate. First of all, switch to the <code>Copilot Dev Camp</code> environment, using the environment selctor in the upper right corner of the screen. Then, on the left-side menu panel, select More, then Discover all, then look for Custom connectors. You can eventually pin the menu item if you plan to use it frequently. The page with the list of custom connectors will appear. Select the command + New custom connector and choose Import an OpenAPI file.</p> <p></p> <p>Provide a name for the connector and browse for the OpenAPI JSON file of the <code>HR-Service</code>. You can also find the file here. Once you have provided a name and the Open API specification file, select the Continue button to complete the connector creation.</p> <p></p> <p>You will see a multi-step/multi-tab registration process showing up. The first tab is the General one, where you can configure a custom icon, color, and description for the connector. In the General tab you also need to configure the Host value, which has to be the host name of the dev tunnel URL that you copied in Exercise 1 - Step 3. Last but not least, you need to configure the Base URL, where you can leave the default value <code>/</code>.</p> <p></p> <p>Select the Security command at the bottom of the page to switch to the security settings for the connector. In the Security tab select <code>OAuth 2.0</code> as the authentication type. Then choose <code>Azure Active Directory</code> as the flavor of OAuth 2.0 protocol to support.</p> <p></p> <p>Once you have selected <code>OAuth 2.0</code> as the authentication type and <code>Azure Active Directory</code>, the tab will prompt you to provide all the needed settings to properly configure security for the custom connector. Specifically, you need to provide:</p> <ul> <li>Client ID: the <code>&lt;Client-Id&gt;</code> of the consumer application that you registered in Exercise 1 - Step 4.</li> <li>Client secret: the <code>&lt;Client-Secret&gt;</code> of the consumer application that you registered in Exercise 1 - Step 4.</li> <li>Authorization URL: the Entra ID authorization URL. Should always be the default one, unless you are using GCC tenants.</li> <li>Tenant ID: the <code>&lt;Tenant-Id&gt;</code> of the consumer application that you registered in Exercise 1 - Step 4.</li> <li>Resource URL: The <code>&lt;Application-ID-URI&gt;</code> that you registered in Exercise 1 - Step 2 for the <code>HR-Service-API</code> application. Should be something like <code>api://&lt;Client-Id&gt;</code>, where this time the <code>&lt;Client-Id&gt;</code> is the one of the <code>HR-Service-API</code> application.</li> <li>Enable on-behalf-of login: Keep it with value <code>False</code>.</li> <li>Scope: the scope that you configured for the <code>HR-Service-API</code> application in Exercise 1 - Step 2. It should be <code>HR.Consume</code>.</li> <li>Redirect URL: this is a read-only field that you will use soon.</li> </ul> <p></p> <p>Now save the connector settings by selecting the Create connector command in the upper right corner of the tab. Once the connector will be saved, the Security tab reloads and you will be able to see an actual value for the Redirect URL field. Copy that value and go back to Microsoft Entra ID admin center. Go to the consumer application that you registered in Exercise 1 - Step 4 and 1\ufe0f\u20e3 select the Authentication menu item on the left menu, then 2\ufe0f\u20e3 select + Add a platform. In the panel that shows up on the right side, 3\ufe0f\u20e3 select Web, and the 4\ufe0f\u20e3 paste the Redirect URL that you just copied from the custom connector interface and 5\ufe0f\u20e3 select Configure to confirm the new settings.</p> <p></p> <p>You have just configured the consumer application to support the Power Platform as a redirect URL when completing the authentication flow.</p> <p></p> <p>Now you can go back to the custom connector definition and you can move to the Definition tab. There you will find all the operations exposed by the REST API. Their definition was retrieved by the OpenAPI specification file. You don't need to do anything here. You can simply switch to the Test tab, if you like, in order to test that the REST API is working as expected.</p> <p></p>"},{"location":"pages/make/copilot-studio/05-connectors/#step-2-testing-the-custom-connector","title":"Step 2: Testing the custom connector","text":"<p>In he Test tab you can see the list of operations on the left side. Choose one operation, like for example getCandidates, then connect to the target connector selecting the + New connection command and following the prompts of Power Platform to authenticate. Once the connection is ready, you can test the selected operation by selecting the Test operation command and looking for the output in the lower part of the screen.</p> <p></p> <p></p>"},{"location":"pages/make/copilot-studio/05-connectors/#exercise-3-consuming-the-custom-connector","title":"Exercise 3 : Consuming the custom connector","text":"<p>In this excercise you are going to consume the custom connector that you created in Exercise 2.</p>"},{"location":"pages/make/copilot-studio/05-connectors/#step-1-consuming-the-custom-connector-from-the-agent","title":"Step 1: Consuming the custom connector from the agent","text":"<p>In this step you are going to consume the custom connector from the agent for Microsoft 365 Copilot Chat that you created in Lab MCS4.</p> <p>Open a browser and, using the work account of your target Microsoft 365 tenant, go to https://copilotstudio.microsoft.com to start using Microsoft Copilot Studio.</p> <p>Then 1\ufe0f\u20e3 browse the list of agents in Copilot Studio and 2\ufe0f\u20e3 select the agent with name Microsoft 365 Copilot.</p> <p></p> <p>Now, edit the <code>Agentic HR</code> agent, go to the Actions section and select + Add action. Follow the instructions that you have already seen in Lab MCS4 - Exercise 2 - Step 1. However, this time select the Custom connector group of actions and search for <code>HR-Services</code>. You will see the actions defined in the <code>HR-Services</code> connector that you created in Exercise 2 - Step 1.</p> <p>Select the <code>Get all candidates</code> action and confirm to connect to the target custom connector. Configure the action as follows:</p> <ul> <li>Name: <code>Get all candidates</code>.</li> <li>Description: <code>Lists all the HR candidates from an external system</code>.</li> <li>Authentication: <code>User authentication</code>.</li> </ul> <p>Add the action by selecting the Add action command. Once you have created the new action, disable the old action that you created in Lab MCS4 - Exercise 2 - Step 1. To disable an action, click on the three dots (...) beside the action and toggle the Status to <code>Off</code>.</p> <p></p> <p>Publish the updated agent and once it is ready and updated, test the new action providing the following prompt in the Microsoft 365 Copilot Chat:</p> <pre><code>Lists all the HR candidates from an external system\n</code></pre> <p>Microsoft 365 Copilot Chat will ask you to allow consuming the external REST API. Select the command Allow once if you want to test the whole process multiple times, or Always allow if you want to consent consuming the REST API for any further request.</p> <p></p> <p>Then Microsoft 365 Copilot Chat will then ask you to sign-in to securely access the external REST API, providing you a message like the following one.</p> <p></p> <p>Select Sign in to Agentic HR to authenticate and connect to the target custom connector. Once the connection is established, go back to the Microsoft 365 Copilot Chat and run one more time the same prompt as before. You will see the list of candidates as they are defined in the HR Service project and, in the lower part of the response, you can notice there is the icon informing you that the response came from the external service.</p> <p></p> <p>For the sake of completeness, go to Visual Studio Code and notice that in the Terminal area, in the lower part of the screen, there is tracing of to the REST request processed by the API. Notice also the message <code>Token is valid for user &lt;username&gt;</code> highlighted in the following screenshot and showing that the request was authenticated for the user consuming the API from within Microsoft 365 Copilot.</p> <p></p> <p>Wonderful! You were able to configure a custom connector and consume it within Microsoft 365 Copilot Chat!</p> <p></p> <p>CONGRATULATIONS!</p> <p>You have completed Lab MCS5 - Power Platform custom connector!</p> <p>Start here with Lab MCS6, to learn how to consume an MCP server in Copilot Studio.  </p> <p></p>"},{"location":"pages/make/copilot-studio/06-mcp/","title":"Lab MCS6 - Consuming an MCP server","text":"<p>In this lab, you are going to understand how to extend an agent made with Microsoft Copilot Studio using an MCP (Model Context Protocol) server. Specifically, you are going to consume an existing MCP server that provides tools for managing a hypothetical list of candidates for a job role. The MCP server will offer functionalities to:</p> <ul> <li>List all candidates </li> <li>Search for candidates by criteria</li> <li>Add new candidates </li> <li>Update existing candidate information</li> <li>Remove candidates </li> </ul> Get a quick overview of the lab in this video. <p>Do these labs if you want to build agents with Microsoft Copilot Studio</p> <ul> <li>MCS0 - Setup</li> <li>MCS1 - First agent</li> <li>MCS2 - Defining Topics</li> <li>MCS3 - Defining Tools</li> <li>MCS4 - Extending Microsoft 365 Copilot</li> <li>MCS5 - Consuming a custom connector</li> <li>MCS6 - Consuming an MCP server</li> <li>MCS7 - Creating Autonomous Agents</li> <li>MCS8 - Integrating Azure AI Search for RAG</li> </ul> <p>Learn about MCP</p> <p>This lab introduces MCP concepts and shows how to integrate them with Copilot Studio. MCP is a new protocol that allows AI assistants to securely connect to external data sources and tools. You can learn more about MCP reading the content available in the Model Context Protocol (MCP) for beginners training class.</p> <p>In this lab you will learn:</p> <ul> <li>How to configure and connect to an existing MCP server</li> <li>How to consume MCP tools and resources from an external server</li> <li>How to integrate MCP servers with Copilot Studio agents</li> </ul>"},{"location":"pages/make/copilot-studio/06-mcp/#exercise-1-setting-up-the-mcp-server","title":"Exercise 1 : Setting up the MCP Server","text":"<p>In this exercise you are going to setup a pre-built MCP server that provides HR candidates management functionality. The server is based on Microsoft .NET and relies on the MCP SDK for C#. The server provides tools to manage a hypothetical list of job candidates. In this exercise you are going to download and configure the server, so that you can run it locally.</p>"},{"location":"pages/make/copilot-studio/06-mcp/#step-1-understanding-the-mcp-server-and-prerequisites","title":"Step 1: Understanding the MCP Server and prerequisites","text":"<p>The HR MCP server that you will be consuming in this lab provides the following tools:</p> <ul> <li>list_candidates: Provides the whole list of candidates</li> <li>search_candidates: Searches for candidates by name, email, skills, or current role</li> <li>add_candidate: Adds a new candidate to the list</li> <li>update_candidate: Updates an existing candidate by email</li> <li>remove_candidate: Removes a candidate by email</li> </ul> <p>The server manages candidates information including:</p> <ul> <li>Personal details (firstname, lastname, full name, email)</li> <li>Professional information (spoken languages, skills, current role)</li> </ul> <p>Before starting, make sure you have:</p> <ul> <li>.NET 8.0 SDK</li> <li>Visual Studio Code</li> <li>Node.js v.22 or higher</li> <li>MCP Inspector</li> <li>Dev tunnel</li> </ul> <p></p>"},{"location":"pages/make/copilot-studio/06-mcp/#step-2-downloading-and-running-the-mcp-server","title":"Step 2: Downloading and running the MCP Server","text":"<p>For this lab, you will use a pre-built HR MCP server. Download the server files from here.</p> <p>Extract the files from the zip and open the target folder with Visual Studio Code. The server is already implemented and ready to run.</p> <p></p> <p>The main elements of the project outline are:</p> <ul> <li><code>Configuration</code>: folder with the <code>HRMCPServerConfiguration.cs</code> file defining the configuration settings for the MCP server.</li> <li><code>Data</code>: folder with the <code>candidates.json</code> file providing the list of candidates.</li> <li><code>Services</code>: folder with the <code>ICandidateService.cs</code> interface and the actual <code>CandidateService.cs</code> implementation of a service to load and manage the list of candidates.</li> <li><code>Tools</code>: folder with the <code>HRTools.cs</code> file defining the MCP tools and the <code>Models.cs</code> file defining the data models used by the tools.</li> <li><code>DevTunnel_Instructions.MD</code>: instructions about how to expose the MCP server via a dev tunnel.</li> <li><code>Progam.cs</code>: the main entry point of the project, where the MCP server gets initialized.</li> </ul> <p>Open a new terminal window from within Visual Studio Code or simply start a new terminal window and move to the root folder of the MCP server project that you just extracted. Then install dependencies, build, and start the .NET project by invoking the following command:</p> <pre><code>dotnet run\n</code></pre> <p>Check that the MCP server is up and running. You should be able to consume the server via browser at the URL http://localhost:47002/. You will see an error inside a JSON message, that's ok. It means that you are reaching the MCP server.</p> <p>Info</p> <p>The pre-built HR MCP Server provided with this lab is not a production-ready solution. It operates using an in-memory list of candidates and does not retain data across multiple conversation sessions. It was developed specifically for the purpose of this lab, to offer a simple and accessible solution. If you are a professional developer, you may consider it a starting point for understanding the fundamentals of building an MCP server exposed via HTTP. If you like you can improve the server relying on a container app and adding persistence storage. For example, here you can find a more advanced version of the server, implemented by Fabian Williams (Microsoft).</p> <p></p>"},{"location":"pages/make/copilot-studio/06-mcp/#step-3-configure-the-dev-tunnel","title":"Step 3: Configure the dev tunnel","text":"<p>Now, you need to expose the MCP server with a public URL. Since you are running the server locally on your development machine, you need to rely on a reverse proxy tool to expose your <code>localhost</code> via a public URL. For the sake of simplicity, you can use the dev tunnel tool provided by Microsoft, following these steps:</p> <ul> <li>Install dev tunnel on your environment following these instructions</li> <li>Login with dev tunnel, executing the following command:</li> </ul> <pre><code>devtunnel user login\n</code></pre> <ul> <li>Host your dev tunnel, executing the following commands:</li> </ul> <p>Important</p> <p>Replace the <code>hr-mcp</code> name suggested below with whatever name you like, in order to have a unique name for your dev tunnel. For example, if your name is Rose you can use <code>hr-mcp-rose</code> as the name for your tunnel. In case you will get an error like <code>Request not permitted. Unauthorized tunnel creation access ...</code> it means that someone else is already using that name. To solve the issue, simply provide a different name.</p> <pre><code>devtunnel create hr-mcp -a --host-header unchanged\ndevtunnel port create hr-mcp -p 47002\ndevtunnel host hr-mcp\n</code></pre> <p>The command line will display the connection information, such as:</p> <p></p> <p>Copy the \"Connect via browser\" URL and save it in a safe place. Open a browser and navigate to the just copied URL. You might need to confirm that you want to consume the MCP server via the dev tunnel through a confirmation page like the following one.</p> <p></p> <p>Be sure to leave both the dev tunnel command and the MCP server running as you do the exercises in this lab. If you need to restart it, just repeat the last command <code>devtunnel host hr-mcp</code>.</p> <p></p>"},{"location":"pages/make/copilot-studio/06-mcp/#step-4-testing-the-mcp-server","title":"Step 4: Testing the MCP server","text":"<p>You are now ready to test the MCP server on your local environment. For the sake of simplicity, you can use the MCP Inspector. Start a terminal window and run the following command:</p> <pre><code>npx @modelcontextprotocol/inspector\n</code></pre> <p>The Node.js engine will download and run the MCP Inspector, in the terminal window you should see an output like the following one.</p> <p></p> <p>The browser will start automatically and you will see the following interface.</p> <p></p> <p>Configure the MCP Inspector with the following settings:</p> <ul> <li>1\ufe0f\u20e3 Transport type: Streamable HTTP</li> <li>2\ufe0f\u20e3 URL: the URL that you saved from the \"Connect via browser\" of the dev tunnel</li> </ul> <p>Then select the 3\ufe0f\u20e3 Connect button to start consuming the MCP server. The connection should be successful, and you should be able to have a green bullet and the message Connected just below the connection handling commands. Now, in the Tools section of the screen, select the 1\ufe0f\u20e3 List Tools command to retrieve the list of tools exposed by the MCP server. Then, select the 2\ufe0f\u20e3 list_candidates tool, and then select 3\ufe0f\u20e3 Run tool to invoke the selected tool.</p> <p></p> <p>In case of successful response, you will see a Success message in green and the output of the tool invocation. In the History section you can always review all the invocations sent to the MCP server.</p> <p></p> <p>You are now ready to consume the MCP server from an agent in Microsoft Copilot Studio.</p> <p></p>"},{"location":"pages/make/copilot-studio/06-mcp/#exercise-2-creating-a-new-agent-in-copilot-studio","title":"Exercise 2 : Creating a New Agent in Copilot Studio","text":"<p>In this exercise you are going to create a new agent in Microsoft Copilot Studio that will consume the MCP server you configured in Exercise 1.</p>"},{"location":"pages/make/copilot-studio/06-mcp/#step-1-creating-the-new-agent","title":"Step 1: Creating the new agent","text":"<p>Open a browser and, using the work account of your target Microsoft 365 tenant, go to https://copilotstudio.microsoft.com to start using Microsoft Copilot Studio.</p> <p>Select the <code>Copilot Dev Camp</code> environment that you created in Exercise 1 of Lab MCS0 - Setup, and then select Create in the left navigation menu, then choose Agent to create a new agent.</p> <p>Choose to Configure and define your new agent with the following settings:</p> <ul> <li>Name: </li> </ul> <pre><code>HR Candidate Management\n</code></pre> <ul> <li>Description: </li> </ul> <pre><code>An AI assistant that helps manage HR candidates using MCP server integration \nfor comprehensive candidate management\n</code></pre> <ul> <li>Instructions: </li> </ul> <pre><code>You are a helpful HR assistant that specializes in candidate management. You can help users search \nfor candidates, check their availability, get detailed candidate information, and add new \ncandidates to the system. \nAlways provide clear and helpful information about candidates, including their skills, experience, \ncontact details, and availability status.\n</code></pre> <p></p> <p>Select Create to create your new agent.</p> <p></p>"},{"location":"pages/make/copilot-studio/06-mcp/#step-2-configuring-the-agents-conversation-starters","title":"Step 2: Configuring the agent's conversation starters","text":"<p>After creating the agent, you'll be taken to the agent configuration page. In the Suggested prompts section, add these helpful prompts:</p> <ol> <li>Title: <code>List all candidates</code> - Prompt: <code>List all the candidates</code></li> <li>Title: <code>Search candidates</code> - Prompt: <code>Search for candidates with name [NAME_TO_SEARCH]</code></li> <li>Title: <code>Add new candidate</code> - Prompt: <code>Add a candidate with firstname [FIRSTNAME], lastname [LASTNAME],  e-mail [EMAIL], role [ROLE], spoken languages [LANGUAGES], and skills [SKILLS]</code></li> </ol> <p></p> <p>Select the Save button to confirm your changes.</p> <p></p>"},{"location":"pages/make/copilot-studio/06-mcp/#exercise-3-integrating-mcp-server-with-copilot-studio","title":"Exercise 3 : Integrating MCP Server with Copilot Studio","text":"<p>In this exercise you are going to configure the integration between your MCP server and the Copilot Studio agent.</p>"},{"location":"pages/make/copilot-studio/06-mcp/#step-1-adding-tools-exposed-by-the-mcp-server","title":"Step 1: Adding tools exposed by the MCP server","text":"<p>In your agent, navigate to the 1\ufe0f\u20e3 Tools section and select 2\ufe0f\u20e3 + Add a tool.</p> <p></p> <p>Choose 1\ufe0f\u20e3 Model Context Protocol group to see all the already existing MCP servers available to you agent. Now select 2\ufe0f\u20e3 + New tool to add the actual HR MCP server.</p> <p></p> <p>A new dialog shows up allowing you to select the kind of tool that you want to add. Select the Model Context Protocol option.</p> <p></p> <p>A new dialog will open, allowing you to configure the new MCP server providing name, description, URL, and authentication method.</p> <p>Provide a name for the MCP server, for example:</p> <p><code>HR MCP Server</code></p> <p>Provide a description, for example:</p> <p><code>Allows managing a list of candidates for the HR department</code></p> <p>Configure the URL of the server, providing the URL that you copied from the dev tunnel with name <code>[Connect via browser of your dev tunnel]</code>.</p> <p>Select None as the authentication method and then select Create to configure the actual tool.</p> <p></p> <p>Once the tool will get created, you will see a new dialog window requesting you to connect to the MCP server.</p> <p></p> <p>Select the <code>Not connected</code> option and then select Create a new connection. Follow the steps and you will be able to connect to the target MCP server.</p> <p></p> <p>Once the connection is completely configured, you can select the Add and configure command in the dialog window and see the MCP server and tools properly configured.</p> <p></p> <p>All the tools exposed by the MCP server are now available to your agent, as you can verify in the window displaying the MCP server details and tools.</p> <p></p> <p></p>"},{"location":"pages/make/copilot-studio/06-mcp/#step-2-test-the-new-mcp-server-integration","title":"Step 2: Test the new MCP server integration","text":"<p>Publish your agent by selecting Publish in the top right corner. Once published, test the agent in the integrated Test panel using the following prompt:</p> <pre><code>List all candidates\n</code></pre> <p>The agent should use the MCP server's <code>list_candidates</code> tool to return a complete list of all candidates in your HR system. However, in order to being able to consume the list of candidates you will need to connect to the target connector. As such, Copilot Studio will ask you to Open connection manager, connect to the MCP server, and then Retry the request.</p> <p></p> <p>Once the connection is established, you can get the actual list of candidates from the HR MCP server.</p> <p></p> <p>Debugging the MCP server locally</p> <p>If you are a developer and you like to dig into the MCP server implementation, you can add breakpoints to the <code>HRTools.cs</code> file and attach a debugger from Visual Studio Code. You will be able to dig into the code and debug the actual MCP server in action.</p> <p>You can also make the agent available in the Microsoft 365 Copilot Chat. Select the 1\ufe0f\u20e3 Channels section, then select the 2\ufe0f\u20e3 Teams and Microsoft 365 Copilot channel, check the 3\ufe0f\u20e3 Make agent available in Microsoft 365 Copilot option, and then select the 4\ufe0f\u20e3 Add channel command. Wait for the channel to be enabled, then close the channel side panel and publish the agent again selecting the Publish command of the agent in the top right corner.</p> <p></p> <p>Now, open the Teams and Microsoft 365 Copilot channel again and select the command See agent in Microsoft 365 to add the agent to Microsoft 365 Copilot.</p> <p></p> <p>You will see the interface to add the agent to Microsoft 365 Copilot, select Add and then Open, in order to play with the agent in Microsoft 365 Copilot.</p> <p>Agent details</p> <p>If you like, through the Teams and Microsoft 365 Copilot channel configuration panel, you can also provide additional details about the agent like a description, a custom icon, etc.</p> <p></p> <p>You can now play with the agent in Microsoft 365 Copilot, notice the suggested prompts in the UI of the agent. Now, for example, you can try with another prompt like:</p> <pre><code>Search for candidate Alice\n</code></pre> <p></p> <p>Now the agent should use the MCP server's <code>search_candidates</code> tool and return only one candidate matching the search criteria. However, since we are in the Microsoft 365 Copilot context, you will need to connect again to the MCP server, using the Microsoft Copilot Studio connections management interface.</p> <p></p> <p>Once connected, you will be able to run again the prompt and get the expected response.</p> <p></p> <p>It is now time to test a much more advanced tool, like the <code>add_candidate</code> one to add a new candidate to the HR system. Use the following prompt:</p> <pre><code>Add a new candidate: John Smith, Software Engineer, skills: React, Node.js, \nemail: john.smith@email.com, speaks English and Spanish\n</code></pre> <p>The agent will understand your intent, will extract the input arguments for the <code>add_candidate</code> tool, and will invoke it adding a new candidate to the list. The response from the MCP server will be a simple confirmation.</p> <p></p> <p>You can double check the outcome by listing again the whole list of candidates. You can find <code>John Smith</code> as a new candidate at the end of the list.</p> <p></p> <p>You can also have fun with other prompts like:</p> <pre><code>Update the candidate with email bob.brown@example.com to speak also French\n</code></pre> <p>or:</p> <pre><code>Add skill \"Project Management\" to candidate bob.brown@example.com\n</code></pre> <p>or:</p> <pre><code>Remove candidate bob.brown@example.com\n</code></pre> <p>The agent will invoke the right tools for you and will act accordingly to your prompts.</p> <p>Well done! Your agent is fully functional and capable of consuming all the tools exposed by the HR MCP server.</p> <p></p> <p>CONGRATULATIONS!</p> <p>You have completed Lab MCS6 - Consuming an MCP server!</p> <p>Start here with Lab MCS7, to learn how to create autonomous agents in Copilot Studio.  </p> <p></p>"},{"location":"pages/make/copilot-studio/07-autonomous/","title":"Lab MCS7 - Creating Autonomous Agents","text":"<p>In this lab, you are going to understand how to create an autonomous agent using Microsoft Copilot Studio. The autonomous agent that you are going to create automatically processes candidate data from PDF files uploaded to SharePoint. The agent monitors a SharePoint document library for new PDF uploads, extracts candidate information using AI, and automatically creates candidate records using the MCP server you built in Lab MCS6. This lab demonstrates how autonomous agents can streamline HR workflows by automating document processing and data entry tasks.</p> Get a quick overview of the lab in this video. <p>Do these labs if you want to build agents with Microsoft Copilot Studio</p> <ul> <li>MCS0 - Setup</li> <li>MCS1 - First agent</li> <li>MCS2 - Defining Topics</li> <li>MCS3 - Defining Tools</li> <li>MCS4 - Extending Microsoft 365 Copilot</li> <li>MCS5 - Consuming a custom connector</li> <li>MCS6 - Consuming an MCP server</li> <li>MCS7 - Creating Autonomous Agents</li> <li>MCS8 - Integrating Azure AI Search for RAG</li> </ul> <p>Note</p> <p>This lab builds on the previous one, Lab MCS6. You should be able to continue consuming the same MCP server that you configured in the previous lab.</p> <p>In this lab you will learn:</p> <ul> <li>How to create autonomous agents in Microsoft Copilot Studio</li> <li>How to configure SharePoint document library triggers</li> <li>How to process PDF documents with AI to extract structured data</li> <li>How to integrate autonomous agents with MCP servers</li> </ul>"},{"location":"pages/make/copilot-studio/07-autonomous/#exercise-1-setting-up-the-sharepoint-environment","title":"Exercise 1: Setting up the SharePoint Environment","text":"<p>In this exercise you are going to prepare a SharePoint document library that will serve as the trigger point for your autonomous agent. The agent will monitor this library for new PDF files containing candidate data and automatically process them.</p>"},{"location":"pages/make/copilot-studio/07-autonomous/#step-1-creating-the-sharepoint-document-library","title":"Step 1: Creating the SharePoint Document Library","text":"<p>Before creating the autonomous agent, you need to set up a SharePoint document library where HR personnel can upload candidate PDF files.</p> <p>Navigate to your SharePoint site (you can use any SharePoint site of your Microsoft 365 tenant, or you can create a new one from scratch) and create a new document library:</p> <ol> <li>Go to Site contents and select New \u2192 Document library</li> <li>Select Blank library as the template</li> <li>Name the library: <code>Candidates Data</code></li> <li>Set the description: <code>Document library for candidate PDF data files</code></li> <li>Select Create to create the library</li> </ol> <p></p> <p>Once created, configure the library permissions to ensure your autonomous agent can access it:</p> <ol> <li>Select Settings (gear icon) \u2192 Library settings</li> <li>Under Permissions and Management, select Permissions for this document library</li> <li>Ensure that the account you're using for Microsoft Copilot Studio has at least Contribute permissions</li> </ol> <p></p>"},{"location":"pages/make/copilot-studio/07-autonomous/#step-2-preparing-sample-pdf-files","title":"Step 2: Preparing Sample PDF Files","text":"<p>For testing purposes, download resumes.zip and unzip the folder. The downloaded files describe hypothetical candidates including information such as:</p> <ul> <li>Full name</li> <li>Email address  </li> <li>Current role/position</li> <li>Skills and expertise</li> <li>Spoken languages</li> </ul> <p>You can also create simple PDF files using any word processor and save them as PDF, or use existing resume/CV files. Make sure the text is readable (not scanned images) so that AI can extract the information properly.</p> <p></p>"},{"location":"pages/make/copilot-studio/07-autonomous/#step-3-ensuring-prerequisites","title":"Step 3: Ensuring Prerequisites","text":"<p>Before proceeding, ensure you have completed the following:</p> <ul> <li>Lab MCS6: The HR MCP server should be running and accessible via dev tunnel</li> <li>SharePoint Access: Permissions to create and manage document libraries</li> <li>Power Platform Environment: Access to the same environment used in previous labs</li> <li>Sample PDF Files: At least 2-3 test PDF files with candidate data</li> </ul> <p>Also verify that the HR MCP server from Lab MCS6 is still running and if not, you can simply run it:</p> <pre><code>dotnet run\n</code></pre> <p>And ensure your dev tunnel is active:</p> <pre><code>devtunnel host hr-mcp\n</code></pre> <p>Keep both services running throughout this lab as the autonomous agent will need to communicate with the MCP server.</p> <p></p>"},{"location":"pages/make/copilot-studio/07-autonomous/#exercise-2-creating-the-autonomous-agent","title":"Exercise 2: Creating the Autonomous Agent","text":"<p>In this exercise you are going to create the autonomous agent in Microsoft Copilot Studio that will monitor the SharePoint document library and process new PDF uploads automatically.</p>"},{"location":"pages/make/copilot-studio/07-autonomous/#step-1-creating-the-autonomous-agent","title":"Step 1: Creating the Autonomous Agent","text":"<p>Open a browser and, using the work account of your target Microsoft 365 tenant, go to https://copilotstudio.microsoft.com to start using Microsoft Copilot Studio.</p> <p>Select the <code>Copilot Dev Camp</code> environment that you created in previous labs, then select Create in the left navigation menu, and choose Agent to create a new agent.</p> <p>Choose to Configure and define your autonomous agent with the following settings:</p> <ul> <li>Name: </li> </ul> <pre><code>Autonomous HR Docs Processor\n</code></pre> <ul> <li>Description: </li> </ul> <pre><code>An autonomous AI agent that monitors SharePoint for new candidate PDF uploads and \nautomatically processes them to create candidate records via MCP server integration\n</code></pre> <ul> <li>Instructions: </li> </ul> <pre><code>You are an autonomous HR assistant that specializes in processing candidate data \nfrom PDF documents. When a new PDF file is uploaded to the SharePoint document library, \nyou automatically:\n\n1. Extract candidate information from the PDF file content including name, email, skills, languages, and role\n2. Validate and structure the extracted data\n3. Create a new candidate record using the 'add_candidate' tool of the HR MCP server\n4. Provide confirmation of successful processing\n5. Send me an email with confirmation that the new candidate record was created and with a recap of candidate's data\n\nAlways ensure data accuracy and provide clear feedback about the processing results. \nHandle errors gracefully and provide informative messages when processing fails.\n\nIMPORTANT: Do not wait for any user input. Work completely autonomously.\n\nDO NOT invent or assume fake data about candidates. AVOID allucinations.\nYou MUST ONLY process real and existing data.\n</code></pre> <p>Select Create to create your autonomous agent.</p> <p></p>"},{"location":"pages/make/copilot-studio/07-autonomous/#step-2-enhancing-agent-intelligence","title":"Step 2: Enhancing Agent Intelligence","text":"<p>After creating the agent, you need to ensure that its capabilities are enhanced with generative AI reasoning and knowledge integration.</p> <p>In the Orchestration section, ensure that the Use generative AI to determine how best to respond to users and events is enabled. This enables the agent to intelligently process different types of events and determine the appropriate actions.</p> <p></p> <p>In the Knowledge section, you can optionally add knowledge sources if you have specific HR documentation or candidate processing guidelines. For this lab, we'll rely on the agent's built-in AI capabilities and the MCP server integration.</p> <p>In case of any configuration changes, select Save to confirm them.</p> <p></p>"},{"location":"pages/make/copilot-studio/07-autonomous/#step-3-adding-the-mcp-server-integration","title":"Step 3: Adding the MCP Server Integration","text":"<p>Your autonomous agent needs access to the HR MCP server tools to create candidate records. Navigate to the Tools section and select + Add a tool.</p> <ol> <li>Choose Model Context Protocol group</li> <li>Find and select the HR MCP Server that you configured in Lab MCS6</li> <li>Select Add and configure to integrate the MCP server tools</li> </ol> <p></p> <p>This gives your autonomous agent access to all the HR MCP server tools:</p> <ul> <li><code>list_candidates</code></li> <li><code>search_candidates</code> </li> <li><code>add_candidate</code></li> <li><code>update_candidate</code></li> <li><code>remove_candidate</code></li> </ul> <p>The agent will primarily use the <code>add_candidate</code> tool for processing new PDF uploads.</p> <p></p>"},{"location":"pages/make/copilot-studio/07-autonomous/#step-4-adding-the-email-management-mcp-server","title":"Step 4: Adding the Email Management MCP Server","text":"<p>Your autonomous agent also needs access to the Email Management MCP Server to being able to send e-mails. Navigate to the Tools section and select + Add a tool.</p> <ol> <li>Choose Model Context Protocol group</li> <li>Find and select Email Management MCP Server</li> <li>Select Add and configure to integrate the MCP server tools</li> </ol> <p>This gives your autonomous agent access to a wide set of tools to manage the e-mails in the current user's mailbox. The agent will primarily use the <code>SendEmail</code> tool for sending notification e-mails.</p> <p></p>"},{"location":"pages/make/copilot-studio/07-autonomous/#exercise-3-configuring-sharepoint-triggers","title":"Exercise 3: Configuring SharePoint Triggers","text":"<p>In this exercise you will configure the autonomous agent to automatically trigger when new PDF files are uploaded to the SharePoint document library.</p>"},{"location":"pages/make/copilot-studio/07-autonomous/#step-1-adding-the-sharepoint-trigger","title":"Step 1: Adding the SharePoint Trigger","text":"<p>In your autonomous agent, navigate to the 1\ufe0f\u20e3 Overview section, scroll to the 2\ufe0f\u20e3 Triggers panel and select 3\ufe0f\u20e3 + Add trigger.</p> <p></p> <p>From the Add trigger dialog, select When a file is created (properties only) from the SharePoint connector options. Then select Next to configure the trigger.</p> <p></p> <p>The next step of the trigger's configuration is to give a name to the trigger and to configure/connect the permissions to access the target apps. In the current scenario the apps are:</p> <ul> <li>Microsoft Copilot Studio</li> <li>SharePoint</li> </ul> <p>Configure the trigger as follows:</p> <ul> <li>Trigger name: <code>When PDF uploaded to Candidate Data library</code></li> </ul> <p></p> <p>Select Next and proceed to configure the trigger with the following additional settings:</p> <ul> <li>Site Address: Select your target SharePoint site or enter its URL</li> <li>Library Name: Select <code>Candidate Data</code> (the library you created)</li> <li>Folder: Leave blank to monitor the entire library</li> <li>Limit columns by View (Optional): All Documents</li> <li>Additional instructions to the agent when it's invoked by this trigger: Use content from <code>Body</code> and read content of the PDF file.</li> </ul> <p></p> <p>Select Create trigger to add the SharePoint monitoring trigger to your agent. The process takes a while to complete. Once it is ready, you will see a dialog inviting you to test the trigger.</p> <p></p> <p>Select Close to return to the Overview section of your agent.</p> <p></p>"},{"location":"pages/make/copilot-studio/07-autonomous/#step-2-testing-the-trigger","title":"Step 2: Testing the Trigger","text":"<p>In the list of Triggers there is now the new trigger and you can select the little flask near the ellipsis (...) to test it.</p> <p></p> <p>Select the flask, a dialog window shows up waiting for a file to be uploaded in the target library in SharePoint Online.</p> <p></p> <p>Once at least one file will be uploaded in the target library, the dialog updates and allows you to select the Start testing command to test the autonomous agent. In case there are more than one files uploaded, you can select the one you want to use to test the trigger.</p> <p>You can simply upload in the target SharePoint Online library one of the resumes that you downloaded before and wait for the agent to process it.</p> <p>Note</p> <p>It can take up to one minute for the agent to get evidence of the new file(s) uploaded. Be patient while waiting for the trigger test dialog to be ready for testing.</p> <p></p> <p>Once the test starts, the agent can interact with you through the Test your agent side panel. The very first thing you will need to do in this scenario is to connect the agent instance to the target HR MCP Server, so that the agent can create the new candidate. Select Open connection manager in the automated message sent by the agent, then Connect the agent to the HR MCP Server, lastly go back to the Test your agent panel and select Retry.</p> <p>You should be able to see a confirmation message that the candidate described in the PDF resume that you uploaded got added to the target HR MCP server.</p> <p></p> <p>If you like, you can send a prompt to <code>List all the candidates</code> to validate that the new candidate is now part of the list. Your autonomous agent is ready! You can now Publish it and it will start processing files autonomously!</p> <p>When you publish the agent, you might see a couple of warnings like in the following picture.</p> <p></p> <ol> <li>Full access for editors: users with Editor permission will have access to embedded connections used by Flows or Triggers added to this agent.</li> <li>Your agent includes triggers that use the author's credentials: If the instructions in these triggers share data with other users, those users can use the original editor's credentials to access information or complete a task.</li> </ol> <p>Once you have published the agent, try to upload new PDF resume files and see what happens. If you go to the Activity section of the agent, after uploading one or more files to the target SharePoint Online library, you will see the <code>Automated</code> invocation of the agent.</p> <p></p> <p></p>"},{"location":"pages/make/copilot-studio/07-autonomous/#exercise-4-inside-the-autonomous-agents","title":"Exercise 4: Inside the autonomous agents","text":"<p>In this exercise you will understand how an autonomous agent works and what happens behind the scenes.</p>"},{"location":"pages/make/copilot-studio/07-autonomous/#step-1-behind-the-scenes-of-the-trigger","title":"Step 1: Behind the scenes of the trigger","text":"<p>After creating and testing the trigger, you might want to understand how an autonomous agent works. Select the ellipsis (...) next to your trigger and choose Edit in Power Automate.</p> <p></p> <p>In Power Automate, you'll see the flow that sits behind the scenes of the autonomous agent's trigger. </p> <p></p> <p>The flow is really trivial. There are simply a triggering action of type When a file is created (properties only) from the SharePoint connector and another action Sends a prompt to the specified copilot for processing to invoke the target agent. Practically speaking, a trigger of an autonomous agent is a Power Automate flow that sends a prompt to the agent. As such, almost any trigger for a Power Automate flow can become a trigger for a Copilot Studio autonomous agent.</p> <p>In case of need, you can customize the behavior of the flow to add additional behaviors or functionalities to the trigger before invoking the autonomous agent. However, if that is the case, you need to keep into account the insights that you can find in the next step.</p> <p></p>"},{"location":"pages/make/copilot-studio/07-autonomous/#step-2-handling-multiple-files-uploads","title":"Step 2: Handling multiple files uploads","text":"<p>Another interesting thing to know about triggers of autonomous agents is that, when you upload multiple files to SharePoint, or in general when multiple triggering events happen you will not always see one Power Automate flow triggered for each file/event. Likewise, you will not see one agent instance for each file/event. In fact, for example when processing files uploaded to a SharePoint Online document library, there could be one flow instance processing multiple files uploaded in a single unit of time. The Power Automate flow will then trigger one agent instance, which will process one by one every single file.</p> <p>You can clearly inspect the described behavior if you upload two (or more) files at once and then wait for the flow to run in Power Automate and for the autonomous agent to be invoked in Copilot Studio. In fact, there will be only one flow executed for a set of uploaded files and there will be one agent instance for that flow.</p> <p>You can validate this behavior selecting the Activity section of the autonomous agent and inspecting one <code>Automated</code> instance with more than one <code>Completed steps</code> like in the following screenshot.</p> <p></p> <p>Selecting the instance you can see that the agent autonomously processed two (or more) files invoking the <code>add_candidate</code> tool for each of them. There is no need to define complex logic in your agent. Just because in the agent's instructions we said</p> <pre><code>... When a new PDF file is uploaded to the SharePoint document library: ...\n</code></pre> <p>That's enough for the agent's autonomous intelligence to loop across all the uploaded files and apply the same logic to all of them. This is amazing and gives you the idea of how powerful AI is nowadays!</p> <p></p> <p></p> <p>CONGRATULATIONS!</p> <p>You have completed Lab MCS7 - Creating Autonomous Agents!</p> <p>Start here with Lab MCS8, to learn how to use RAG via Microsoft Azure AI Search in Copilot Studio.  </p> <p></p>"},{"location":"pages/make/copilot-studio/08-rag/","title":"Lab MCS8 - Integrating Azure AI Search for RAG","text":"<p>In this lab, you are going to understand how to enhance your Microsoft Copilot Studio agents with Retrieval-Augmented Generation (RAG) capabilities using Azure AI Search. You'll create a specialized HR Knowledge Agent that can search through candidate documents using vector search, providing intelligent, contextual responses backed by your organization's data. This lab demonstrates how to create powerful AI agents that combine the conversational abilities of Copilot Studio with the advanced search capabilities of Azure AI Search.</p> <p>Do these labs if you want to build agents with Microsoft Copilot Studio</p> <ul> <li>MCS0 - Setup</li> <li>MCS1 - First agent</li> <li>MCS2 - Defining Topics</li> <li>MCS3 - Defining Tools</li> <li>MCS4 - Extending Microsoft 365 Copilot</li> <li>MCS5 - Consuming a custom connector</li> <li>MCS6 - Consuming an MCP server</li> <li>MCS7 - Creating Autonomous Agents</li> <li>MCS8 - Integrating Azure AI Search for RAG</li> </ul> <p>Important</p> <p>You should have experience with Microsoft Copilot Studio agent creation and basic Azure resource management.</p> <p>In this lab you will learn:</p> <ul> <li>How to create and configure Azure AI Search service for knowledge indexing</li> <li>How to import and vectorize PDF documents using Azure AI Search</li> <li>How to integrate Azure AI Search as a knowledge source in Microsoft Copilot Studio</li> <li>How to create agents that leverage RAG for intelligent document search</li> </ul> What is Retrieval-Augmented Generation (RAG)? <p>Retrieval-Augmented Generation (RAG) is a technique used in artificial intelligence to improve the quality of responses generated by language models. Here's a simple example to understand it better:</p> <p>Imagine you have a smart assistant that can write answers to your questions. Sometimes, this assistant might not know everything it needs to give a great answer. To help with this, RAG lets the assistant look up information from a large collection of documents, similar to how you might search the internet for answers. After finding the relevant information, the assistant then uses this data to write a better, more accurate response.</p> <p>So, RAG combines two steps:</p> <ul> <li>Retrieval: Finding relevant information from a big pool of data.</li> <li>Generation: Using that information to create a detailed and accurate response.</li> </ul> <p>This way, RAG helps in providing more informed and useful answers, making it very effective for tasks like answering questions, writing articles, and assisting with research.</p> <p>Learn more about the RAG by watching this Doodle to Code video!</p> <p></p> Benefits of using Vector Search <p>Vector search is an advanced technique used to find information quickly and accurately based on its meaning rather than just matching exact words. Unlike traditional text-based search, which relies on exact keyword matches, vector search uses numeric vectors to find content that is similar to your query. This enables Vector search to handle:</p> <ul> <li>Semantic or conceptual similarity: Matching concepts that are similar in meaning even if they use different words (e.g., \"recruitment\" and \"hiring\").</li> <li>Multilingual content: Finding equivalent content across different languages (e.g., \"resume\" in English and \"curriculum vitae\" in Latin).</li> <li>Multiple content types: Searching across different formats (e.g., text documents, and PDFs).</li> </ul> <p>Here is how vector search works:</p> <ol> <li>Converting text to vectors: Text or documents are turned into a series of numbers (a vector) that captures the essence or meaning of that content. This is done using embedding models.</li> <li>Storing vectors: These vectors are stored in a special database (for example an Azure AI Search index) designed to handle them efficiently.</li> <li>Searching with vectors: When you search for something, your query is also converted into a vector. The search system then looks for vectors in the index that are close to your query vector in terms of meaning.</li> </ol> <p>For example, if you search for \"software engineering skills,\" the system can find candidates with \"programming expertise\" or \"development capabilities\" even if they don't have the exact words from your search query.</p>"},{"location":"pages/make/copilot-studio/08-rag/#exercise-1-setting-up-azure-ai-search-service","title":"Exercise 1: Setting up Azure AI Search Service","text":"<p>In this exercise you are going to create and configure the Azure AI Search service that will serve as the knowledge foundation for your RAG-enabled agent.</p>"},{"location":"pages/make/copilot-studio/08-rag/#step-1-creating-azure-ai-search-service-resource","title":"Step 1: Creating Azure AI Search Service Resource","text":"<p>Before integrating with Microsoft Copilot Studio, you need to set up Azure AI Search service to store and index your documents.</p> <p>Navigate to the Azure Portal and create an Azure AI Search service:</p> <ol> <li>Select Create a resource and search for <code>Azure AI Search</code></li> <li>Select the Azure AI Search service and then Create</li> <li> <p>Fill out the following details and select Review + Create:</p> <ul> <li>Subscription: Your Azure subscription</li> <li>Resource group: Select the same resource group used for other labs or create new one: <code>copilot-camp-rg</code></li> <li>Service name: A descriptive name such as <code>copilotcamp-ai-search</code> (must be globally unique)</li> <li>Location: Choose the same region as your other Azure resources, if any</li> <li>Pricing tier: Basic (sufficient for this lab)</li> </ul> </li> </ol> <p></p> <p>Once your Azure AI Search service is created, navigate to your resource:</p> <ol> <li>In the Overview section, copy and save the URL (you'll need this later)</li> <li>Navigate to Keys under Settings, in the left navigation bar, and copy the Primary admin key (you'll need this later)</li> </ol> <p>Both the URL and admin key will be required when connecting to Azure AI Search from within Microsoft Copilot Studio.</p> <p></p>"},{"location":"pages/make/copilot-studio/08-rag/#step-2-creating-azure-storage-account","title":"Step 2: Creating Azure Storage Account","text":"<p>For storing the documents that will be indexed, you need an Azure Storage Account that will work with Azure AI Search.</p> <p>In the Azure Portal, create a storage account:</p> <ol> <li>Select Create a resource and search for <code>Storage Account</code></li> <li>Select Storage Account and then Create</li> <li> <p>Fill out the following details and select Review + Create:</p> <ul> <li>Subscription: Your Azure subscription</li> <li>Resource group: Select the same resource group as your Azure AI Search service</li> <li>Storage account name: A unique name such as <code>copilotcampstorage</code> (must be globally unique)</li> <li>Region: Same region as your Azure AI Search service</li> <li>Preferred storage type: Azure Blob Storage or Azure Data Lake Storage Gen 2</li> <li>Performance: Standard</li> <li>Redundancy: Locally redundant storage (LRS)</li> </ul> </li> </ol> <p></p> <p>After the storage account is created, you'll use it to store the PDF documents before they are indexed by Azure AI Search.</p> <p></p>"},{"location":"pages/make/copilot-studio/08-rag/#step-3-creating-text-embedding-model","title":"Step 3: Creating Text Embedding Model","text":"<p>To enable vector search capabilities, you need to create a text embedding model in Azure OpenAI that will convert documents and queries into vector representations.</p> <p>If you don't already have an Azure OpenAI service instance, create one first:</p> <ol> <li>In the Azure Portal, select Create a resource and search for <code>Azure OpenAI</code></li> <li>Select Azure OpenAI and then Create</li> <li> <p>Fill out the following details:</p> <ul> <li>Subscription: Your Azure subscription</li> <li>Resource group: Select the same resource group as your other resources</li> <li>Region: Choose a region that supports Azure OpenAI (such as East US, West Europe, or South Central US)</li> <li>Name: A descriptive name such as <code>copilotcamp-openai</code></li> <li>Pricing tier: Standard S0</li> </ul> </li> <li> <p>Move Next until the end of the creation wizard and then select Create</p> </li> <li>Wait for the deployment to complete (this may take a few minutes)</li> <li>Once created, navigate to your Azure OpenAI resource and note the endpoint URL for later use</li> </ol> <p>Now navigate to Azure AI Foundry. If it is the first time that you access the Azure AI Foundry portal, you might need to select the Azure OpenAI instance that you just created. Select the service instance and proceed with the creation of an embedding model going through the following steps:</p> <ol> <li>Select 1\ufe0f\u20e3 Deployments from the left navigation</li> <li>Select 2\ufe0f\u20e3 + Deploy model</li> <li>Select 3\ufe0f\u20e3 Deploy base model to start deploying the model</li> <li>In the popup dialog, search for model 4\ufe0f\u20e3 <code>text-embedding-ada-002</code></li> <li>Select 5\ufe0f\u20e3 Confirm to start configuring the deployment</li> <li> <p>When the configuration dialog pops up, configure the following settings:</p> <ul> <li>Deployment name: <code>text-embeddings</code> (remember this name)</li> <li>Deployment type: Standard</li> <li>Model version: 2 (Default)</li> <li>Content Filter: DefaultV2</li> </ul> </li> <li> <p>Select 6\ufe0f\u20e3 Deploy and wait for the deployment to complete</p> </li> </ol> <p></p> What does <code>text-embedding-ada-002</code> do? <p>The <code>text-embedding-ada-002</code> model on Azure OpenAI converts text into numeric vectors that represent the meaning of the text. This allows for vector search, where instead of matching exact words, the search finds text with similar meanings. It works with multiple languages and different content types, making it useful for comparing text across languages and formats. When used with Azure AI Search, it improves search results by finding the most relevant and contextually accurate information. This model is perfect for creating advanced search solutions and applications that need to understand natural language.</p> <p>The text embedding model is essential for converting both the indexed documents and user queries into vectors that can be compared for semantic similarity.</p> <p>Tip: Handling quota limitations</p> <p>If you see a \"No quota available\" message, you can either:</p> <ol> <li>Select a different region for your deployment</li> <li>Request additional quota from the Azure OpenAI quota management page</li> <li>Free up resources from other deployments you're not using</li> </ol> <p></p>"},{"location":"pages/make/copilot-studio/08-rag/#exercise-2-creating-and-populating-the-search-index","title":"Exercise 2: Creating and Populating the Search Index","text":"<p>In this exercise you will create a search index in Azure AI Search and populate it with candidate resume documents using the integrated vectorization feature.</p>"},{"location":"pages/make/copilot-studio/08-rag/#step-1-preparing-sample-documents","title":"Step 1: Preparing Sample Documents","text":"<p>For this lab, download the sample resume documents that will be indexed for search. Download fictitious_resumes.zip and unzip the folder to access the PDF files.</p> <p>These sample resumes contain diverse candidate profiles with information such as:</p> <ul> <li>Candidate names and contact information</li> <li>Technical skills and expertise areas</li> <li>Work experience and role history</li> <li>Education backgrounds</li> <li>Language proficiencies</li> <li>Professional certifications</li> </ul> <p>Review the content of these files to understand the type of information that will be searchable through your RAG-enabled agent. Notice also that the documents are written in various languages. This will not be a problem for the <code>text-embedding-ada-002</code> model or for the vector index.</p> <p></p>"},{"location":"pages/make/copilot-studio/08-rag/#step-2-uploading-sample-documents-in-the-storage-account","title":"Step 2: Uploading sample documents in the Storage Account","text":"<p>Using Azure AI Search, you'll create a vector index with your resume documents using the integrated vectorization feature.</p> <p>Navigate to Azure Portal and access the Azure Storage Account service instance. </p> <ol> <li>Select the 1\ufe0f\u20e3 Containers in the Data storage group of commands in the left navigation</li> <li>Select the 2\ufe0f\u20e3 + Add container command in the command bar</li> <li>Provide a name 3\ufe0f\u20e3 for the new container, for example <code>resumes</code></li> <li>Select 4\ufe0f\u20e3 Create to create the actual container</li> </ol> <p></p> <p>Once the container has been created, you can upload the resume files following these steps:</p> <ol> <li>Select 1\ufe0f\u20e3 Upload</li> <li>Drag and drop the resume files or select 2\ufe0f\u20e3 Browse for files and select the resume files</li> <li>Select the 3\ufe0f\u20e3 Upload command and wait for the upload to complete</li> </ol> <p></p> <p></p>"},{"location":"pages/make/copilot-studio/08-rag/#step-3-populating-the-vector-index-with-integrated-vectorization","title":"Step 3: Populating the Vector Index with Integrated Vectorization","text":"<p>Once the resume files are uploaded go back to the home page of the Azure Portal and access the Azure AI Search service instance. Then select the Import data (new) command in the top command bar.</p> <p></p> <p>A new page will show up, through which you can configure the data import process. Select the Azure Blob Storage data source.</p> <p></p> <p>Right after, select RAG as the scenario that you are targeting.</p> <p></p> <p>Now configure the RAG scenario accordingly to the following settings:</p> <ol> <li> <p>Configure your Azure Blob Storage section:</p> <ul> <li>Subscription: Your Azure subscription</li> <li>Storage account: the Storage Account you created before</li> <li>Blob container: the new container that you just created and where you uploaded the resume files, for example <code>resumes</code></li> <li>Blob folder: you can leave it blank, unless you created a folders structure in the storage container</li> <li>Parsing mode: use the <code>Default</code> value</li> <li>Move Next</li> </ul> </li> <li> <p>Vectorize your text section:</p> <ul> <li>Kind: Azure OpenAI</li> <li>Subscription: Your Azure subscription</li> <li>Azure Open AI service: select the Azure OpenAI instance that you created</li> <li>Model deployment: select the <code>text-embeddings</code> model that you just created</li> <li>Authentication type: the default <code>API Key</code> value is ok</li> <li>Check the box to declare <code>I acknowledge that connecting to an Azure OpenAI service will incur additional costs to my account.</code></li> <li>Move Next</li> </ul> </li> <li> <p>Vectorize your images section:</p> <ul> <li>In case you are willing to process images and text in images, you could configure specific settings</li> <li>Here you can simply move Next</li> </ul> </li> <li> <p>Advanced ranking and relevancy section:</p> <ul> <li>If you like you can schedule recurring updates of the index, on a timer based model. You can also choose whether to use the semantic ranker to get results also based on semantic and not only on lexical analysis. Last but not least, you can configure the fields that will be created in the target index</li> <li>Here you can simply move Next</li> </ul> </li> <li> <p>Review and create section:</p> <ul> <li>Here you can provide a prefix for the index, indexer, data source, and skillset that will be created. For example you can use the value <code>resumes</code></li> <li>Review the settings and when you are ready select Create to create and feed the vector index</li> </ul> </li> </ol> <p></p> <p>Once the vector index is created, a small dialog confirms the index creation and availability. Select the Start searching command to start playing with the index. In the search index page, you can simply select the Search command and see the output. Notice that, for every value in the index, you also have a <code>text_vector</code> field that contains the text vectorized using the <code>text-embedding-ada-002</code> model.</p> <p></p> <p></p>"},{"location":"pages/make/copilot-studio/08-rag/#exercise-3-creating-the-rag-enabled-agent","title":"Exercise 3: Creating the RAG-Enabled Agent","text":"<p>In this exercise you will create a Microsoft Copilot Studio agent that leverages your Azure AI Search index to provide intelligent, document-backed responses about HR candidates.</p>"},{"location":"pages/make/copilot-studio/08-rag/#step-1-creating-the-hr-knowledge-agent","title":"Step 1: Creating the HR Knowledge Agent","text":"<p>Navigate to Microsoft Copilot Studio and create a new agent optimized for knowledge search.</p> <p>Using your work account, access your <code>Copilot Dev Camp</code> environment and create a new agent:</p> <ol> <li>Select Create \u2192 + New agent</li> <li>Choose to manually Configure the agent</li> </ol> <p>Define your agent as follows:</p> <ul> <li>Name: </li> </ul> <pre><code>HR Knowledge Agent\n</code></pre> <ul> <li>Description: </li> </ul> <pre><code>An intelligent HR assistant that searches through candidate documents using advanced \nvector search capabilities to provide contextual, document-backed responses\n</code></pre> <ul> <li>Instructions: </li> </ul> <pre><code>You are an intelligent HR Knowledge Assistant specializing in candidate search. \nYou have access to a comprehensive database of candidate resumes through advanced \nvector search capabilities.\n\nWhen users ask questions, you should:\n\n1. Search through the candidate database using semantic understanding\n2. Provide detailed, accurate information based on the indexed documents\n3. Always include proper citations and references to source documents\n4. Explain your reasoning when matching candidates to requirements\n5. Suggest alternative candidates when exact matches aren't available\n6. Help users understand the skills and qualifications of different candidates\n\nYou excel at:\n- Finding candidates with specific technical skills\n- Matching language requirements with candidate profiles\n- Identifying experience levels and career progression\n- Understanding educational backgrounds and certifications\n- Semantic search that goes beyond keyword matching\n\nAlways provide helpful, accurate information while respecting privacy and being professional.\n</code></pre> <p></p> <p>Select Create to create your knowledge-enabled agent.</p> <p>Once the agent is created, double check that the option to Use generative AI to determine how best to respond to users and events is enabled, in order to have the Generative AI based orchestrator configured. Also verify that <code>GPT-4o</code> model is selected in the Details panel of the agent's settings.</p> <p></p> <p></p>"},{"location":"pages/make/copilot-studio/08-rag/#step-2-adding-azure-ai-search-as-knowledge-source","title":"Step 2: Adding Azure AI Search as Knowledge Source","text":"<p>Integrate your Azure AI Search index as a knowledge source for your agent.</p> <p>Navigate to the Knowledge section and add your search index:</p> <ol> <li>Select + Add knowledge</li> <li>From the Add knowledge dialog, select Featured</li> <li>Select Azure AI Search</li> </ol> <p></p> <p>Configure the Azure AI Search connection:</p> <ol> <li>Select Create new connection</li> <li> <p>Configure the authentication:</p> <ul> <li>Authentication type: Access Key</li> <li>Azure AI Search Endpoint URL: Enter the URL you saved from your Azure AI Search service</li> <li>Azure AI Search Admin Key: Enter the admin key you copied earlier</li> </ul> </li> <li> <p>Select Create to establish the connection (a green checkmark confirms success)</p> </li> </ol> <p></p> <p>Complete the knowledge source configuration:</p> <ol> <li>Select the index with name <code>resumes</code> (or whatever else name you used when you created the index)</li> <li>Select Add to agent to complete the integration</li> </ol> <p></p> <p>The knowledge source will appear in your knowledge sources table with a status of \"In progress\" while Copilot Studio indexes the metadata. Wait for the status to change to \"Ready\" before proceeding.</p> <p></p>"},{"location":"pages/make/copilot-studio/08-rag/#exercise-4-testing-the-agent","title":"Exercise 4: Testing the agent","text":"<p>In this exercise you will test your RAG-enabled agent and learn how to leverage different types of queries and use cases.</p>"},{"location":"pages/make/copilot-studio/08-rag/#step-1-testing-basic-knowledge-retrieval","title":"Step 1: Testing Basic Knowledge Retrieval","text":"<p>Start by testing fundamental search capabilities to ensure your agent can access and use the indexed knowledge effectively.</p> <p>In the test panel, try these basic queries to validate the knowledge integration:</p> <pre><code>Hello! Can you help me find candidates with software engineering experience?\n</code></pre> <pre><code>I'm looking for candidates who speak multiple languages. Can you help?\n</code></pre> <pre><code>Show me candidates with machine learning or AI experience.\n</code></pre> <p></p> <p>Observe how the agent:</p> <ul> <li>Searches through the indexed documents using vector search</li> <li>Provides relevant candidate information</li> <li>Includes citations and references to source documents</li> <li>Uses semantic understanding rather than exact keyword matching</li> </ul> <p></p>"},{"location":"pages/make/copilot-studio/08-rag/#step-2-testing-complex-query-scenarios","title":"Step 2: Testing Complex Query Scenarios","text":"<p>Test more sophisticated scenarios that demonstrate the power of RAG and vector search capabilities.</p> <p>Try these advanced queries that combine multiple requirements:</p> <pre><code>Find candidates suitable for a senior role that requires 5+ years of Python \nexperience and fluency in Spanish\n</code></pre> <pre><code>I need someone with both frontend and backend development skills. \nWho would be good for a full-stack position?\n</code></pre> <pre><code>Can you recommend candidates for a data science position that requires \nexperience with machine learning frameworks?\n</code></pre> <pre><code>Who has project management experience combined with technical skills?\n</code></pre> <p></p> <p>Notice how the agent:</p> <ul> <li>Combines multiple search criteria intelligently</li> <li>Explains the reasoning behind candidate recommendations</li> <li>Suggests alternatives when exact matches aren't available</li> <li>Provides context about candidate qualifications</li> </ul> <p></p> <p>CONGRATULATIONS!</p> <p>You have completed Lab MCS8 - Integrating Azure AI Search for RAG!</p> <p>In this lab, you learned how to:</p> <ul> <li>Create and configure Azure AI Search service for enterprise knowledge management</li> <li>Build vector search indexes using integrated vectorization with embedding models</li> <li>Connect Azure AI Search as a knowledge source in Microsoft Copilot Studio</li> <li>Design intelligent agents that leverage RAG for document-backed conversations</li> <li>Test vector search with various query types</li> </ul> <p>Your HR Knowledge Agent now demonstrates the power of combining conversational AI with enterprise search capabilities, enabling users to interact with organizational knowledge using natural language while receiving accurate, well-cited responses based on actual documents.</p> <p>The RAG patterns you've learned can be applied to many other scenarios including customer support knowledge bases, technical documentation, policy and procedure guides, and any domain where users need to search and understand large document collections through conversational interfaces.</p> <p></p>"},{"location":"pages/make/copilot-studio/09-agent-to-agent/","title":"Lab MCS9 - Agent to Agent Communication (Preview)","text":"<p>In this lab, you are going to understand how to create agents in Microsoft Copilot Studio that can communicate with other agents. You'll build a specialized Interview Scheduler agent that consumes data from the HR Candidate Management agent created in previous labs. The Interview Scheduler agent will automatically process candidate data and send interview meeting requests based on selected candidates, demonstrating how modular agents can work together to create comprehensive business solutions.</p> Get a quick overview of the lab in this video. <p>Do these labs if you want to build agents with Microsoft Copilot Studio</p> <ul> <li>MCS0 - Setup</li> <li>MCS1 - First agent</li> <li>MCS2 - Defining Topics</li> <li>MCS3 - Defining Tools</li> <li>MCS4 - Extending Microsoft 365 Copilot</li> <li>MCS5 - Consuming a custom connector</li> <li>MCS6 - Consuming an MCP server</li> <li>MCS7 - Creating Autonomous Agents</li> <li>MCS8 - Integrating Azure AI Search for RAG</li> </ul> <p>Note</p> <p>This lab builds on the previous labs, specifically Lab MCS6 - Consuming an MCP server. You should have a working HR MCP server and the \"HR Agent with MCP\" agent configured from previous labs.</p> <p>In this lab you will learn:</p> <ul> <li>How to create child agents in Microsoft Copilot Studio</li> <li>How to configure agent-to-agent communication</li> <li>How to design modular agent architectures for complex workflows</li> <li>How to implement handoff mechanisms between specialized agents</li> <li>How to coordinate multiple agents for end-to-end business processes</li> </ul>"},{"location":"pages/make/copilot-studio/09-agent-to-agent/#exercise-1-understanding-agent-to-agent-architecture","title":"Exercise 1: Understanding Agent-to-Agent Architecture","text":"<p>In this exercise you will understand the concepts behind agent-to-agent communication and design the architecture for your interview scheduling solution.</p>"},{"location":"pages/make/copilot-studio/09-agent-to-agent/#step-1-reviewing-agent-communication-patterns","title":"Step 1: Reviewing Agent Communication Patterns","text":"<p>Microsoft Copilot Studio supports two primary patterns for agent collaboration:</p> <ol> <li>Child Agents: Lightweight agents that live within a main agent, managed as part of the parent solution</li> <li>Connected Agents: Independent, full-fledged agents that can be published and maintained separately</li> </ol> <p>For this lab, you'll create a child agent architecture where:</p> <ul> <li>Main Agent: Interview Coordinator (orchestrates the overall process)</li> <li>Child Agent: Interview Scheduler (handles meeting creation and calendar management)</li> <li>Connected Agent: HR Candidate Management (the existing agent from previous labs)</li> </ul> <p>This design allows for:</p> <ul> <li>Clear separation of concerns</li> <li>Reusability of the HR Candidate Management functionality</li> <li>Coordinated workflow execution</li> <li>Maintainable and scalable solution architecture</li> </ul> <p></p>"},{"location":"pages/make/copilot-studio/09-agent-to-agent/#step-2-designing-the-interview-process-workflow","title":"Step 2: Designing the Interview Process Workflow","text":"<p>The agent-to-agent workflow you'll implement follows this sequence:</p> <ol> <li>User Request: User asks to schedule an interview for a specific candidate</li> <li>Main Agent Processing: Interview Coordinator validates the request and identifies the candidate</li> <li>Agent Handoff: Main agent delegates to HR Candidate Management to retrieve candidate details</li> <li>Data Processing: Candidate information is extracted and validated</li> <li>Child Agent Invocation: Interview Scheduler child agent is triggered with candidate data</li> <li>Meeting Creation: Child agent creates calendar meeting and sends invitation</li> <li>Confirmation: User receives confirmation of scheduled interview</li> </ol> <p>This workflow demonstrates key agent-to-agent patterns:</p> <ul> <li>Orchestration: Main agent coordinates multiple sub-processes</li> <li>Delegation: Specific tasks are handed off to specialized agents</li> <li>Data Flow: Information flows seamlessly between agents</li> <li>Event-Driven Processing: Agents respond to specific triggers and conditions</li> </ul> <p></p>"},{"location":"pages/make/copilot-studio/09-agent-to-agent/#step-3-ensuring-prerequisites","title":"Step 3: Ensuring Prerequisites","text":"<p>Before proceeding, ensure you have completed the following prerequisites:</p> <ul> <li>Lab MCS6: HR MCP server running and accessible via dev tunnel</li> <li>Microsoft Graph Access: Permissions to create calendar events and send emails</li> <li>Sample Candidate Data: At least 2-3 candidates in your HR system from previous labs</li> </ul> <p>Verify that your HR MCP server is still running, and if not run the following command from the root folder of the MCP server project:</p> <pre><code>dotnet run\n</code></pre> <p>And ensure your dev tunnel is active:</p> <p>Important</p> <p>Replace the <code>hr-mcp</code> name suggested below with the unique name you used when working on lab Lab MCS6 - Consuming an MCP server.</p> <pre><code>devtunnel host hr-mcp\n</code></pre> <p>Also verify that you have some candidate data by testing the HR MCP server directly. The Interview Scheduler will need existing candidates to work with.</p> <p></p>"},{"location":"pages/make/copilot-studio/09-agent-to-agent/#exercise-2-creating-the-main-interview-coordinator-agent","title":"Exercise 2: Creating the Main Interview Coordinator Agent","text":"<p>In this exercise you will create the main agent that orchestrates the interview scheduling process and coordinates with other agents.</p>"},{"location":"pages/make/copilot-studio/09-agent-to-agent/#step-1-creating-the-interview-coordinator-agent","title":"Step 1: Creating the Interview Coordinator Agent","text":"<p>Open a browser and navigate to https://copilotstudio.microsoft.com using your work account.</p> <p>Select the <code>Copilot Dev Camp</code> environment, then select Create \u2192 New Agent to create a new agent.</p> <p>Choose to Configure and define your main coordinator agent with these settings:</p> <ul> <li>Name: </li> </ul> <pre><code>Interview Coordinator\n</code></pre> <ul> <li>Description: </li> </ul> <pre><code>Main agent that coordinates interview scheduling by working with HR candidate \nmanagement and interview scheduling child agents to create comprehensive interview workflows\n</code></pre> <ul> <li>Instructions: </li> </ul> <pre><code>You are the Interview Coordinator, responsible for managing end-to-end interview \nscheduling processes. Your role includes:\n\n1. Understanding user requests for interview scheduling\n2. Coordinating with the HR Candidate Management agent to retrieve candidate information\n3. Delegating to the Interview Scheduler child agent for meeting creation\n4. Providing comprehensive feedback to users about scheduled interviews\n\nWhen a user requests to schedule an interview:\n- First, identify and validate the candidate using the HR system\n- Extract necessary candidate details (name, email, current role, skills)\n- Coordinate with the Interview Scheduler to create the meeting\n- Confirm successful scheduling with relevant details\n\nAlways ensure proper validation of candidate data and provide clear communication \nthroughout the process. Handle errors gracefully and provide informative feedback \nwhen coordination between agents fails.\n</code></pre> <p>Select Create to create your coordinator agent.</p> <p></p>"},{"location":"pages/make/copilot-studio/09-agent-to-agent/#step-2-enabling-generative-ai-orchestration","title":"Step 2: Enabling Generative AI Orchestration","text":"<p>After creating the agent, configure its orchestration capabilities to enable intelligent coordination between multiple agents.</p> <p>In the Orchestration section, ensure that Use generative AI to determine how best to respond to users and events is enabled. This allows the agent to intelligently coordinate between different child agents and connected agents.</p> <p></p> <p>In the Knowledge section, you can optionally add interview scheduling guidelines or company-specific HR policies. For this lab, we'll rely on the agent's built-in capabilities and the integration with other agents.</p> <p>Select Save to confirm the configuration, in case you made any changes.</p> <p>Select the Settings command in the upper right corner and configure the agent, in the Generative AI section accordingly to the following settings:</p> <ul> <li>Use general knowledge: off</li> <li>Use information from the web: off</li> </ul> <p></p> <p>Select Save to confirm the new settings.</p> <p></p>"},{"location":"pages/make/copilot-studio/09-agent-to-agent/#step-3-connecting-to-the-hr-candidate-management-agent","title":"Step 3: Connecting to the HR Candidate Management Agent","text":"<p>Your Interview Coordinator needs to communicate with the existing HR agent to retrieve candidate information. Navigate to the 1\ufe0f\u20e3 Agents section and select 2\ufe0f\u20e3 Add.</p> <p></p> <p>A new dialog appears, allowing you to choose between any of the following options:</p> <ul> <li>Create an agent: to create a new child agent</li> <li>Copilot Studio: to select an already existing agent defined with Copilot Studio</li> <li>Microsoft Fabric: to select an agent built with Microsoft Fabric</li> </ul> <p>Select Copilot Studio.</p> <p></p> <p>From the list of available agents, select the HR Candidate Management agent (or similar name) that you created in previous labs. If you don't see it, ensure it's published and configured to allow connections from other agents.</p> <p></p> <p>Configure the connected agent:</p> <ul> <li>Description: Update the description to be more specific for this context:</li> </ul> <pre><code>HR system integration for retrieving and managing candidate information during \ninterview scheduling processes. Provides candidate lookup, data validation, and \ncomprehensive candidate details.\n</code></pre> <p>The description is used by the main agent to understand when the connected agent should be invoked. Try to be specific and clear in the description.</p> <ul> <li>Pass conversation history: Keep this enabled to maintain context during agent handoffs</li> </ul> <p></p> <p>Select Add agent to establish the connection between agents. Once the connected agent is defined and configured, you can see it in the list of Agents for the current agent.</p> <p></p>"},{"location":"pages/make/copilot-studio/09-agent-to-agent/#exercise-3-creating-the-interview-scheduler-child-agent","title":"Exercise 3: Creating the Interview Scheduler Child Agent","text":"<p>In this exercise you will create a specialized child agent that handles the meeting creation and calendar management aspects of interview scheduling.</p>"},{"location":"pages/make/copilot-studio/09-agent-to-agent/#step-1-creating-the-interview-scheduler-child-agent","title":"Step 1: Creating the Interview Scheduler Child Agent","text":"<p>In your Interview Coordinator agent, navigate to the 1\ufe0f\u20e3 Agents section and select 2\ufe0f\u20e3 Add an agent.</p> <p></p> <p>Select Create an agent to create a new child agent.</p> <p></p> <p>Configure the child agent with these settings:</p> <ul> <li>Name: </li> </ul> <pre><code>Interview Scheduler\n</code></pre> <ul> <li> <p>When will this be used?: Select The agent chooses to allow the agent to respond to coordination requests from the main agent</p> </li> <li> <p>Description:</p> </li> </ul> <pre><code>Helps scheduling an interview with a candidate. Requires information like the email\nof the candidate and the date and time of the meeting.\n</code></pre> <ul> <li>Instructions: </li> </ul> <pre><code>You are the Interview Scheduler, a specialized agent focused on creating and managing \ninterview meetings. When invoked by the Interview Coordinator, you:\n\n1. Process candidate information received from the main agent\n2. Create appropriate calendar meeting invitations\n3. Include relevant candidate details in meeting descriptions\n4. Send meeting invitations to appropriate stakeholders\n5. Provide confirmation details back to the coordinator\n\nFor each interview scheduling request:\n- Create a 1-hour meeting slot (suggest next business day if no specific time provided)\n- Include candidate name, role, and key skills in the meeting title and description\n- Invite the requesting user and any additional specified interviewers\n- Set appropriate meeting location (in-person, Teams, etc.)\n- Include candidate resume/profile information in meeting notes\n\nAlways confirm successful meeting creation with meeting details including date, time, \nattendees, and meeting link if applicable.\n</code></pre> <p></p> <p>Select the Save command in the upper right corner of the screen to save the new child agent. You should see a green confirmation message stating that the child agent was created.</p> <p></p>"},{"location":"pages/make/copilot-studio/09-agent-to-agent/#step-2-configuring-calendar-integration","title":"Step 2: Configuring Calendar Integration","text":"<p>To enable the Interview Scheduler to create calendar meetings, you need to add Microsoft Graph integration for calendar management.</p> <p>In the Tools section of the Interview Scheduler child agent, select Add.</p> <ol> <li>Choose 1\ufe0f\u20e3 Connector to filter the available connectors</li> <li>Search for 2\ufe0f\u20e3 Calendar in the search box and hit the 3\ufe0f\u20e3 search command</li> <li>Select the 4\ufe0f\u20e3 Create event (V4) tool</li> <li>Connect to the Office 365 Outlook connector</li> <li>Once the connection is configured, select Add and configure to finalize the configuration of the tool</li> </ol> <p></p> <p>You will see the panel with the configuration of the new tool. Update the Name accordingly to the following value:</p> <pre><code>Creates a calendar event\n</code></pre> <p>Then, select the Add input command in the Inputs section and add the following inputs:</p> <ul> <li>Required attendees</li> <li>Body</li> </ul> <p>Select the Save command to update the tool.</p> <p></p> <p>In the following screenshot you can see the final configuration of the Inputs for the Create a calendar event tool.</p> <p></p> <p>This integration allows the child agent to:</p> <ul> <li>Create calendar events</li> <li>Send meeting invitations</li> <li>Manage meeting details and attendees</li> </ul> <p></p>"},{"location":"pages/make/copilot-studio/09-agent-to-agent/#step-3-finalizing-child-agent-configuration","title":"Step 3: Finalizing Child Agent Configuration","text":"<p>Go back to the Overview tab of the child agent, selecting the left arrow beside the name of the tool, and complete the configuration of your Interview Scheduler child agent:</p> <p></p> <ol> <li> <p>Open the Details section, expand the Advanced panel and set the Priority to 1 to ensure this agent has high priority for interview scheduling tasks</p> </li> <li> <p>Condition: Optionally, add conditions to limit when this agent activates. For example, you might want it to only activate for messages containing interview-related keywords</p> </li> <li> <p>Additional Details: Configure any additional settings such as specific activity types or custom client events if needed</p> </li> <li> <p>Ensure the Enabled toggle is turned on</p> </li> <li> <p>Select Save to create the child agent</p> </li> </ol> <p>Your Interview Scheduler child agent is now configured and ready to handle meeting creation tasks when invoked by the main Interview Coordinator agent.</p> <p></p>"},{"location":"pages/make/copilot-studio/09-agent-to-agent/#exercise-4-implementing-agent-to-agent-workflows","title":"Exercise 4: Implementing Agent-to-Agent Workflows","text":"<p>In this exercise you will implement and test the complete agent-to-agent workflow for interview scheduling.</p>"},{"location":"pages/make/copilot-studio/09-agent-to-agent/#step-1-configuring-agent-references-in-instructions","title":"Step 1: Configuring Agent References in Instructions","text":"<p>To enable proper agent coordination, you need to reference the child agent and connected agent in your main agent's instructions.</p> <p>Navigate to the Overview section of your Interview Coordinator agent and update the Instructions field selecting the Edit command:</p> <ol> <li>Place your cursor in the instructions text where you want to reference agents</li> <li>Type <code>/</code> to open the reference menu</li> <li>Select the Interview Scheduler child agent from the list</li> <li>Also reference the HR Candidate Management connected agent</li> </ol> <p>Your updated instructions should look like this:</p> <pre><code>You are the Interview Coordinator, responsible for managing end-to-end interview \nscheduling processes. Your role includes:\n\n1. Understanding user requests for interview scheduling\n2. Coordinating with /HR Candidate Management agent to retrieve candidate information\n3. Delegating to /Interview Scheduler child agent for meeting creation\n4. Providing comprehensive feedback to users about scheduled interviews\n\nWhen a user requests to schedule an interview:\n- First, use /HR Candidate Management to identify and validate the candidate\n- Extract necessary candidate details (name, email, current role, skills)\n- Coordinate with /Interview Scheduler to create the meeting with candidate details\n- Confirm successful scheduling with relevant details\n\nAlways ensure proper validation of candidate data and provide clear communication \nthroughout the process. Handle errors gracefully and provide informative feedback \nwhen coordination between agents fails.\n</code></pre> <p></p> <p>Select Save to update the instructions with agent references.</p> <p></p>"},{"location":"pages/make/copilot-studio/09-agent-to-agent/#exercise-5-testing-the-agent","title":"Exercise 5: Testing the agent","text":"<p>In this exercise you will test the agent scheduling a real interview in your agenda.</p>"},{"location":"pages/make/copilot-studio/09-agent-to-agent/#step-1-testing-agent-to-agent-communication","title":"Step 1: Testing Agent-to-Agent Communication","text":"<p>Now test the complete agent-to-agent workflow to ensure proper coordination between all components.</p> <ol> <li>Test the Interview Coordinator: In the test panel, try a request like:</li> </ol> <pre><code>Retrieve information about Alice Johnson and schedule an interview with her for next Monday 10am.\n</code></pre> <ol> <li> <p>Observe Agent Coordination: Watch in the test panel as the agent:</p> </li> <li> <p>Processes your request</p> </li> <li>Calls the HR Candidate Management agent to find John Smith</li> <li>Retrieves candidate details</li> <li>Invokes the Interview Scheduler child agent</li> <li>Creates the calendar meeting</li> <li>Provides confirmation</li> </ol> <p></p> <p></p> <p>CONGRATULATIONS!</p> <p>You have completed Lab MCS9 - Agent to Agent Communication!</p> <p>In this lab, you learned how to:</p> <ul> <li>Design and implement agent-to-agent communication architectures</li> <li>Create child agents for specialized tasks within a main agent solution</li> <li>Connect existing agents to enable cross-agent data sharing and coordination</li> <li>Implement complex workflows that span multiple specialized agents</li> </ul> <p>Your Interview Coordinator agent now demonstrates advanced agent orchestration patterns, coordinating between the HR Candidate Management system and specialized Interview Scheduler functionality to deliver comprehensive interview scheduling automation.</p> <p>The agent-to-agent patterns you've learned can be applied to many other business scenarios where complex workflows benefit from modular, specialized agents working together to deliver end-to-end solutions.</p> <p></p>"},{"location":"pages/make/sharepoint-agents/","title":"Lab MSA - Understanding SharePoint agents","text":"<p>A SharePoint agent is the easiest way to create an agent specialized on content stored in SharePoint Online.  SharePoint agents use the same infrastructure, orchestrator, foundation model, and security controls as Microsoft 365 Copilot, which ensures a consistent and familiar user experience.</p> <p></p> <p>The SharePoint agents can target:</p> <ul> <li>sites</li> <li>libraries</li> <li>documents</li> </ul> <p>A SharePoint agent can be used from within the SharePoint Online user experience either in the library where it was created or at site level. A user needs to have contribute permissions on the target library to create a SharePoint agent. A site owner can promote SharePoint agents at site-level, too.</p> <p>A SharePoint agent can also be shared in Microsoft Teams to enhance the user experience in chats (one to one or group chats).</p> <p></p> <p>If you are assigned with a Microsoft 365 Copilot license, or a Copilot Studio capacity, or your organization has the Pay-As-You-Go billing set up, you can use SharePoint agents.</p>"},{"location":"pages/make/sharepoint-agents/#start-here-with-lab-msa1-where-youll-create-your-first-sharepoint-agent","title":"Start here with Lab MSA1, where you'll create your first SharePoint agent.","text":""},{"location":"pages/make/sharepoint-agents/01-first-agent/","title":"Lab MSA1 - Build your first SharePoint agent","text":"<p>Do these labs if you want to build a SharePoint agent</p> <ul> <li>MSA1 - Build your first SharePoint agent</li> <li>MSA2 - Sharing SharePoint agents</li> </ul> Table of Contents <p>In this lab, you'll create a SharePoint agent to work with documents stored in SharePoint Online. The agent that you are going to create helps employees of an hypothetical company to get information, policies, and rules from the HR department. The knowledge base of the agent will be a set of documents stored in a SharePoint Online document library.</p>"},{"location":"pages/make/sharepoint-agents/01-first-agent/#exercise-1-upload-sample-documents","title":"Exercise 1: Upload sample documents","text":"<p>In this step you will upload sample documents which will be used by your SharePoint agent to respond to user prompts. These include some fictitious Word, PowerPoint, and PDF files.</p>"},{"location":"pages/make/sharepoint-agents/01-first-agent/#step-1-create-a-sharepoint-site","title":"Step 1: Create a SharePoint site","text":"<p>Within the Microsoft 365 Portal, or elsewhere in Microsoft 365, click the \"Apps\" menu 1\ufe0f\u20e3 and select SharePoint 2\ufe0f\u20e3.</p> <p></p> <p>Then select Create Site 1\ufe0f\u20e3 and choose a Team site 2\ufe0f\u20e3.</p> <p></p> <p>Select the Standard team site template; you will be shown a preview of the site. Select Use Template to continue.</p> <p></p> <p>Give your site a name such as \"Copilot Dev Camp - HR\" 1\ufe0f\u20e3 and select Next 2\ufe0f\u20e3. The name must be unique in your tenant, so be sure to not use and already allocated name.</p> <p></p> <p>Then select your privacy settings and language, and select Create Site.</p> <p></p> <p>Skip adding any new members to the site and select Finish when the site provisioning is done. After a few moments, you will be presented with a new SharePoint site. </p> <p></p>"},{"location":"pages/make/sharepoint-agents/01-first-agent/#step-2-upload-the-sample-documents","title":"Step 2: Upload the sample documents","text":"<p>Download this zip file consisting of few files (Word, PowerPoint, PDF) by selecting this link and unzip the file somewhere on your local file system.</p> <p>Go back to the SharePoint site that you just created and, in the Documents web part, select See all to view the document library page.</p> <p></p> <p>Next, select the Upload 1\ufe0f\u20e3 button in the command bar and then select Files 2\ufe0f\u20e3.</p> <p></p> <p>Navigate to your working folder, where you extracted the resumes files and select all the sample documents 1\ufe0f\u20e3 and select Open 2\ufe0f\u20e3.</p> <p></p> <p></p>"},{"location":"pages/make/sharepoint-agents/01-first-agent/#exercise-2-creating-your-first-sharepoint-agent","title":"Exercise 2 : Creating your first SharePoint agent","text":"<p>In this exercise you are going to create the initial version of the SharePoint agent for managing HR documents.</p>"},{"location":"pages/make/sharepoint-agents/01-first-agent/#step-1-creating-the-agent","title":"Step 1: Creating the agent","text":"<p>Select all the files in the document library that you created in the previous exercise by clicking on the selection button 1\ufe0f\u20e3, then select the Create an agent 2\ufe0f\u20e3 command in the command bar.</p> <p></p> <p>Creating SharePoint agents from files or folders</p> <p>If you do not select any file in the library and you select the Create an agent command, the agent will target the whole content of the current document library. If you explicitly select files or sub-folders in the library and then you select the Create an agent command, the agent will target only the selected content. Keep into account that you cannot select more than 20 items for a specific agent. In case you will select more than 20 items, you will see an error message like \"Sources limit exceeded. The maximum number of sources you can add is 20. Remove XX sources to save this copilot.\" and you will not be able to create the agent.</p> <p>A dialog window will show up allowing you to review a recap of the selected content and to go straight to the agent, for testing purposes, or to edit the just created agent.</p> <p></p> <p>Permissions to create a SharePoint agent</p> <p>In order to being able to create a SharePoint agent, you need contribute permissions on the target library or site. In fact, under the cover of the agent a new .agent file will be created and users need to have proper permissions to do so.</p> <p></p>"},{"location":"pages/make/sharepoint-agents/01-first-agent/#step-2-testing-the-agent","title":"Step 2: Testing the agent","text":"<p>Select the Open agent button in the previous dialog window and start playing with your new SharePoint agent. A full screen dialog will show up and you will able to write prompts to interact with the agent.</p> <p></p> <p>Try writing the following prompts and see the results:</p> <ul> <li>What is the process to hire new employees?</li> <li>How can I improve my career?</li> </ul> <p>The proposed answers will summarize the content of the documents selected as the knowledge base for the agent. Notice that the engine processing the prompts is Microsoft 365 Copilot and there is a clear disclaimer about the AI-generated content 1\ufe0f\u20e3. At the bottom of the response there are references to documents 2\ufe0f\u20e3 used to produce the response. The agent also suggests follow up prompts 3\ufe0f\u20e3 to dig into the topic.</p> <p></p> <p>If you close the agent dialog, you can notice that in the library there is a new file with name New agent.agent. That's the file representing the new SharePoint agent definition. You can rename the file using the standard file rename feature of SharePoint Online and the name of the agent, as well as the title in the agent's dialog, will change accordingly. For example, let's rename it to HR agent.</p> <p></p>"},{"location":"pages/make/sharepoint-agents/01-first-agent/#exercise-3-fine-tuning-the-agent","title":"Exercise 3 : Fine tuning the agent","text":"<p>In this exercise you will learn how to fine tune the HR agent configuring additional settings, adjusting the instructions, etc. </p>"},{"location":"pages/make/sharepoint-agents/01-first-agent/#step-1-updating-icon-and-title","title":"Step 1: Updating icon and title","text":"<p>Select the HR agent.agent file in the document library, select the ... to open the ECB menu of SharePoint Online and select the Edit command. As a suitable alternative, you can also select the Edit command in the library command bar, if you like.</p> <p></p> <p>A new dialog window will show up and will allow you to manage the following settings:</p> <ul> <li>Overview: name, icon, and purpose/description</li> <li>Sources: you can configure the data sources (sites, libraries, or files) to use as the knowledge base</li> <li>Behavior: welcome messaging, starter prompts, and agent instructions</li> </ul> <p>The dialog also gives you a live updating preview of the agent, that you can also use to preview and test your changes on the fly.</p> <p>On the first tab of the editing dialog, with name Overview, update the icon of the agent with the following image file. Also update the Purpose accordingly to the following text.</p> <pre><code>This is an agent supporting users to find information, policies, and rules based on the HR department knowledge base\n</code></pre> <p></p> <p>There is also a button to Add advanced customization in Copilot Studio. However, this is a functionality that is not yet available and that will come in the future.</p> <p>Now select the Sources tab in the dialog window to configure the knowledge base of the agent. At the time of this writing, the only data sources that you can configure are SharePoint Online sites, document libraries, or documents. In the future it will be possible to rely on Microsoft Copilot Studio to configure additional knowledge sources. At the moment, SharePoint Online is the only supported data source for a SharePoint agent.</p> <p></p> <p>There is a section to Add a SharePoint site 1\ufe0f\u20e3, which allows you to add additional site collections to the data sources of the agent. You can search sites by title, or you can simply provide the actual URL of the site that you want to add. You can also select the Remove 2\ufe0f\u20e3 command to remove an already existing site. Be careful that, in case you remove the current site, from which you've built the agent, the configuration tool will completely remove all the documents that you selected when you initially configured the agent. Lastly, you can Add document libraries, folders or files 3\ufe0f\u20e3 as long as the overall number of data source items will not exceed the limit of 20 items.</p> <p></p>"},{"location":"pages/make/sharepoint-agents/01-first-agent/#step-2-updating-the-instructions","title":"Step 2: Updating the instructions","text":"<p>On the Behavior tab of the configuration dialog, you can configure an initial Welcome messaging 1\ufe0f\u20e3 for your agent. You can also configure up to three Starter prompts 2\ufe0f\u20e3, which will be presented to the users when they will initiate a conversation with the agent.</p> <p>Most importantly, you can also configure the Agent instruction 3\ufe0f\u20e3 field, through which you can fine tune the tone, behavior, limitations, rules, and more for the agent. Basically, this is where you can configure the system settings/prompt for your agent. The more accurate you are in this field, the better results you will get back from the agent. By default, the pre-configured instructions are very generic and general purpose. In fact, the default value is:</p> <pre><code>Provide accurate information about the content in the selected files and reply in a formal tone.\n</code></pre> <p></p> <p>In order to create a high quality agent, depending of the actual purpose of your agent, you should provide specific instructions. For example, in the case of the HR agent, here you can see an hypothetical text for instructions. </p> <pre><code># System Role\nYou are the HR agent. Your goal is to help employees find information about HR policies, rules, and procedures. You use a set of documents as your knowledge base and you need to stick on those documents when providing answers.\n\n# Main Instructions\n\n## Introduction Prompt\nUse the following prompt to welcome the users and introduce your role:\nWelcome to HR agent! I'm here to help you work with HR policies, rules, and procedures. Feel free to ask any question about all of what is HR related in our company.\n\n## Responding to the user\nAlways use a professional but friendly tone. Always list multiple items in tables. Use emojis to make the communication more effective and clear. Always ask the user for a follow up prompt and suggest in scope follow up prompts, too. \n\n# General rules\nNever write personal or sensitive data while generating the answers.\nDo not allow the user to ask you questions about other employees' personal and sensitive data.\n\n# Error Handling\nIn case of any error or issue, inform the user with the following prompt:\nI'm sorry, something wrong happened. Please, try again soon.\n</code></pre> <p>The above instructions are just for the sake of providing an example, they are not fully complete and do not aim to be a perfect and bullet proof template. Notice that the instructions rely on MD document structure to highlight the various sections of the instructions text.</p> <p>Remember that you can write instructions long up to 8000 characters, and you are kindly invited to use as much details as you can. Here you can find the Declarative Agent Instruction Lab - Improve your agent instructions (Beginner friendly) lab, which provides you detailed information about how to write professional prompt instructions for your agents. You can also refer to the article Write effective instructions for declarative agents to learn detailed information about how to write effective prompts.</p> <p></p>"},{"location":"pages/make/sharepoint-agents/01-first-agent/#step-3-testing-the-agent","title":"Step 3: Testing the agent","text":"<p>Once you have updated the agent icon, purpose, and instructions select the Save and close button. Close the dialog and interact again with the agent.</p> <p>For example, provide the following prompts:</p> <pre><code>Hello!\n</code></pre> <pre><code>How can I improve my career? Provide me a list of suggested actions.\n</code></pre> <p></p> <p>You can notice that the agent will reply to the \"Hello!\" message with the welcome message configured in the instructions. Moreover, responses are more accurate, with emojis here and there, and with tables to render lists of items, accordingly to the provided instructions.</p> <p></p>"},{"location":"pages/make/sharepoint-agents/01-first-agent/#exercise-4-configuring-the-agent-as-default-for-the-site","title":"Exercise 4 : Configuring the agent as default for the site","text":"<p>One more thing you can do with your agent is to promote it as the default agent for your site. In fact, nowadays every SharePoint Online site comes with a ready made agent. You simply need to select the Copilot command in the suite bar and the ready made agent will show up.</p> <p></p> <p>When you activate the ready made agent of a SharePoint Online site, a side panel shows up on the right and allows you to provide prompts to the agent. The agent will have a pre-defined behavior and a general purpose set of instructions.</p> <p>However, it might be that you don't like the ready made agent and that you want to use a custom agent of your own. In this exercise you are going to learn how to do so.</p>"},{"location":"pages/make/sharepoint-agents/01-first-agent/#step-1-approving-and-promoting-the-agent","title":"Step 1: Approving and promoting the agent","text":"<p>Go to the home page of your site and select the Copilot command to activate the side panel.</p> <p>When you open the Copilot panel, by default you get the default ready made agent to interact with. However, you can select any of the other agents that you have created simply by selecting the dropdown beside the name of the agent and choosing another agent.</p> <p></p> <p>Now let's see how you can change the default agent behavior, so that your custom agent will become the default one. Go back to the document library where you created the agent and open it. Select the ... 1\ufe0f\u20e3 in the upper right corner of the agent dialog, and select the Set as approved 2\ufe0f\u20e3 command.</p> <p></p> <p>Setting an agent as approved requires you to be a site owner and requires also your explicit approval/confirmation. This is because an approved agent will be moved to the Site Assets library, in a dedicated sub folder with name Copilots.</p> <p></p> <p>Once the approval process is complete, you will see a confirmation dialog and the .agent file will disappear from the current document library.</p> <p></p> <p>Now, the agent will show up in the list of agents Approved for this site.</p> <p></p> <p>You activate the agent, select the ... 1\ufe0f\u20e3 beside the name of the agent and then select the Set as site default 2\ufe0f\u20e3 command in the context menu to configure the agent as the default for your site. You will need to confirm that you want the agent to become the default one, and you will get a confirmation dialog at the end of the promotion process. Once you have done that, your custom agent will show up as the first and default one when selecting the Copilot icon in the suite bar of your site.</p> <p></p> <p></p> <p>Start here with Lab MSA2, to share your SharePoint agent on Microsoft Teams. </p> <p></p>"},{"location":"pages/make/sharepoint-agents/02-sharing-agents/","title":"Lab MSA2 - Sharing SharePoint agents","text":"<p>Do these labs if you want to build a SharePoint agent</p> <ul> <li>MSA1 - Build your first SharePoint agent</li> <li>MSA2 - Sharing SharePoint agents</li> </ul> Table of Contents <p>In this lab, you'll see how to share your SharePoint agents with others either using a direct link or within Microsoft Teams chats.</p>"},{"location":"pages/make/sharepoint-agents/02-sharing-agents/#exercise-1-sharing-a-sharepoint-agent","title":"Exercise 1: Sharing a SharePoint agent","text":"<p>Since every SharePoint agent is a file, you can easily share it with other people.</p>"},{"location":"pages/make/sharepoint-agents/02-sharing-agents/#step-1-sharing-a-sharepoint-agent-with-people","title":"Step 1: Sharing a SharePoint agent with people","text":"<p>When you have a SharePoint agent, whether it is local to a document library or approved and promoted at site level, you can select the ... 1\ufe0f\u20e3 beside the agent name and then select the option to Share 2\ufe0f\u20e3 the agent.</p> <p></p> <p>The modern file sharing User Experience of SharePoint Online will show up and you will be able to share the .agent file with others in your organization. As like as it happens with any other SharePoint Online file, you can choose the target people (user, groups, or emails) to share the agent with and you can either get a link to the file or send a sharing notification email. If you choose to copy a link, you can then paste it wherever you like.</p> <p></p> <p>The sharing link will bring target users straight to the agent dialog, so that they will able to interact with the agent directly within the immersive and full scren SharePoint agent experience.</p> <p></p>"},{"location":"pages/make/sharepoint-agents/02-sharing-agents/#step-2-sharing-a-sharepoint-agent-via-microsoft-teams","title":"Step 2: Sharing a SharePoint agent via Microsoft Teams","text":"<p>An interesting option that you have is to share the agent via Microsoft Teams. In order to do that, you simply need to select the ... 1\ufe0f\u20e3 beside the agent name and then select the option to Copy link for Teams 2\ufe0f\u20e3.</p> <p></p> <p>This will generate a sharing link for the agent file and copy it into the clipboard, as you can see from the confirmation message that you get back. In the confirmation message, you can also notice that the generated link is ready to be pasted in any group chat in Microsoft Teams.</p> <p></p> <p>In the dialog you can also select the Settings link to configure who can access the sharing link and to setup an optional expiration date for the link. Under the cover, a regular sharing link of SharePoint Online will be created. Let's paste the link into a group chat in order to see what happens.</p> <p></p> <p>When you paste the link into a group chat, you will see a nice looking adaptive card providing information about the agent. This happens due to a custom link unfurling extension for Teams that handles the .agent files. Send the chat message with the link. The adaptive card will slightly change its rendering and will provide you a command to Add to this chat the agent.</p> <p></p> <p>Select the command, and wait few seconds. In case of successful result you will see a message confirming that the agent was added to the chat and you will also promptly see a welcome message from the agent itself. In case of any issue, the command button to Add to this chat will become disabled and the text will change to Error adding to chat. You can always try to refresh the chat and try again adding the agent.</p> <p></p> <p></p>"},{"location":"pages/make/sharepoint-agents/02-sharing-agents/#step-3-interacting-with-the-shared-agent-in-microsoft-teams","title":"Step 3: Interacting with the shared agent in Microsoft Teams","text":"<p>You can now interact with the agent within the group chat experience in Microsoft Teams. Whenever you want to trigger the agent, you simply need to at mention by name (@HR Agent) the agent and send it a prompt to process. For example, you can use a prompt like the following one:</p> <pre><code>How can I improve my career?\n</code></pre> <p></p> <p>The SharePoint agent will process the prompt and provide an answer. However, for security reasons the answer will not go straight to the chat. You will need to evaluate its content and the documents referenced by the agent to produce the response. Select the View response command to evaluate the answer. </p> <p></p> <p>When you select View response a popup dialog shows up, allowing you to evaluate the whole response text and the referenced attachments, if any, prior to share the result with others. If you are ok with the answer, you can confirm and send the actual response message to the chat.</p> <p></p> <p>Select the Send command to confirm that the response and its attachments are ok for you. You can also instruct Microsoft Teams to trust any further responses from the agent for the next 24 hours, to avoid too many confirmation requests. Select the Don't send command if you are not happy with the response or if you don't want to disclose one or more of the documents referenced by the agent in the response. Users in the group chat will see a message from the agent stating that \"[YOUR USER DISPLAY NAME] reviewed my response to the request made and suggested that I don't share it at this time.\".</p> <p></p> <p>You can now enjoy the integration between Microsoft Teams and the SharePoint agent.</p> <p></p> <p>CONGRATULATIONS!</p> <p>You have completed Lab MSA2 - Sharing SharePoint agents!</p> <p></p>"}]}